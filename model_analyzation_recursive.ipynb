{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1f1672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_pipeline2 as dp\n",
    "import seaborn as sns\n",
    "from test_fncs import recursive_pred\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import training_models as tm\n",
    "import ml_models\n",
    "\n",
    "\n",
    "from test_fncs import recursive_pred\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b837e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = dp.get_cmapss_data(0, 80, data_dir ='data_synthetic', chosen_sensor = 11)\n",
    "output_sizes = [5,10,20,40]\n",
    "input_sizes = [5,10,20,40]\n",
    "\n",
    "config = {\n",
    "    'input_size' : 30,\n",
    "    'lr' : 1e-4,\n",
    "    'batch_size' : 32,\n",
    "    'hidden_size' : 8,\n",
    "    'output_size' : 3,\n",
    "    'layer_amt' : 3\n",
    "    }\n",
    "\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c909576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for output_size in output_sizes:\n",
    "               \n",
    "        # Update configuration\n",
    "        config['input_size'] = input_size\n",
    "        config['output_size'] = 1\n",
    "\n",
    "        # Load model\n",
    "        state_dict = torch.load(f'models/mlp/output_size{1}input_size{input_size}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.MLP, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "        mod.eval()\n",
    "\n",
    "        # Load data\n",
    "        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \n",
    "                                             outp_size=output_size, batch_size=32, shuffle=False)\n",
    "\n",
    "        \n",
    "        preds = recursive_pred(mod, dataloader,output_size)\n",
    "\n",
    "        \n",
    "        # Convert to tensor\n",
    "        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\n",
    "        \n",
    "        ys = []\n",
    "        for batch in dataloader:\n",
    "            x,y,tx,ty,sensor = batch\n",
    "            ys.append(y)\n",
    "            \n",
    "        ys = torch.concat(ys)\n",
    "\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model' : 'MLP_recursive',\n",
    "            'input_size': input_size,\n",
    "            'output_size': output_size,\n",
    "            'loss': loss(preds_tensor,ys).detach().item(),\n",
    "            'r2' : r2_score(ys, preds_tensor),\n",
    "            'predictions': preds_tensor.tolist(),  # Save as list if needed\n",
    "        })\n",
    "\n",
    "        # Also store in df_test\n",
    "        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e96aa88f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"results = []\\n\\nfor input_size in input_sizes:\\n    for output_size in output_sizes:\\n        \\n        # Update configuration\\n        config['input_size'] = input_size\\n        config['output_size'] = 1\\n\\n        # Load model\\n        state_dict = torch.load(f'models/transformer/output_size{1}input_size{input_size}.pt')\\n        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.Transformer, data_dir='data_synthetic')\\n        mod.load_state_dict(state_dict)\\n        \\n        mod.eval()\\n\\n        # Load data\\n        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \\n                                             outp_size=output_size, batch_size=32, shuffle=False)\\n\\n        preds = recursive_pred(mod, dataloader,output_size, mod_type = 'transformer')\\n        \\n        \\n        # Convert to tensor\\n        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\\n        \\n        ys = []\\n        for batch in dataloader:\\n            x,y,tx,ty,sensor = batch\\n            ys.append(y)\\n            \\n        ys = torch.concat(ys)\\n        \\n        print(preds_tensor.shape)\\n        print(ys.shape)\\n\\n\\n        # Save results\\n        results.append({\\n            'model' : 'Transformer_recursive',\\n            'input_size': input_size,\\n            'output_size': output_size,\\n            'loss': loss(preds_tensor,ys).detach().item(),\\n            'r2' : r2_score(ys, preds_tensor),\\n            'predictions': preds_tensor.tolist(),  # Save as list if needed\\n        })\\n\\n        # Also store in df_test\\n        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\\n\\n\\n# Create DataFrame\\ndf_this = pd.DataFrame(results)\\ndf_results = pd.concat([df_this, df_results])\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"results = []\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for output_size in output_sizes:\n",
    "        \n",
    "        # Update configuration\n",
    "        config['input_size'] = input_size\n",
    "        config['output_size'] = 1\n",
    "\n",
    "        # Load model\n",
    "        state_dict = torch.load(f'models/transformer/output_size{1}input_size{input_size}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.Transformer, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "        \n",
    "        mod.eval()\n",
    "\n",
    "        # Load data\n",
    "        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \n",
    "                                             outp_size=output_size, batch_size=32, shuffle=False)\n",
    "\n",
    "        preds = recursive_pred(mod, dataloader,output_size, mod_type = 'transformer')\n",
    "        \n",
    "        \n",
    "        # Convert to tensor\n",
    "        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\n",
    "        \n",
    "        ys = []\n",
    "        for batch in dataloader:\n",
    "            x,y,tx,ty,sensor = batch\n",
    "            ys.append(y)\n",
    "            \n",
    "        ys = torch.concat(ys)\n",
    "        \n",
    "        print(preds_tensor.shape)\n",
    "        print(ys.shape)\n",
    "\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model' : 'Transformer_recursive',\n",
    "            'input_size': input_size,\n",
    "            'output_size': output_size,\n",
    "            'loss': loss(preds_tensor,ys).detach().item(),\n",
    "            'r2' : r2_score(ys, preds_tensor),\n",
    "            'predictions': preds_tensor.tolist(),  # Save as list if needed\n",
    "        })\n",
    "\n",
    "        # Also store in df_test\n",
    "        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df_this = pd.DataFrame(results)\n",
    "df_results = pd.concat([df_this, df_results])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ae1e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for output_size in output_sizes:\n",
    "        \n",
    "        # Update configuration\n",
    "        config['input_size'] = input_size\n",
    "        config['output_size'] = 1\n",
    "\n",
    "        # Load model\n",
    "        state_dict = torch.load(f'models/gcn/output_size{1}input_size{input_size}.pt')\n",
    "        mod = tm.train_gcn(config, it_amt=0, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "        \n",
    "        mod.eval()\n",
    "\n",
    "        # Load data\n",
    "        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \n",
    "                                             outp_size=output_size, batch_size=32, gcn = True, shuffle=False)\n",
    "\n",
    "        preds = recursive_pred(mod, dataloader,output_size, mod_type = 'gcn')\n",
    "        \n",
    "        # Convert to tensor\n",
    "        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\n",
    "        \n",
    "        ys = []\n",
    "        for batch in dataloader:\n",
    "            y = np.vstack(batch.y)\n",
    "            \n",
    "            ys.append(y)\n",
    "            \n",
    "        ys = torch.from_numpy(np.concatenate(ys))\n",
    "\n",
    "        \n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model' : 'GCN_recursive',\n",
    "            'input_size': input_size,\n",
    "            'output_size': output_size,\n",
    "            'loss': loss(preds_tensor,ys).detach().item(),\n",
    "            'r2' : r2_score(ys, preds_tensor),\n",
    "            'predictions': preds_tensor.tolist(),  # Save as list if needed\n",
    "        })\n",
    "\n",
    "        # Also store in df_test\n",
    "        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\n",
    "\n",
    "\n",
    "# Create DataFrame\n",
    "df_this = pd.DataFrame(results)\n",
    "df_results = pd.concat([df_this, df_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "024e5728",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for output_size in output_sizes:\n",
    "        \n",
    "        # Update configuration\n",
    "        config['input_size'] = input_size\n",
    "        config['output_size'] = 1\n",
    "\n",
    "        # Load model\n",
    "        state_dict = torch.load(f'models/gru/output_size{1}input_size{input_size}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.GRU, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "        \n",
    "        mod.eval()\n",
    "\n",
    "        # Load data\n",
    "        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \n",
    "                                             outp_size=output_size, batch_size=32, shuffle=False)\n",
    "\n",
    "        preds = recursive_pred(mod, dataloader,output_size)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\n",
    "        \n",
    "        ys = []\n",
    "        for batch in dataloader:\n",
    "            x,y,tx,ty,sensor = batch\n",
    "            ys.append(y)\n",
    "            \n",
    "        ys = torch.concat(ys)\n",
    "\n",
    "        \n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model' : 'GRU_recursive',\n",
    "            'input_size': input_size,\n",
    "            'output_size': output_size,\n",
    "            'loss': loss(preds_tensor,ys).detach().item(),\n",
    "            'r2' : r2_score(ys, preds_tensor),\n",
    "            'predictions': preds_tensor.tolist(),  # Save as list if needed\n",
    "        })\n",
    "\n",
    "        # Also store in df_test\n",
    "        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\n",
    "\n",
    "# Create DataFrame\n",
    "df_this = pd.DataFrame(results)\n",
    "df_results = pd.concat([df_this, df_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9e8106e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for output_size in output_sizes:\n",
    "        \n",
    "        # Update configuration\n",
    "        config['input_size'] = input_size\n",
    "        config['output_size'] = 1\n",
    "\n",
    "        # Load model\n",
    "        state_dict = torch.load(f'models/lstm/output_size{1}input_size{input_size}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.LSTM, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "        \n",
    "        mod.eval()\n",
    "\n",
    "        # Load data\n",
    "        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \n",
    "                                             outp_size=output_size, batch_size=32, shuffle=False)\n",
    "\n",
    "        \n",
    "        preds = recursive_pred(mod, dataloader,output_size)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\n",
    "        \n",
    "        ys = []\n",
    "        for batch in dataloader:\n",
    "            x,y,tx,ty,sensor = batch\n",
    "            ys.append(y)\n",
    "            \n",
    "        ys = torch.concat(ys)\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model' : 'LSTM_recursive',\n",
    "            'input_size': input_size,\n",
    "            'output_size': output_size,\n",
    "            'loss': loss(preds_tensor, ys).detach().item(),\n",
    "            'r2' : r2_score(ys, preds_tensor),\n",
    "            'predictions': preds_tensor.tolist(),  # Save as list if needed\n",
    "        })\n",
    "\n",
    "        # Also store in df_test\n",
    "        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\n",
    "\n",
    "# Create DataFrame\n",
    "df_this = pd.DataFrame(results)\n",
    "df_results = pd.concat([df_this, df_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f24bb10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for output_size in output_sizes:\n",
    "        \n",
    "        # Update configuration\n",
    "        config['input_size'] = input_size\n",
    "        config['output_size'] = 1\n",
    "\n",
    "        # Load model\n",
    "        state_dict = torch.load(f'models/cnn/output_size{1}input_size{input_size}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.CNN, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "\n",
    "        # Load data\n",
    "        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \n",
    "                                             outp_size=output_size, batch_size=32, shuffle=False)\n",
    "\n",
    "        preds = recursive_pred(mod, dataloader,output_size)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\n",
    "        \n",
    "        ys = []\n",
    "        for batch in dataloader:\n",
    "            x,y,tx,ty,sensor = batch\n",
    "            ys.append(y)\n",
    "            \n",
    "        ys = torch.concat(ys)\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model' : 'CNN_recursive',\n",
    "            'input_size': input_size,\n",
    "            'output_size': output_size,\n",
    "            'loss': loss(preds_tensor,ys).detach().item(),\n",
    "            'r2' : r2_score(ys, preds_tensor),\n",
    "            'predictions': preds_tensor.tolist(),  # Save as list if needed\n",
    "        })\n",
    "\n",
    "        # Also store in df_test\n",
    "        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\n",
    "\n",
    "# Create DataFrame\n",
    "df_this = pd.DataFrame(results)\n",
    "df_results = pd.concat([df_this, df_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e830e67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for input_size in input_sizes:\n",
    "    for output_size in output_sizes:\n",
    "        \n",
    "        # Update configuration\n",
    "        config['input_size'] = input_size\n",
    "        config['output_size'] = 1\n",
    "\n",
    "        # Load model\n",
    "        state_dict = torch.load(f'models/baseline/output_size{1}input_size{input_size}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.Baseline, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "\n",
    "        # Load data\n",
    "        dataloader, idx = dp.get_loaded_data(df_test, win_size=config['input_size'], \n",
    "                                             outp_size=output_size, batch_size=32, shuffle=False)\n",
    "\n",
    "        preds = recursive_pred(mod, dataloader,output_size)\n",
    "        \n",
    "        # Convert to tensor\n",
    "        preds_tensor = torch.from_numpy(preds).detach()#.numpy()\n",
    "        \n",
    "        ys = []\n",
    "        for batch in dataloader:\n",
    "            x,y,tx,ty,sensor = batch\n",
    "            ys.append(y)\n",
    "            \n",
    "        ys = torch.concat(ys)\n",
    "\n",
    "\n",
    "        # Save results\n",
    "        results.append({\n",
    "            'model' : 'Baseline_recursive',\n",
    "            'input_size': input_size,\n",
    "            'output_size': output_size,\n",
    "            'loss': loss(preds_tensor, ys).detach().item(),\n",
    "            'r2' : r2_score(ys, preds_tensor),\n",
    "            'predictions': preds_tensor.tolist(),  # Save as list if needed\n",
    "        })\n",
    "\n",
    "        # Also store in df_test\n",
    "        #df_test[f'mlp_outp{output_size}_inp{input_size}'] = preds_tensor\n",
    "\n",
    "# Create DataFrame\n",
    "df_this = pd.DataFrame(results)\n",
    "df_results = pd.concat([df_this, df_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba60135b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>input_size</th>\n",
       "      <th>output_size</th>\n",
       "      <th>loss</th>\n",
       "      <th>r2</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline_recursive</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.267927</td>\n",
       "      <td>0.715866</td>\n",
       "      <td>[[1.099663496017456, 1.0919311046600342, 1.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline_recursive</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.274108</td>\n",
       "      <td>0.696406</td>\n",
       "      <td>[[1.099663496017456, 1.0919311046600342, 1.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baseline_recursive</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.293724</td>\n",
       "      <td>0.650273</td>\n",
       "      <td>[[1.099663496017456, 1.0919311046600342, 1.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baseline_recursive</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.336407</td>\n",
       "      <td>0.554643</td>\n",
       "      <td>[[1.099663496017456, 1.0919311046600342, 1.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baseline_recursive</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.244151</td>\n",
       "      <td>0.740569</td>\n",
       "      <td>[[1.2792531251907349, 1.3027280569076538, 1.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP_recursive</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.312081</td>\n",
       "      <td>0.584994</td>\n",
       "      <td>[[1.1928584575653076, 1.2058427333831787, 1.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLP_recursive</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>0.238310</td>\n",
       "      <td>0.744593</td>\n",
       "      <td>[[1.2438881397247314, 1.3076837062835693, 1.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MLP_recursive</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>0.245662</td>\n",
       "      <td>0.724117</td>\n",
       "      <td>[[1.2438881397247314, 1.3076837062835693, 1.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MLP_recursive</td>\n",
       "      <td>40</td>\n",
       "      <td>20</td>\n",
       "      <td>0.269570</td>\n",
       "      <td>0.673055</td>\n",
       "      <td>[[1.2438881397247314, 1.3076837062835693, 1.24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLP_recursive</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0.359904</td>\n",
       "      <td>0.517994</td>\n",
       "      <td>[[1.2438881397247314, 1.3076837062835693, 1.24...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  input_size  output_size      loss        r2  \\\n",
       "0   Baseline_recursive           5            5  0.267927  0.715866   \n",
       "1   Baseline_recursive           5           10  0.274108  0.696406   \n",
       "2   Baseline_recursive           5           20  0.293724  0.650273   \n",
       "3   Baseline_recursive           5           40  0.336407  0.554643   \n",
       "4   Baseline_recursive          10            5  0.244151  0.740569   \n",
       "..                 ...         ...          ...       ...       ...   \n",
       "11       MLP_recursive          20           40  0.312081  0.584994   \n",
       "12       MLP_recursive          40            5  0.238310  0.744593   \n",
       "13       MLP_recursive          40           10  0.245662  0.724117   \n",
       "14       MLP_recursive          40           20  0.269570  0.673055   \n",
       "15       MLP_recursive          40           40  0.359904  0.517994   \n",
       "\n",
       "                                          predictions  \n",
       "0   [[1.099663496017456, 1.0919311046600342, 1.007...  \n",
       "1   [[1.099663496017456, 1.0919311046600342, 1.007...  \n",
       "2   [[1.099663496017456, 1.0919311046600342, 1.007...  \n",
       "3   [[1.099663496017456, 1.0919311046600342, 1.007...  \n",
       "4   [[1.2792531251907349, 1.3027280569076538, 1.28...  \n",
       "..                                                ...  \n",
       "11  [[1.1928584575653076, 1.2058427333831787, 1.16...  \n",
       "12  [[1.2438881397247314, 1.3076837062835693, 1.24...  \n",
       "13  [[1.2438881397247314, 1.3076837062835693, 1.24...  \n",
       "14  [[1.2438881397247314, 1.3076837062835693, 1.24...  \n",
       "15  [[1.2438881397247314, 1.3076837062835693, 1.24...  \n",
       "\n",
       "[96 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631ac2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('results/model_recursive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e669b821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227505ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
