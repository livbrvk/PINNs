{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0dad2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ml_models\n",
    "import data_pipeline2 as dp\n",
    "import training_models as tm\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn.models import GCN\n",
    "\n",
    "import pinns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d9d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size' : 10,\n",
    "    'lr' : 1e-6,\n",
    "    'batch_size' : 32,\n",
    "    'hidden_size' : 8,\n",
    "    'output_size' : 40,\n",
    "    'layer_amt' : 3,\n",
    "    'lambda_' : 2e-5\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abe07726",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\774067232.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/mlp/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "RMSE, train 0.29971678864693585, test 0.3130444372543181\n",
      "RMSE, train 0.29962387968829324, test 0.3130386501851708\n",
      "RMSE, train 0.2997073370480596, test 0.31303248471683925\n",
      "RMSE, train 0.29958382336318057, test 0.313053284630631\n",
      "RMSE, train 0.29954689741134644, test 0.3130287603296415\n",
      "RMSE, train 0.2997227651055693, test 0.3130327928246874\n",
      "RMSE, train 0.2995710516471443, test 0.313030952154988\n",
      "RMSE, train 0.2996469717518333, test 0.31304119978890277\n",
      "RMSE, train 0.2994898499369913, test 0.313034070260597\n",
      "RMSE, train 0.29949573749872177, test 0.3130289237908643\n",
      "RMSE, train 0.29965922772009973, test 0.31303087027385984\n",
      "RMSE, train 0.2995288008436889, test 0.3130278725816746\n",
      "RMSE, train 0.2994835372731855, test 0.31303707728482255\n",
      "RMSE, train 0.29966967704097913, test 0.31303172249986666\n",
      "RMSE, train 0.29959576145215255, test 0.31304555800225997\n",
      "RMSE, train 0.29963083211833513, test 0.31306089445798085\n",
      "RMSE, train 0.29964995970790137, test 0.31303090158135\n",
      "RMSE, train 0.2996881321109012, test 0.31304138086058875\n",
      "RMSE, train 0.2997379543801683, test 0.3130346651029105\n",
      "RMSE, train 0.29961653698627405, test 0.3130585476003512\n",
      "RMSE, train 0.2995163165488278, test 0.31304557576324\n",
      "RMSE, train 0.2994398467406667, test 0.31304135993875637\n",
      "Early stopping at epoch 22 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\774067232.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/mlp/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.28160434449561916, test 0.2988389215121667\n",
      "RMSE, train 0.281557282188324, test 0.2987682269886136\n",
      "RMSE, train 0.2815208967887994, test 0.29861576373999316\n",
      "RMSE, train 0.2814891797048275, test 0.2986255943154295\n",
      "RMSE, train 0.28145832146960076, test 0.2986145767693718\n",
      "RMSE, train 0.2814742909236388, test 0.298691486629347\n",
      "RMSE, train 0.28144237432967534, test 0.2986373792712887\n",
      "RMSE, train 0.281433078639134, test 0.29860120406374335\n",
      "RMSE, train 0.2814974306207715, test 0.2985049582396944\n",
      "RMSE, train 0.2814134814673, test 0.29865781171247363\n",
      "RMSE, train 0.2814014798989802, test 0.29854532548536855\n",
      "RMSE, train 0.2814409506667142, test 0.29863839301591116\n",
      "RMSE, train 0.2814001783051274, test 0.29851434131463367\n",
      "RMSE, train 0.2813987053855501, test 0.29849762671316665\n",
      "RMSE, train 0.28144318474964664, test 0.29850381178160507\n",
      "RMSE, train 0.2814120737967467, test 0.2985475566238165\n",
      "RMSE, train 0.28139448828167385, test 0.29845858567083877\n",
      "RMSE, train 0.2814317241762624, test 0.2985137007199228\n",
      "RMSE, train 0.2814021323515911, test 0.29849341201285523\n",
      "RMSE, train 0.28142145531948165, test 0.2984917152983447\n",
      "RMSE, train 0.2813848667975628, test 0.2984822168946266\n",
      "RMSE, train 0.28138992197886864, test 0.298579182010144\n",
      "RMSE, train 0.2814365623123718, test 0.2985460730269551\n",
      "RMSE, train 0.28140343661711675, test 0.29851205615947646\n",
      "RMSE, train 0.281433430735511, test 0.2985732701296608\n",
      "RMSE, train 0.2814164361116862, test 0.298554668823878\n",
      "RMSE, train 0.28141835057223685, test 0.29850867452720803\n",
      "Early stopping at epoch 27 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\774067232.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/mlp/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27589309990727356, test 0.29768953257136876\n",
      "RMSE, train 0.27588968432817174, test 0.297671745551957\n",
      "RMSE, train 0.27586010331413496, test 0.29791554659605024\n",
      "RMSE, train 0.2758759168601743, test 0.29794742597473994\n",
      "RMSE, train 0.27587435605391014, test 0.2980752721428871\n",
      "RMSE, train 0.2758554238675418, test 0.29777826286024517\n",
      "RMSE, train 0.2758786707634553, test 0.2982640514771144\n",
      "RMSE, train 0.27585820797479377, test 0.2978812471032143\n",
      "RMSE, train 0.27583129864657985, test 0.29779878821637895\n",
      "RMSE, train 0.27583762059475214, test 0.2979249303539594\n",
      "RMSE, train 0.27584412147735327, test 0.2980194568634033\n",
      "RMSE, train 0.2758472569065917, test 0.297952900826931\n",
      "Early stopping at epoch 12 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\774067232.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/mlp/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.26716605515866265, test 0.2920792666383279\n",
      "RMSE, train 0.26715507815560074, test 0.29224018370493865\n",
      "RMSE, train 0.26713447927314543, test 0.29397989083559084\n",
      "RMSE, train 0.26710865862458666, test 0.29169349926404464\n",
      "RMSE, train 0.26712785271283623, test 0.2928250722396068\n",
      "RMSE, train 0.26711656315675775, test 0.29189853503918034\n",
      "RMSE, train 0.26715034882413263, test 0.29215682374361235\n",
      "RMSE, train 0.26714001985910896, test 0.29219987721015245\n",
      "RMSE, train 0.26710240292214904, test 0.2950852576356668\n",
      "RMSE, train 0.2671316703346288, test 0.2929177771394069\n",
      "RMSE, train 0.2671426910199109, test 0.2916446396937737\n",
      "RMSE, train 0.267133119693055, test 0.29291597887491566\n",
      "RMSE, train 0.267105134662438, test 0.2925305733313927\n",
      "RMSE, train 0.2670939459329082, test 0.2924668783178696\n",
      "RMSE, train 0.2671145390591517, test 0.29511605738065183\n",
      "RMSE, train 0.2670932861503411, test 0.2920924096535414\n",
      "RMSE, train 0.26710292302373784, test 0.2925189181398123\n",
      "RMSE, train 0.267106908550515, test 0.29209654147808367\n",
      "RMSE, train 0.2671157359798378, test 0.29238757987817127\n",
      "RMSE, train 0.2670901210694298, test 0.2918177495400111\n",
      "RMSE, train 0.2671110984692321, test 0.29162183786049867\n",
      "RMSE, train 0.26709930115956754, test 0.29350954924638456\n",
      "RMSE, train 0.2670987686635549, test 0.2915773225518373\n",
      "RMSE, train 0.2671239064582783, test 0.29330804504645175\n",
      "RMSE, train 0.26715672508207067, test 0.29209377062626374\n",
      "RMSE, train 0.2671134528991218, test 0.29181935351628524\n",
      "RMSE, train 0.26710064880944484, test 0.29694704730541277\n",
      "RMSE, train 0.26713591711914797, test 0.2929040187826523\n",
      "RMSE, train 0.2671188769682174, test 0.293198470503856\n",
      "RMSE, train 0.2671501957738882, test 0.29231686622668535\n",
      "RMSE, train 0.2671343633597514, test 0.2922559978488164\n",
      "RMSE, train 0.26709572334898596, test 0.2925574706915097\n",
      "RMSE, train 0.2671172589620697, test 0.2933421853261116\n",
      "Early stopping at epoch 33 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "output_sizes = [40]\n",
    "input_sizes = [5,10,20,40]\n",
    "\n",
    "\n",
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "        \n",
    "        \n",
    "        state_dict = torch.load(f'models/mlp/output_size{output}input_size{inputs}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.MLP, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "\n",
    "        pinn_mod = pinns.decay_pinn(mod)\n",
    "        \n",
    "        mod = pinns.train_pinn_2(config, it_amt=100, model=pinn_mod, data_dir = 'data_synthetic')\n",
    "        \n",
    "        torch.save(obj = mod.state_dict(), f = 'pinn_models_2/mlp/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c43c0a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\3660115559.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/cnn/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2991625889224936, test 0.3125186518888281\n",
      "RMSE, train 0.2992046433876662, test 0.31256912483109367\n",
      "RMSE, train 0.2991458615128743, test 0.3125825962333968\n",
      "RMSE, train 0.29912374760673216, test 0.3126132972914763\n",
      "RMSE, train 0.2990601640968859, test 0.31264519661363926\n",
      "RMSE, train 0.2991666147134706, test 0.3126765179513681\n",
      "RMSE, train 0.29912910204207693, test 0.31269585153069157\n",
      "RMSE, train 0.299221648527241, test 0.3126928291537545\n",
      "RMSE, train 0.2990278927723178, test 0.31270653129828097\n",
      "RMSE, train 0.2992303404583616, test 0.3127293547596594\n",
      "RMSE, train 0.29912955119003587, test 0.3127432811741877\n",
      "Early stopping at epoch 11 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\3660115559.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/cnn/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.28157179170485697, test 0.29845742291460436\n",
      "RMSE, train 0.2815526652742516, test 0.2983298447603981\n",
      "RMSE, train 0.28152203439462065, test 0.29830418278773624\n",
      "RMSE, train 0.2815234668251842, test 0.2983094318769872\n",
      "RMSE, train 0.28153118690607526, test 0.29831757955253124\n",
      "RMSE, train 0.28153033069137373, test 0.29823721665889025\n",
      "RMSE, train 0.28152713856913825, test 0.2983230468817055\n",
      "RMSE, train 0.28150135007771576, test 0.2982925397033493\n",
      "RMSE, train 0.28151233663613145, test 0.2982264819244544\n",
      "RMSE, train 0.2814880208008819, test 0.298259568400681\n",
      "RMSE, train 0.2814931394250104, test 0.2982796374708414\n",
      "RMSE, train 0.28149328599072465, test 0.2983128436220189\n",
      "RMSE, train 0.28148573215561684, test 0.2982375767702858\n",
      "RMSE, train 0.2814787970197321, test 0.29829175863415003\n",
      "RMSE, train 0.281492662550223, test 0.2982779908925295\n",
      "RMSE, train 0.28146266602356024, test 0.29821590551485616\n",
      "RMSE, train 0.2815021746086352, test 0.29835642920807004\n",
      "RMSE, train 0.2814652709798379, test 0.2982839165876309\n",
      "RMSE, train 0.2815041190596542, test 0.29830741276964545\n",
      "RMSE, train 0.28151256843197225, test 0.29819805299242336\n",
      "RMSE, train 0.28151563863561613, test 0.298426135443151\n",
      "RMSE, train 0.28148658622545425, test 0.2982434034347534\n",
      "RMSE, train 0.2814770344682414, test 0.2984522079738478\n",
      "RMSE, train 0.28147031374350945, test 0.29819750785827637\n",
      "RMSE, train 0.2814624185363452, test 0.2982342285104096\n",
      "RMSE, train 0.2814662689437168, test 0.2983051886161168\n",
      "RMSE, train 0.28148495078538405, test 0.29821674230818945\n",
      "RMSE, train 0.2815081620908747, test 0.29830070631578565\n",
      "RMSE, train 0.2814907355215212, test 0.29818593555440503\n",
      "RMSE, train 0.2814736384333986, test 0.2981789105882247\n",
      "RMSE, train 0.2815141210878136, test 0.2982747938173513\n",
      "RMSE, train 0.28146558732847976, test 0.29823021109526354\n",
      "RMSE, train 0.2814801352644207, test 0.2981989725182454\n",
      "RMSE, train 0.28147708688570994, test 0.29824987255657714\n",
      "RMSE, train 0.2815000774583431, test 0.29829778832693893\n",
      "RMSE, train 0.2814654932931216, test 0.29818542518963415\n",
      "RMSE, train 0.2814591547304934, test 0.2982518128119409\n",
      "RMSE, train 0.2814508384526378, test 0.2983100440663596\n",
      "RMSE, train 0.2814699776395403, test 0.29833016234139603\n",
      "RMSE, train 0.2814731529415256, test 0.2984137434201936\n",
      "Early stopping at epoch 40 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\3660115559.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/cnn/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2755416246919298, test 0.2969787284731865\n",
      "RMSE, train 0.2755704317292113, test 0.29673527744081285\n",
      "RMSE, train 0.27551999182071324, test 0.2968795062767135\n",
      "RMSE, train 0.27547417147300957, test 0.2970355989204513\n",
      "RMSE, train 0.27550657197953554, test 0.2968591026133961\n",
      "RMSE, train 0.27547987608736096, test 0.29667412373754715\n",
      "RMSE, train 0.2754533048668962, test 0.2967785704467032\n",
      "RMSE, train 0.2754873032116826, test 0.2964688706729147\n",
      "RMSE, train 0.2754501324859912, test 0.29676924265093274\n",
      "RMSE, train 0.27547017703801796, test 0.29676190200779173\n",
      "RMSE, train 0.2754658143314711, test 0.29661937355995177\n",
      "RMSE, train 0.2754422813011308, test 0.2966829091310501\n",
      "RMSE, train 0.2754204581689963, test 0.2966889167825381\n",
      "RMSE, train 0.2754683967308214, test 0.2967130157682631\n",
      "RMSE, train 0.2754141183072987, test 0.29658544609944026\n",
      "RMSE, train 0.27545457797230416, test 0.296476944287618\n",
      "RMSE, train 0.2754603822356607, test 0.2966582675774892\n",
      "RMSE, train 0.2754213197051354, test 0.2965908484326469\n",
      "Early stopping at epoch 18 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\3660115559.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/cnn/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.26688296159851216, test 0.29411249187512273\n",
      "RMSE, train 0.26678094806329483, test 0.29434604923694563\n",
      "RMSE, train 0.26672848311725805, test 0.2934927082596681\n",
      "RMSE, train 0.2666455760273235, test 0.29400195334202206\n",
      "RMSE, train 0.26666982532290284, test 0.2933610970011124\n",
      "RMSE, train 0.2666537601071355, test 0.29368263272902906\n",
      "RMSE, train 0.26665474075208945, test 0.29517753918965656\n",
      "RMSE, train 0.2666515519964361, test 0.2937583300547722\n",
      "RMSE, train 0.2666407285542503, test 0.29291217239239276\n",
      "RMSE, train 0.26664399153718327, test 0.2934196505409021\n",
      "RMSE, train 0.2665947497912285, test 0.29379966109991074\n",
      "RMSE, train 0.2666282113003211, test 0.2929472105625348\n",
      "RMSE, train 0.26661961634768133, test 0.2938041497881596\n",
      "RMSE, train 0.2666209633940848, test 0.30004931203065777\n",
      "RMSE, train 0.2666194523884871, test 0.2947296106662506\n",
      "RMSE, train 0.26661815524472626, test 0.2943468607771091\n",
      "RMSE, train 0.2666290228797639, test 0.2941099676566246\n",
      "RMSE, train 0.26662534920968745, test 0.29287193218866986\n",
      "RMSE, train 0.2665932237916275, test 0.2936964371265509\n",
      "RMSE, train 0.2666107162693951, test 0.2975026848606574\n",
      "RMSE, train 0.266583866790819, test 0.29368863713282806\n",
      "RMSE, train 0.266626889646239, test 0.29501499178317875\n",
      "RMSE, train 0.2665845407782314, test 0.29430751693554413\n",
      "RMSE, train 0.2666097074004349, test 0.2931784036067816\n",
      "RMSE, train 0.26659292437577176, test 0.294341137393927\n",
      "RMSE, train 0.2666014411089205, test 0.29397108176579845\n",
      "RMSE, train 0.26660483133198687, test 0.29656532597847474\n",
      "RMSE, train 0.2666050133025535, test 0.2936502916690631\n",
      "Early stopping at epoch 28 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "        \n",
    "        \n",
    "        state_dict = torch.load(f'models/cnn/output_size{output}input_size{inputs}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.CNN, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "\n",
    "        pinn_mod = pinns.decay_pinn(mod)\n",
    "        \n",
    "        mod = pinns.train_pinn_2(config, it_amt=100, model=pinn_mod, data_dir = 'data_synthetic')\n",
    "        \n",
    "        torch.save(obj = mod.state_dict(), f = 'pinn_models_2/cnn/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47986c66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\1594771382.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/lstm/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.29980113512146445, test 0.31344554144324677\n",
      "RMSE, train 0.2997409721749919, test 0.3131843940778212\n",
      "RMSE, train 0.29984342049998586, test 0.31337250994913507\n",
      "RMSE, train 0.30007471541320785, test 0.31330346398883396\n",
      "RMSE, train 0.3001044162692534, test 0.3129650444695444\n",
      "RMSE, train 0.2998551980644683, test 0.3130541963107658\n",
      "RMSE, train 0.2997630440008378, test 0.31326269486335795\n",
      "RMSE, train 0.3000200126675347, test 0.31358705792162156\n",
      "RMSE, train 0.3002242209494551, test 0.31368822070083235\n",
      "RMSE, train 0.2998999553962558, test 0.31323085800565853\n",
      "RMSE, train 0.30002188485817105, test 0.3129514227009783\n",
      "RMSE, train 0.2999638102238219, test 0.312935021188524\n",
      "RMSE, train 0.2998128862719081, test 0.313088800871011\n",
      "RMSE, train 0.2999518912986905, test 0.31294383274184334\n",
      "RMSE, train 0.29973707000171645, test 0.31283677978949115\n",
      "RMSE, train 0.29999336858979064, test 0.3130284851849681\n",
      "RMSE, train 0.29989178817546164, test 0.31305022492553247\n",
      "RMSE, train 0.2998275221632862, test 0.3132160652165461\n",
      "RMSE, train 0.2997273931001976, test 0.312617843801325\n",
      "RMSE, train 0.2997492197308972, test 0.313200855345437\n",
      "RMSE, train 0.29974517102346443, test 0.31296902172493213\n",
      "RMSE, train 0.2997030937147024, test 0.31336879188364203\n",
      "RMSE, train 0.29980496209670393, test 0.31343747765728924\n",
      "RMSE, train 0.29966759987740177, test 0.3133235447334521\n",
      "RMSE, train 0.2997744187239038, test 0.31321939314254604\n",
      "RMSE, train 0.29975956678390503, test 0.3134609945494719\n",
      "RMSE, train 0.30000007990519983, test 0.31298017652347837\n",
      "RMSE, train 0.2996172926099493, test 0.3133788966771328\n",
      "RMSE, train 0.2997621152832339, test 0.3132172663404484\n",
      "Early stopping at epoch 29 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\1594771382.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/lstm/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.28260087056292427, test 0.3001727430770795\n",
      "RMSE, train 0.28267117473061637, test 0.2991994828917086\n",
      "RMSE, train 0.2828234276461481, test 0.2994555526723464\n",
      "RMSE, train 0.28288627389555027, test 0.2994077745825052\n",
      "RMSE, train 0.2826744673228023, test 0.29975763025383156\n",
      "RMSE, train 0.28269161919903274, test 0.2995249469143649\n",
      "RMSE, train 0.282624308697202, test 0.2995024765841663\n",
      "RMSE, train 0.2826083110965262, test 0.29940230135495466\n",
      "RMSE, train 0.28275128359896967, test 0.29952908447012305\n",
      "RMSE, train 0.2826984291425859, test 0.29922194484000403\n",
      "RMSE, train 0.28267504632322477, test 0.29969771718606353\n",
      "RMSE, train 0.28269961656946124, test 0.29936190973967314\n",
      "Early stopping at epoch 12 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\1594771382.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/lstm/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27777538563042, test 0.2993405102027787\n",
      "RMSE, train 0.27812626732970186, test 0.29883255677090753\n",
      "RMSE, train 0.2778309336650082, test 0.2988122069173389\n",
      "RMSE, train 0.27794534586510566, test 0.29900116754902734\n",
      "RMSE, train 0.2775772640084963, test 0.2992148490415679\n",
      "RMSE, train 0.277533651884354, test 0.2992356874876552\n",
      "RMSE, train 0.27790999296058544, test 0.29901957843038773\n",
      "RMSE, train 0.277752588339893, test 0.29935867173804176\n",
      "RMSE, train 0.2779596372434714, test 0.29826646082931096\n",
      "RMSE, train 0.2777480334043503, test 0.29933889855941137\n",
      "RMSE, train 0.27782953926173826, test 0.29894755482673646\n",
      "RMSE, train 0.2778725113589166, test 0.29894334210289847\n",
      "RMSE, train 0.27772010296502847, test 0.29842871858014003\n",
      "RMSE, train 0.27764651496616016, test 0.2987484109070566\n",
      "RMSE, train 0.2776222832280028, test 0.29980551368660396\n",
      "RMSE, train 0.2777603481898732, test 0.2988712415099144\n",
      "RMSE, train 0.2777154934454478, test 0.29894826263189317\n",
      "RMSE, train 0.27790739983721885, test 0.29871572487884096\n",
      "RMSE, train 0.2777463703785302, test 0.29857706112994087\n",
      "Early stopping at epoch 19 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\livb\\AppData\\Local\\Temp\\ipykernel_23544\\1594771382.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f'models/lstm/output_size{output}input_size{inputs}.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27272428562893675, test 0.29744988278700757\n",
      "RMSE, train 0.27311453761712784, test 0.2975943014025688\n",
      "RMSE, train 0.2727123617754547, test 0.2980226442599908\n",
      "RMSE, train 0.2727641983195629, test 0.29893916788009495\n",
      "RMSE, train 0.2728541812792745, test 0.298203863012485\n",
      "RMSE, train 0.2730933230056941, test 0.2990589888814168\n",
      "RMSE, train 0.2731367540879413, test 0.2986441718844267\n",
      "RMSE, train 0.2725960131839057, test 0.3013656015197436\n",
      "RMSE, train 0.27289451640157314, test 0.2980610648026833\n",
      "RMSE, train 0.2729039606739799, test 0.30111302588230526\n",
      "RMSE, train 0.27240361250078193, test 0.29942917021421284\n",
      "Early stopping at epoch 11 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "        \n",
    "        \n",
    "        state_dict = torch.load(f'models/lstm/output_size{output}input_size{inputs}.pt')\n",
    "        mod = tm.train_model(config, it_amt=0, model_fnc=ml_models.LSTM, data_dir='data_synthetic')\n",
    "        mod.load_state_dict(state_dict)\n",
    "\n",
    "        pinn_mod = pinns.decay_pinn(mod)\n",
    "        \n",
    "        mod = pinns.train_pinn_2(config, it_amt=100, model=pinn_mod, data_dir = 'data_synthetic')\n",
    "        \n",
    "        torch.save(obj = mod.state_dict(), f = 'pinn_models_2/lstm/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ec71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2d386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da1de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
