{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6186b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_models\n",
    "import data_pipeline2 as dp \n",
    "import numpy as np\n",
    "from training_models import train_model\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7dffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size' : 30,\n",
    "    'lr' : 1e-4,\n",
    "    'batch_size' : 32,\n",
    "    'hidden_size' : 8,\n",
    "    'output_size' : 3,\n",
    "    'layer_amt' : 3\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2d2bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.8928982212609453, test 0.5770193543885985\n",
      "RMSE, train 0.33254431506155036, test 0.2732703227910303\n",
      "RMSE, train 0.2613470951323453, test 0.2674983993412987\n",
      "RMSE, train 0.2570705356687425, test 0.2642514620336794\n",
      "RMSE, train 0.2553223943256814, test 0.2625001622063498\n",
      "RMSE, train 0.25387998997222766, test 0.26130669347701535\n",
      "RMSE, train 0.25298088426764304, test 0.2598103696420308\n",
      "RMSE, train 0.2527177558674407, test 0.26042137222905315\n",
      "RMSE, train 0.25236210534754006, test 0.2592940906723661\n",
      "RMSE, train 0.252031032570266, test 0.26060007200125723\n",
      "RMSE, train 0.2517912176993525, test 0.25885772861299977\n",
      "RMSE, train 0.25172020655434596, test 0.2580884402437556\n",
      "RMSE, train 0.2516310063776056, test 0.2578858527084512\n",
      "RMSE, train 0.2515727540868309, test 0.25926839247826605\n",
      "RMSE, train 0.2513482026284627, test 0.2580556026509693\n",
      "RMSE, train 0.2514134786375191, test 0.2579028797486136\n",
      "RMSE, train 0.2513279315128392, test 0.2573323755134498\n",
      "RMSE, train 0.2512229588250869, test 0.25722008120388756\n",
      "RMSE, train 0.25134536855128914, test 0.2587897463911964\n",
      "RMSE, train 0.2512155770961004, test 0.2580485390799661\n",
      "RMSE, train 0.2510820419892021, test 0.25880410582307845\n",
      "RMSE, train 0.25099028741182544, test 0.25780467388610684\n",
      "RMSE, train 0.25105287196490134, test 0.2577236797059736\n",
      "RMSE, train 0.25101773189049464, test 0.25822457599063076\n",
      "RMSE, train 0.2511188050385992, test 0.25771477686301353\n",
      "RMSE, train 0.25092197794157994, test 0.25739550434293285\n",
      "RMSE, train 0.2509535360683801, test 0.2572203627036464\n",
      "RMSE, train 0.25084093345601566, test 0.25761294749475294\n",
      "Early stopping at epoch 28 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.7978090349931707, test 0.3440207463404364\n",
      "RMSE, train 0.2595663941672698, test 0.24495070101308428\n",
      "RMSE, train 0.2400103905784939, test 0.24334215612943508\n",
      "RMSE, train 0.2382552930067184, test 0.24268399382179434\n",
      "RMSE, train 0.2372523231756108, test 0.2412863871898533\n",
      "RMSE, train 0.23709706286428428, test 0.24117715453559702\n",
      "RMSE, train 0.23587757362588216, test 0.23928806136462313\n",
      "RMSE, train 0.23530981169357473, test 0.23956164354381482\n",
      "RMSE, train 0.23496355276238098, test 0.24123199739732032\n",
      "RMSE, train 0.23499582787817305, test 0.23913970774362894\n",
      "RMSE, train 0.23492384315864276, test 0.23813590801451817\n",
      "RMSE, train 0.23487532312269152, test 0.23931133236027946\n",
      "RMSE, train 0.23440746503018658, test 0.23865688155012682\n",
      "RMSE, train 0.2343472699495221, test 0.2391835531173659\n",
      "RMSE, train 0.23452952381992628, test 0.23925928580613176\n",
      "RMSE, train 0.23412364191914858, test 0.23907969799662424\n",
      "RMSE, train 0.23406858356134128, test 0.23886182374698073\n",
      "RMSE, train 0.2342836156577958, test 0.23928905321546823\n",
      "RMSE, train 0.23407978633878684, test 0.23928154524692818\n",
      "RMSE, train 0.23436096716325291, test 0.23857943393474768\n",
      "RMSE, train 0.2341801376960538, test 0.2383685715434965\n",
      "Early stopping at epoch 21 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.5527497510125896, test 0.25274579455716567\n",
      "RMSE, train 0.24135678377487005, test 0.24355311273482808\n",
      "RMSE, train 0.23630379394554635, test 0.24102058340060084\n",
      "RMSE, train 0.23419902155966138, test 0.24311363932333493\n",
      "RMSE, train 0.23333344324184124, test 0.23759817005249492\n",
      "RMSE, train 0.23224698227923563, test 0.23748057499005085\n",
      "RMSE, train 0.23147620467234775, test 0.23611401145656905\n",
      "RMSE, train 0.23061424979904313, test 0.23599957609385774\n",
      "RMSE, train 0.2303722951013142, test 0.23645887837598198\n",
      "RMSE, train 0.23046815427127423, test 0.23532232805563694\n",
      "RMSE, train 0.2301017445351269, test 0.2354592663938539\n",
      "RMSE, train 0.22945234478155432, test 0.2345899263756317\n",
      "RMSE, train 0.22928201728093345, test 0.23518322917975878\n",
      "RMSE, train 0.22978861928621588, test 0.23419753167974322\n",
      "RMSE, train 0.2297581898759423, test 0.23738563858103334\n",
      "RMSE, train 0.228862875035958, test 0.23515511258390911\n",
      "RMSE, train 0.22903542101446753, test 0.2353259257057257\n",
      "RMSE, train 0.22941473377411808, test 0.2344562734166781\n",
      "RMSE, train 0.2287351354035233, test 0.23408827721549755\n",
      "RMSE, train 0.2288043398592772, test 0.23391125305441388\n",
      "RMSE, train 0.2283919882545593, test 0.2356020220669738\n",
      "RMSE, train 0.22857173919868368, test 0.234173567344745\n",
      "RMSE, train 0.2284492354180767, test 0.2340794918045663\n",
      "RMSE, train 0.22856191807845508, test 0.23394344760137692\n",
      "RMSE, train 0.22898671582245878, test 0.23522265144346052\n",
      "RMSE, train 0.22862098686921317, test 0.23385496300302053\n",
      "RMSE, train 0.22843961085655543, test 0.23355678808793687\n",
      "RMSE, train 0.2287654414582354, test 0.23442787003883145\n",
      "RMSE, train 0.22843271598759998, test 0.23386432975530624\n",
      "RMSE, train 0.22809031721689046, test 0.233638606638762\n",
      "RMSE, train 0.22833705326514459, test 0.23541119969204852\n",
      "RMSE, train 0.22850659013048671, test 0.2336782418322145\n",
      "RMSE, train 0.22801048254598177, test 0.2336935266983091\n",
      "RMSE, train 0.22825424825903703, test 0.23372801249487357\n",
      "RMSE, train 0.2283134526694253, test 0.23361859509819433\n",
      "RMSE, train 0.22816847944691745, test 0.23360417325768554\n",
      "RMSE, train 0.22821568449867813, test 0.2340378784819653\n",
      "Early stopping at epoch 37 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.6632987497138806, test 0.27866895526063207\n",
      "RMSE, train 0.2512777881043339, test 0.26247230230593216\n",
      "RMSE, train 0.24232666414933443, test 0.25566837374193996\n",
      "RMSE, train 0.23772114771362704, test 0.2489912763384043\n",
      "RMSE, train 0.2338979356257614, test 0.24341987014985553\n",
      "RMSE, train 0.23147808281184665, test 0.2406835596935422\n",
      "RMSE, train 0.23028414433284136, test 0.2378671040721968\n",
      "RMSE, train 0.22908858184953862, test 0.23680269170333357\n",
      "RMSE, train 0.2280208671327707, test 0.23625577431099087\n",
      "RMSE, train 0.22781907238937504, test 0.23515128957874634\n",
      "RMSE, train 0.22765547003339184, test 0.2357693631567207\n",
      "RMSE, train 0.2277225841343545, test 0.23492245142366372\n",
      "RMSE, train 0.22718433717483552, test 0.2345599686982585\n",
      "RMSE, train 0.22705988262319907, test 0.23488371081504167\n",
      "RMSE, train 0.2268689938938703, test 0.23388722524339078\n",
      "RMSE, train 0.22664532945591395, test 0.2335856651120326\n",
      "RMSE, train 0.22670634419864003, test 0.2343846529576124\n",
      "RMSE, train 0.22673676170070872, test 0.2340795418211058\n",
      "RMSE, train 0.22674135200519266, test 0.23349062543289334\n",
      "RMSE, train 0.22641788833821302, test 0.23559587441530883\n",
      "RMSE, train 0.22619633255682015, test 0.23490908683515063\n",
      "RMSE, train 0.22641586121127258, test 0.23382252147969076\n",
      "RMSE, train 0.22626680880784988, test 0.23346641287207603\n",
      "RMSE, train 0.2263403705772466, test 0.2343501452283532\n",
      "RMSE, train 0.2257423903748642, test 0.23354015579702808\n",
      "RMSE, train 0.22577907226819696, test 0.2338742356674344\n",
      "RMSE, train 0.2256924601756303, test 0.23453540742105128\n",
      "RMSE, train 0.22597487962544677, test 0.23430795266347773\n",
      "RMSE, train 0.22549388955096072, test 0.23331757598355704\n",
      "RMSE, train 0.22603471020596694, test 0.23359807317747788\n",
      "RMSE, train 0.2262707029187025, test 0.233735836019703\n",
      "RMSE, train 0.22602697312476241, test 0.2339289656602869\n",
      "RMSE, train 0.22572013136524005, test 0.2333915153993111\n",
      "RMSE, train 0.22565613272722126, test 0.23360740824365148\n",
      "RMSE, train 0.22549562001498616, test 0.23442530873067238\n",
      "RMSE, train 0.22569477478117816, test 0.23277915123046614\n",
      "RMSE, train 0.22563179208939285, test 0.23380920356687376\n",
      "RMSE, train 0.22542149945204468, test 0.23460188413075372\n",
      "RMSE, train 0.22532305402374495, test 0.2338468604081986\n",
      "RMSE, train 0.2253537496334044, test 0.23300046678267272\n",
      "RMSE, train 0.2255069097606265, test 0.23374482039727418\n",
      "RMSE, train 0.2253668340265324, test 0.23366794508754038\n",
      "RMSE, train 0.2252186233431172, test 0.23403099734409183\n",
      "RMSE, train 0.2255762031830865, test 0.23410506736414105\n",
      "RMSE, train 0.22554716771926403, test 0.23415189652758486\n",
      "RMSE, train 0.22553144893242238, test 0.23298896542366812\n",
      "Early stopping at epoch 46 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.852555266731689, test 0.61009311158795\n",
      "RMSE, train 0.3717650466808869, test 0.2642788968302987\n",
      "RMSE, train 0.25963450926205806, test 0.2614575268562175\n",
      "RMSE, train 0.2584222542242177, test 0.26166403047309433\n",
      "RMSE, train 0.25804265708692614, test 0.2608326624247653\n",
      "RMSE, train 0.2575588375630398, test 0.26030707975064427\n",
      "RMSE, train 0.25715490247333245, test 0.2603286529375502\n",
      "RMSE, train 0.256918944448473, test 0.2602180778241355\n",
      "RMSE, train 0.2566439433684272, test 0.25996344567330415\n",
      "RMSE, train 0.2563653332331488, test 0.2602351349739989\n",
      "RMSE, train 0.25623799175504713, test 0.2595193924243785\n",
      "RMSE, train 0.2560158401667591, test 0.2592749541456049\n",
      "RMSE, train 0.25581052998501447, test 0.2593612917198623\n",
      "RMSE, train 0.25573240572045886, test 0.2591002786701376\n",
      "RMSE, train 0.2554596021410919, test 0.2589100881302652\n",
      "RMSE, train 0.25543404707024175, test 0.2589516994381739\n",
      "RMSE, train 0.2552383101034549, test 0.25885896828056365\n",
      "RMSE, train 0.2551530297665346, test 0.25879321364331836\n",
      "RMSE, train 0.2550718589956241, test 0.25874838762539476\n",
      "RMSE, train 0.25494334203822, test 0.25851460441577534\n",
      "RMSE, train 0.25483780101903025, test 0.25857503749122307\n",
      "RMSE, train 0.2546625128015876, test 0.2585911439223723\n",
      "RMSE, train 0.2546112947165966, test 0.2583542451385624\n",
      "RMSE, train 0.2545596758324292, test 0.2582902500698389\n",
      "RMSE, train 0.2544713442424132, test 0.2583381899378516\n",
      "RMSE, train 0.2543885654078857, test 0.2581943268618308\n",
      "RMSE, train 0.25433147133838746, test 0.25800501783032065\n",
      "RMSE, train 0.2542296451546492, test 0.2582432983581685\n",
      "RMSE, train 0.2542557499461597, test 0.25813798557135686\n",
      "RMSE, train 0.25414493827209356, test 0.2579929994896424\n",
      "RMSE, train 0.2540114600391638, test 0.2579047565371537\n",
      "RMSE, train 0.2540831723580918, test 0.2578713100803785\n",
      "RMSE, train 0.2540208591869281, test 0.2581380918498867\n",
      "RMSE, train 0.25389275105009157, test 0.2577994134554193\n",
      "RMSE, train 0.25392789417697537, test 0.25792253731696074\n",
      "RMSE, train 0.2538306514221814, test 0.25764627385237987\n",
      "RMSE, train 0.25376798422826874, test 0.25781929111185153\n",
      "RMSE, train 0.25375696076380627, test 0.2578701094901266\n",
      "RMSE, train 0.2537880965298222, test 0.25772916174624577\n",
      "RMSE, train 0.25363290874708083, test 0.257879586751796\n",
      "RMSE, train 0.25369132607574424, test 0.25781793301263134\n",
      "RMSE, train 0.25365690250069867, test 0.25764965530762\n",
      "RMSE, train 0.2536614274666194, test 0.25846579806371167\n",
      "RMSE, train 0.2536356036040571, test 0.2575848536057906\n",
      "RMSE, train 0.2536209000635051, test 0.2576860592138669\n",
      "RMSE, train 0.25355187761447123, test 0.25774859249099225\n",
      "RMSE, train 0.2535381781898679, test 0.2574851445176385\n",
      "RMSE, train 0.25351015162924606, test 0.2574923938709842\n",
      "RMSE, train 0.2534594309606379, test 0.25761712644218415\n",
      "RMSE, train 0.25340644690778946, test 0.2575044140589139\n",
      "RMSE, train 0.2534584472737005, test 0.2580292552463279\n",
      "RMSE, train 0.25347436507863386, test 0.2575332901694558\n",
      "RMSE, train 0.2534320685231397, test 0.2574962653404425\n",
      "RMSE, train 0.2534135461093918, test 0.25775461994912013\n",
      "RMSE, train 0.253401935851622, test 0.2578176917616001\n",
      "RMSE, train 0.25333517228042884, test 0.25773336719875495\n",
      "RMSE, train 0.2533486781101073, test 0.2574246466652421\n",
      "RMSE, train 0.2533883961638616, test 0.2574370847014356\n",
      "RMSE, train 0.25330583631030973, test 0.2575590514447078\n",
      "RMSE, train 0.253394176192101, test 0.2575116616881583\n",
      "RMSE, train 0.25330946639540697, test 0.25743400114626924\n",
      "RMSE, train 0.2533188067797211, test 0.25753734316215043\n",
      "RMSE, train 0.2533157017502573, test 0.25739775474899074\n",
      "RMSE, train 0.2533040170167242, test 0.2572447955608368\n",
      "RMSE, train 0.2532867145754637, test 0.25728647792634884\n",
      "RMSE, train 0.2532378711527394, test 0.2572795953139786\n",
      "RMSE, train 0.25319812864425684, test 0.25753736101891384\n",
      "RMSE, train 0.253308707427594, test 0.25743058397750224\n",
      "RMSE, train 0.2532042873001868, test 0.2573237910497287\n",
      "RMSE, train 0.2531934143795121, test 0.2575201113854558\n",
      "RMSE, train 0.25324448528549365, test 0.25753732493593673\n",
      "RMSE, train 0.25327255426635664, test 0.25735728935269286\n",
      "RMSE, train 0.2531305987447981, test 0.2574235660231803\n",
      "RMSE, train 0.2531609987960227, test 0.25737165690453584\n",
      "Early stopping at epoch 74 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.6865039602045185, test 0.26203534865783434\n",
      "RMSE, train 0.24300512185027776, test 0.24373372480020686\n",
      "RMSE, train 0.23996739585168106, test 0.24336001213829397\n",
      "RMSE, train 0.23967434619822778, test 0.242854244501914\n",
      "RMSE, train 0.2391585560192254, test 0.24254095743773346\n",
      "RMSE, train 0.23888999673206945, test 0.24228207868034557\n",
      "RMSE, train 0.23852855438166412, test 0.24228348052602702\n",
      "RMSE, train 0.23843771878106534, test 0.24192148194474689\n",
      "RMSE, train 0.23833718369445525, test 0.24194597276085514\n",
      "RMSE, train 0.23814761050599664, test 0.24225160125958717\n",
      "RMSE, train 0.2379548233156362, test 0.24188190281896269\n",
      "RMSE, train 0.2380623049603021, test 0.24177124932155772\n",
      "RMSE, train 0.2378070125710373, test 0.24185093833228288\n",
      "RMSE, train 0.2378346471747091, test 0.24207720337277752\n",
      "RMSE, train 0.23771510457943293, test 0.24249185356548278\n",
      "RMSE, train 0.23779060337538563, test 0.24252128007553392\n",
      "RMSE, train 0.23774802749437735, test 0.24195280506954356\n",
      "RMSE, train 0.23767139781112515, test 0.24171675615391489\n",
      "RMSE, train 0.23776750408174577, test 0.24178034180806854\n",
      "RMSE, train 0.2376032736121623, test 0.24141262471675873\n",
      "RMSE, train 0.23756419818017108, test 0.24153635511964056\n",
      "RMSE, train 0.23759353364055807, test 0.24154167256112827\n",
      "RMSE, train 0.23756853411020326, test 0.2415524272847984\n",
      "RMSE, train 0.23755020063278104, test 0.24135201108657708\n",
      "RMSE, train 0.23738502446284965, test 0.24154693772227076\n",
      "RMSE, train 0.23750360734945486, test 0.24143590096194864\n",
      "RMSE, train 0.2374650751017342, test 0.24163822476136482\n",
      "RMSE, train 0.2373722951458998, test 0.24125133669477397\n",
      "RMSE, train 0.23730358358257073, test 0.24176980441404602\n",
      "RMSE, train 0.2374211729250171, test 0.24138907242124363\n",
      "RMSE, train 0.2372624444013292, test 0.24153524233123003\n",
      "RMSE, train 0.23738015113660127, test 0.2413130708165088\n",
      "RMSE, train 0.23707269898746625, test 0.24139516434427036\n",
      "RMSE, train 0.23730353780152383, test 0.2413643769035905\n",
      "RMSE, train 0.23712996310315843, test 0.24163921947701503\n",
      "RMSE, train 0.2374793357900844, test 0.24132016705254378\n",
      "RMSE, train 0.23741342536797208, test 0.24186989665031433\n",
      "RMSE, train 0.23705850267582687, test 0.24131109855942806\n",
      "Early stopping at epoch 38 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.49817561444244096, test 0.25202912810657707\n",
      "RMSE, train 0.2417832462356501, test 0.24750377091446094\n",
      "RMSE, train 0.23870631695313133, test 0.24442458019724914\n",
      "RMSE, train 0.2367323562665183, test 0.24275997307683742\n",
      "RMSE, train 0.23581498669772885, test 0.24183163539107358\n",
      "RMSE, train 0.23494929597917985, test 0.2405839404091239\n",
      "RMSE, train 0.23463769198632708, test 0.2400040944506015\n",
      "RMSE, train 0.23410019531748652, test 0.24031123904777424\n",
      "RMSE, train 0.2335163147426119, test 0.2396574498021177\n",
      "RMSE, train 0.2336018173782914, test 0.2390879239620907\n",
      "RMSE, train 0.23343246542160806, test 0.2384459442858185\n",
      "RMSE, train 0.2331246048017265, test 0.23886344462100947\n",
      "RMSE, train 0.23288298685566272, test 0.23861277542476142\n",
      "RMSE, train 0.23284259954698724, test 0.23872853030583688\n",
      "RMSE, train 0.2327162030930093, test 0.23774934879371099\n",
      "RMSE, train 0.23272113232571057, test 0.2383474881893822\n",
      "RMSE, train 0.2324340318477751, test 0.2377339073323778\n",
      "RMSE, train 0.23244940965134075, test 0.23852830699511937\n",
      "RMSE, train 0.23243485170382042, test 0.23783469985106162\n",
      "RMSE, train 0.2322553884814248, test 0.23766966350376606\n",
      "RMSE, train 0.2321246047879616, test 0.2381568050810269\n",
      "RMSE, train 0.23242358798424922, test 0.23777184821665287\n",
      "RMSE, train 0.2321213727942739, test 0.23742964158632926\n",
      "RMSE, train 0.23225362511242137, test 0.23863731590764864\n",
      "RMSE, train 0.23206236426087506, test 0.23804693682385342\n",
      "RMSE, train 0.23202414849614786, test 0.23740564592714822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23203335017420368, test 0.23738801572471857\n",
      "RMSE, train 0.23200413581462728, test 0.23734953640294926\n",
      "RMSE, train 0.23208971487151253, test 0.23763493288840568\n",
      "RMSE, train 0.2319880571370551, test 0.23763669268893345\n",
      "RMSE, train 0.23195962062458586, test 0.23762353363313846\n",
      "RMSE, train 0.23196596189651614, test 0.23806345396276032\n",
      "RMSE, train 0.2319029480024101, test 0.23705221513020142\n",
      "RMSE, train 0.23181721214245607, test 0.2371198178402015\n",
      "RMSE, train 0.23172472920552836, test 0.2373572075739503\n",
      "RMSE, train 0.23170289601765426, test 0.23786524856196983\n",
      "RMSE, train 0.231661938569125, test 0.23769870254078082\n",
      "RMSE, train 0.2317578676674101, test 0.2381575714264597\n",
      "RMSE, train 0.23181521480249684, test 0.23728059684591635\n",
      "RMSE, train 0.23174389313768456, test 0.23702976293861866\n",
      "RMSE, train 0.23199321391276026, test 0.23796660120465926\n",
      "RMSE, train 0.23173880122585755, test 0.23791902113173688\n",
      "RMSE, train 0.23169266697108615, test 0.237147165994559\n",
      "RMSE, train 0.23203285233257642, test 0.2375851712588753\n",
      "RMSE, train 0.23178583039437503, test 0.23736801158104623\n",
      "RMSE, train 0.23165264410780406, test 0.2378141096393977\n",
      "RMSE, train 0.2315258761311928, test 0.23735200467386416\n",
      "RMSE, train 0.23151739607189736, test 0.2376871512138418\n",
      "RMSE, train 0.23173032100424007, test 0.23751331839178288\n",
      "RMSE, train 0.23154217397595284, test 0.23803598327296122\n",
      "Early stopping at epoch 50 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.753895509213865, test 0.47416661273349414\n",
      "RMSE, train 0.3600026787711822, test 0.30224056180679437\n",
      "RMSE, train 0.26799601633420495, test 0.27734470653413523\n",
      "RMSE, train 0.25201114859149626, test 0.2646752768995786\n",
      "RMSE, train 0.24411781747941574, test 0.2570443823181017\n",
      "RMSE, train 0.23896204922484884, test 0.250498366777343\n",
      "RMSE, train 0.2363636854371115, test 0.24646965060571227\n",
      "RMSE, train 0.23419523661760364, test 0.24424368609683683\n",
      "RMSE, train 0.23310936732367957, test 0.24229147939971\n",
      "RMSE, train 0.23242344257301106, test 0.24157831855494566\n",
      "RMSE, train 0.2319874182379916, test 0.2408139371510708\n",
      "RMSE, train 0.2315423849305197, test 0.24059525373006108\n",
      "RMSE, train 0.23135154470254857, test 0.24071898409212478\n",
      "RMSE, train 0.231255396872686, test 0.2404048414242388\n",
      "RMSE, train 0.23109835597588554, test 0.2404121541314655\n",
      "RMSE, train 0.23089693228015107, test 0.2396005927914321\n",
      "RMSE, train 0.2307736692553919, test 0.239641907991785\n",
      "RMSE, train 0.23068544552786718, test 0.23989231854376167\n",
      "RMSE, train 0.23055130053848977, test 0.2399688299858209\n",
      "RMSE, train 0.2303165745327117, test 0.23991834966823308\n",
      "RMSE, train 0.23041238535587247, test 0.2392924397882789\n",
      "RMSE, train 0.23038075336034258, test 0.2407118778939199\n",
      "RMSE, train 0.2302185763356738, test 0.24058695814826273\n",
      "RMSE, train 0.2300817263665584, test 0.2398410996403357\n",
      "RMSE, train 0.22996456112284533, test 0.23922326047011097\n",
      "RMSE, train 0.22977811579016427, test 0.23944759609723332\n",
      "RMSE, train 0.2300266690534018, test 0.23932579009219854\n",
      "RMSE, train 0.22987533690439751, test 0.23914293794318883\n",
      "RMSE, train 0.22989207546256282, test 0.23892791283251058\n",
      "RMSE, train 0.22960393385811365, test 0.23890014519595137\n",
      "RMSE, train 0.22963054656690957, test 0.23870857872746207\n",
      "RMSE, train 0.22959202444203616, test 0.23941543005933666\n",
      "RMSE, train 0.2294950189027926, test 0.23855709036191305\n",
      "RMSE, train 0.22956330407511052, test 0.23838945967380445\n",
      "RMSE, train 0.2294299182434245, test 0.24045318937060808\n",
      "RMSE, train 0.22955590482883173, test 0.23879340230816543\n",
      "RMSE, train 0.22922861168028966, test 0.23856621905408723\n",
      "RMSE, train 0.2293090391129911, test 0.23844078138019098\n",
      "RMSE, train 0.22918339008078306, test 0.23835190272692477\n",
      "RMSE, train 0.2292335583557418, test 0.2389725571629977\n",
      "RMSE, train 0.22902030514184304, test 0.2389497377655723\n",
      "RMSE, train 0.22905862590065795, test 0.23936180318846847\n",
      "RMSE, train 0.22898804507512044, test 0.2391989092634182\n",
      "RMSE, train 0.22902150517716677, test 0.2380351084049302\n",
      "RMSE, train 0.22864408058758762, test 0.23821302796855118\n",
      "RMSE, train 0.22891004860838352, test 0.2380226505826218\n",
      "RMSE, train 0.22869566742394548, test 0.23995218087326398\n",
      "RMSE, train 0.22890065566688994, test 0.23841739468502277\n",
      "RMSE, train 0.2286057061627325, test 0.23840797564598046\n",
      "RMSE, train 0.2286790733961138, test 0.2388826458141057\n",
      "RMSE, train 0.22865350191051045, test 0.23842580736887575\n",
      "RMSE, train 0.22874357513081472, test 0.23834392654173303\n",
      "RMSE, train 0.22844608802084235, test 0.2378865069512165\n",
      "RMSE, train 0.22857847055625216, test 0.23791286213831467\n",
      "RMSE, train 0.22854192052173147, test 0.23787590424821833\n",
      "RMSE, train 0.22858956478044282, test 0.2379502294340519\n",
      "RMSE, train 0.22839283607991226, test 0.2375435923988169\n",
      "RMSE, train 0.2283124381945011, test 0.23808500848033212\n",
      "RMSE, train 0.22844675106786574, test 0.23791705147184508\n",
      "RMSE, train 0.22824241709155382, test 0.23799004548727865\n",
      "RMSE, train 0.22823083032751434, test 0.2380418816600183\n",
      "RMSE, train 0.22823225362522387, test 0.23796559102607495\n",
      "RMSE, train 0.22820989590839535, test 0.23800067317606222\n",
      "RMSE, train 0.22829778874998863, test 0.23749341326530535\n",
      "RMSE, train 0.22791451787744582, test 0.23775194886356893\n",
      "RMSE, train 0.22805628267943423, test 0.2375538722433225\n",
      "RMSE, train 0.22833566101664143, test 0.23802520334720612\n",
      "RMSE, train 0.22799445564851784, test 0.23766080839465362\n",
      "RMSE, train 0.22807660567731322, test 0.23853332797686258\n",
      "RMSE, train 0.22804876874157734, test 0.23708488619086718\n",
      "RMSE, train 0.22778993899635697, test 0.23735031786591115\n",
      "RMSE, train 0.22775489376051794, test 0.23707888388272488\n",
      "RMSE, train 0.22775461205934838, test 0.23725328421351885\n",
      "RMSE, train 0.22776893141945884, test 0.23721642265416154\n",
      "RMSE, train 0.22770166510037512, test 0.23763219003725533\n",
      "RMSE, train 0.2274102258580238, test 0.23748799074779858\n",
      "RMSE, train 0.22770980798382048, test 0.23734066266604145\n",
      "RMSE, train 0.22760945041197145, test 0.23711344810447307\n",
      "RMSE, train 0.22758959958780658, test 0.23726815948582658\n",
      "RMSE, train 0.2273895419897252, test 0.2374792466259966\n",
      "RMSE, train 0.22743046112486087, test 0.23711724473972512\n",
      "RMSE, train 0.22749165268865365, test 0.23754466452983894\n",
      "Early stopping at epoch 82 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.8493916138021413, test 0.6173578970513102\n",
      "RMSE, train 0.43357078078364536, test 0.32369480496746\n",
      "RMSE, train 0.28047896897004654, test 0.271861620121083\n",
      "RMSE, train 0.2663181952762702, test 0.26817362035735176\n",
      "RMSE, train 0.2641134827959636, test 0.2668583910849135\n",
      "RMSE, train 0.26305468642145147, test 0.26594131313643216\n",
      "RMSE, train 0.26248493174876064, test 0.26550898536787193\n",
      "RMSE, train 0.2619391263208606, test 0.26505798833855126\n",
      "RMSE, train 0.2614596958987969, test 0.26469966554540697\n",
      "RMSE, train 0.26120744328484063, test 0.2643065285884728\n",
      "RMSE, train 0.26111879593823567, test 0.26420256987971774\n",
      "RMSE, train 0.26070081116246785, test 0.2653580175365432\n",
      "RMSE, train 0.26053177001924555, test 0.263565420346745\n",
      "RMSE, train 0.2605145510501605, test 0.2636414758734784\n",
      "RMSE, train 0.260333480975352, test 0.26371794547569954\n",
      "RMSE, train 0.2603600612602943, test 0.2639739196431839\n",
      "RMSE, train 0.2602684165943753, test 0.26410593635449975\n",
      "RMSE, train 0.25999964927592556, test 0.2635457816265397\n",
      "RMSE, train 0.2601681534231694, test 0.26328560558416075\n",
      "RMSE, train 0.2599990644361362, test 0.26343409906504517\n",
      "RMSE, train 0.2602286999814274, test 0.2631679159604897\n",
      "RMSE, train 0.2598516050695388, test 0.2632839415790671\n",
      "RMSE, train 0.2598890232707351, test 0.26306588316367846\n",
      "RMSE, train 0.2598190855019349, test 0.2632093567211749\n",
      "RMSE, train 0.2597000115851233, test 0.26323273146556597\n",
      "RMSE, train 0.25972845713215426, test 0.2631696153242709\n",
      "RMSE, train 0.2595981060534962, test 0.26285149308584504\n",
      "RMSE, train 0.2596923740011109, test 0.26326242518627035\n",
      "RMSE, train 0.2595806281613417, test 0.2629025684574903\n",
      "RMSE, train 0.25959112880027985, test 0.2629938196327727\n",
      "RMSE, train 0.25956687017166913, test 0.26309250686633384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.25957508154275005, test 0.26307366018073036\n",
      "RMSE, train 0.25961587433356886, test 0.26276925875473833\n",
      "RMSE, train 0.25958530995840867, test 0.26290603335631096\n",
      "RMSE, train 0.2594777504828843, test 0.2627799538737636\n",
      "RMSE, train 0.2595603893980507, test 0.2628710223203998\n",
      "RMSE, train 0.2594422175864543, test 0.2627538509540639\n",
      "RMSE, train 0.2595932314957469, test 0.2627990032404156\n",
      "RMSE, train 0.2594291563492176, test 0.2632196358704971\n",
      "RMSE, train 0.25955533344021514, test 0.26284989196870284\n",
      "RMSE, train 0.2593538789463437, test 0.26276122046224143\n",
      "RMSE, train 0.2593483479370263, test 0.26297257386021694\n",
      "RMSE, train 0.2595456327534904, test 0.2631593784790928\n",
      "RMSE, train 0.2592747697899164, test 0.2628135789754027\n",
      "RMSE, train 0.25933911866885573, test 0.26279703515060876\n",
      "RMSE, train 0.2591568148456329, test 0.2628067401001009\n",
      "RMSE, train 0.2593558076307301, test 0.2627821963722423\n",
      "Early stopping at epoch 47 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.6930555896141474, test 0.29094212936318437\n",
      "RMSE, train 0.2595671351421664, test 0.2537301532600237\n",
      "RMSE, train 0.24784617682804222, test 0.2501427684141242\n",
      "RMSE, train 0.24608032775532668, test 0.2493119180202484\n",
      "RMSE, train 0.24551806277783306, test 0.24916637021562327\n",
      "RMSE, train 0.24514086645753014, test 0.2496596027975497\n",
      "RMSE, train 0.24469780194278481, test 0.24864354276138803\n",
      "RMSE, train 0.24454550381805235, test 0.24811133742332458\n",
      "RMSE, train 0.24419465939456997, test 0.2482050111760264\n",
      "RMSE, train 0.24412008506224162, test 0.24786454957464468\n",
      "RMSE, train 0.24396490737511095, test 0.2475373387336731\n",
      "RMSE, train 0.24391834627670847, test 0.24758924116259035\n",
      "RMSE, train 0.24371717908200186, test 0.2479644634153532\n",
      "RMSE, train 0.24368533324410707, test 0.2481603741645813\n",
      "RMSE, train 0.24367767164281978, test 0.24808173373989437\n",
      "RMSE, train 0.24355503821828564, test 0.24752352522767107\n",
      "RMSE, train 0.2434477565964316, test 0.24722556718017744\n",
      "RMSE, train 0.24340152775279528, test 0.24724327844122182\n",
      "RMSE, train 0.24344245222596858, test 0.24722134004468505\n",
      "RMSE, train 0.24328713903634663, test 0.2475492141816927\n",
      "RMSE, train 0.24327559221828565, test 0.24737236253593278\n",
      "RMSE, train 0.24322369884533487, test 0.2472466494726098\n",
      "RMSE, train 0.24319975967113633, test 0.2471255293358927\n",
      "RMSE, train 0.24309778767153462, test 0.248073928900387\n",
      "RMSE, train 0.24306983812346328, test 0.24712954267211582\n",
      "RMSE, train 0.24306087021868195, test 0.2472072440644969\n",
      "RMSE, train 0.24299727215761846, test 0.24713668253110802\n",
      "RMSE, train 0.24300854445895825, test 0.24717454184656557\n",
      "RMSE, train 0.24301512260978642, test 0.24697578432767286\n",
      "RMSE, train 0.24296075061374917, test 0.24790141945299896\n",
      "RMSE, train 0.24293013514986464, test 0.24757877044055773\n",
      "RMSE, train 0.24290194854361744, test 0.24778125428635142\n",
      "RMSE, train 0.24283430290323407, test 0.2468383066032244\n",
      "RMSE, train 0.2428358755926671, test 0.24744724488776662\n",
      "RMSE, train 0.2428395676321791, test 0.24706401073414347\n",
      "RMSE, train 0.2428191051108569, test 0.24723353567330733\n",
      "RMSE, train 0.24278549150803033, test 0.24735424259434577\n",
      "RMSE, train 0.24277695567364904, test 0.24720976197201272\n",
      "RMSE, train 0.2427296264219689, test 0.2471054055120634\n",
      "RMSE, train 0.24271607427460373, test 0.24733472090700398\n",
      "RMSE, train 0.2427013808754599, test 0.24680229542048082\n",
      "RMSE, train 0.24267857722669145, test 0.2468746419834054\n",
      "RMSE, train 0.24271308113435272, test 0.2470742782820826\n",
      "RMSE, train 0.24266025711902894, test 0.24685021807318147\n",
      "RMSE, train 0.24260603954457932, test 0.24698586995187014\n",
      "RMSE, train 0.24267762851942876, test 0.24662548925565636\n",
      "RMSE, train 0.242562003228062, test 0.2468864786884059\n",
      "RMSE, train 0.24258052166986363, test 0.2467183636582416\n",
      "RMSE, train 0.24261232090603774, test 0.24689511345780413\n",
      "RMSE, train 0.242545186460904, test 0.24705482747243798\n",
      "RMSE, train 0.2426098900236142, test 0.24672201781169228\n",
      "RMSE, train 0.24251334179358877, test 0.24693027048007302\n",
      "RMSE, train 0.2425911337010673, test 0.2466898710831352\n",
      "RMSE, train 0.24259682584973152, test 0.24686726331710815\n",
      "RMSE, train 0.24256190451973308, test 0.24679655264253203\n",
      "RMSE, train 0.24256804588620576, test 0.24684741535912388\n",
      "Early stopping at epoch 56 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.5218202994276055, test 0.25400471618962944\n",
      "RMSE, train 0.24486655080398637, test 0.25209351253072054\n",
      "RMSE, train 0.2431650405641094, test 0.25040599225311105\n",
      "RMSE, train 0.2421128105355485, test 0.24916795470298977\n",
      "RMSE, train 0.24131452318932445, test 0.2488852662777682\n",
      "RMSE, train 0.2407237381210776, test 0.24780010630231386\n",
      "RMSE, train 0.24027709579387588, test 0.24754099042043773\n",
      "RMSE, train 0.23983454189760267, test 0.24680012450852526\n",
      "RMSE, train 0.23962328031725946, test 0.24802092291893216\n",
      "RMSE, train 0.23938696480652677, test 0.24678575486764995\n",
      "RMSE, train 0.23915520771469237, test 0.24634895070430335\n",
      "RMSE, train 0.23897824566727796, test 0.24624756921868807\n",
      "RMSE, train 0.238771431582391, test 0.2460004839055035\n",
      "RMSE, train 0.23858904146961032, test 0.24636359348756456\n",
      "RMSE, train 0.23855046831037965, test 0.24612675074043625\n",
      "RMSE, train 0.2383226130842628, test 0.24545423508784092\n",
      "RMSE, train 0.23827339451542884, test 0.24526286166195477\n",
      "RMSE, train 0.2381655091394758, test 0.24588388450648807\n",
      "RMSE, train 0.23802579214353733, test 0.24587438986935747\n",
      "RMSE, train 0.23806222838938504, test 0.24495552630599485\n",
      "RMSE, train 0.2379670422774794, test 0.24480451028281397\n",
      "RMSE, train 0.23779052358972652, test 0.24484154937464161\n",
      "RMSE, train 0.23772162559855678, test 0.2455852240870852\n",
      "RMSE, train 0.23765654263875943, test 0.2453177259602678\n",
      "RMSE, train 0.23768855257151908, test 0.24470229009422687\n",
      "RMSE, train 0.23764213709152332, test 0.24550620090523992\n",
      "RMSE, train 0.23759021606680525, test 0.24567768497204562\n",
      "RMSE, train 0.23757785685661129, test 0.24508592541064692\n",
      "RMSE, train 0.2374788069337473, test 0.2452605362605611\n",
      "RMSE, train 0.2374454197461295, test 0.24445408418637896\n",
      "RMSE, train 0.2374354573843725, test 0.24521867766839647\n",
      "RMSE, train 0.23746065451291645, test 0.24493634400017764\n",
      "RMSE, train 0.23737272382985317, test 0.244864460115039\n",
      "RMSE, train 0.2373742094021207, test 0.24473062923195166\n",
      "RMSE, train 0.23727190975651077, test 0.24494231348737663\n",
      "RMSE, train 0.23724475502967834, test 0.24415834179711998\n",
      "RMSE, train 0.23713497647121884, test 0.2456720910214503\n",
      "RMSE, train 0.23723909352392358, test 0.2450724762240681\n",
      "RMSE, train 0.2371675568578489, test 0.2444067112076173\n",
      "RMSE, train 0.23722089502977148, test 0.2449155206527185\n",
      "RMSE, train 0.23716015779651334, test 0.24479837852333663\n",
      "RMSE, train 0.23709833301236277, test 0.24489119156784966\n",
      "RMSE, train 0.23709333704726043, test 0.2446224774242541\n",
      "RMSE, train 0.23706414707573006, test 0.24458621606367445\n",
      "RMSE, train 0.23703684744679873, test 0.24494278786379262\n",
      "RMSE, train 0.23698314620106745, test 0.24428837766887945\n",
      "Early stopping at epoch 46 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.7173725925762244, test 0.308571629691869\n",
      "RMSE, train 0.2571054905878775, test 0.2662646803073585\n",
      "RMSE, train 0.24701916185593364, test 0.2612188702138762\n",
      "RMSE, train 0.24359003785583708, test 0.256066659775873\n",
      "RMSE, train 0.2407777944598535, test 0.2522273203358054\n",
      "RMSE, train 0.23870487458477116, test 0.24935941227401295\n",
      "RMSE, train 0.23736507005312227, test 0.24819027663518986\n",
      "RMSE, train 0.23661674833809487, test 0.24669367851068577\n",
      "RMSE, train 0.23620406519433465, test 0.24583450999731818\n",
      "RMSE, train 0.2358493415093181, test 0.24586769876380762\n",
      "RMSE, train 0.23569951556397206, test 0.2451490374902884\n",
      "RMSE, train 0.23539640901215148, test 0.24478947588553032\n",
      "RMSE, train 0.2352169637351927, test 0.2446758607402444\n",
      "RMSE, train 0.2350612808056552, test 0.24440415436401963\n",
      "RMSE, train 0.23495589719727786, test 0.24481796411176523\n",
      "RMSE, train 0.23480819891950097, test 0.2441068481033047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23468100719831206, test 0.24372675269842148\n",
      "RMSE, train 0.23455224686650314, test 0.243816447754701\n",
      "RMSE, train 0.23446498137682376, test 0.2434531057563921\n",
      "RMSE, train 0.23437119651623448, test 0.24379849170024195\n",
      "RMSE, train 0.23424044390669976, test 0.24333870830014348\n",
      "RMSE, train 0.2341797834619729, test 0.2435201839543879\n",
      "RMSE, train 0.23419782876817866, test 0.24321839803208908\n",
      "RMSE, train 0.2340538745200393, test 0.2434446096109847\n",
      "RMSE, train 0.2340250571794582, test 0.24323958158493042\n",
      "RMSE, train 0.23395678607953918, test 0.24324283003807068\n",
      "RMSE, train 0.23390249256985357, test 0.2429946322614948\n",
      "RMSE, train 0.23382593047889796, test 0.24312494291613498\n",
      "RMSE, train 0.23377154718595322, test 0.24403433362022042\n",
      "RMSE, train 0.23372965354961578, test 0.24326289538294077\n",
      "RMSE, train 0.23362062133923925, test 0.24308982212096453\n",
      "RMSE, train 0.2335742497534463, test 0.24313673516735435\n",
      "RMSE, train 0.23355991837352214, test 0.24324496819948158\n",
      "RMSE, train 0.2335212759372562, test 0.24366923592363796\n",
      "RMSE, train 0.2334505021195821, test 0.24289926964168748\n",
      "RMSE, train 0.2334538082582782, test 0.243742057432731\n",
      "RMSE, train 0.23333960447949592, test 0.2428379038659235\n",
      "RMSE, train 0.23343727504364167, test 0.24304771314685544\n",
      "RMSE, train 0.23336535458913957, test 0.24296728878592452\n",
      "RMSE, train 0.23328904864011388, test 0.24307421393071613\n",
      "RMSE, train 0.23322931123953877, test 0.24302591709420085\n",
      "RMSE, train 0.2332469623046692, test 0.24276793375611305\n",
      "RMSE, train 0.2332009719026209, test 0.24271058229108652\n",
      "RMSE, train 0.23320412319717984, test 0.24256795862068734\n",
      "RMSE, train 0.23318975934326047, test 0.2430100541872283\n",
      "RMSE, train 0.23303033272274817, test 0.2427539691949884\n",
      "RMSE, train 0.23303079349224012, test 0.24340914965917668\n",
      "RMSE, train 0.23302055789966775, test 0.2427540086209774\n",
      "RMSE, train 0.2329863044950697, test 0.24265886393065253\n",
      "RMSE, train 0.23304915127128062, test 0.24268390502159795\n",
      "RMSE, train 0.23291961562753927, test 0.2434111018665135\n",
      "RMSE, train 0.23287720925579167, test 0.24239541155596575\n",
      "RMSE, train 0.23280849059422812, test 0.24310300390546521\n",
      "RMSE, train 0.23285624524108087, test 0.24280769160638252\n",
      "RMSE, train 0.2327369423300931, test 0.24341402497763434\n",
      "RMSE, train 0.23272409244920267, test 0.24297158839181066\n",
      "RMSE, train 0.232728308988641, test 0.24249890415618816\n",
      "RMSE, train 0.23268316215788476, test 0.24277223149935404\n",
      "RMSE, train 0.23269996156144623, test 0.2431482831016183\n",
      "RMSE, train 0.23265357153734775, test 0.2423973400145769\n",
      "RMSE, train 0.23263480529339628, test 0.24280809719736376\n",
      "RMSE, train 0.2326543325125569, test 0.24226765412216386\n",
      "RMSE, train 0.23259265020941244, test 0.242437445713828\n",
      "RMSE, train 0.23264570391238337, test 0.24238308720911542\n",
      "RMSE, train 0.23254182434292756, test 0.24273403190697232\n",
      "RMSE, train 0.23250095629029804, test 0.24239070511733493\n",
      "RMSE, train 0.2325244110943091, test 0.24242572657143077\n",
      "RMSE, train 0.23247158689179806, test 0.24263564823195338\n",
      "RMSE, train 0.23249698896901777, test 0.24277937784790993\n",
      "RMSE, train 0.2324411751269692, test 0.24382913205772638\n",
      "RMSE, train 0.23241106292816124, test 0.24252692284062505\n",
      "RMSE, train 0.23232493082983324, test 0.24278697526703277\n",
      "Early stopping at epoch 72 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.6741421132435725, test 0.3944401384464332\n",
      "RMSE, train 0.31644299373128054, test 0.294841022629823\n",
      "RMSE, train 0.2847958217519041, test 0.28936847898044754\n",
      "RMSE, train 0.2817811712720036, test 0.28822056177471367\n",
      "RMSE, train 0.2802969791271068, test 0.2872735353718911\n",
      "RMSE, train 0.2794931058595383, test 0.28556965650724514\n",
      "RMSE, train 0.2784695002637917, test 0.28496191783675123\n",
      "RMSE, train 0.2779052661719665, test 0.2847622268434082\n",
      "RMSE, train 0.27736841778479887, test 0.2842811908839004\n",
      "RMSE, train 0.2769431685115777, test 0.2838364310030426\n",
      "RMSE, train 0.2768010719474365, test 0.28306213447025846\n",
      "RMSE, train 0.2764195286565357, test 0.2830242917739919\n",
      "RMSE, train 0.2761295963736141, test 0.2824835285012211\n",
      "RMSE, train 0.27597925540928225, test 0.28248785915119307\n",
      "RMSE, train 0.275705043104739, test 0.2826565891238196\n",
      "RMSE, train 0.27549622823080466, test 0.281974672872041\n",
      "RMSE, train 0.27546257829224624, test 0.2818581960829241\n",
      "RMSE, train 0.2750838129154218, test 0.2825216367574675\n",
      "RMSE, train 0.27497868178197243, test 0.2813569964574916\n",
      "RMSE, train 0.27478949874964154, test 0.281282456059541\n",
      "RMSE, train 0.27462902658645366, test 0.28099790601325886\n",
      "RMSE, train 0.27439765622413237, test 0.2815128208271095\n",
      "RMSE, train 0.2742465021888155, test 0.2808516902316894\n",
      "RMSE, train 0.2740790679369097, test 0.2807910689818008\n",
      "RMSE, train 0.27398957123813544, test 0.2799666438783918\n",
      "RMSE, train 0.27400201578545413, test 0.2803499453834125\n",
      "RMSE, train 0.27396909944502096, test 0.28020434866526295\n",
      "RMSE, train 0.2736266121950025, test 0.2804996561525123\n",
      "RMSE, train 0.2736085084853349, test 0.27988097524004324\n",
      "RMSE, train 0.27357703765493074, test 0.28017028979957104\n",
      "RMSE, train 0.2735185284565217, test 0.27993014601192306\n",
      "RMSE, train 0.27344936177881196, test 0.27959365690393106\n",
      "RMSE, train 0.2733671539229765, test 0.27990190046174185\n",
      "RMSE, train 0.27331393798062487, test 0.27994617726653814\n",
      "RMSE, train 0.27323838097727116, test 0.28025538394493715\n",
      "RMSE, train 0.27328585558986873, test 0.28001240521137205\n",
      "RMSE, train 0.2733061226299905, test 0.27963883243501186\n",
      "RMSE, train 0.27312778735082915, test 0.27988795270877226\n",
      "RMSE, train 0.2730343210671203, test 0.28037998931748526\n",
      "RMSE, train 0.2729914879227516, test 0.2793370076854314\n",
      "RMSE, train 0.27313133804756573, test 0.27916200139692854\n",
      "RMSE, train 0.2729855256727318, test 0.2797528182023338\n",
      "RMSE, train 0.27303275764637785, test 0.27989857111658367\n",
      "RMSE, train 0.27299726395695295, test 0.2797726198498692\n",
      "RMSE, train 0.2729649597328473, test 0.2792594406221594\n",
      "RMSE, train 0.2730575384073008, test 0.2796916006399052\n",
      "RMSE, train 0.27283981059371515, test 0.27943133749067783\n",
      "RMSE, train 0.27289275860734497, test 0.27915935923478435\n",
      "RMSE, train 0.272954416950284, test 0.27925682107784916\n",
      "RMSE, train 0.27281017082059567, test 0.2791769046868597\n",
      "RMSE, train 0.2728104800765031, test 0.2793368705149208\n",
      "RMSE, train 0.2728988218216595, test 0.2791774541671787\n",
      "RMSE, train 0.2728396571994088, test 0.2793136600937162\n",
      "RMSE, train 0.27297998948554325, test 0.2793130118932043\n",
      "RMSE, train 0.2728617542579543, test 0.27984831255993675\n",
      "RMSE, train 0.27270619834170623, test 0.27867464468415293\n",
      "RMSE, train 0.27279180061063996, test 0.2792186848819256\n",
      "RMSE, train 0.27285448314057975, test 0.2796592756307551\n",
      "RMSE, train 0.27283846978138737, test 0.27925318027181284\n",
      "RMSE, train 0.27269865838660656, test 0.2791572463299547\n",
      "RMSE, train 0.2726525046531931, test 0.27889476330684765\n",
      "RMSE, train 0.27271092275648595, test 0.2792851938200848\n",
      "RMSE, train 0.2727008203210914, test 0.27906790947807686\n",
      "RMSE, train 0.27268073621788314, test 0.2793631592233266\n",
      "RMSE, train 0.27264972995309267, test 0.27889977688235895\n",
      "RMSE, train 0.27265631217582553, test 0.27899825014173985\n",
      "Early stopping at epoch 66 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.5372788806199493, test 0.2776930354057102\n",
      "RMSE, train 0.26377907622555447, test 0.2705928747533658\n",
      "RMSE, train 0.2608510852194153, test 0.26909033174908487\n",
      "RMSE, train 0.25969941750369263, test 0.2681657112793091\n",
      "RMSE, train 0.2589891356470339, test 0.26692664541235755\n",
      "RMSE, train 0.25846534833779783, test 0.26690120707958115\n",
      "RMSE, train 0.2580057462769239, test 0.2663527049055887\n",
      "RMSE, train 0.2576165176226419, test 0.26669281803139855\n",
      "RMSE, train 0.2574172559206796, test 0.26629717839420386\n",
      "RMSE, train 0.25720943908119415, test 0.2654489407298762\n",
      "RMSE, train 0.2569815168332626, test 0.26528537710872263\n",
      "RMSE, train 0.25677295971344405, test 0.2652270839028402\n",
      "RMSE, train 0.2566348237774832, test 0.2648738238516204\n",
      "RMSE, train 0.2564902441918583, test 0.26550446409697925\n",
      "RMSE, train 0.2563962498387414, test 0.2653048069925483\n",
      "RMSE, train 0.2562542278737231, test 0.26513575167830933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.256204286932678, test 0.2648540707903171\n",
      "RMSE, train 0.2560969392347229, test 0.2644146807970257\n",
      "RMSE, train 0.2560406281140888, test 0.2648046232691599\n",
      "RMSE, train 0.2559713443298511, test 0.26554377787156935\n",
      "RMSE, train 0.2559173392140277, test 0.26445986467217086\n",
      "RMSE, train 0.25579295805216906, test 0.2649466694768416\n",
      "RMSE, train 0.2558070312968284, test 0.2650635539118303\n",
      "RMSE, train 0.2557556170786443, test 0.26477014512643904\n",
      "RMSE, train 0.25570641314368614, test 0.2643204450333884\n",
      "RMSE, train 0.25566890010518345, test 0.2640365669760135\n",
      "RMSE, train 0.25563949851043555, test 0.2644423992808806\n",
      "RMSE, train 0.25557062965337474, test 0.2642767991221279\n",
      "RMSE, train 0.25565739731083004, test 0.264261660909434\n",
      "RMSE, train 0.2555187605154354, test 0.2642465222866163\n",
      "RMSE, train 0.25545955696581724, test 0.26425457028074\n",
      "RMSE, train 0.2554479625928028, test 0.2643696515385164\n",
      "RMSE, train 0.25546956476609267, test 0.2645891251367167\n",
      "RMSE, train 0.25539335154097176, test 0.2647686667671991\n",
      "RMSE, train 0.2553642413875447, test 0.26408682558514657\n",
      "RMSE, train 0.255377016092897, test 0.2637877004955887\n",
      "RMSE, train 0.25530160372166355, test 0.2645442943780794\n",
      "RMSE, train 0.25540084655776685, test 0.2640712280339057\n",
      "RMSE, train 0.2553795432763784, test 0.2643536292358276\n",
      "RMSE, train 0.25530301896445956, test 0.2648303715187475\n",
      "RMSE, train 0.25520528408577625, test 0.26375522895143666\n",
      "RMSE, train 0.25529336718834034, test 0.2643256175135254\n",
      "RMSE, train 0.2552704555504525, test 0.2643535931449418\n",
      "RMSE, train 0.25520329294316974, test 0.2639468649932004\n",
      "RMSE, train 0.25516696578317694, test 0.2639237065380866\n",
      "RMSE, train 0.2551889696196056, test 0.26459374271948405\n",
      "RMSE, train 0.25518284677924596, test 0.2640914297705397\n",
      "RMSE, train 0.25515975519146084, test 0.26472199250251877\n",
      "RMSE, train 0.2551179832607641, test 0.26410293825175785\n",
      "RMSE, train 0.2550698089091767, test 0.26395822377926714\n",
      "RMSE, train 0.25508652022734885, test 0.26416941862040705\n",
      "Early stopping at epoch 51 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.7075523132383116, test 0.48230802897110725\n",
      "RMSE, train 0.35487582738071044, test 0.27470672550131975\n",
      "RMSE, train 0.25728630127646296, test 0.2687800594614547\n",
      "RMSE, train 0.2538093699766168, test 0.2669762351269861\n",
      "RMSE, train 0.25323718021714486, test 0.2653627242278127\n",
      "RMSE, train 0.25274923472109995, test 0.2655174353169006\n",
      "RMSE, train 0.25239572293543194, test 0.2642304755530311\n",
      "RMSE, train 0.25222301886653675, test 0.2650689219386832\n",
      "RMSE, train 0.25190939809109425, test 0.26311841722830986\n",
      "RMSE, train 0.2517519398214132, test 0.26551120098933434\n",
      "RMSE, train 0.25160350659397607, test 0.2645485391026562\n",
      "RMSE, train 0.25139393284032013, test 0.2631754216927927\n",
      "RMSE, train 0.25135724880066734, test 0.26246259368739083\n",
      "RMSE, train 0.2512315649742752, test 0.2636156372942971\n",
      "RMSE, train 0.25110734769114407, test 0.2631222132629561\n",
      "RMSE, train 0.2510009361276151, test 0.26332554741970543\n",
      "RMSE, train 0.25087075282304133, test 0.2629915160461537\n",
      "RMSE, train 0.25083089529618513, test 0.26271142195729374\n",
      "RMSE, train 0.25072458506763123, test 0.2632191819184035\n",
      "RMSE, train 0.25077053465639326, test 0.26269727959794903\n",
      "RMSE, train 0.2506010830756321, test 0.2625652660154602\n",
      "RMSE, train 0.25056492829266186, test 0.2622742422865432\n",
      "RMSE, train 0.2505180394706137, test 0.2615295100269966\n",
      "RMSE, train 0.25047684873226417, test 0.26237946719799227\n",
      "RMSE, train 0.25046148744020214, test 0.2632818291488203\n",
      "RMSE, train 0.25036339383935136, test 0.26206158882784614\n",
      "RMSE, train 0.25029822054923007, test 0.2621545707716525\n",
      "RMSE, train 0.25025024263281154, test 0.26238871850435014\n",
      "RMSE, train 0.2502515277075371, test 0.2622379709794683\n",
      "RMSE, train 0.250139442730403, test 0.26179654303106287\n",
      "RMSE, train 0.25017331055677416, test 0.2619664431775658\n",
      "RMSE, train 0.2500872735880899, test 0.26170701150176595\n",
      "RMSE, train 0.25009739321088, test 0.26240986802624267\n",
      "Early stopping at epoch 33 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.5348698835809919, test 0.3095241841342714\n",
      "RMSE, train 0.2715606736847654, test 0.2914342216319508\n",
      "RMSE, train 0.26295403859043376, test 0.2828320695294274\n",
      "RMSE, train 0.2576314080355945, test 0.274335621131791\n",
      "RMSE, train 0.25341079345931905, test 0.27019474489821327\n",
      "RMSE, train 0.25019616302293585, test 0.26664350794421304\n",
      "RMSE, train 0.24812080411898157, test 0.2623243197798729\n",
      "RMSE, train 0.24703077204786542, test 0.26089781191613937\n",
      "RMSE, train 0.2463727765729164, test 0.26156476736068723\n",
      "RMSE, train 0.2459499766884467, test 0.2598966939581765\n",
      "RMSE, train 0.2456145293388084, test 0.2592454562584559\n",
      "RMSE, train 0.2453443128866648, test 0.2581844314932823\n",
      "RMSE, train 0.24519504261306033, test 0.258643770383464\n",
      "RMSE, train 0.24499950511757576, test 0.25838532365030714\n",
      "RMSE, train 0.24483801621311116, test 0.25835636506477994\n",
      "RMSE, train 0.24473880906150025, test 0.25899070137076907\n",
      "RMSE, train 0.2446474333336411, test 0.25887092798948286\n",
      "RMSE, train 0.24447752149760563, test 0.25782946480645075\n",
      "RMSE, train 0.24439308280250777, test 0.25762578083409204\n",
      "RMSE, train 0.2443348000232743, test 0.25740487972895304\n",
      "RMSE, train 0.2442651448063452, test 0.2586383099357287\n",
      "RMSE, train 0.24417103152230102, test 0.2581479084160593\n",
      "RMSE, train 0.24407449179903837, test 0.2571486069096459\n",
      "RMSE, train 0.24397693658774755, test 0.257940867708789\n",
      "RMSE, train 0.24386107017891104, test 0.2568525758054521\n",
      "RMSE, train 0.24381940560842139, test 0.2574301802449756\n",
      "RMSE, train 0.24386865635605834, test 0.25652723064025246\n",
      "RMSE, train 0.2436977876726829, test 0.2574944549136692\n",
      "RMSE, train 0.24366250369105377, test 0.25718675471014446\n",
      "RMSE, train 0.2436505806333614, test 0.2571395729978879\n",
      "RMSE, train 0.2435809014380139, test 0.25708138230774136\n",
      "RMSE, train 0.24351890742618118, test 0.257313121524122\n",
      "RMSE, train 0.2434874154486746, test 0.2566458836197853\n",
      "RMSE, train 0.24352289306506955, test 0.25780191504293015\n",
      "RMSE, train 0.243394062766489, test 0.25674373159805935\n",
      "RMSE, train 0.24346400343504235, test 0.2570437384976281\n",
      "RMSE, train 0.24334108006118765, test 0.25640140142705703\n",
      "RMSE, train 0.243209808542722, test 0.2570373836490843\n",
      "RMSE, train 0.243261728164642, test 0.2572611568702592\n",
      "RMSE, train 0.24324513325151406, test 0.2567635413673189\n",
      "RMSE, train 0.24318746234368122, test 0.25808805922667183\n",
      "RMSE, train 0.2431167911165808, test 0.2571277954512172\n",
      "RMSE, train 0.24322745127658638, test 0.25631730208794273\n",
      "RMSE, train 0.24322154045586958, test 0.2564612138602469\n",
      "RMSE, train 0.24295123282950523, test 0.2562660758694013\n",
      "RMSE, train 0.24297825755134747, test 0.25797200914886265\n",
      "RMSE, train 0.2430633033382282, test 0.2561372167534298\n",
      "RMSE, train 0.24292688963387532, test 0.2562594387266371\n",
      "RMSE, train 0.24301447986431843, test 0.25641419457064735\n",
      "RMSE, train 0.24290457239369498, test 0.25664522929324046\n",
      "RMSE, train 0.2428910607356588, test 0.25681601381964153\n",
      "RMSE, train 0.2427495503521994, test 0.2563523726330863\n",
      "RMSE, train 0.24281559964877897, test 0.25624448508024217\n",
      "RMSE, train 0.2428097164614824, test 0.2557041625181834\n",
      "RMSE, train 0.24275510551312543, test 0.2556435907880465\n",
      "RMSE, train 0.24273451548220334, test 0.25672988080316117\n",
      "RMSE, train 0.24273279369520048, test 0.25813886771599454\n",
      "RMSE, train 0.2426791152141165, test 0.25661737968524295\n",
      "RMSE, train 0.2426125030070945, test 0.25630799531936643\n",
      "RMSE, train 0.24261612487289141, test 0.25671197457445993\n",
      "RMSE, train 0.24264937438412176, test 0.25592714349428813\n",
      "RMSE, train 0.24258644722221354, test 0.2572597309947014\n",
      "RMSE, train 0.24254119159237073, test 0.2565428872903188\n",
      "RMSE, train 0.24245521478415177, test 0.25637026329835255\n",
      "RMSE, train 0.24249426570703397, test 0.2561408074365722\n",
      "Early stopping at epoch 65 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7273041704318925, test 0.6426009475582778\n",
      "RMSE, train 0.4274578530222979, test 0.33497381691980843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.3114835037724605, test 0.32411936647964246\n",
      "RMSE, train 0.3071487032988252, test 0.32354156928833083\n",
      "RMSE, train 0.306268616672833, test 0.321718355922988\n",
      "RMSE, train 0.305256084154171, test 0.3208273607071\n",
      "RMSE, train 0.304515059864317, test 0.3187570177545451\n",
      "RMSE, train 0.3039465738610708, test 0.31849795399290143\n",
      "RMSE, train 0.30342326577397605, test 0.3186050626364621\n",
      "RMSE, train 0.303320245229819, test 0.3171596813081491\n",
      "RMSE, train 0.3029258763440372, test 0.3170742838069646\n",
      "RMSE, train 0.3025314024578971, test 0.31694529484016726\n",
      "RMSE, train 0.3023326897169384, test 0.3170740721803723\n",
      "RMSE, train 0.3019936210077374, test 0.31590038778805973\n",
      "RMSE, train 0.30195185359940846, test 0.3153098449863569\n",
      "RMSE, train 0.3020912304265575, test 0.3157163885506717\n",
      "RMSE, train 0.30140321969548767, test 0.315991908913911\n",
      "RMSE, train 0.3011938353185257, test 0.315001596104015\n",
      "RMSE, train 0.30109404927360983, test 0.31530720010550334\n",
      "RMSE, train 0.30101449412355213, test 0.31463395284883905\n",
      "RMSE, train 0.3008238736239506, test 0.3151334120769693\n",
      "RMSE, train 0.30077495886818995, test 0.31495584171227736\n",
      "RMSE, train 0.3005190559806334, test 0.3142283290925652\n",
      "RMSE, train 0.30073887375718517, test 0.31388629145092434\n",
      "RMSE, train 0.3008367312493709, test 0.31388971630973045\n",
      "RMSE, train 0.3003670536801401, test 0.3147265465572627\n",
      "RMSE, train 0.30028324674423285, test 0.31344081235654425\n",
      "RMSE, train 0.3002983013254506, test 0.31404486539387944\n",
      "RMSE, train 0.3001804718688531, test 0.3139467919715727\n",
      "RMSE, train 0.30006916831932906, test 0.31405135206501894\n",
      "RMSE, train 0.2999316063734605, test 0.3133274795431079\n",
      "RMSE, train 0.3002307437597102, test 0.31517336585304956\n",
      "RMSE, train 0.3001299493178762, test 0.31336657221269126\n",
      "RMSE, train 0.29989136023160007, test 0.31371187636948594\n",
      "RMSE, train 0.29985271186583784, test 0.3131884387647263\n",
      "RMSE, train 0.29980196791056607, test 0.3139790519319399\n",
      "RMSE, train 0.29969956315962787, test 0.31386374599403805\n",
      "RMSE, train 0.29979502196562613, test 0.3138997359107239\n",
      "RMSE, train 0.29972750422132627, test 0.3140341049492961\n",
      "RMSE, train 0.2998981048469147, test 0.31351384339910565\n",
      "RMSE, train 0.29988987751141155, test 0.31350406116307383\n",
      "RMSE, train 0.2997853265924967, test 0.3137255810727977\n",
      "RMSE, train 0.29978000975616986, test 0.31315073340830174\n",
      "RMSE, train 0.2998234241982253, test 0.3133803154482986\n",
      "RMSE, train 0.2996038394117122, test 0.3134802602457278\n",
      "RMSE, train 0.29958827002998667, test 0.3132841590076986\n",
      "RMSE, train 0.2996220068418601, test 0.3135752200779289\n",
      "RMSE, train 0.2995405711579731, test 0.31364819557979856\n",
      "RMSE, train 0.29961753474471037, test 0.3123929374145739\n",
      "RMSE, train 0.29943786036851644, test 0.31325717345632687\n",
      "RMSE, train 0.29958418080888344, test 0.3132958875762092\n",
      "RMSE, train 0.2994415493713906, test 0.3129254189705608\n",
      "RMSE, train 0.2995354466158487, test 0.3129846152633127\n",
      "RMSE, train 0.29942582984862526, test 0.31286862041011\n",
      "RMSE, train 0.2994027703198944, test 0.3128275762904774\n",
      "RMSE, train 0.2994458066222137, test 0.3131637519056147\n",
      "RMSE, train 0.2993793083140786, test 0.31292742550975144\n",
      "RMSE, train 0.29937986727157256, test 0.313050100899706\n",
      "RMSE, train 0.29925891170437585, test 0.3125195756103053\n",
      "Early stopping at epoch 59 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.6656262692477968, test 0.4204332356651624\n",
      "RMSE, train 0.31015808714760673, test 0.30459608960275847\n",
      "RMSE, train 0.2886856734903172, test 0.30421726653973263\n",
      "RMSE, train 0.2874884726197431, test 0.3035224803412954\n",
      "RMSE, train 0.2867227577500873, test 0.3020879381025831\n",
      "RMSE, train 0.28609093820506876, test 0.3010215430210034\n",
      "RMSE, train 0.28559901320723574, test 0.3016228621515135\n",
      "RMSE, train 0.2851265301608076, test 0.3014395927699904\n",
      "RMSE, train 0.2848833010654257, test 0.30083679671709734\n",
      "RMSE, train 0.28457514121375904, test 0.3002296187914908\n",
      "RMSE, train 0.28432528629447473, test 0.2991953329183161\n",
      "RMSE, train 0.2841769669092063, test 0.29961112840101123\n",
      "RMSE, train 0.283951254768504, test 0.29893465572968125\n",
      "RMSE, train 0.28368427024947274, test 0.29959868763883907\n",
      "RMSE, train 0.2836375204150123, test 0.299479757125179\n",
      "RMSE, train 0.283433653527137, test 0.2993995180974404\n",
      "RMSE, train 0.28337983994020355, test 0.29959539386133355\n",
      "RMSE, train 0.2831586076304166, test 0.29892036753396195\n",
      "RMSE, train 0.28307836988207064, test 0.29910084418952465\n",
      "RMSE, train 0.2830362088150448, test 0.29999913725381094\n",
      "RMSE, train 0.2829019412247821, test 0.2987853159817557\n",
      "RMSE, train 0.2828114115905882, test 0.2988965723974009\n",
      "RMSE, train 0.2827205823527442, test 0.29899002859989804\n",
      "RMSE, train 0.2826240616239081, test 0.29821263486519456\n",
      "RMSE, train 0.28261926615930566, test 0.2981732136880358\n",
      "RMSE, train 0.2825151062523476, test 0.2996836492481331\n",
      "RMSE, train 0.28248847008805084, test 0.29876041086390615\n",
      "RMSE, train 0.28240210073764876, test 0.298555963827918\n",
      "RMSE, train 0.28240393911196726, test 0.299350898557653\n",
      "RMSE, train 0.2822844843295487, test 0.2990381469329198\n",
      "RMSE, train 0.2822066956397259, test 0.29827899967009824\n",
      "RMSE, train 0.2821780522212838, test 0.2979689611432453\n",
      "RMSE, train 0.2821318733722273, test 0.299284834569941\n",
      "RMSE, train 0.28214857027386175, test 0.2981851956186195\n",
      "RMSE, train 0.2820112556219101, test 0.2982302925859888\n",
      "RMSE, train 0.2818808661717357, test 0.2984519250070055\n",
      "RMSE, train 0.28196588312887183, test 0.2982763615436852\n",
      "RMSE, train 0.2819022684160507, test 0.29889948867882293\n",
      "RMSE, train 0.28193620377869316, test 0.29891562601551414\n",
      "RMSE, train 0.28191954492017474, test 0.29855819201717776\n",
      "RMSE, train 0.28179145852724713, test 0.2985953163976471\n",
      "RMSE, train 0.2817923093233446, test 0.29832809294263524\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.5525839087776739, test 0.31313013169500564\n",
      "RMSE, train 0.28800875342117166, test 0.3071133820546998\n",
      "RMSE, train 0.28285039824777536, test 0.3033468458387587\n",
      "RMSE, train 0.2810110129275412, test 0.3027562661303414\n",
      "RMSE, train 0.2800981333715254, test 0.3014085627264447\n",
      "RMSE, train 0.2793678690722047, test 0.3011106236113442\n",
      "RMSE, train 0.27872199394471564, test 0.3003006264567375\n",
      "RMSE, train 0.2783092650763108, test 0.2989120692014694\n",
      "RMSE, train 0.27791581148246547, test 0.30100125273068745\n",
      "RMSE, train 0.27765629145334353, test 0.3000218755669064\n",
      "RMSE, train 0.2773813263505617, test 0.2986249445213212\n",
      "RMSE, train 0.2771319505178703, test 0.2985176258616977\n",
      "RMSE, train 0.27701509902580085, test 0.2988377559516165\n",
      "RMSE, train 0.27682747886669284, test 0.29741721351941425\n",
      "RMSE, train 0.27662763393150186, test 0.2965541558133231\n",
      "RMSE, train 0.2765663433669391, test 0.2979657193024953\n",
      "RMSE, train 0.2764779587961593, test 0.29709940354029335\n",
      "RMSE, train 0.27636245965475664, test 0.29725550380018023\n",
      "RMSE, train 0.2762689642668413, test 0.29748124281565347\n",
      "RMSE, train 0.27610819057794916, test 0.2989471054739422\n",
      "RMSE, train 0.27606857076006114, test 0.29714187218083277\n",
      "RMSE, train 0.275991414876961, test 0.2966701438029607\n",
      "RMSE, train 0.27602026669805585, test 0.2966200335158242\n",
      "RMSE, train 0.2758560270231689, test 0.29765482213762073\n",
      "RMSE, train 0.2757609231533066, test 0.2972472815050019\n",
      "Early stopping at epoch 25 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.5563869125375124, test 0.3537910660872093\n",
      "RMSE, train 0.3071332004304244, test 0.3298260046121402\n",
      "RMSE, train 0.2920290331509997, test 0.31762018627845323\n",
      "RMSE, train 0.2859979458501406, test 0.31588115638647324\n",
      "RMSE, train 0.28235215487138504, test 0.30964183463500095\n",
      "RMSE, train 0.27933165746685873, test 0.3048464866020741\n",
      "RMSE, train 0.2770452977990807, test 0.3036225012097603\n",
      "RMSE, train 0.27487194663453324, test 0.299951766928037\n",
      "RMSE, train 0.2734984500200206, test 0.2992323254927611\n",
      "RMSE, train 0.27242914338906604, test 0.2978029308410791\n",
      "RMSE, train 0.2717362746271389, test 0.30196467156593615\n",
      "RMSE, train 0.2712885072205297, test 0.29634104153284657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2708552136228092, test 0.2954725086306914\n",
      "RMSE, train 0.27060740898331376, test 0.296379865362094\n",
      "RMSE, train 0.2703448917914031, test 0.29433396764290637\n",
      "RMSE, train 0.27011720190909794, test 0.2940552706519763\n",
      "RMSE, train 0.27000775171960256, test 0.29507806438666123\n",
      "RMSE, train 0.26984197374816254, test 0.294351142568466\n",
      "RMSE, train 0.2697328321658934, test 0.29522852523204607\n",
      "RMSE, train 0.26948902660812546, test 0.29797041951081693\n",
      "RMSE, train 0.2695050845357859, test 0.294469011708712\n",
      "RMSE, train 0.2692639779914577, test 0.2955810565214891\n",
      "RMSE, train 0.2691223548487339, test 0.2945122118943777\n",
      "RMSE, train 0.26900191502964754, test 0.2933148592710495\n",
      "RMSE, train 0.26892973617229876, test 0.29483156899611157\n",
      "RMSE, train 0.2688085879677924, test 0.29414767237045825\n",
      "RMSE, train 0.26871505258982054, test 0.2940593761129257\n",
      "RMSE, train 0.2686228373340357, test 0.294051720163761\n",
      "RMSE, train 0.26846538836896605, test 0.2950111012428235\n",
      "RMSE, train 0.26846395432949066, test 0.29452348462282085\n",
      "RMSE, train 0.2683201338921752, test 0.2941508751649123\n",
      "RMSE, train 0.26821818961718374, test 0.2926577948606931\n",
      "RMSE, train 0.2680672428039747, test 0.2950414839463356\n",
      "RMSE, train 0.2678898098034279, test 0.29349640565804946\n",
      "RMSE, train 0.267989241909758, test 0.2966083013094388\n",
      "RMSE, train 0.2678058617675787, test 0.2933614760255202\n",
      "RMSE, train 0.26768856256550344, test 0.29396078544549453\n",
      "RMSE, train 0.2675242693717606, test 0.29538847563358456\n",
      "RMSE, train 0.2674969486265539, test 0.29436352390509385\n",
      "RMSE, train 0.2674909139812178, test 0.2949384557895171\n",
      "RMSE, train 0.26736742959029947, test 0.2928316264580458\n",
      "RMSE, train 0.26725854504145563, test 0.2937545596789091\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "output_sizes = [1,5,10,20,40]\n",
    "input_sizes = [5,10,20,40]\n",
    "\n",
    "\n",
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.CNN, data_dir = 'data_synthetic')\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/cnn/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ab3b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9644330839512376, test 0.847439190072398\n",
      "RMSE, train 0.7018526143177225, test 0.5032935421313008\n",
      "RMSE, train 0.3989692619254467, test 0.3162067985582736\n",
      "RMSE, train 0.2941823287060845, test 0.27803419266016255\n",
      "RMSE, train 0.26737444585726666, test 0.2667120897000836\n",
      "RMSE, train 0.25847135202981264, test 0.26358341305486616\n",
      "RMSE, train 0.2555308881778962, test 0.26096935101574464\n",
      "RMSE, train 0.2543625642247351, test 0.2601591121525534\n",
      "RMSE, train 0.25380279870313616, test 0.2603211922030295\n",
      "RMSE, train 0.2533398568777463, test 0.2596506977513913\n",
      "RMSE, train 0.2530435624388838, test 0.2594997612459044\n",
      "RMSE, train 0.25275748716335994, test 0.25878788470741243\n",
      "RMSE, train 0.2525487185967534, test 0.25902289849135185\n",
      "RMSE, train 0.2523857262795386, test 0.2586086456093096\n",
      "RMSE, train 0.2522539735399923, test 0.25819438719941723\n",
      "RMSE, train 0.2519237926678931, test 0.259208157298065\n",
      "RMSE, train 0.2519041720203496, test 0.25791885944143417\n",
      "RMSE, train 0.25176297976329864, test 0.2576933476112543\n",
      "RMSE, train 0.25165807890149916, test 0.2582938909049957\n",
      "RMSE, train 0.2516138484119898, test 0.25723914237272355\n",
      "RMSE, train 0.2514989356190084, test 0.25746408345237853\n",
      "RMSE, train 0.2515040681119493, test 0.2576954858678003\n",
      "RMSE, train 0.25139375321066426, test 0.2575923068028304\n",
      "RMSE, train 0.25130694823361666, test 0.25794539979148295\n",
      "RMSE, train 0.2511701358136217, test 0.2572710478017407\n",
      "RMSE, train 0.25117494167369814, test 0.25724989908837503\n",
      "RMSE, train 0.25114536931804515, test 0.2578417421468804\n",
      "RMSE, train 0.25104921467219415, test 0.25705579632232267\n",
      "RMSE, train 0.2509419396077927, test 0.25698145815441686\n",
      "RMSE, train 0.25086093607097276, test 0.25671339221298695\n",
      "RMSE, train 0.25079950510630966, test 0.2564584800312596\n",
      "RMSE, train 0.25076812043373764, test 0.2576219518819163\n",
      "RMSE, train 0.2508661723419612, test 0.2579496358671496\n",
      "RMSE, train 0.2507702596485615, test 0.2566019386173256\n",
      "RMSE, train 0.2506069473539416, test 0.25714265777459067\n",
      "RMSE, train 0.25070627403294615, test 0.256781717942607\n",
      "RMSE, train 0.2506275193493357, test 0.2565223798756638\n",
      "RMSE, train 0.2506598982621323, test 0.25680765281281165\n",
      "RMSE, train 0.2505838405856266, test 0.2569842876926545\n",
      "RMSE, train 0.25062595982207614, test 0.256269451711447\n",
      "RMSE, train 0.25061867562796286, test 0.2561781163657865\n",
      "RMSE, train 0.2504723894119027, test 0.2562491069397619\n",
      "RMSE, train 0.2506019222612673, test 0.25661264371968084\n",
      "RMSE, train 0.2504619317563626, test 0.2557970543181704\n",
      "RMSE, train 0.25046871040060587, test 0.2562085123912942\n",
      "RMSE, train 0.25038906522536936, test 0.2563803528826083\n",
      "RMSE, train 0.25036832691711397, test 0.2557819954329921\n",
      "RMSE, train 0.2504579756600348, test 0.2578638770407246\n",
      "RMSE, train 0.2503065111873885, test 0.2560413471393047\n",
      "RMSE, train 0.25035191110883775, test 0.2562908948429169\n",
      "RMSE, train 0.2503135270133556, test 0.25606814495498137\n",
      "RMSE, train 0.25032912452407036, test 0.2573376219839819\n",
      "RMSE, train 0.25027412583999953, test 0.2558137952920891\n",
      "RMSE, train 0.2503061079872927, test 0.2561405036718615\n",
      "RMSE, train 0.25030702139019023, test 0.25789072677012415\n",
      "RMSE, train 0.25022770757437224, test 0.2562386803328991\n",
      "RMSE, train 0.2502883118338029, test 0.2565947150991809\n",
      "Early stopping at epoch 57 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9725702345853875, test 0.807531193760801\n",
      "RMSE, train 0.6041693515200847, test 0.4074504811409091\n",
      "RMSE, train 0.30388398100490027, test 0.2625510041132446\n",
      "RMSE, train 0.24528062661830713, test 0.24686760720142648\n",
      "RMSE, train 0.2393827840746173, test 0.2421780840670767\n",
      "RMSE, train 0.23739073840290428, test 0.24017324421770317\n",
      "RMSE, train 0.23668012666979782, test 0.24015022906636405\n",
      "RMSE, train 0.23571466265419716, test 0.2386529372989639\n",
      "RMSE, train 0.23540677160386614, test 0.23838718888188196\n",
      "RMSE, train 0.23505489979135363, test 0.23847368408825773\n",
      "RMSE, train 0.2347625297181278, test 0.2378475598929342\n",
      "RMSE, train 0.23474692989155832, test 0.23817751618209948\n",
      "RMSE, train 0.2345187015348842, test 0.2383069298730409\n",
      "RMSE, train 0.2340842049704631, test 0.23844087474848613\n",
      "RMSE, train 0.233952295155781, test 0.23822508413683285\n",
      "RMSE, train 0.23391948748937985, test 0.2373664702388866\n",
      "RMSE, train 0.23412221641494677, test 0.23827388032901387\n",
      "RMSE, train 0.2339093894037882, test 0.23846830821726933\n",
      "RMSE, train 0.23359905528696442, test 0.23805830837034983\n",
      "RMSE, train 0.23344192088313914, test 0.23821959823123678\n",
      "RMSE, train 0.2331237601877948, test 0.2373440875864226\n",
      "RMSE, train 0.23321727854821847, test 0.2373806334847261\n",
      "RMSE, train 0.23318038903448263, test 0.23830555976668666\n",
      "RMSE, train 0.2333062260679388, test 0.2394995539148977\n",
      "RMSE, train 0.23334391181345893, test 0.23837211253968152\n",
      "RMSE, train 0.23310974650537436, test 0.23712467285227184\n",
      "RMSE, train 0.23308689206054337, test 0.23685974744725818\n",
      "RMSE, train 0.23284612593018575, test 0.2376653682594457\n",
      "RMSE, train 0.23294774023627463, test 0.23708141084052314\n",
      "RMSE, train 0.23297468311933853, test 0.23753556190443434\n",
      "RMSE, train 0.23293889850860666, test 0.23798412127682\n",
      "RMSE, train 0.23295798535771697, test 0.23650383111859155\n",
      "RMSE, train 0.23273401717968314, test 0.23659467749482344\n",
      "RMSE, train 0.23286673058623727, test 0.23867380132606206\n",
      "RMSE, train 0.23304944486934165, test 0.23765156602810236\n",
      "RMSE, train 0.23289407151732366, test 0.23677221039109977\n",
      "RMSE, train 0.23298576011167846, test 0.2370261543176391\n",
      "RMSE, train 0.23266887811091747, test 0.23711745484062463\n",
      "RMSE, train 0.2329776784488064, test 0.2369717850911716\n",
      "RMSE, train 0.2327371769497993, test 0.23733289860004236\n",
      "RMSE, train 0.23332092105618374, test 0.23674629086797888\n",
      "RMSE, train 0.2326947514133656, test 0.23994996534152466\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.6957283886765112, test 0.37393396413117125\n",
      "RMSE, train 0.26927103891746323, test 0.2519514437830239\n",
      "RMSE, train 0.24090520465679005, test 0.24744629689998793\n",
      "RMSE, train 0.23818845293923482, test 0.24559336077225835\n",
      "RMSE, train 0.2365486016914026, test 0.2440402585555587\n",
      "RMSE, train 0.23539372312743018, test 0.24251861112159595\n",
      "RMSE, train 0.23427379372785848, test 0.24137831139459945\n",
      "RMSE, train 0.23349375287289303, test 0.24014273357757351\n",
      "RMSE, train 0.23261794020562793, test 0.23938615986129694\n",
      "RMSE, train 0.23218248026775146, test 0.23886238482960484\n",
      "RMSE, train 0.2318648369962981, test 0.23886373521466003\n",
      "RMSE, train 0.23117584511161104, test 0.23768317555649238\n",
      "RMSE, train 0.23085569725361968, test 0.23732226185108485\n",
      "RMSE, train 0.23057590339229558, test 0.23700401899323129\n",
      "RMSE, train 0.23015018482642896, test 0.2370462005859927\n",
      "RMSE, train 0.23046107714110092, test 0.2366127684843122\n",
      "RMSE, train 0.2299124123667603, test 0.23623320950489296\n",
      "RMSE, train 0.22951804563752623, test 0.23593951271552788\n",
      "RMSE, train 0.22933425714593453, test 0.2357202314101813\n",
      "RMSE, train 0.22956845013381066, test 0.23540618434025531\n",
      "RMSE, train 0.22892023767553157, test 0.23574123694969898\n",
      "RMSE, train 0.22892093497997662, test 0.23512542345806173\n",
      "RMSE, train 0.22883372204199529, test 0.23524874259243933\n",
      "RMSE, train 0.22873816804400385, test 0.23493505413072152\n",
      "RMSE, train 0.22890852571232742, test 0.2351721861775507\n",
      "RMSE, train 0.22858331076054175, test 0.2349690236804778\n",
      "RMSE, train 0.22850182314099535, test 0.23510066589765383\n",
      "RMSE, train 0.22856669604524113, test 0.2345419214352181\n",
      "RMSE, train 0.2283521446464921, test 0.23446419933124593\n",
      "RMSE, train 0.22843555400747734, test 0.2343236613169051\n",
      "RMSE, train 0.22825625928035423, test 0.2344815821239823\n",
      "RMSE, train 0.228068616137957, test 0.2342387246327442\n",
      "RMSE, train 0.22863079211922852, test 0.2341976913443783\n",
      "RMSE, train 0.22827681621064, test 0.23417036261474877\n",
      "RMSE, train 0.22816829826595433, test 0.23415811908872505\n",
      "RMSE, train 0.22802412865766838, test 0.23410144023466528\n",
      "RMSE, train 0.22786319143037553, test 0.2342690502603849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.22854355665475828, test 0.2343326066538953\n",
      "RMSE, train 0.22799166498471424, test 0.23413192742226416\n",
      "RMSE, train 0.2278644481955815, test 0.2348986977809354\n",
      "RMSE, train 0.22830981095589553, test 0.2340626901571165\n",
      "RMSE, train 0.22817207351803526, test 0.23394322924708066\n",
      "RMSE, train 0.22853707954255756, test 0.23388190090394856\n",
      "RMSE, train 0.22786381475325587, test 0.2343430387738504\n",
      "RMSE, train 0.2277207466076686, test 0.2339128315318049\n",
      "RMSE, train 0.2281259169488319, test 0.23407304469953505\n",
      "RMSE, train 0.22797569500675588, test 0.23394625437887093\n",
      "RMSE, train 0.22774719210194627, test 0.23393586578599193\n",
      "RMSE, train 0.22769948887799593, test 0.2338384861093864\n",
      "RMSE, train 0.22750601404384255, test 0.2338353761455469\n",
      "RMSE, train 0.22792691569020754, test 0.23387137329892108\n",
      "RMSE, train 0.2278112626787442, test 0.23421243852690646\n",
      "RMSE, train 0.22754160362456652, test 0.23389764777139613\n",
      "RMSE, train 0.22801503419939642, test 0.23380603758912338\n",
      "RMSE, train 0.227882467877509, test 0.2340825851679894\n",
      "RMSE, train 0.22748159410666302, test 0.23394029927358292\n",
      "RMSE, train 0.22773107066591666, test 0.23427292750331394\n",
      "RMSE, train 0.22761010980682334, test 0.23394662076443956\n",
      "RMSE, train 0.22734064308565055, test 0.23381706784691728\n",
      "RMSE, train 0.22724274248837917, test 0.23383798639763864\n",
      "RMSE, train 0.2273275832345745, test 0.23394130941545754\n",
      "RMSE, train 0.2277037625087858, test 0.23404427787713838\n",
      "RMSE, train 0.22724393215070146, test 0.2339960445176091\n",
      "RMSE, train 0.22744283049917424, test 0.23375592040911056\n",
      "RMSE, train 0.22762530969022943, test 0.23433252136435426\n",
      "RMSE, train 0.22743305765680158, test 0.23403716858541757\n",
      "RMSE, train 0.2274813216600591, test 0.23411097717389726\n",
      "RMSE, train 0.22759230895591442, test 0.23400838790755524\n",
      "RMSE, train 0.2274091553522834, test 0.23396991147545346\n",
      "RMSE, train 0.22702556526435336, test 0.23387446345990165\n",
      "RMSE, train 0.22716386394618926, test 0.2342294986572182\n",
      "RMSE, train 0.22728765595442196, test 0.23421944449083848\n",
      "RMSE, train 0.22718205368086727, test 0.23390966562325494\n",
      "RMSE, train 0.22733217927375074, test 0.23407624792634396\n",
      "Early stopping at epoch 74 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.8275419369090997, test 0.4930965020960453\n",
      "RMSE, train 0.31790790397469354, test 0.2667791245906961\n",
      "RMSE, train 0.2480183036771196, test 0.2614954321407804\n",
      "RMSE, train 0.2448955541365471, test 0.25715237702516947\n",
      "RMSE, train 0.24235145196425317, test 0.2539583875560293\n",
      "RMSE, train 0.23985743504862228, test 0.2502244477178536\n",
      "RMSE, train 0.23743278230929432, test 0.24739561361425064\n",
      "RMSE, train 0.23581968608861323, test 0.24829028386111354\n",
      "RMSE, train 0.2340925800345109, test 0.24397571611345983\n",
      "RMSE, train 0.2330861113129766, test 0.2426416035376343\n",
      "RMSE, train 0.23193550086746922, test 0.2399270647734988\n",
      "RMSE, train 0.23097977209347245, test 0.24005665732365028\n",
      "RMSE, train 0.2297751369546023, test 0.23859781932597066\n",
      "RMSE, train 0.22932259311681716, test 0.23679054528474808\n",
      "RMSE, train 0.22898555029548154, test 0.2365200233225729\n",
      "RMSE, train 0.22864346853446277, test 0.23740818804385616\n",
      "RMSE, train 0.22773067299321045, test 0.2369726292935072\n",
      "RMSE, train 0.227974220043435, test 0.23467300854185047\n",
      "RMSE, train 0.22749495250228483, test 0.23456117985587494\n",
      "RMSE, train 0.2273018558760816, test 0.23398425817197444\n",
      "RMSE, train 0.22682087023815847, test 0.2340476656807404\n",
      "RMSE, train 0.22689649909023454, test 0.23396762212117514\n",
      "RMSE, train 0.22654495214007636, test 0.2341076939129362\n",
      "RMSE, train 0.22621598043134503, test 0.23434260633646273\n",
      "RMSE, train 0.22623270643354884, test 0.2343644242660672\n",
      "RMSE, train 0.22634305703611532, test 0.23405708314157\n",
      "RMSE, train 0.22599655075047637, test 0.23306608105114862\n",
      "RMSE, train 0.22579515238152484, test 0.23417037199525273\n",
      "RMSE, train 0.22552450909890537, test 0.23407930734695173\n",
      "RMSE, train 0.22562622707470506, test 0.23304843383969046\n",
      "RMSE, train 0.22573925503185086, test 0.23321700578226762\n",
      "RMSE, train 0.22556159319911764, test 0.2329931881497888\n",
      "RMSE, train 0.22540094040174188, test 0.2328929275128187\n",
      "RMSE, train 0.22538780977589418, test 0.2327502770166771\n",
      "RMSE, train 0.22556309277516276, test 0.23184611436490918\n",
      "RMSE, train 0.22517094026744222, test 0.2328291249771913\n",
      "RMSE, train 0.22505114965478673, test 0.23309383439082726\n",
      "RMSE, train 0.22508943785061986, test 0.2330263777106416\n",
      "RMSE, train 0.22506785447884858, test 0.23218893632292747\n",
      "RMSE, train 0.22539239136728864, test 0.23237949565929525\n",
      "RMSE, train 0.22501063218833722, test 0.23279443806877323\n",
      "RMSE, train 0.22503231392911055, test 0.23294706153226832\n",
      "RMSE, train 0.2249747295297131, test 0.23363041965400472\n",
      "RMSE, train 0.2247985155457244, test 0.232512122714052\n",
      "RMSE, train 0.22480203769656526, test 0.23429986264775782\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9684782625446396, test 0.8884011285364135\n",
      "RMSE, train 0.7670613353050524, test 0.6015954931412847\n",
      "RMSE, train 0.45380739777559237, test 0.35658439353477855\n",
      "RMSE, train 0.31111726879833207, test 0.29191872600681523\n",
      "RMSE, train 0.27461099192019434, test 0.27254961677326645\n",
      "RMSE, train 0.26419266000870734, test 0.2669159698584848\n",
      "RMSE, train 0.2605735477540762, test 0.26414487701802214\n",
      "RMSE, train 0.25878331383630154, test 0.26276873938800877\n",
      "RMSE, train 0.25777875307586884, test 0.26170348924053605\n",
      "RMSE, train 0.2570595018745911, test 0.2608009810782661\n",
      "RMSE, train 0.2564831697832673, test 0.26027362775211493\n",
      "RMSE, train 0.2560880705413799, test 0.25973814553465724\n",
      "RMSE, train 0.25576303463669553, test 0.2596059287628852\n",
      "RMSE, train 0.25548319978218886, test 0.2592665815402654\n",
      "RMSE, train 0.25525872878009276, test 0.25888351517275343\n",
      "RMSE, train 0.255107905084808, test 0.25871181266366944\n",
      "RMSE, train 0.2549625424848449, test 0.2584670556724564\n",
      "RMSE, train 0.2548565841430137, test 0.2585134341204462\n",
      "RMSE, train 0.2547445750585006, test 0.25862255655536964\n",
      "RMSE, train 0.25466240609004615, test 0.2584060317228648\n",
      "RMSE, train 0.25451738231124416, test 0.258207460696047\n",
      "RMSE, train 0.25449894014145097, test 0.2581550885330547\n",
      "RMSE, train 0.25439325717067524, test 0.2579154176406624\n",
      "RMSE, train 0.2543147627204176, test 0.2578461372162685\n",
      "RMSE, train 0.2542303817707204, test 0.25801368230137944\n",
      "RMSE, train 0.2541951382712972, test 0.25795651935348823\n",
      "RMSE, train 0.25415102473550266, test 0.2576394925925357\n",
      "RMSE, train 0.25413395160989416, test 0.25782076423325817\n",
      "RMSE, train 0.25408747753188493, test 0.2577987915474521\n",
      "RMSE, train 0.25404354223921416, test 0.2578201287787808\n",
      "RMSE, train 0.2540058956571644, test 0.2576063509322395\n",
      "RMSE, train 0.2539776023477316, test 0.2574531791870259\n",
      "RMSE, train 0.2539657666798561, test 0.25744858679692606\n",
      "RMSE, train 0.2539315222492141, test 0.2575053108378875\n",
      "RMSE, train 0.25392872674931444, test 0.2574588397810282\n",
      "RMSE, train 0.2539051054345985, test 0.25742012816519777\n",
      "RMSE, train 0.25388715461257005, test 0.25750867012611106\n",
      "RMSE, train 0.25386209437443363, test 0.25745607789390346\n",
      "RMSE, train 0.2538534699067954, test 0.25765552377897843\n",
      "RMSE, train 0.2537800937951092, test 0.25742423485133276\n",
      "RMSE, train 0.2538042821050171, test 0.25757010515071144\n",
      "RMSE, train 0.2537952246024243, test 0.25753176975841363\n",
      "RMSE, train 0.25372705452384486, test 0.257464346683715\n",
      "RMSE, train 0.2537288222642195, test 0.2577293388360788\n",
      "RMSE, train 0.25372032616888324, test 0.2574971209872853\n",
      "RMSE, train 0.2537030545513957, test 0.2573126032332744\n",
      "RMSE, train 0.253679366211497, test 0.25751618351325517\n",
      "RMSE, train 0.2536933312733327, test 0.25738950209184125\n",
      "RMSE, train 0.2536454640268799, test 0.2574267468669198\n",
      "RMSE, train 0.2536697657478432, test 0.2573675737400685\n",
      "RMSE, train 0.2536670810452873, test 0.2574015961698264\n",
      "RMSE, train 0.2536191740223477, test 0.2575779533829571\n",
      "RMSE, train 0.25363051038115253, test 0.25735210929035157\n",
      "RMSE, train 0.2536809361810165, test 0.2574750484267542\n",
      "RMSE, train 0.25364798304414554, test 0.2572663069263963\n",
      "RMSE, train 0.25360935647040606, test 0.25749256098565976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2535846350233882, test 0.25732536072080786\n",
      "RMSE, train 0.2535833467639262, test 0.25722495411053176\n",
      "RMSE, train 0.25360056670803216, test 0.2572826227127028\n",
      "RMSE, train 0.2535623570062941, test 0.2577080943367698\n",
      "RMSE, train 0.2535838864803795, test 0.2574666170788205\n",
      "RMSE, train 0.2534976072849766, test 0.25731485454011555\n",
      "RMSE, train 0.25354951707225654, test 0.25728315114974976\n",
      "RMSE, train 0.25353794544935226, test 0.25732610725666866\n",
      "RMSE, train 0.2534839850399763, test 0.2573297015152687\n",
      "RMSE, train 0.2535005288438932, test 0.2573954958068438\n",
      "RMSE, train 0.2535073250051468, test 0.25726730321064467\n",
      "RMSE, train 0.2535487170962076, test 0.25723443420465325\n",
      "Early stopping at epoch 68 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9363641006764302, test 0.8255620967533629\n",
      "RMSE, train 0.694453461849985, test 0.5240477890533916\n",
      "RMSE, train 0.43755824303577756, test 0.3361349339454861\n",
      "RMSE, train 0.29961824103081525, test 0.271126286710723\n",
      "RMSE, train 0.25829952548850665, test 0.25526422502125723\n",
      "RMSE, train 0.24784080748838827, test 0.2502709830463943\n",
      "RMSE, train 0.24414353161927096, test 0.24799440296019537\n",
      "RMSE, train 0.24241435515486504, test 0.24682673205763606\n",
      "RMSE, train 0.24142694636440473, test 0.24587612131894646\n",
      "RMSE, train 0.24086185778714408, test 0.24511325523509817\n",
      "RMSE, train 0.24015961664397856, test 0.2444438127390409\n",
      "RMSE, train 0.23967014290084523, test 0.24398640581106734\n",
      "RMSE, train 0.2393468320985471, test 0.24341870907504679\n",
      "RMSE, train 0.23914164344757055, test 0.24324044244269194\n",
      "RMSE, train 0.23893369361758232, test 0.24307660063949682\n",
      "RMSE, train 0.23869150258169686, test 0.24287614011663503\n",
      "RMSE, train 0.23855155500129235, test 0.2425105939224615\n",
      "RMSE, train 0.23854330151287978, test 0.2425632469229779\n",
      "RMSE, train 0.23841719858902544, test 0.2424401632052357\n",
      "RMSE, train 0.2382726054792562, test 0.24217703584897315\n",
      "RMSE, train 0.2381155001045751, test 0.2421174644161079\n",
      "RMSE, train 0.23818407626437746, test 0.24203387597354792\n",
      "RMSE, train 0.2383088797084556, test 0.2419679032291396\n",
      "RMSE, train 0.23830741582330595, test 0.24177755870051304\n",
      "RMSE, train 0.2380210949985449, test 0.2417476811146332\n",
      "RMSE, train 0.23781475871185626, test 0.2416838918954639\n",
      "RMSE, train 0.23791489562342974, test 0.24159224659709608\n",
      "RMSE, train 0.23781871112171282, test 0.24166989818973056\n",
      "RMSE, train 0.23758724436533352, test 0.24148523251889115\n",
      "RMSE, train 0.2378318931999778, test 0.24153394618276822\n",
      "RMSE, train 0.23788240364144655, test 0.2415185547986273\n",
      "RMSE, train 0.2377127501651768, test 0.24163313096357605\n",
      "RMSE, train 0.23772876300225573, test 0.24149611137681087\n",
      "RMSE, train 0.23776112068906302, test 0.24158639965926187\n",
      "RMSE, train 0.23784296503983254, test 0.24142538326776633\n",
      "RMSE, train 0.2375817958973656, test 0.24125237093638566\n",
      "RMSE, train 0.23754089984519422, test 0.24149832861908413\n",
      "RMSE, train 0.2375264422706336, test 0.24147248987929296\n",
      "RMSE, train 0.23757607819250792, test 0.2412447434360698\n",
      "RMSE, train 0.2374714088957172, test 0.24133705789760007\n",
      "RMSE, train 0.23744985282667413, test 0.24123668152902086\n",
      "RMSE, train 0.23746537571111, test 0.24124707003771248\n",
      "RMSE, train 0.23754811684085317, test 0.24138749075137964\n",
      "RMSE, train 0.23737858731515152, test 0.24128735949427393\n",
      "RMSE, train 0.23739860557820186, test 0.24138003057342464\n",
      "RMSE, train 0.23736308705954512, test 0.24120306463564856\n",
      "RMSE, train 0.23729361599880802, test 0.241302294246221\n",
      "RMSE, train 0.23728324340517856, test 0.24115930320852894\n",
      "RMSE, train 0.23733018791256857, test 0.24123212000576116\n",
      "RMSE, train 0.2374033145914393, test 0.24123657873626483\n",
      "RMSE, train 0.23735127126998154, test 0.2410936685184301\n",
      "RMSE, train 0.2373048045233754, test 0.24108663352869325\n",
      "RMSE, train 0.2372460535550413, test 0.2411301888651767\n",
      "RMSE, train 0.2375074628094011, test 0.24106972033189514\n",
      "RMSE, train 0.23723350148186212, test 0.24115948379039764\n",
      "RMSE, train 0.2371805067335771, test 0.24108729221053044\n",
      "RMSE, train 0.2372469515963034, test 0.24113950587935368\n",
      "RMSE, train 0.23725228722799907, test 0.24099041723598869\n",
      "RMSE, train 0.23712467128210815, test 0.24121442664477785\n",
      "RMSE, train 0.2373032385160115, test 0.24134840260622864\n",
      "RMSE, train 0.23716644490183877, test 0.24110916269532703\n",
      "RMSE, train 0.237183855861918, test 0.241085218676066\n",
      "RMSE, train 0.2372397178830194, test 0.24089419589204303\n",
      "RMSE, train 0.23728873857781907, test 0.241108653909069\n",
      "RMSE, train 0.23722449508457144, test 0.24109687795073298\n",
      "RMSE, train 0.23711964457241957, test 0.24118236553365902\n",
      "RMSE, train 0.23714047824301995, test 0.24122377043053256\n",
      "RMSE, train 0.23716412419992045, test 0.24125430202585155\n",
      "RMSE, train 0.23729244868986862, test 0.24115742477825133\n",
      "RMSE, train 0.23708110706003244, test 0.24092411780256337\n",
      "RMSE, train 0.23725924533137605, test 0.24107011281332727\n",
      "RMSE, train 0.23716966102807974, test 0.24100205251726053\n",
      "RMSE, train 0.23726204711913076, test 0.24101678648237454\n",
      "Early stopping at epoch 73 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9930922294234399, test 0.8982809454734836\n",
      "RMSE, train 0.7412348092251614, test 0.5456505002720016\n",
      "RMSE, train 0.4258600185120028, test 0.3304792063842927\n",
      "RMSE, train 0.28222105387509, test 0.26036995609423946\n",
      "RMSE, train 0.24754429376462966, test 0.2500204896288259\n",
      "RMSE, train 0.24221473669304566, test 0.24791373804743802\n",
      "RMSE, train 0.24044609056838456, test 0.24567860537873848\n",
      "RMSE, train 0.23903642140312653, test 0.24507063813507557\n",
      "RMSE, train 0.2379264141999039, test 0.2438670758690153\n",
      "RMSE, train 0.2369270892184804, test 0.2429479979244726\n",
      "RMSE, train 0.23624439329752994, test 0.24181295691856317\n",
      "RMSE, train 0.23539589751260212, test 0.2409818060696125\n",
      "RMSE, train 0.2347074951935957, test 0.24050838566784347\n",
      "RMSE, train 0.23428825579567414, test 0.23958423028567008\n",
      "RMSE, train 0.23374666224897298, test 0.2392989910606827\n",
      "RMSE, train 0.23346752454252803, test 0.23890576152397053\n",
      "RMSE, train 0.23337213263272719, test 0.239045338572136\n",
      "RMSE, train 0.23329558186151883, test 0.23866522990699326\n",
      "RMSE, train 0.23305576065786524, test 0.23850046457456692\n",
      "RMSE, train 0.23289911935921587, test 0.23826967259602888\n",
      "RMSE, train 0.2328738983485174, test 0.23892591255051748\n",
      "RMSE, train 0.23289750159306205, test 0.23803480315421308\n",
      "RMSE, train 0.23275910976925188, test 0.23823857187692607\n",
      "RMSE, train 0.2326147047587729, test 0.23805741220712662\n",
      "RMSE, train 0.2325902771456309, test 0.23772088717669249\n",
      "RMSE, train 0.23253128802594536, test 0.23801888126347745\n",
      "RMSE, train 0.23246110521240693, test 0.2377172592761261\n",
      "RMSE, train 0.23229331878665227, test 0.23798336594232491\n",
      "RMSE, train 0.23249602658686294, test 0.23793005623987742\n",
      "RMSE, train 0.2323741668384839, test 0.2378170249451484\n",
      "RMSE, train 0.23227122964942118, test 0.2376169486503516\n",
      "RMSE, train 0.23238798115637826, test 0.237876017311854\n",
      "RMSE, train 0.2322383609342679, test 0.23790742470217602\n",
      "RMSE, train 0.23215876259964796, test 0.23821765689977578\n",
      "RMSE, train 0.23226128940618634, test 0.2378667608967849\n",
      "RMSE, train 0.23220882008018576, test 0.23757264723203012\n",
      "RMSE, train 0.2322948468861237, test 0.23746272828429937\n",
      "RMSE, train 0.2321594911333263, test 0.2376466059525098\n",
      "RMSE, train 0.2321827157455332, test 0.23827428756547825\n",
      "RMSE, train 0.23220812696517162, test 0.23746057533259904\n",
      "RMSE, train 0.23215842662553643, test 0.23769857428435767\n",
      "RMSE, train 0.2320230382784779, test 0.23741881216743163\n",
      "RMSE, train 0.23216326440601306, test 0.23781599583370344\n",
      "RMSE, train 0.23211605249536843, test 0.23768956427063262\n",
      "RMSE, train 0.23213248880080928, test 0.23751408699899912\n",
      "RMSE, train 0.23210172975245125, test 0.23784353770315647\n",
      "RMSE, train 0.23208438652143498, test 0.2376235762078847\n",
      "RMSE, train 0.23204694652609317, test 0.23823203146457672\n",
      "RMSE, train 0.23215547798116223, test 0.23776736349931785\n",
      "RMSE, train 0.2321727249876866, test 0.2376180086284876\n",
      "RMSE, train 0.23214268077302863, test 0.2371720727533102\n",
      "RMSE, train 0.2322278487656371, test 0.23812359105795622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23207765700770358, test 0.23781762378556387\n",
      "RMSE, train 0.2321978108490734, test 0.2375654796404498\n",
      "RMSE, train 0.23205093565459864, test 0.23815957749528543\n",
      "RMSE, train 0.23200166082589974, test 0.2376737728981035\n",
      "RMSE, train 0.23210769917710414, test 0.23776473317827498\n",
      "RMSE, train 0.23219091365669808, test 0.23763196955301932\n",
      "RMSE, train 0.23219013123211, test 0.23734826687723398\n",
      "RMSE, train 0.23204959231004735, test 0.23732951682593142\n",
      "RMSE, train 0.23201922676272382, test 0.23778847219156368\n",
      "Early stopping at epoch 61 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9331562658976809, test 0.8150484212721237\n",
      "RMSE, train 0.6136636346359999, test 0.40659536075110386\n",
      "RMSE, train 0.3182963347085239, test 0.29144402661106805\n",
      "RMSE, train 0.2608325552459451, test 0.2710341743447564\n",
      "RMSE, train 0.24974475615181957, test 0.2626530753843712\n",
      "RMSE, train 0.24399903566009548, test 0.2569072436202656\n",
      "RMSE, train 0.2403615218721567, test 0.2521412130257096\n",
      "RMSE, train 0.2377805032910811, test 0.24881127822880794\n",
      "RMSE, train 0.23596469748282492, test 0.24646812195729728\n",
      "RMSE, train 0.23433096364395542, test 0.2441741559240553\n",
      "RMSE, train 0.23334173453757698, test 0.24267273704812983\n",
      "RMSE, train 0.2323604069449791, test 0.241678437500289\n",
      "RMSE, train 0.231594236490196, test 0.2408649290751929\n",
      "RMSE, train 0.23104136956350144, test 0.2399103311878262\n",
      "RMSE, train 0.23077567031010437, test 0.23990741296850068\n",
      "RMSE, train 0.2302488058003936, test 0.23896739473848633\n",
      "RMSE, train 0.23009127178081382, test 0.23853340895489009\n",
      "RMSE, train 0.22978021648956104, test 0.2383310069339444\n",
      "RMSE, train 0.22983247679282517, test 0.23798546556270483\n",
      "RMSE, train 0.229580174521304, test 0.2377144271376157\n",
      "RMSE, train 0.22957576989836098, test 0.2376859284410573\n",
      "RMSE, train 0.2294132325862031, test 0.23746544694659685\n",
      "RMSE, train 0.22949409204327972, test 0.23734148749799439\n",
      "RMSE, train 0.22913143734622993, test 0.237215398688509\n",
      "RMSE, train 0.22902601359817393, test 0.23700546450687177\n",
      "RMSE, train 0.2290596308364262, test 0.2370708416206668\n",
      "RMSE, train 0.2289501761238849, test 0.23685651144596062\n",
      "RMSE, train 0.22886537857044006, test 0.23706034834336753\n",
      "RMSE, train 0.22870128476095083, test 0.23687559953241638\n",
      "RMSE, train 0.2287381926419391, test 0.23666818620580615\n",
      "RMSE, train 0.22881639273359022, test 0.23710280822383034\n",
      "RMSE, train 0.2286848814606958, test 0.2371297538882554\n",
      "RMSE, train 0.22867859907284344, test 0.23658990589055148\n",
      "RMSE, train 0.22847748090556316, test 0.23717595275604364\n",
      "RMSE, train 0.22860762710093285, test 0.23640530082312497\n",
      "RMSE, train 0.22844681070894368, test 0.2364003500252059\n",
      "RMSE, train 0.22837952959799826, test 0.23633829045175303\n",
      "RMSE, train 0.2283076191808309, test 0.23639770409073493\n",
      "RMSE, train 0.22834545002298426, test 0.23647970969628807\n",
      "RMSE, train 0.22821974182332933, test 0.23625597703938533\n",
      "RMSE, train 0.22828216078374672, test 0.2364735636446211\n",
      "RMSE, train 0.2284175405656796, test 0.2363505687075432\n",
      "RMSE, train 0.2285708936619001, test 0.2363844739668297\n",
      "RMSE, train 0.22841008404647808, test 0.23616038955221272\n",
      "RMSE, train 0.22818643681723214, test 0.2362133279593304\n",
      "RMSE, train 0.22819773025792503, test 0.23612365171764838\n",
      "RMSE, train 0.22809113769776082, test 0.23612043111011236\n",
      "RMSE, train 0.22808058140913257, test 0.2360305855370531\n",
      "RMSE, train 0.22831543638828622, test 0.23613545148059575\n",
      "RMSE, train 0.22792271901750916, test 0.23617510888913665\n",
      "RMSE, train 0.22794861639770145, test 0.23624436828223142\n",
      "RMSE, train 0.22793590384911208, test 0.23613806430137518\n",
      "RMSE, train 0.22802220408811547, test 0.23593915095835022\n",
      "RMSE, train 0.2278744692032961, test 0.23599354546479503\n",
      "RMSE, train 0.22828797169011497, test 0.23600498127816905\n",
      "RMSE, train 0.22784517996905776, test 0.23582883073826028\n",
      "RMSE, train 0.22786340241327263, test 0.23582545013138742\n",
      "RMSE, train 0.2279542469235096, test 0.23603106568558047\n",
      "RMSE, train 0.2278520672201819, test 0.23597876712529345\n",
      "RMSE, train 0.22813400363863826, test 0.2357639492762209\n",
      "RMSE, train 0.22797721974132695, test 0.2358795217793397\n",
      "RMSE, train 0.2278060573164583, test 0.2357182028618726\n",
      "RMSE, train 0.22787534851753916, test 0.2357529778071124\n",
      "RMSE, train 0.22769573556764786, test 0.2359708829058541\n",
      "RMSE, train 0.22764247644938584, test 0.23566907975408766\n",
      "RMSE, train 0.2276867805162677, test 0.2356727240663586\n",
      "RMSE, train 0.2276231448341407, test 0.23559907500189964\n",
      "RMSE, train 0.22762726768304783, test 0.23571852647294902\n",
      "RMSE, train 0.22763650443559755, test 0.2356136775378025\n",
      "RMSE, train 0.22751788725771355, test 0.23564327876977245\n",
      "RMSE, train 0.22778773825151122, test 0.23557110717802338\n",
      "RMSE, train 0.22784114055208005, test 0.2355953518188361\n",
      "RMSE, train 0.22753814857425783, test 0.2356125849364984\n",
      "RMSE, train 0.22759895915652836, test 0.23548110371286218\n",
      "RMSE, train 0.22764722154018058, test 0.23572363425986936\n",
      "RMSE, train 0.2274125441362339, test 0.23552703240303077\n",
      "RMSE, train 0.22750250557961266, test 0.23567605394907673\n",
      "RMSE, train 0.22760186094818022, test 0.23544346202503552\n",
      "RMSE, train 0.22746162397062866, test 0.23546877623808504\n",
      "RMSE, train 0.22741923228015526, test 0.23565620545184973\n",
      "RMSE, train 0.22760572428371037, test 0.2354225788754646\n",
      "RMSE, train 0.22765128401934664, test 0.23571175276631057\n",
      "RMSE, train 0.22740354022799028, test 0.23552215972332038\n",
      "RMSE, train 0.22730602480671516, test 0.2357718048974721\n",
      "RMSE, train 0.22746421010540865, test 0.23564713440760218\n",
      "RMSE, train 0.22747981446296486, test 0.23535371007341327\n",
      "RMSE, train 0.2274357407629344, test 0.23556333208324934\n",
      "RMSE, train 0.22759491686133126, test 0.23538027703762054\n",
      "RMSE, train 0.2274124268214685, test 0.23579382038477695\n",
      "RMSE, train 0.22741490923105068, test 0.23532719910144806\n",
      "RMSE, train 0.2272909917939263, test 0.23545239399177859\n",
      "RMSE, train 0.22732238566234234, test 0.23538505684847782\n",
      "RMSE, train 0.22739769740617655, test 0.23535300685901833\n",
      "RMSE, train 0.2273252188139265, test 0.23545635122843464\n",
      "RMSE, train 0.22752518798873594, test 0.23583579454759154\n",
      "RMSE, train 0.22727057243034718, test 0.23542312479982472\n",
      "RMSE, train 0.22736481393170532, test 0.23537292670119891\n",
      "RMSE, train 0.22717485731708975, test 0.23542590333957863\n",
      "RMSE, train 0.22719290502788386, test 0.2353084757171496\n",
      "RMSE, train 0.22722980030299983, test 0.23524149198724767\n",
      "RMSE, train 0.2273066741913047, test 0.2353011112321507\n",
      "RMSE, train 0.22745959577321423, test 0.235204867792852\n",
      "RMSE, train 0.22723155700052863, test 0.23538552871858232\n",
      "RMSE, train 0.22725296880330317, test 0.23544385096039436\n",
      "RMSE, train 0.2271408069979008, test 0.23545680563859264\n",
      "RMSE, train 0.22703987647822552, test 0.23519404954982526\n",
      "RMSE, train 0.22718223568716958, test 0.23548128824643413\n",
      "RMSE, train 0.22717254927659675, test 0.23522679402370644\n",
      "RMSE, train 0.2271438276345106, test 0.2353758994075987\n",
      "RMSE, train 0.22725498486847634, test 0.23521426350179345\n",
      "RMSE, train 0.22700523025832142, test 0.23526925119486722\n",
      "RMSE, train 0.22714128591174892, test 0.23523686961694198\n",
      "RMSE, train 0.2270615272460765, test 0.23528545507878967\n",
      "RMSE, train 0.22717801946008118, test 0.23518794564285664\n",
      "RMSE, train 0.22703254740220702, test 0.2352050237282358\n",
      "RMSE, train 0.22716410261348874, test 0.23535829120212132\n",
      "RMSE, train 0.2271652371055631, test 0.2352232848755037\n",
      "RMSE, train 0.22696551119494263, test 0.23522877828641373\n",
      "RMSE, train 0.22691762651382857, test 0.23607612092687627\n",
      "RMSE, train 0.22725459372210327, test 0.23515942828221756\n",
      "RMSE, train 0.2269380273329308, test 0.23524396392432126\n",
      "RMSE, train 0.22696099009519685, test 0.23534590367114905\n",
      "RMSE, train 0.22712032369413118, test 0.23527363273832533\n",
      "RMSE, train 0.22688180277429176, test 0.23545040099909811\n",
      "RMSE, train 0.22694394990692512, test 0.23529640231469665\n",
      "RMSE, train 0.22707905112093993, test 0.2352278136243724\n",
      "RMSE, train 0.2271242474358356, test 0.23524585110370558\n",
      "RMSE, train 0.2270353200018843, test 0.2356333737120484\n",
      "RMSE, train 0.2270008754030708, test 0.23509732370424752\n",
      "RMSE, train 0.22690584290144206, test 0.23533126711845398\n",
      "RMSE, train 0.2269930387767428, test 0.23514320663731508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.22691758556296016, test 0.23523270963418363\n",
      "RMSE, train 0.2270076633738422, test 0.23516015181637773\n",
      "RMSE, train 0.2268912907698918, test 0.23514609535535178\n",
      "RMSE, train 0.22704002068066073, test 0.23518464691711194\n",
      "RMSE, train 0.22678519818194046, test 0.2352311426039898\n",
      "RMSE, train 0.22690545277519739, test 0.23550724200528078\n",
      "RMSE, train 0.22675208634444147, test 0.23538268425247885\n",
      "RMSE, train 0.2268333048138467, test 0.23514118293921152\n",
      "Early stopping at epoch 139 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9124427296159682, test 0.8450129835282342\n",
      "RMSE, train 0.7427050454064834, test 0.614048892411135\n",
      "RMSE, train 0.5321329601170602, test 0.42212178570739295\n",
      "RMSE, train 0.37518385588383873, test 0.32404864352133317\n",
      "RMSE, train 0.30672221273676425, test 0.2908140668424509\n",
      "RMSE, train 0.28290269071282437, test 0.2802701267903134\n",
      "RMSE, train 0.2749069906648033, test 0.27582206766484146\n",
      "RMSE, train 0.2714052237878161, test 0.27348599620794845\n",
      "RMSE, train 0.2683935306104254, test 0.27106041145526755\n",
      "RMSE, train 0.2664334330984876, test 0.26974537046784064\n",
      "RMSE, train 0.26526256001069526, test 0.2691012384780383\n",
      "RMSE, train 0.26422704377573386, test 0.26757358557592004\n",
      "RMSE, train 0.2634594119654214, test 0.26698547008179\n",
      "RMSE, train 0.26273376272975907, test 0.26633974227864865\n",
      "RMSE, train 0.26231405613097275, test 0.265857112862296\n",
      "RMSE, train 0.26177927913251986, test 0.26529668726153294\n",
      "RMSE, train 0.261305828848161, test 0.26500144891314587\n",
      "RMSE, train 0.26098527232846935, test 0.26457919357186654\n",
      "RMSE, train 0.26107420575273926, test 0.26446777190697396\n",
      "RMSE, train 0.2606959696089433, test 0.2643047160768913\n",
      "RMSE, train 0.2605366849702252, test 0.2640533512931759\n",
      "RMSE, train 0.2604004534438622, test 0.2640329517297826\n",
      "RMSE, train 0.2603804738499409, test 0.2637767777857134\n",
      "RMSE, train 0.2603478846717472, test 0.2635493384579481\n",
      "RMSE, train 0.2603115256844966, test 0.26378924929994646\n",
      "RMSE, train 0.26032277756978656, test 0.2636573524293253\n",
      "RMSE, train 0.2602455575665659, test 0.2633525509450395\n",
      "RMSE, train 0.2600443098109123, test 0.26341804420038806\n",
      "RMSE, train 0.26005179884512564, test 0.2632212313049931\n",
      "RMSE, train 0.2599749781252924, test 0.26365159489845824\n",
      "RMSE, train 0.2599641695187604, test 0.2631598245036804\n",
      "RMSE, train 0.26008237818302204, test 0.2634183107796362\n",
      "RMSE, train 0.2598366830959793, test 0.26328974393969873\n",
      "RMSE, train 0.2598984576453847, test 0.263292829111471\n",
      "RMSE, train 0.2597439602817878, test 0.26322516899997905\n",
      "RMSE, train 0.2598157257518985, test 0.26297740133131964\n",
      "RMSE, train 0.25968121647957926, test 0.2632150658864086\n",
      "RMSE, train 0.25973317673629964, test 0.2630117616410983\n",
      "RMSE, train 0.25971010345811685, test 0.26302574372897713\n",
      "RMSE, train 0.2597071484408595, test 0.26289177395529667\n",
      "RMSE, train 0.25970264635056506, test 0.2628729811916917\n",
      "RMSE, train 0.2595927687900618, test 0.2629778782947589\n",
      "RMSE, train 0.2595225600602706, test 0.26280042832180606\n",
      "RMSE, train 0.2596947113282917, test 0.26278312971531337\n",
      "RMSE, train 0.259506682195693, test 0.26317364280506717\n",
      "RMSE, train 0.25954685858951126, test 0.26289535882109305\n",
      "RMSE, train 0.2594399601836835, test 0.2629601148478055\n",
      "RMSE, train 0.2594919223492303, test 0.26275879157296683\n",
      "RMSE, train 0.25945768890178894, test 0.2629565959007053\n",
      "RMSE, train 0.25949712168456107, test 0.26272042802834916\n",
      "RMSE, train 0.25935031338171527, test 0.26271182967949724\n",
      "RMSE, train 0.2594951123984392, test 0.26267514213667076\n",
      "RMSE, train 0.25949494355966235, test 0.26260215877476384\n",
      "RMSE, train 0.2594580345225236, test 0.262723567248401\n",
      "RMSE, train 0.25938855576490566, test 0.26291116301791145\n",
      "RMSE, train 0.2594101333852149, test 0.26275055337760406\n",
      "RMSE, train 0.2594231868024207, test 0.2628593829981351\n",
      "RMSE, train 0.2593226381385129, test 0.26275037077523894\n",
      "RMSE, train 0.25943819531970774, test 0.2627519016801301\n",
      "RMSE, train 0.2595864190173543, test 0.2625268446439404\n",
      "RMSE, train 0.2593785423077335, test 0.2624874484993644\n",
      "RMSE, train 0.25939553862145126, test 0.2625921900242062\n",
      "RMSE, train 0.2595778817911286, test 0.2627518692259061\n",
      "RMSE, train 0.25926475408525507, test 0.2624981864276579\n",
      "RMSE, train 0.2593843710323996, test 0.2625986524557663\n",
      "RMSE, train 0.25925088935523977, test 0.26250638635986945\n",
      "RMSE, train 0.25945076420287455, test 0.262799989621518\n",
      "RMSE, train 0.2592995525761084, test 0.26267087762638675\n",
      "RMSE, train 0.2594346347118705, test 0.26258598028098123\n",
      "RMSE, train 0.2594232852609197, test 0.2625221982598305\n",
      "RMSE, train 0.25927754192928637, test 0.2625369817271071\n",
      "Early stopping at epoch 71 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9252108925213985, test 0.8643320964730304\n",
      "RMSE, train 0.7890655071872055, test 0.6665364705997965\n",
      "RMSE, train 0.5773542657526183, test 0.4646326194638791\n",
      "RMSE, train 0.40917222774459044, test 0.349786414011665\n",
      "RMSE, train 0.322265202041138, test 0.29702211553635804\n",
      "RMSE, train 0.2810602222594992, test 0.27241940355819205\n",
      "RMSE, train 0.2623263651271788, test 0.2609659000583317\n",
      "RMSE, train 0.25419312990774773, test 0.2562167481235836\n",
      "RMSE, train 0.25053203919004735, test 0.25355523669201396\n",
      "RMSE, train 0.24871906473631566, test 0.2525906145572662\n",
      "RMSE, train 0.24766593896279668, test 0.2517550556556038\n",
      "RMSE, train 0.24691708888977196, test 0.2510658437791078\n",
      "RMSE, train 0.2464036265123169, test 0.25058685968751493\n",
      "RMSE, train 0.2458827005197035, test 0.2499831224265306\n",
      "RMSE, train 0.24550876790171217, test 0.24946629106998444\n",
      "RMSE, train 0.24512562016519518, test 0.24954959128213966\n",
      "RMSE, train 0.24488563766018853, test 0.24888306869112928\n",
      "RMSE, train 0.24465052438642823, test 0.24859132196592248\n",
      "RMSE, train 0.24448431768867873, test 0.24841730801955514\n",
      "RMSE, train 0.2442945964840061, test 0.24852808804615684\n",
      "RMSE, train 0.24417300791244345, test 0.24822323801724808\n",
      "RMSE, train 0.2440631668026027, test 0.24814617128475852\n",
      "RMSE, train 0.24394932579083048, test 0.24775546167207801\n",
      "RMSE, train 0.24387702633747377, test 0.24804864137069038\n",
      "RMSE, train 0.24382787512619278, test 0.24812676621520002\n",
      "RMSE, train 0.24376073482816132, test 0.24808102288971776\n",
      "RMSE, train 0.24370240045201247, test 0.2477786140597385\n",
      "RMSE, train 0.24365938288770664, test 0.24755415747994963\n",
      "RMSE, train 0.24362479621690802, test 0.24774217022501904\n",
      "RMSE, train 0.24358521155111348, test 0.24753058008525683\n",
      "RMSE, train 0.24357775369394105, test 0.24755780398845673\n",
      "RMSE, train 0.2435347568836941, test 0.24737800307895827\n",
      "RMSE, train 0.24353264091880458, test 0.24741085080996802\n",
      "RMSE, train 0.24350225213606647, test 0.24747933019762453\n",
      "RMSE, train 0.2434656011640646, test 0.2475247243176336\n",
      "RMSE, train 0.24348015776358845, test 0.24770856123903523\n",
      "RMSE, train 0.24344571871236126, test 0.2474665298410084\n",
      "RMSE, train 0.24341339910612492, test 0.2475296519372774\n",
      "RMSE, train 0.24344541445659224, test 0.24707164906937143\n",
      "RMSE, train 0.24339638903515606, test 0.24731605882230012\n",
      "RMSE, train 0.24339302333423793, test 0.24755777509316154\n",
      "RMSE, train 0.24338363272369287, test 0.24735599548920342\n",
      "RMSE, train 0.24336268710103004, test 0.24754872477572898\n",
      "RMSE, train 0.24336827712453854, test 0.24731709270373634\n",
      "RMSE, train 0.24336578755495147, test 0.24723218277744624\n",
      "RMSE, train 0.2433168644484947, test 0.24738622152287026\n",
      "RMSE, train 0.2433038783237939, test 0.2473052566466124\n",
      "RMSE, train 0.24329141968754447, test 0.24730568269024725\n",
      "RMSE, train 0.24328953306133327, test 0.24718759021033412\n",
      "Early stopping at epoch 49 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9132243386833122, test 0.808535471421863\n",
      "RMSE, train 0.6388451449005058, test 0.4604127557452666\n",
      "RMSE, train 0.38435459076823675, test 0.3315008170560959\n",
      "RMSE, train 0.3032491886361832, test 0.28704372308123005\n",
      "RMSE, train 0.2713846500478518, test 0.2682168956743468\n",
      "RMSE, train 0.2571993883816116, test 0.25949880138996545\n",
      "RMSE, train 0.2502123296528119, test 0.25499314042406346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2462376974556478, test 0.25253330061741924\n",
      "RMSE, train 0.24386320887926982, test 0.25069181621074677\n",
      "RMSE, train 0.2423106967534185, test 0.2503641655138873\n",
      "RMSE, train 0.24134282630788906, test 0.24877109235032982\n",
      "RMSE, train 0.2404946273551928, test 0.24794807647346356\n",
      "RMSE, train 0.2398920567380473, test 0.24695957253832335\n",
      "RMSE, train 0.23946384938575763, test 0.2473541796207428\n",
      "RMSE, train 0.23912355791560203, test 0.2470988640818027\n",
      "RMSE, train 0.23882825007754058, test 0.24591002770520132\n",
      "RMSE, train 0.2386237001004775, test 0.24587137422977237\n",
      "RMSE, train 0.23841505133517654, test 0.2453103146148384\n",
      "RMSE, train 0.2382770538864649, test 0.24540436582280956\n",
      "RMSE, train 0.23816205758284026, test 0.24557456770621308\n",
      "RMSE, train 0.23805214173991585, test 0.2454332409922136\n",
      "RMSE, train 0.23802953701249152, test 0.24492006605371422\n",
      "RMSE, train 0.2379227102203754, test 0.24447551301313103\n",
      "RMSE, train 0.23787378112163243, test 0.24467011903404096\n",
      "RMSE, train 0.23783275384806732, test 0.24551524891765839\n",
      "RMSE, train 0.23785632928925246, test 0.2447558503358736\n",
      "RMSE, train 0.23777783658739698, test 0.24492959965259656\n",
      "RMSE, train 0.2377495580256787, test 0.24447710607029977\n",
      "RMSE, train 0.2377359166139979, test 0.2448086786434191\n",
      "RMSE, train 0.23774541961237988, test 0.24474302863855973\n",
      "RMSE, train 0.23767374619641113, test 0.2447998816267066\n",
      "RMSE, train 0.23767641751354585, test 0.24445020263894982\n",
      "RMSE, train 0.23767401044144223, test 0.24480432353982137\n",
      "RMSE, train 0.23763914179106999, test 0.24459655774295877\n",
      "RMSE, train 0.23763889421796586, test 0.24481647933295014\n",
      "RMSE, train 0.23764087931324013, test 0.2446529302028341\n",
      "RMSE, train 0.23757511821696575, test 0.2449690431629846\n",
      "RMSE, train 0.237593296631302, test 0.24454862098081395\n",
      "RMSE, train 0.23760155899107724, test 0.24515028202205624\n",
      "RMSE, train 0.23758020064889582, test 0.24423396054211013\n",
      "RMSE, train 0.23759569488298732, test 0.2444247488581806\n",
      "RMSE, train 0.23757773530857446, test 0.2446324751464599\n",
      "RMSE, train 0.23756240127867112, test 0.2446814605949122\n",
      "RMSE, train 0.23755077279335715, test 0.24409590224060443\n",
      "RMSE, train 0.2375333063939227, test 0.24464848869984304\n",
      "RMSE, train 0.23754381184620707, test 0.24460219188567695\n",
      "RMSE, train 0.23752146504919625, test 0.2443391345783111\n",
      "RMSE, train 0.2375153112705513, test 0.24495701942968806\n",
      "RMSE, train 0.23751843994642052, test 0.24502802961463227\n",
      "RMSE, train 0.2375360533194157, test 0.2444101704643407\n",
      "RMSE, train 0.2374929464317758, test 0.24421254251528224\n",
      "RMSE, train 0.2375146746635437, test 0.24453655445794448\n",
      "RMSE, train 0.23748162255158872, test 0.24492460735347293\n",
      "RMSE, train 0.2374709058436043, test 0.24406167536700538\n",
      "RMSE, train 0.23749821128599313, test 0.2446293356495166\n",
      "RMSE, train 0.2374536014859452, test 0.24440360411044654\n",
      "RMSE, train 0.23749107586829651, test 0.24502653539727587\n",
      "RMSE, train 0.23744499940642327, test 0.24417308629105944\n",
      "RMSE, train 0.23744206177279553, test 0.24458915911136417\n",
      "RMSE, train 0.23745847991229171, test 0.2449104269163324\n",
      "RMSE, train 0.23742764078982742, test 0.24419277482623353\n",
      "RMSE, train 0.23746606289939495, test 0.24539777240075103\n",
      "RMSE, train 0.23742911299782485, test 0.24466838516773434\n",
      "RMSE, train 0.2374349946465193, test 0.24457929508948545\n",
      "Early stopping at epoch 64 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9234598089348186, test 0.8291989540060362\n",
      "RMSE, train 0.7374261388875017, test 0.6139314491301775\n",
      "RMSE, train 0.5236585912379351, test 0.41464793247481185\n",
      "RMSE, train 0.3594820217953788, test 0.32862012181431055\n",
      "RMSE, train 0.29973005781872103, test 0.3001550603657961\n",
      "RMSE, train 0.2752083328110401, test 0.2827957033490141\n",
      "RMSE, train 0.2608945058527017, test 0.2715268209576607\n",
      "RMSE, train 0.2523038499057293, test 0.2640562124239902\n",
      "RMSE, train 0.2473970836762226, test 0.25872050039470196\n",
      "RMSE, train 0.24403374412595624, test 0.2549717736740907\n",
      "RMSE, train 0.24148412688512993, test 0.2514620710474749\n",
      "RMSE, train 0.2395767295977684, test 0.24935807179038724\n",
      "RMSE, train 0.23831103877587753, test 0.2475331051585575\n",
      "RMSE, train 0.23730942215582337, test 0.24648099594439069\n",
      "RMSE, train 0.23659274072358102, test 0.2460512121518453\n",
      "RMSE, train 0.2360442089236746, test 0.24490814609453082\n",
      "RMSE, train 0.23555669041745592, test 0.24422068785255155\n",
      "RMSE, train 0.23511632546933012, test 0.24368851445615292\n",
      "RMSE, train 0.23481201771834884, test 0.24335799366235733\n",
      "RMSE, train 0.2345560784969065, test 0.2429441938487192\n",
      "RMSE, train 0.23436811784602174, test 0.24306908156722784\n",
      "RMSE, train 0.2340772437928903, test 0.24277753413965306\n",
      "RMSE, train 0.23391785423713501, test 0.2425684534634153\n",
      "RMSE, train 0.23375002482924798, test 0.24210143741220236\n",
      "RMSE, train 0.23361952678121703, test 0.24219551092634597\n",
      "RMSE, train 0.23348921661575636, test 0.24179425773521265\n",
      "RMSE, train 0.23341884309745797, test 0.2419221382588148\n",
      "RMSE, train 0.23325886791854195, test 0.2418656968511641\n",
      "RMSE, train 0.2332113462716642, test 0.2421569616223375\n",
      "RMSE, train 0.23313932267553877, test 0.24148977175354958\n",
      "RMSE, train 0.23310998507370853, test 0.24131612665951252\n",
      "RMSE, train 0.23299741534271626, test 0.24143590979898968\n",
      "RMSE, train 0.23298454322297163, test 0.24156582712506255\n",
      "RMSE, train 0.23293266720091454, test 0.2412102115340531\n",
      "RMSE, train 0.23285509423926623, test 0.24130676329756776\n",
      "RMSE, train 0.2328568875338092, test 0.24129945784807205\n",
      "RMSE, train 0.2328046562921519, test 0.24129113679130873\n",
      "RMSE, train 0.23276721095346442, test 0.24151144595816731\n",
      "RMSE, train 0.23271396560500365, test 0.24143568178017935\n",
      "RMSE, train 0.23274206904449848, test 0.24114682711660862\n",
      "RMSE, train 0.23265324156693737, test 0.24151516131435832\n",
      "RMSE, train 0.23265638127170427, test 0.24125507334247231\n",
      "RMSE, train 0.23262465331289503, test 0.24124223630254468\n",
      "RMSE, train 0.23258273055156073, test 0.24106352822855115\n",
      "RMSE, train 0.2325754366213023, test 0.24107327032834291\n",
      "RMSE, train 0.23254158543516892, test 0.2413400726703306\n",
      "RMSE, train 0.23251218687404285, test 0.24110803877313933\n",
      "RMSE, train 0.23247655330583303, test 0.2410399580063919\n",
      "RMSE, train 0.23247404174521716, test 0.24109171672413746\n",
      "RMSE, train 0.23249102974630365, test 0.2412689016200602\n",
      "RMSE, train 0.23245073787190698, test 0.2410056305428346\n",
      "RMSE, train 0.2324462252659629, test 0.24110139797752103\n",
      "RMSE, train 0.23244501567549175, test 0.24117205835257968\n",
      "RMSE, train 0.2323832708326253, test 0.24122740188613534\n",
      "RMSE, train 0.2323883188267549, test 0.24101165138805905\n",
      "RMSE, train 0.2323766424123085, test 0.24080954119563103\n",
      "RMSE, train 0.23235270313241266, test 0.2409656772700449\n",
      "RMSE, train 0.23236171231426375, test 0.24084080941975117\n",
      "RMSE, train 0.23231841732907776, test 0.24077931481103101\n",
      "RMSE, train 0.23230215523279074, test 0.2411597822792828\n",
      "RMSE, train 0.23230018161914565, test 0.24094831695159277\n",
      "RMSE, train 0.23224437582974483, test 0.24095637739325562\n",
      "RMSE, train 0.23226483452199687, test 0.24131784106915197\n",
      "RMSE, train 0.23225877117930036, test 0.2407320950490733\n",
      "RMSE, train 0.23222409843495398, test 0.24066399270668626\n",
      "RMSE, train 0.23221147891999494, test 0.24096324465548\n",
      "RMSE, train 0.23222302731992017, test 0.2411624804760019\n",
      "RMSE, train 0.23218853406683362, test 0.2412793062006434\n",
      "RMSE, train 0.23217582574697457, test 0.24112735145414868\n",
      "RMSE, train 0.2321408148666825, test 0.240922925217698\n",
      "RMSE, train 0.23216242106123405, test 0.24081625742837787\n",
      "RMSE, train 0.23212095876835814, test 0.24118310725316405\n",
      "RMSE, train 0.23213411179004292, test 0.24107163942729434\n",
      "RMSE, train 0.23211945916968163, test 0.24073294612268606\n",
      "RMSE, train 0.23210027588136267, test 0.24094887574513754\n",
      "Early stopping at epoch 75 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8707608284513935, test 0.8153733640377011\n",
      "RMSE, train 0.7047908434031576, test 0.561557122107063\n",
      "RMSE, train 0.44887267127795416, test 0.3796550878988845\n",
      "RMSE, train 0.3434297520026143, test 0.329234847000667\n",
      "RMSE, train 0.30946274591946654, test 0.30722145962395836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.29419608235618905, test 0.2966809699844037\n",
      "RMSE, train 0.28652888994201337, test 0.29076031715209993\n",
      "RMSE, train 0.2819924190932629, test 0.28727561235427856\n",
      "RMSE, train 0.2792924718204926, test 0.28478031871574266\n",
      "RMSE, train 0.27792493161422754, test 0.2838902531989983\n",
      "RMSE, train 0.27699735968460965, test 0.2823852725060923\n",
      "RMSE, train 0.2763158529996872, test 0.28262213338166475\n",
      "RMSE, train 0.2758966120434742, test 0.2820269661024213\n",
      "RMSE, train 0.2755152749015355, test 0.28296544935022083\n",
      "RMSE, train 0.2753550895288879, test 0.2813809620482581\n",
      "RMSE, train 0.27488166493138455, test 0.2809841212417398\n",
      "RMSE, train 0.2747460210894707, test 0.28075463723923477\n",
      "RMSE, train 0.2744634798149657, test 0.28065438262586084\n",
      "RMSE, train 0.27436371667063053, test 0.2801882725741182\n",
      "RMSE, train 0.2742109154888747, test 0.2800922117062977\n",
      "RMSE, train 0.2742755738348743, test 0.28032147405403\n",
      "RMSE, train 0.2739435564199045, test 0.27968662830867935\n",
      "RMSE, train 0.273941433540097, test 0.27990151702293325\n",
      "RMSE, train 0.27385277617601006, test 0.28002610776041237\n",
      "RMSE, train 0.27365703023726645, test 0.27984924241900444\n",
      "RMSE, train 0.2735011489952312, test 0.27963084767439533\n",
      "RMSE, train 0.2734595622891694, test 0.2799267259293369\n",
      "RMSE, train 0.2734808776698081, test 0.27945498204124825\n",
      "RMSE, train 0.27355249180643126, test 0.27945536335131954\n",
      "RMSE, train 0.2735507642132005, test 0.27944603296262877\n",
      "RMSE, train 0.27335496577951646, test 0.2796314663386771\n",
      "RMSE, train 0.2734687241334022, test 0.28007320168295075\n",
      "RMSE, train 0.2732352486817665, test 0.27978286878871067\n",
      "RMSE, train 0.2733456151223131, test 0.2792748280667833\n",
      "RMSE, train 0.2732117038406838, test 0.2793500982224941\n",
      "RMSE, train 0.27322725156293715, test 0.27935761412871735\n",
      "RMSE, train 0.2731251198806534, test 0.27964406260954483\n",
      "RMSE, train 0.27315142409863813, test 0.2793744448572397\n",
      "RMSE, train 0.27313107031363026, test 0.2792884651571512\n",
      "RMSE, train 0.27314704338449797, test 0.2794667952028768\n",
      "RMSE, train 0.2730987121661504, test 0.27908709911363466\n",
      "RMSE, train 0.27306325493425065, test 0.2791950001514384\n",
      "RMSE, train 0.2730560753015651, test 0.2790369714743325\n",
      "RMSE, train 0.2730274055972858, test 0.2790324219635555\n",
      "RMSE, train 0.2730258503251086, test 0.27926595149827854\n",
      "RMSE, train 0.27307163451621735, test 0.2797347944495933\n",
      "RMSE, train 0.2729605841480829, test 0.2791888645983168\n",
      "RMSE, train 0.27297679206644526, test 0.27911496149109943\n",
      "RMSE, train 0.27299780345040986, test 0.2794731323208128\n",
      "RMSE, train 0.2731203869926644, test 0.2787464519164392\n",
      "RMSE, train 0.27283104306212697, test 0.27882680150547196\n",
      "RMSE, train 0.27305214727106697, test 0.2792592252205525\n",
      "RMSE, train 0.2730628018285714, test 0.27902629332883017\n",
      "RMSE, train 0.27292823593471044, test 0.27909091274653164\n",
      "RMSE, train 0.27289080918484526, test 0.27911371564758675\n",
      "RMSE, train 0.27298933465626246, test 0.2793610629492572\n",
      "RMSE, train 0.2728418536110901, test 0.2789718983694911\n",
      "RMSE, train 0.2730006876854076, test 0.2790703555302961\n",
      "RMSE, train 0.27311892197152887, test 0.2789139404360737\n",
      "RMSE, train 0.27286170325637643, test 0.2789871583559683\n",
      "Early stopping at epoch 60 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8489193336311477, test 0.7641267021861645\n",
      "RMSE, train 0.6114914939141595, test 0.470745331923896\n",
      "RMSE, train 0.3912481273369939, test 0.348201341311866\n",
      "RMSE, train 0.3101248950634837, test 0.3016825050389001\n",
      "RMSE, train 0.28085235065275244, test 0.28569920620787037\n",
      "RMSE, train 0.2710685655140556, test 0.2804601245790447\n",
      "RMSE, train 0.2672949624101677, test 0.277688956725488\n",
      "RMSE, train 0.2653062890864274, test 0.2750855350713117\n",
      "RMSE, train 0.2637790965392451, test 0.2740414712680589\n",
      "RMSE, train 0.2624881048707684, test 0.2729775937051948\n",
      "RMSE, train 0.2614743769703425, test 0.2718729534006994\n",
      "RMSE, train 0.26062194732406213, test 0.2707641101484999\n",
      "RMSE, train 0.25991177301636725, test 0.2698584941275623\n",
      "RMSE, train 0.25927629428727744, test 0.2690904807606968\n",
      "RMSE, train 0.25877045926892706, test 0.2684904952114875\n",
      "RMSE, train 0.2583247169584971, test 0.267686142423831\n",
      "RMSE, train 0.2579387461123445, test 0.267677583278866\n",
      "RMSE, train 0.25758914171713887, test 0.26795078950737594\n",
      "RMSE, train 0.25734230946131353, test 0.26698280720535766\n",
      "RMSE, train 0.257040956729998, test 0.26669285863364506\n",
      "RMSE, train 0.25681365020740193, test 0.266685411060622\n",
      "RMSE, train 0.2566254382510356, test 0.26675211535681276\n",
      "RMSE, train 0.25644361207704375, test 0.2661608326325723\n",
      "RMSE, train 0.25632763590513324, test 0.26624332928876265\n",
      "RMSE, train 0.25617186063608244, test 0.26516056129144966\n",
      "RMSE, train 0.2560188699129451, test 0.26520149396100173\n",
      "RMSE, train 0.2559506005102209, test 0.2650123674661741\n",
      "RMSE, train 0.25582372874957027, test 0.26507632721454727\n",
      "RMSE, train 0.2557524943164646, test 0.2650534100488785\n",
      "RMSE, train 0.25566571900796464, test 0.2656381327077883\n",
      "RMSE, train 0.25565179069881483, test 0.26502546572357144\n",
      "RMSE, train 0.2555501797474553, test 0.2648536761146073\n",
      "RMSE, train 0.255508795213539, test 0.2651434451888461\n",
      "RMSE, train 0.25541396084922313, test 0.2653321236918826\n",
      "RMSE, train 0.2553989115785056, test 0.26478745508084606\n",
      "RMSE, train 0.2553609243756987, test 0.2652564486232373\n",
      "RMSE, train 0.25533850855223267, test 0.2647496163845062\n",
      "RMSE, train 0.2552974693844671, test 0.2645292630709639\n",
      "RMSE, train 0.25526680920957984, test 0.2649222852986887\n",
      "RMSE, train 0.255273362446259, test 0.2648730373710667\n",
      "RMSE, train 0.2552034591946901, test 0.2641520556233345\n",
      "RMSE, train 0.25522229038680083, test 0.2647033916154039\n",
      "RMSE, train 0.25520377151768303, test 0.2644182238556923\n",
      "RMSE, train 0.255181764741115, test 0.26473409019478966\n",
      "RMSE, train 0.2551619883609994, test 0.2646075782425907\n",
      "RMSE, train 0.25510917015941686, test 0.26448601470627914\n",
      "RMSE, train 0.25512814074086504, test 0.26435092638391966\n",
      "RMSE, train 0.255072604580845, test 0.2650058660485329\n",
      "RMSE, train 0.25508247289155095, test 0.26407093151446875\n",
      "RMSE, train 0.25504622608423233, test 0.2640878845245466\n",
      "RMSE, train 0.2550465003190554, test 0.26500429404438086\n",
      "RMSE, train 0.25503730018844517, test 0.26467137394148277\n",
      "RMSE, train 0.25502907451359147, test 0.26428771032652726\n",
      "RMSE, train 0.2550044666157175, test 0.26392117074323357\n",
      "RMSE, train 0.2550234954319727, test 0.26457559378868944\n",
      "RMSE, train 0.2549850309576689, test 0.26396430892135025\n",
      "RMSE, train 0.2549894482832853, test 0.26435863124121217\n",
      "RMSE, train 0.25500301582396295, test 0.2645083612531697\n",
      "RMSE, train 0.25496024137254253, test 0.2642756232974726\n",
      "RMSE, train 0.2549319292999169, test 0.26504570942953093\n",
      "RMSE, train 0.25492815569778193, test 0.2649200257905033\n",
      "RMSE, train 0.2549456312851521, test 0.2642355226322052\n",
      "RMSE, train 0.2549355510171219, test 0.26421250867734264\n",
      "RMSE, train 0.25491746929328, test 0.26448481796531503\n",
      "Early stopping at epoch 64 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.901149734536146, test 0.8424144092115383\n",
      "RMSE, train 0.7732308376005314, test 0.6811270595175548\n",
      "RMSE, train 0.6159405238979503, test 0.5327923077981449\n",
      "RMSE, train 0.47249270688892825, test 0.404443283682888\n",
      "RMSE, train 0.361555699816509, test 0.33241075711342893\n",
      "RMSE, train 0.30912400583898086, test 0.3028729317836391\n",
      "RMSE, train 0.2847894749420556, test 0.28801017189488826\n",
      "RMSE, train 0.27131554615327697, test 0.2795006399883807\n",
      "RMSE, train 0.2636828401309577, test 0.2750417908418526\n",
      "RMSE, train 0.25957239251097136, test 0.272120054051714\n",
      "RMSE, train 0.25740404986287524, test 0.27069081857945154\n",
      "RMSE, train 0.25612937271453423, test 0.2703492622641684\n",
      "RMSE, train 0.25526122115286964, test 0.2690956424740912\n",
      "RMSE, train 0.25453826349732994, test 0.26816752509584707\n",
      "RMSE, train 0.25392389053262043, test 0.2673308601946507\n",
      "RMSE, train 0.25330820792927594, test 0.2663593392059641\n",
      "RMSE, train 0.2527344493359115, test 0.266083820496948\n",
      "RMSE, train 0.252265278949024, test 0.2676437455184251\n",
      "RMSE, train 0.2519076718570501, test 0.2661665118145711\n",
      "RMSE, train 0.25159594905064964, test 0.2640117457480107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2513831079430931, test 0.2673868680173911\n",
      "RMSE, train 0.251125881974884, test 0.2642895097582086\n",
      "RMSE, train 0.2509723632041179, test 0.2640274303052032\n",
      "RMSE, train 0.2507464385584811, test 0.2636101610452226\n",
      "RMSE, train 0.2506247731611451, test 0.2628584943928765\n",
      "RMSE, train 0.25049504927954597, test 0.2638249766190075\n",
      "RMSE, train 0.25037064199776093, test 0.26251613746568997\n",
      "RMSE, train 0.25027921533924385, test 0.2619496957190986\n",
      "RMSE, train 0.25020114348365124, test 0.2628087660352003\n",
      "RMSE, train 0.2501176981135955, test 0.2637119873345477\n",
      "RMSE, train 0.2500739431367068, test 0.2625812882358588\n",
      "RMSE, train 0.2500040572216279, test 0.26271802056761623\n",
      "RMSE, train 0.24996078127636762, test 0.2631379147467104\n",
      "RMSE, train 0.2498810281733719, test 0.2615019835314704\n",
      "RMSE, train 0.24987582802206207, test 0.26225855121913466\n",
      "RMSE, train 0.24984401160068015, test 0.26183447415388905\n",
      "RMSE, train 0.2497966275008444, test 0.2619344007621691\n",
      "RMSE, train 0.2497429799934464, test 0.262398215607532\n",
      "RMSE, train 0.24972274304852066, test 0.2626851535248525\n",
      "RMSE, train 0.24970955162744907, test 0.2610229505497275\n",
      "RMSE, train 0.24968995309640563, test 0.2615831006788513\n",
      "RMSE, train 0.24965407166656575, test 0.261414117170769\n",
      "RMSE, train 0.2496463775351608, test 0.2627810944341919\n",
      "RMSE, train 0.24960475972457624, test 0.26114842208843786\n",
      "RMSE, train 0.24959564538154919, test 0.26143747293254704\n",
      "RMSE, train 0.2495918546110887, test 0.261050714306461\n",
      "RMSE, train 0.24957883170409895, test 0.2619734766703207\n",
      "RMSE, train 0.24956843083516436, test 0.2632054881852807\n",
      "RMSE, train 0.2495165139861458, test 0.2606796542706999\n",
      "RMSE, train 0.24954666894575195, test 0.2609759590868811\n",
      "RMSE, train 0.24953423748390124, test 0.26184263463737895\n",
      "RMSE, train 0.24951981241657728, test 0.26243678892700417\n",
      "RMSE, train 0.24948145158925136, test 0.26104450327100104\n",
      "RMSE, train 0.24948915449853748, test 0.26195402313204647\n",
      "RMSE, train 0.24949602595134474, test 0.26123904675534626\n",
      "RMSE, train 0.24947963198403564, test 0.26061143169125306\n",
      "RMSE, train 0.2494457192418128, test 0.26233544367030986\n",
      "RMSE, train 0.24944664240591316, test 0.26213383616752994\n",
      "RMSE, train 0.24943191404155768, test 0.2610250688293605\n",
      "RMSE, train 0.24944129179180943, test 0.26085206576921405\n",
      "RMSE, train 0.249412670342203, test 0.2623911926757942\n",
      "RMSE, train 0.24938697107755656, test 0.26148472046389165\n",
      "RMSE, train 0.24942799854023723, test 0.26154513063940027\n",
      "RMSE, train 0.24935868524032648, test 0.2631571917857939\n",
      "RMSE, train 0.24937335545121916, test 0.26050697021114017\n",
      "RMSE, train 0.2494229063781027, test 0.26159878509137235\n",
      "RMSE, train 0.2493478430704946, test 0.2612673293039637\n",
      "RMSE, train 0.24937073203277135, test 0.2618895543431773\n",
      "RMSE, train 0.24934235250581754, test 0.26066606455636254\n",
      "RMSE, train 0.24932045597503416, test 0.2615999823924407\n",
      "RMSE, train 0.2493377787695928, test 0.2608042310163813\n",
      "RMSE, train 0.2493326319226743, test 0.26130433264866615\n",
      "RMSE, train 0.24939057496409517, test 0.2608190271460894\n",
      "RMSE, train 0.24932733461296192, test 0.26070726510969183\n",
      "RMSE, train 0.24931599744849986, test 0.2625301522248\n",
      "Early stopping at epoch 75 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8675127244702568, test 0.8141171038150787\n",
      "RMSE, train 0.6896098740499296, test 0.5711786889367634\n",
      "RMSE, train 0.46062482479768946, test 0.4081097039911482\n",
      "RMSE, train 0.3415574698917307, test 0.3321983188390732\n",
      "RMSE, train 0.28853829562503375, test 0.294749289088779\n",
      "RMSE, train 0.26470771709060414, test 0.2774521776371532\n",
      "RMSE, train 0.2561929898281303, test 0.2718013467060195\n",
      "RMSE, train 0.25306611076358837, test 0.2693430595927768\n",
      "RMSE, train 0.2514648570847319, test 0.2678845041328006\n",
      "RMSE, train 0.2502638011206835, test 0.26649520893891654\n",
      "RMSE, train 0.24924016155483267, test 0.26532486379146575\n",
      "RMSE, train 0.24833931478689303, test 0.263571288353867\n",
      "RMSE, train 0.2478034641704148, test 0.26321850038237044\n",
      "RMSE, train 0.24724585805941784, test 0.26277527461449307\n",
      "RMSE, train 0.24683941800317996, test 0.26226266241735885\n",
      "RMSE, train 0.24651393226054158, test 0.2619290103514989\n",
      "RMSE, train 0.24619306575737873, test 0.2617397364642885\n",
      "RMSE, train 0.2459204115395276, test 0.26133961528539656\n",
      "RMSE, train 0.24568040375760944, test 0.26067191428608366\n",
      "RMSE, train 0.2454763016691105, test 0.26066063079569074\n",
      "RMSE, train 0.24530098597315766, test 0.2608034382263819\n",
      "RMSE, train 0.24520361319063808, test 0.2601268857717514\n",
      "RMSE, train 0.24504517528888672, test 0.26023391203747853\n",
      "RMSE, train 0.24492645291787274, test 0.25957531382640203\n",
      "RMSE, train 0.2447917104329703, test 0.259639506538709\n",
      "RMSE, train 0.2447301070243522, test 0.25983959270848167\n",
      "RMSE, train 0.24462336109012284, test 0.2593863108091884\n",
      "RMSE, train 0.24453992647623438, test 0.25951687031322057\n",
      "RMSE, train 0.24447722524163537, test 0.2590250058306588\n",
      "RMSE, train 0.2443987227916075, test 0.25913698888487285\n",
      "RMSE, train 0.244340649110609, test 0.25903514011038675\n",
      "RMSE, train 0.24427386210613816, test 0.2587498227755229\n",
      "RMSE, train 0.24420938506280637, test 0.25873362173636755\n",
      "RMSE, train 0.24413721809650687, test 0.2589685613910357\n",
      "RMSE, train 0.24409477167695037, test 0.25906021810240215\n",
      "RMSE, train 0.2440266278635138, test 0.2586458875073327\n",
      "RMSE, train 0.2439640768454724, test 0.2587630195750131\n",
      "RMSE, train 0.24388671684457927, test 0.2582925404111544\n",
      "RMSE, train 0.24386389416986398, test 0.2582243060072263\n",
      "RMSE, train 0.24384425600583984, test 0.2587125645743476\n",
      "RMSE, train 0.24377010284729725, test 0.2588853299617767\n",
      "RMSE, train 0.24376171216810488, test 0.2585436941848861\n",
      "RMSE, train 0.24375657881848575, test 0.25849227988057666\n",
      "RMSE, train 0.24367648905338946, test 0.25858039740059113\n",
      "RMSE, train 0.24360749205810361, test 0.2580583870410919\n",
      "RMSE, train 0.24356542475461318, test 0.2575087736050288\n",
      "RMSE, train 0.24354631969870905, test 0.2579000577330589\n",
      "RMSE, train 0.24345197940290456, test 0.2586176186800003\n",
      "RMSE, train 0.24343351240588648, test 0.2579738560650084\n",
      "RMSE, train 0.24345168776589263, test 0.2586597242289119\n",
      "RMSE, train 0.24340669236414517, test 0.25777016315195295\n",
      "RMSE, train 0.2433576928878409, test 0.2574992650085025\n",
      "RMSE, train 0.24333862293602, test 0.25849470297495525\n",
      "RMSE, train 0.24330655294608555, test 0.2582611218094826\n",
      "RMSE, train 0.2432340963510169, test 0.2583971392777231\n",
      "RMSE, train 0.24328839670455038, test 0.25831395718786454\n",
      "RMSE, train 0.24319631166535247, test 0.2580575582053926\n",
      "RMSE, train 0.2431876149701301, test 0.25812315030230415\n",
      "RMSE, train 0.2431658397145027, test 0.2579289608531528\n",
      "RMSE, train 0.24313941517608828, test 0.257680193748739\n",
      "RMSE, train 0.2431213777421941, test 0.2577233807908164\n",
      "RMSE, train 0.24312754943364392, test 0.25768409305148654\n",
      "Early stopping at epoch 62 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7946852856568427, test 0.7910170657466157\n",
      "RMSE, train 0.7516721134372328, test 0.723178442981508\n",
      "RMSE, train 0.6391002616701615, test 0.5721048938505577\n",
      "RMSE, train 0.5013660433677123, test 0.4704542951752441\n",
      "RMSE, train 0.4215366637794196, test 0.4116083801996828\n",
      "RMSE, train 0.37466923918001227, test 0.3745967185858524\n",
      "RMSE, train 0.34586945496736354, test 0.35209102431933087\n",
      "RMSE, train 0.32850796742077853, test 0.33842201877121975\n",
      "RMSE, train 0.318151329505123, test 0.33034411644694783\n",
      "RMSE, train 0.31225577925848785, test 0.32497729014868687\n",
      "RMSE, train 0.30875425743881824, test 0.32200114985909123\n",
      "RMSE, train 0.3066692252468072, test 0.3196339959448034\n",
      "RMSE, train 0.3053748497607364, test 0.3185629655014385\n",
      "RMSE, train 0.304745050215488, test 0.31791012034271704\n",
      "RMSE, train 0.30370089637621106, test 0.3173270442269065\n",
      "RMSE, train 0.3033141863229514, test 0.3168822763243107\n",
      "RMSE, train 0.30326598237808294, test 0.31587529694191135\n",
      "RMSE, train 0.3024576639706465, test 0.3160738648489268\n",
      "RMSE, train 0.30230076600112077, test 0.3162208115211641\n",
      "RMSE, train 0.302112852995145, test 0.315752187461564\n",
      "RMSE, train 0.301963577570717, test 0.315257361139914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.30179214350023015, test 0.3154798153072897\n",
      "RMSE, train 0.3015453874846251, test 0.31504015218127857\n",
      "RMSE, train 0.30148711159351693, test 0.31524827444192133\n",
      "RMSE, train 0.3012063203420499, test 0.3149615839274243\n",
      "RMSE, train 0.3013197408401587, test 0.3148267585219759\n",
      "RMSE, train 0.30108279248467285, test 0.31491176919503644\n",
      "RMSE, train 0.30114980723280776, test 0.3149728455928841\n",
      "RMSE, train 0.3011525871919828, test 0.3147125597855057\n",
      "RMSE, train 0.30079613210665274, test 0.31414666169821615\n",
      "RMSE, train 0.3007276928949473, test 0.31411775525170144\n",
      "RMSE, train 0.30059094788975704, test 0.31424254269310925\n",
      "RMSE, train 0.30082507668322633, test 0.31441032766091703\n",
      "RMSE, train 0.3005505282532032, test 0.3141649156206786\n",
      "RMSE, train 0.30054301471611106, test 0.31404907263890663\n",
      "RMSE, train 0.3004128239629904, test 0.31381211422308525\n",
      "RMSE, train 0.30031268061810423, test 0.3141462607215149\n",
      "RMSE, train 0.30030769310108313, test 0.31354481403273765\n",
      "RMSE, train 0.30053822878374736, test 0.3139130614622675\n",
      "RMSE, train 0.3003318697797057, test 0.31380712143098466\n",
      "RMSE, train 0.30025405066957683, test 0.3138193418883314\n",
      "RMSE, train 0.30006162130016567, test 0.31372862060864765\n",
      "RMSE, train 0.30024696882896146, test 0.3136052686457682\n",
      "RMSE, train 0.30006610713261556, test 0.31336896016140176\n",
      "RMSE, train 0.30012178093122094, test 0.3131885498461097\n",
      "RMSE, train 0.2999879533475069, test 0.3132186649423657\n",
      "RMSE, train 0.30002950641957354, test 0.3134849249112486\n",
      "RMSE, train 0.29997101972621926, test 0.3134319314149895\n",
      "RMSE, train 0.2998323221588485, test 0.31318674319320255\n",
      "RMSE, train 0.2998914879662483, test 0.31319102298731755\n",
      "RMSE, train 0.29994155029358666, test 0.31364871847509135\n",
      "RMSE, train 0.2998518302198727, test 0.3130451190953303\n",
      "RMSE, train 0.2997486448521136, test 0.313421973375359\n",
      "RMSE, train 0.29983853328344584, test 0.313625742540215\n",
      "RMSE, train 0.29992365020994455, test 0.3131312062643995\n",
      "RMSE, train 0.29985822227152753, test 0.312906262549487\n",
      "RMSE, train 0.2998477843177931, test 0.3131959555727063\n",
      "RMSE, train 0.2996643068665106, test 0.31340186689237154\n",
      "RMSE, train 0.2998999841420167, test 0.313014531978453\n",
      "RMSE, train 0.2997086181471575, test 0.3130946656068166\n",
      "RMSE, train 0.2998901342558686, test 0.3131648597091135\n",
      "RMSE, train 0.29976525811665217, test 0.31336098578241134\n",
      "RMSE, train 0.29973922447645285, test 0.31331548215162874\n",
      "RMSE, train 0.2997007141194892, test 0.3130439024681997\n",
      "RMSE, train 0.2998001532843177, test 0.31312794245854775\n",
      "RMSE, train 0.29958152377518, test 0.3130261262859961\n",
      "Early stopping at epoch 66 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7615793305214005, test 0.7401529594014088\n",
      "RMSE, train 0.6669265396065183, test 0.5957155659173926\n",
      "RMSE, train 0.49850554169729505, test 0.42445412930101156\n",
      "RMSE, train 0.37349992328219944, test 0.3495041076093912\n",
      "RMSE, train 0.3206789822439955, test 0.32401466990510625\n",
      "RMSE, train 0.3019061790722789, test 0.3148588150118788\n",
      "RMSE, train 0.29465191224307724, test 0.3107861562942465\n",
      "RMSE, train 0.2913206491355944, test 0.30837506242096424\n",
      "RMSE, train 0.28943571546162017, test 0.30738811877866584\n",
      "RMSE, train 0.2882284121305654, test 0.30638324779768783\n",
      "RMSE, train 0.2873644249306785, test 0.30525296755755943\n",
      "RMSE, train 0.2865743453830782, test 0.3047751251918574\n",
      "RMSE, train 0.2859789400239183, test 0.3037678780965507\n",
      "RMSE, train 0.2854724284449611, test 0.30347601510584354\n",
      "RMSE, train 0.28500411768603806, test 0.30332366470247507\n",
      "RMSE, train 0.2846159239233744, test 0.30221100461979705\n",
      "RMSE, train 0.2842418328303881, test 0.30242931252966326\n",
      "RMSE, train 0.2839545023561728, test 0.30163614451885223\n",
      "RMSE, train 0.2836954490178161, test 0.30091938578213256\n",
      "RMSE, train 0.28352957711827875, test 0.30119318577150506\n",
      "RMSE, train 0.28330707775824, test 0.3008666333431999\n",
      "RMSE, train 0.2831505465913903, test 0.3007349926047027\n",
      "RMSE, train 0.2829752026332749, test 0.30043889333804447\n",
      "RMSE, train 0.2828663137525019, test 0.300650379465272\n",
      "RMSE, train 0.28274829181456806, test 0.3003657197890182\n",
      "RMSE, train 0.28263933388422235, test 0.2999689900316298\n",
      "RMSE, train 0.2825432669634771, test 0.30016234423965216\n",
      "RMSE, train 0.28240784329145846, test 0.29955053081115085\n",
      "RMSE, train 0.28236687537094557, test 0.2996254727865259\n",
      "RMSE, train 0.282352370369916, test 0.2998771133522193\n",
      "RMSE, train 0.2822652736471759, test 0.2998864948749542\n",
      "RMSE, train 0.2821965432829327, test 0.30011601916824776\n",
      "RMSE, train 0.2821739078546413, test 0.29942936822772026\n",
      "RMSE, train 0.2821285534612458, test 0.29936884390190244\n",
      "RMSE, train 0.28210908460496653, test 0.2994554763038953\n",
      "RMSE, train 0.2820513541951324, test 0.29942457533131045\n",
      "RMSE, train 0.2819641605395861, test 0.2993132447203\n",
      "RMSE, train 0.28196557535968647, test 0.29991078066329163\n",
      "RMSE, train 0.28199727694043003, test 0.2996517318921785\n",
      "RMSE, train 0.28197130805464704, test 0.29921754309907556\n",
      "RMSE, train 0.28192240334670954, test 0.29886763154839474\n",
      "RMSE, train 0.2818981416222423, test 0.2987546371296048\n",
      "RMSE, train 0.2818605719943239, test 0.2991219745017588\n",
      "RMSE, train 0.281790786356938, test 0.298862692900002\n",
      "RMSE, train 0.2817955462619512, test 0.29889789254715043\n",
      "RMSE, train 0.28180615024434197, test 0.29956401077409583\n",
      "RMSE, train 0.2817917458261504, test 0.2992061075444023\n",
      "RMSE, train 0.28176219208222447, test 0.29885386023670435\n",
      "RMSE, train 0.2817317603362931, test 0.2992843164441486\n",
      "RMSE, train 0.28175001361905927, test 0.29932561703026295\n",
      "RMSE, train 0.2817149222875484, test 0.29839652543887496\n",
      "RMSE, train 0.2816951216546574, test 0.2992305156464378\n",
      "RMSE, train 0.28169326356264074, test 0.29874379172300297\n",
      "RMSE, train 0.28169338457813164, test 0.2989731477573514\n",
      "RMSE, train 0.28168420098496205, test 0.29884770636757213\n",
      "RMSE, train 0.2816562597649266, test 0.29878381236145896\n",
      "RMSE, train 0.28159816040083613, test 0.29912911153708893\n",
      "RMSE, train 0.28160423838128945, test 0.29824402105684084\n",
      "RMSE, train 0.28163861419365865, test 0.29847800452262163\n",
      "RMSE, train 0.28159173179154445, test 0.29879182390868664\n",
      "RMSE, train 0.2815964947068932, test 0.29919132062544423\n",
      "RMSE, train 0.28155610292698396, test 0.2985098933180173\n",
      "RMSE, train 0.2815425883263651, test 0.2987038064748049\n",
      "RMSE, train 0.28157878821395865, test 0.2989247255027294\n",
      "RMSE, train 0.2815631549391482, test 0.29910097022851306\n",
      "RMSE, train 0.2815743743093929, test 0.29895773545528453\n",
      "RMSE, train 0.2815466439633658, test 0.2987546706572175\n",
      "RMSE, train 0.2815408848527104, test 0.29881783574819565\n",
      "Early stopping at epoch 68 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7841928716939736, test 0.762403310669793\n",
      "RMSE, train 0.6920958475443231, test 0.6333403103881412\n",
      "RMSE, train 0.5671993737432834, test 0.517302037941085\n",
      "RMSE, train 0.46327848286641576, test 0.41871619158320955\n",
      "RMSE, train 0.37459191985207424, test 0.3546338412496779\n",
      "RMSE, train 0.32624821473324717, test 0.32958133187558913\n",
      "RMSE, train 0.30420971213967973, test 0.31740207307868534\n",
      "RMSE, train 0.29338464337699816, test 0.3108401225672828\n",
      "RMSE, train 0.2879171467453964, test 0.30821327434645757\n",
      "RMSE, train 0.2850819542160574, test 0.30708222256766426\n",
      "RMSE, train 0.2834034216693148, test 0.30603173987732996\n",
      "RMSE, train 0.2822925125893878, test 0.30420347253481544\n",
      "RMSE, train 0.2814209275650528, test 0.3033748146560457\n",
      "RMSE, train 0.28077066406567464, test 0.3028032234973378\n",
      "RMSE, train 0.2802410499265573, test 0.30259000609318415\n",
      "RMSE, train 0.27978271519077436, test 0.30128500875499514\n",
      "RMSE, train 0.27940058583679866, test 0.30155558122528925\n",
      "RMSE, train 0.27899297923251304, test 0.3019257641500897\n",
      "RMSE, train 0.27871663121360973, test 0.30098809483978484\n",
      "RMSE, train 0.27843512454122865, test 0.30078716907236314\n",
      "RMSE, train 0.2781842218014108, test 0.30103840596146053\n",
      "RMSE, train 0.2779797592735033, test 0.3003811339537303\n",
      "RMSE, train 0.2778033696094935, test 0.30036127434836496\n",
      "RMSE, train 0.2775950147858206, test 0.3005541546477212\n",
      "RMSE, train 0.27743451449909623, test 0.29976989726225534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2772912160164584, test 0.29962765822807946\n",
      "RMSE, train 0.27716426981105957, test 0.29947593642605674\n",
      "RMSE, train 0.2770453766992471, test 0.29934568603833517\n",
      "RMSE, train 0.276929532059762, test 0.2996272047360738\n",
      "RMSE, train 0.2768228591854039, test 0.29876581264866725\n",
      "RMSE, train 0.2767155754839314, test 0.29884537872340944\n",
      "RMSE, train 0.27664564047862256, test 0.29890722499953376\n",
      "RMSE, train 0.2765612238340301, test 0.29882971031798256\n",
      "RMSE, train 0.2764885781428242, test 0.2986470595002174\n",
      "RMSE, train 0.2764618194328164, test 0.29866394268141855\n",
      "RMSE, train 0.2763975652241, test 0.29852596041229035\n",
      "RMSE, train 0.2763557555379893, test 0.2989378240373399\n",
      "RMSE, train 0.2763166897139459, test 0.2987795250283347\n",
      "RMSE, train 0.27626524512176565, test 0.2978700194093916\n",
      "RMSE, train 0.27621779082759695, test 0.298377455274264\n",
      "RMSE, train 0.27620982657866977, test 0.29806687153047984\n",
      "RMSE, train 0.2761772949338923, test 0.2980989686316914\n",
      "RMSE, train 0.27615250743463676, test 0.2980837004052268\n",
      "RMSE, train 0.27614457347001026, test 0.2980504451526536\n",
      "RMSE, train 0.27609716476295193, test 0.2980386363135444\n",
      "RMSE, train 0.27606796563635616, test 0.29859369811084535\n",
      "RMSE, train 0.276073680653405, test 0.2980311310953564\n",
      "RMSE, train 0.27602272651426873, test 0.298071406616105\n",
      "RMSE, train 0.2760004152586518, test 0.29807950473494\n",
      "Early stopping at epoch 49 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7831232122543074, test 0.7717898602669055\n",
      "RMSE, train 0.723903762031567, test 0.6734615388589028\n",
      "RMSE, train 0.6223601351645877, test 0.586055881701983\n",
      "RMSE, train 0.5414601273811495, test 0.5143127319140312\n",
      "RMSE, train 0.46643113198681413, test 0.4447973378193684\n",
      "RMSE, train 0.4106162670431107, test 0.40321114047979695\n",
      "RMSE, train 0.3749497868933039, test 0.37589028840645766\n",
      "RMSE, train 0.34998975958779593, test 0.359658739123589\n",
      "RMSE, train 0.33144271401601416, test 0.3437802589092499\n",
      "RMSE, train 0.31736936167207463, test 0.3320022573073705\n",
      "RMSE, train 0.3069702581360333, test 0.3255781787328231\n",
      "RMSE, train 0.2990743615359904, test 0.32252586881319684\n",
      "RMSE, train 0.2933141547849988, test 0.3180351318457188\n",
      "RMSE, train 0.28923576624594, test 0.3110805358260106\n",
      "RMSE, train 0.286321753328463, test 0.3088860828907062\n",
      "RMSE, train 0.2841052430626759, test 0.31253769726325303\n",
      "RMSE, train 0.2824079105601504, test 0.3061905822310692\n",
      "RMSE, train 0.281049515367297, test 0.30710893869400024\n",
      "RMSE, train 0.2799196928925232, test 0.30717373830385697\n",
      "RMSE, train 0.2788025153296016, test 0.30504123388956755\n",
      "RMSE, train 0.27774772479712406, test 0.30302444329628575\n",
      "RMSE, train 0.27662867493347215, test 0.30233874152868223\n",
      "RMSE, train 0.2758414638098155, test 0.3013107151939319\n",
      "RMSE, train 0.2751780013521884, test 0.3027628295314618\n",
      "RMSE, train 0.2745432878766104, test 0.29933431075933653\n",
      "RMSE, train 0.27405971711112703, test 0.30050379553666484\n",
      "RMSE, train 0.2736175622431289, test 0.2998801410580293\n",
      "RMSE, train 0.2732201793762011, test 0.2998116216980494\n",
      "RMSE, train 0.2729063436992443, test 0.2976147723503602\n",
      "RMSE, train 0.27263251035198616, test 0.2974395201756404\n",
      "RMSE, train 0.2723110034086994, test 0.2993901026172516\n",
      "RMSE, train 0.2720361923874353, test 0.29714910227518815\n",
      "RMSE, train 0.27179577719199693, test 0.29677638449730015\n",
      "RMSE, train 0.27154258650225643, test 0.29629515550839597\n",
      "RMSE, train 0.27135112979144693, test 0.29766264443214124\n",
      "RMSE, train 0.2711099023202498, test 0.2958390074662673\n",
      "RMSE, train 0.2709925388250024, test 0.29488229617858547\n",
      "RMSE, train 0.27081275515467207, test 0.2959854881732892\n",
      "RMSE, train 0.27062560028376237, test 0.296768504457596\n",
      "RMSE, train 0.2704505783468021, test 0.2946632105188492\n",
      "RMSE, train 0.2703222334384918, test 0.29527324801072097\n",
      "RMSE, train 0.27019798323929867, test 0.2966172842261119\n",
      "RMSE, train 0.2701111031098529, test 0.29622879051245177\n",
      "RMSE, train 0.2699676841683106, test 0.29377023111551237\n",
      "RMSE, train 0.269875512641167, test 0.29633804811881137\n",
      "RMSE, train 0.26974548301964163, test 0.2944298164966779\n",
      "RMSE, train 0.2696444331392692, test 0.2944033153546162\n",
      "RMSE, train 0.2695656899258355, test 0.2950847748762522\n",
      "RMSE, train 0.2694967053018255, test 0.293582660647539\n",
      "RMSE, train 0.2693680634843969, test 0.29413190484046936\n",
      "RMSE, train 0.2692477318263871, test 0.295082077001914\n",
      "RMSE, train 0.2691958110744708, test 0.2932856163153282\n",
      "RMSE, train 0.2691158438304503, test 0.29320836468384814\n",
      "RMSE, train 0.26902788724297677, test 0.2940075655396168\n",
      "RMSE, train 0.2689769297745369, test 0.29580632941080975\n",
      "RMSE, train 0.268878633405932, test 0.29453925253489077\n",
      "RMSE, train 0.2688057980154905, test 0.29412214114115787\n",
      "RMSE, train 0.2686757748464929, test 0.29249779402445525\n",
      "RMSE, train 0.26864874089061286, test 0.29308915271972996\n",
      "RMSE, train 0.26856266978745147, test 0.29504546695030653\n",
      "RMSE, train 0.26853302859257316, test 0.2943734136911539\n",
      "RMSE, train 0.2684093283901333, test 0.29376596957445145\n",
      "RMSE, train 0.2683874697328728, test 0.29373688308092266\n",
      "RMSE, train 0.26832575659699903, test 0.2923324744288738\n",
      "RMSE, train 0.26824942393652, test 0.2930959319839111\n",
      "RMSE, train 0.2681954611220464, test 0.2925601655091995\n",
      "RMSE, train 0.26813702294573977, test 0.2930262933174769\n",
      "RMSE, train 0.26806944896498947, test 0.2926752351415463\n",
      "RMSE, train 0.2680328974378443, test 0.29235040511076266\n",
      "RMSE, train 0.26798239865592705, test 0.29373733202616376\n",
      "RMSE, train 0.2678604241565009, test 0.29246372271042603\n",
      "RMSE, train 0.2678646725193362, test 0.2920174778271944\n",
      "RMSE, train 0.2678187931902312, test 0.29394947871183735\n",
      "RMSE, train 0.2677647165513113, test 0.2921091725046818\n",
      "RMSE, train 0.2676739185769981, test 0.2935817782313396\n",
      "RMSE, train 0.26763392748119674, test 0.29406070441771776\n",
      "RMSE, train 0.2676414180303288, test 0.2929341269609256\n",
      "RMSE, train 0.2674992049223166, test 0.29404330540161866\n",
      "RMSE, train 0.26743469839898226, test 0.2944009827497678\n",
      "RMSE, train 0.26742155223249275, test 0.2929489389061928\n",
      "RMSE, train 0.26733377339126907, test 0.2933279079122421\n",
      "RMSE, train 0.26731014265635306, test 0.29387776687359196\n",
      "Early stopping at epoch 82 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.MLP, data_dir = 'data_synthetic')\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/mlp/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf63eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.057562894382967, test 0.9687445514625118\n",
      "RMSE, train 0.9688993239473448, test 0.927710622549057\n",
      "RMSE, train 0.9084900533375533, test 0.8394780091701015\n",
      "RMSE, train 0.7530620137281098, test 0.6087778323600369\n",
      "RMSE, train 0.5177460059876969, test 0.43166800227857405\n",
      "RMSE, train 0.4007748443736389, test 0.36500813667812654\n",
      "RMSE, train 0.3480738923837074, test 0.32416471826934046\n",
      "RMSE, train 0.31394439426217624, test 0.2982667538547708\n",
      "RMSE, train 0.29278877493833366, test 0.28680133086539084\n",
      "RMSE, train 0.2799075413274435, test 0.27578647651018634\n",
      "RMSE, train 0.272290995985034, test 0.2745932641048585\n",
      "RMSE, train 0.26836166504343506, test 0.2697576333678538\n",
      "RMSE, train 0.26496414071604196, test 0.2699699266062629\n",
      "RMSE, train 0.26285765661670285, test 0.26619363648276173\n",
      "RMSE, train 0.2620406748042276, test 0.2639843111317004\n",
      "RMSE, train 0.2613959417866153, test 0.2638357734728244\n",
      "RMSE, train 0.2612968903373588, test 0.26474337195677144\n",
      "RMSE, train 0.2590948602869341, test 0.2621322227341513\n",
      "RMSE, train 0.2572991317616621, test 0.2620031421463336\n",
      "RMSE, train 0.25835684865065245, test 0.2610997437469421\n",
      "RMSE, train 0.257158385155347, test 0.2620845950178562\n",
      "RMSE, train 0.25778806159501017, test 0.26363388340800037\n",
      "RMSE, train 0.25639761249597365, test 0.2616938526832288\n",
      "RMSE, train 0.25593646122473973, test 0.2606815503489587\n",
      "RMSE, train 0.2551388457535284, test 0.26129464396545965\n",
      "RMSE, train 0.25478805597179494, test 0.258138591844228\n",
      "RMSE, train 0.2557772894504042, test 0.2610171656574934\n",
      "RMSE, train 0.2552807963795577, test 0.2611559488840641\n",
      "RMSE, train 0.25462468320378673, test 0.26010289680092563\n",
      "RMSE, train 0.2546999841310054, test 0.258955609173544\n",
      "RMSE, train 0.2542603360746689, test 0.2597985717678262\n",
      "RMSE, train 0.2540829507229121, test 0.25915215705190936\n",
      "RMSE, train 0.25405611124316696, test 0.2592872537432178\n",
      "RMSE, train 0.25362284963015513, test 0.25859603249738294\n",
      "RMSE, train 0.25295991718533484, test 0.2576392675119062\n",
      "RMSE, train 0.2534580877853241, test 0.26018631842828566\n",
      "RMSE, train 0.2526774188510985, test 0.2588810283810862\n",
      "RMSE, train 0.2533093603850589, test 0.25691403118112394\n",
      "RMSE, train 0.2529350333799251, test 0.26012981935374196\n",
      "RMSE, train 0.25254287754770793, test 0.25928225091868834\n",
      "RMSE, train 0.251804447486231, test 0.257883521157407\n",
      "RMSE, train 0.25300046889913885, test 0.2599286487506282\n",
      "RMSE, train 0.252577234619102, test 0.2571630797559215\n",
      "RMSE, train 0.2524989698627014, test 0.2580737955868244\n",
      "RMSE, train 0.2531191716081069, test 0.25887750653970626\n",
      "RMSE, train 0.2528997259766688, test 0.2588222578408257\n",
      "RMSE, train 0.2523120640530417, test 0.25834701787079534\n",
      "RMSE, train 0.25223979377463873, test 0.2569628964749075\n",
      "Early stopping at epoch 48 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9990091295498102, test 0.961361239764316\n",
      "RMSE, train 0.9632634678591601, test 0.8890359118457668\n",
      "RMSE, train 0.7934766777975839, test 0.6037181566569431\n",
      "RMSE, train 0.4901162339185896, test 0.39291124907899494\n",
      "RMSE, train 0.36537877135431235, test 0.33851129592450196\n",
      "RMSE, train 0.32128282333252883, test 0.30525298859954864\n",
      "RMSE, train 0.29497138044310484, test 0.28050717225005806\n",
      "RMSE, train 0.2818768224132206, test 0.2746044662126825\n",
      "RMSE, train 0.26962977041479064, test 0.2655508701712632\n",
      "RMSE, train 0.2627686076469508, test 0.25803085564335515\n",
      "RMSE, train 0.25711130227154566, test 0.2556832188909704\n",
      "RMSE, train 0.25122496039278597, test 0.25596232182723433\n",
      "RMSE, train 0.25028720246213165, test 0.24995226924084435\n",
      "RMSE, train 0.24877300324589618, test 0.25099283228974695\n",
      "RMSE, train 0.24523178569459722, test 0.24913080603130594\n",
      "RMSE, train 0.24525676329850185, test 0.24963442784202985\n",
      "RMSE, train 0.24508516491967658, test 0.24543067332634255\n",
      "RMSE, train 0.24312855113252455, test 0.24620645647206582\n",
      "RMSE, train 0.24321197887301926, test 0.24425629427856652\n",
      "RMSE, train 0.24196720512410408, test 0.2434035582113857\n",
      "RMSE, train 0.2415727156889342, test 0.2452582002671297\n",
      "RMSE, train 0.24191492530498426, test 0.24416327180941244\n",
      "RMSE, train 0.2405949652436291, test 0.24369004491932136\n",
      "RMSE, train 0.2394787297708544, test 0.24612317024922567\n",
      "RMSE, train 0.23899633155358949, test 0.24390334660602994\n",
      "RMSE, train 0.23866466377005885, test 0.24212826400502654\n",
      "RMSE, train 0.2380351805041435, test 0.24465289477967034\n",
      "RMSE, train 0.2384748625369207, test 0.24430636476632978\n",
      "RMSE, train 0.238357873128252, test 0.2415144245240314\n",
      "RMSE, train 0.23902479565215978, test 0.24382714163665928\n",
      "RMSE, train 0.23833874457700532, test 0.24294788445815568\n",
      "RMSE, train 0.23788157497581683, test 0.24354689482076108\n",
      "RMSE, train 0.23745956793729112, test 0.2398816093433002\n",
      "RMSE, train 0.23718016306579354, test 0.24606057804478101\n",
      "RMSE, train 0.23715453300821154, test 0.2424352877149897\n",
      "RMSE, train 0.23666188781440017, test 0.23995126094207292\n",
      "RMSE, train 0.23683817799274737, test 0.2403546992904884\n",
      "RMSE, train 0.23581360194545525, test 0.24267611732660246\n",
      "RMSE, train 0.23638902292379482, test 0.24181328135088456\n",
      "RMSE, train 0.23673467226477288, test 0.24034821328299105\n",
      "RMSE, train 0.23618480234372954, test 0.2391549945493375\n",
      "RMSE, train 0.23615193597761244, test 0.24028763070333103\n",
      "RMSE, train 0.2367373904296261, test 0.24074196390622904\n",
      "RMSE, train 0.23560059014783213, test 0.23939150411728\n",
      "RMSE, train 0.23618041809934837, test 0.24215288146221933\n",
      "RMSE, train 0.23608911957456033, test 0.24029581593580482\n",
      "RMSE, train 0.23642107325526868, test 0.24032374329803405\n",
      "RMSE, train 0.23514296173265106, test 0.23964387079900948\n",
      "RMSE, train 0.234923198977523, test 0.24070767947464936\n",
      "RMSE, train 0.23550575666944026, test 0.24013733075669974\n",
      "RMSE, train 0.23485981914316595, test 0.2387023764577779\n",
      "RMSE, train 0.23557988795553625, test 0.2404967904829782\n",
      "RMSE, train 0.23552104289292808, test 0.2419227659702301\n",
      "RMSE, train 0.2352887934398072, test 0.24028750853843925\n",
      "RMSE, train 0.23583398999171218, test 0.23999085080278806\n",
      "RMSE, train 0.23431220734378827, test 0.23918141763318668\n",
      "RMSE, train 0.23505228988615126, test 0.24215864186937158\n",
      "RMSE, train 0.23573586037043134, test 0.23838915725138562\n",
      "RMSE, train 0.2347894025446191, test 0.23982259951347162\n",
      "RMSE, train 0.23562625199857995, test 0.23890114212331692\n",
      "RMSE, train 0.23442957597041902, test 0.24060828097103057\n",
      "RMSE, train 0.23439760770090678, test 0.23976677508393596\n",
      "RMSE, train 0.2347212829118074, test 0.24058852621839066\n",
      "RMSE, train 0.23380694024053664, test 0.2394666601557377\n",
      "RMSE, train 0.2344348660334643, test 0.23945980309701162\n",
      "RMSE, train 0.23512091878273708, test 0.2403587902134115\n",
      "RMSE, train 0.23407491050690774, test 0.23819424273553957\n",
      "RMSE, train 0.2343325145874429, test 0.23979316048385682\n",
      "RMSE, train 0.23457425233987178, test 0.23852431096813895\n",
      "RMSE, train 0.23449334630418403, test 0.24029310564856884\n",
      "RMSE, train 0.23438610917764155, test 0.23872859732917517\n",
      "RMSE, train 0.23425020306156233, test 0.2390408855824431\n",
      "RMSE, train 0.23376739311676759, test 0.23931568534659944\n",
      "RMSE, train 0.2340254987239355, test 0.24037023799971116\n",
      "RMSE, train 0.2345314860223276, test 0.238743899159195\n",
      "RMSE, train 0.23449908762506627, test 0.23965066726789003\n",
      "RMSE, train 0.234148443695384, test 0.23975686944466978\n",
      "Early stopping at epoch 77 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.0215808590973363, test 0.9708929448796991\n",
      "RMSE, train 0.9764414961531218, test 0.9183374439415178\n",
      "RMSE, train 0.8724339941798497, test 0.7401509447055951\n",
      "RMSE, train 0.6189201082120827, test 0.48305714823174895\n",
      "RMSE, train 0.43423128137583417, test 0.38463592725364787\n",
      "RMSE, train 0.3710731673977777, test 0.3503669584006594\n",
      "RMSE, train 0.33560155875393066, test 0.3218094971880578\n",
      "RMSE, train 0.31062501205055953, test 0.2973477275748002\n",
      "RMSE, train 0.2904557736634191, test 0.2881129726506116\n",
      "RMSE, train 0.2765130400657654, test 0.2735989624470995\n",
      "RMSE, train 0.26558705940366045, test 0.2664922813051625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2565253717241003, test 0.2604945134698299\n",
      "RMSE, train 0.2507422308900209, test 0.25331624643060197\n",
      "RMSE, train 0.24846313350490415, test 0.24986908140412548\n",
      "RMSE, train 0.24458040657645858, test 0.24867593549322664\n",
      "RMSE, train 0.2430014171198741, test 0.2467264223255609\n",
      "RMSE, train 0.24233093006270273, test 0.245807133484305\n",
      "RMSE, train 0.24068343963450206, test 0.24226238702734312\n",
      "RMSE, train 0.239338352195998, test 0.24501689386210943\n",
      "RMSE, train 0.23871706171966056, test 0.2418160249658844\n",
      "RMSE, train 0.23799189278629543, test 0.2441177951139316\n",
      "RMSE, train 0.23697937964630533, test 0.24247594033939796\n",
      "RMSE, train 0.2354398362481518, test 0.24213752542671405\n",
      "RMSE, train 0.2358781369383147, test 0.24090650154833207\n",
      "RMSE, train 0.23608588398710242, test 0.24130816012620926\n",
      "RMSE, train 0.2360070832470841, test 0.24081020985256163\n",
      "RMSE, train 0.2350060852732994, test 0.2408621753647662\n",
      "RMSE, train 0.23514921756695584, test 0.24058661897454345\n",
      "RMSE, train 0.23533119685423654, test 0.24020672484970929\n",
      "RMSE, train 0.2336616625250784, test 0.23992168099472397\n",
      "RMSE, train 0.23444663850801079, test 0.23883558718258874\n",
      "RMSE, train 0.23318303279531027, test 0.23764679182255477\n",
      "RMSE, train 0.23320087196349082, test 0.2378638562533939\n",
      "RMSE, train 0.23383175618231677, test 0.23858025761549934\n",
      "RMSE, train 0.23448701202869415, test 0.23780890338514982\n",
      "RMSE, train 0.2334944718936359, test 0.24074012518190502\n",
      "RMSE, train 0.23267588448295715, test 0.23819865181780697\n",
      "RMSE, train 0.23212012894817, test 0.23871611548881783\n",
      "RMSE, train 0.23267743506157068, test 0.23808285953444347\n",
      "RMSE, train 0.23217756841292006, test 0.2392958347734652\n",
      "RMSE, train 0.2321391313759757, test 0.23710158532648756\n",
      "RMSE, train 0.23230021548614319, test 0.23698142079407708\n",
      "RMSE, train 0.23201548243001072, test 0.2383956126215165\n",
      "RMSE, train 0.23283616178579677, test 0.23698349793752035\n",
      "RMSE, train 0.23153704809926468, test 0.2365041154910598\n",
      "RMSE, train 0.2305603175719918, test 0.2387920559236878\n",
      "RMSE, train 0.23163536197341072, test 0.23643900035766133\n",
      "RMSE, train 0.23086690869349152, test 0.23706241259187982\n",
      "RMSE, train 0.23222689036685012, test 0.2367252182672944\n",
      "RMSE, train 0.23091152549457195, test 0.23716564626808753\n",
      "RMSE, train 0.23070799981925025, test 0.23731537633820585\n",
      "RMSE, train 0.2311819718558905, test 0.2365417841233705\n",
      "RMSE, train 0.23184092878215096, test 0.23757010280040272\n",
      "RMSE, train 0.23114060016392646, test 0.23749730579162898\n",
      "RMSE, train 0.23082859768097336, test 0.2359147601875297\n",
      "RMSE, train 0.23034807062670112, test 0.23683029001480654\n",
      "RMSE, train 0.23162418025643078, test 0.23620694718862834\n",
      "RMSE, train 0.23097418833261868, test 0.23575762214890697\n",
      "RMSE, train 0.22993845219360487, test 0.23640842853408112\n",
      "RMSE, train 0.23075479102223667, test 0.2352975950690738\n",
      "RMSE, train 0.23033882988922633, test 0.23576743338714568\n",
      "RMSE, train 0.2301351193235373, test 0.23549589946081764\n",
      "RMSE, train 0.23010314186053998, test 0.2355189119514666\n",
      "RMSE, train 0.22987223262471684, test 0.2362991572733511\n",
      "RMSE, train 0.23008757890033316, test 0.23676373803040437\n",
      "RMSE, train 0.22958283512386432, test 0.2356747422824826\n",
      "RMSE, train 0.22982644451770193, test 0.23542160959097377\n",
      "RMSE, train 0.22998855520349576, test 0.2351826574457319\n",
      "RMSE, train 0.23017116005359683, test 0.23590082433401494\n",
      "RMSE, train 0.23026902447821998, test 0.236089481857785\n",
      "RMSE, train 0.2294878287197176, test 0.23659547777813777\n",
      "RMSE, train 0.230084947018481, test 0.236103975524505\n",
      "RMSE, train 0.23022687158732016, test 0.2342676060895125\n",
      "RMSE, train 0.23023821748713694, test 0.2352105631378659\n",
      "RMSE, train 0.2295474868371034, test 0.2361740667307586\n",
      "RMSE, train 0.22948145324678054, test 0.2344297447094792\n",
      "RMSE, train 0.2297563290735806, test 0.23618725295129575\n",
      "RMSE, train 0.22932481181138614, test 0.23557046911956972\n",
      "RMSE, train 0.22942079150918196, test 0.23582908151703968\n",
      "RMSE, train 0.22904148369010832, test 0.23676966745079608\n",
      "RMSE, train 0.22922089362322395, test 0.2352105703270226\n",
      "RMSE, train 0.22973795891252916, test 0.23498889738530443\n",
      "RMSE, train 0.22873996866982121, test 0.2359495242044591\n",
      "Early stopping at epoch 83 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.2531174596283488, test 1.1402054440741445\n",
      "RMSE, train 1.0736052490646344, test 0.9942525549262178\n",
      "RMSE, train 1.0013502228800608, test 0.96574753464437\n",
      "RMSE, train 0.9780946712505277, test 0.9304833844596264\n",
      "RMSE, train 0.9096217870285517, test 0.8133717632176829\n",
      "RMSE, train 0.7612360068608013, test 0.6643263174622667\n",
      "RMSE, train 0.6069931674188532, test 0.526527405807785\n",
      "RMSE, train 0.4888243575653768, test 0.4388106016843927\n",
      "RMSE, train 0.41691668993106606, test 0.3883279471420774\n",
      "RMSE, train 0.3694788880450629, test 0.3476805419606321\n",
      "RMSE, train 0.33646497343775766, test 0.3209829114231409\n",
      "RMSE, train 0.30861863685962976, test 0.29670394328879374\n",
      "RMSE, train 0.29266232814026333, test 0.2848774324737343\n",
      "RMSE, train 0.27719872965875275, test 0.2720799473863022\n",
      "RMSE, train 0.26982500242304974, test 0.26731140108085144\n",
      "RMSE, train 0.2636043799592089, test 0.26341278924077166\n",
      "RMSE, train 0.2577194012256966, test 0.2584618113058455\n",
      "RMSE, train 0.2558787706216935, test 0.25493794613901305\n",
      "RMSE, train 0.25314412973732253, test 0.25860898722620573\n",
      "RMSE, train 0.24957806633025195, test 0.25432518241452234\n",
      "RMSE, train 0.24807455227099057, test 0.251900793874965\n",
      "RMSE, train 0.24518252004089106, test 0.2520059356648548\n",
      "RMSE, train 0.24614069260532362, test 0.2504853362254068\n",
      "RMSE, train 0.24342335017313535, test 0.24912697427413044\n",
      "RMSE, train 0.24289268838477304, test 0.24935074230911686\n",
      "RMSE, train 0.24091483129806338, test 0.24821149280258253\n",
      "RMSE, train 0.23964174865324914, test 0.24657224768809244\n",
      "RMSE, train 0.23979313586236184, test 0.24864657646885105\n",
      "RMSE, train 0.24012596698962418, test 0.24405607318176942\n",
      "RMSE, train 0.2389269868414271, test 0.2426681636156989\n",
      "RMSE, train 0.23677779364272916, test 0.2448775382602916\n",
      "RMSE, train 0.2372624264909999, test 0.24275002146468444\n",
      "RMSE, train 0.23615573545771168, test 0.24072159578402838\n",
      "RMSE, train 0.2366756410260189, test 0.2426313164771772\n",
      "RMSE, train 0.23457249278882808, test 0.24289474702056715\n",
      "RMSE, train 0.23418950141898773, test 0.24251370760155658\n",
      "RMSE, train 0.23471895511082078, test 0.24204857267585456\n",
      "RMSE, train 0.23395597390599354, test 0.24093633700235217\n",
      "RMSE, train 0.23338848761414002, test 0.24055797635924583\n",
      "RMSE, train 0.23431788288892597, test 0.24148742869204165\n",
      "RMSE, train 0.23311664887786196, test 0.24056082145840513\n",
      "RMSE, train 0.2325381596077029, test 0.23971684291666628\n",
      "RMSE, train 0.23236680187302727, test 0.2409398712802167\n",
      "RMSE, train 0.23148086752413566, test 0.2386857139713624\n",
      "RMSE, train 0.23235029803682342, test 0.23966226281196462\n",
      "RMSE, train 0.2313415880597292, test 0.2382078598089078\n",
      "RMSE, train 0.23196626922253494, test 0.23840523080206386\n",
      "RMSE, train 0.23200189211985944, test 0.23841412818314983\n",
      "RMSE, train 0.23040268483053813, test 0.23864966514063815\n",
      "RMSE, train 0.23024456101627508, test 0.2414366835180451\n",
      "RMSE, train 0.23099582475167754, test 0.23903104903943398\n",
      "RMSE, train 0.23044059642530568, test 0.2379469112584404\n",
      "RMSE, train 0.23093801909315273, test 0.2374612843873454\n",
      "RMSE, train 0.22965890960434457, test 0.23812986399028815\n",
      "RMSE, train 0.23075863269106586, test 0.23793892693870208\n",
      "RMSE, train 0.22997671518661528, test 0.23894900667901134\n",
      "RMSE, train 0.22945190338431223, test 0.23759754601062513\n",
      "RMSE, train 0.22999898367394694, test 0.24092387685588762\n",
      "RMSE, train 0.22919510527200518, test 0.23954162337616378\n",
      "RMSE, train 0.22951012673767768, test 0.23668276401711444\n",
      "RMSE, train 0.22944543932104453, test 0.23735309041598263\n",
      "RMSE, train 0.2300014963511351, test 0.23798286030982055\n",
      "RMSE, train 0.22979446015096222, test 0.2377987905752425\n",
      "RMSE, train 0.22901798445100147, test 0.23552266406077965\n",
      "RMSE, train 0.22880824520152623, test 0.23817523956006648\n",
      "RMSE, train 0.22818975171923353, test 0.23614260042999305\n",
      "RMSE, train 0.22832213491557038, test 0.23752785386408076\n",
      "RMSE, train 0.22820607437652166, test 0.2364819385111332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.22789581089785105, test 0.23699798383841328\n",
      "RMSE, train 0.22772387749468798, test 0.23562338561111806\n",
      "RMSE, train 0.22812199557026702, test 0.23617516852477016\n",
      "RMSE, train 0.2276438634869307, test 0.23483114499671787\n",
      "RMSE, train 0.22807212531353238, test 0.23520202554908454\n",
      "RMSE, train 0.22812071154538657, test 0.23530158962981373\n",
      "RMSE, train 0.2279246529844325, test 0.23789763297228253\n",
      "RMSE, train 0.22789284668702783, test 0.23484835481526806\n",
      "RMSE, train 0.2281969473975086, test 0.23642951622605324\n",
      "RMSE, train 0.2278218841922596, test 0.2361736017114976\n",
      "RMSE, train 0.22822009251055114, test 0.23599373476178037\n",
      "RMSE, train 0.2271669696403005, test 0.23413758082132713\n",
      "RMSE, train 0.22724077141085786, test 0.2355134817315083\n",
      "RMSE, train 0.22752713588086404, test 0.23594905319167117\n",
      "RMSE, train 0.22724716708526407, test 0.23558268951726893\n",
      "RMSE, train 0.22659015931135715, test 0.23541815798072255\n",
      "RMSE, train 0.22668811693111865, test 0.23655099933053933\n",
      "RMSE, train 0.22774210689602717, test 0.23592556845031531\n",
      "RMSE, train 0.22740944197539215, test 0.23593110167512707\n",
      "RMSE, train 0.2267842039394777, test 0.2352124298466187\n",
      "RMSE, train 0.2265841133519118, test 0.23497393588517226\n",
      "RMSE, train 0.22701025114067983, test 0.2383073099395808\n",
      "Early stopping at epoch 90 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9949755984688958, test 0.9525423655825213\n",
      "RMSE, train 0.9633997867424642, test 0.9436832252612783\n",
      "RMSE, train 0.9508068035206487, test 0.9214749725396968\n",
      "RMSE, train 0.8896516163142458, test 0.7962709559389383\n",
      "RMSE, train 0.6840275979690975, test 0.5460088770251629\n",
      "RMSE, train 0.48575385647916025, test 0.41922213026314725\n",
      "RMSE, train 0.4014292312485556, test 0.36366885580307196\n",
      "RMSE, train 0.35260695146937526, test 0.3271940381320055\n",
      "RMSE, train 0.32074097159408754, test 0.3048587397110364\n",
      "RMSE, train 0.29921640278471096, test 0.29011455326040914\n",
      "RMSE, train 0.2844747594227233, test 0.28048094121877815\n",
      "RMSE, train 0.2771212242904209, test 0.27428149142541175\n",
      "RMSE, train 0.2709555652052645, test 0.27064037901803484\n",
      "RMSE, train 0.2664870006903525, test 0.26669146477683514\n",
      "RMSE, train 0.26470902721367534, test 0.26629742943058327\n",
      "RMSE, train 0.2633481321616038, test 0.26628615085251073\n",
      "RMSE, train 0.2627476790559388, test 0.2654163607142188\n",
      "RMSE, train 0.26081023470408493, test 0.2632869105201122\n",
      "RMSE, train 0.2603733407994432, test 0.2625475330047371\n",
      "RMSE, train 0.2592685263784182, test 0.26115701193651875\n",
      "RMSE, train 0.2588799174334253, test 0.2610304685663586\n",
      "RMSE, train 0.25851377201897485, test 0.261081041137049\n",
      "RMSE, train 0.2575853020253201, test 0.26198726473760997\n",
      "RMSE, train 0.25782324593033523, test 0.2617959268083257\n",
      "RMSE, train 0.25759469591561823, test 0.2613579851290411\n",
      "RMSE, train 0.2571140627466863, test 0.26009762459550023\n",
      "RMSE, train 0.2565525506412791, test 0.26071317851050824\n",
      "RMSE, train 0.2563590495096099, test 0.2597305673705645\n",
      "RMSE, train 0.2562224603288116, test 0.2593481653978017\n",
      "RMSE, train 0.25608931920461114, test 0.25980824798591867\n",
      "RMSE, train 0.25596520590085176, test 0.2604249220741682\n",
      "RMSE, train 0.25551654653803957, test 0.25914375163799475\n",
      "RMSE, train 0.2555519338817366, test 0.258927723469813\n",
      "RMSE, train 0.2555479952284405, test 0.2593301864694958\n",
      "RMSE, train 0.2555887015656598, test 0.25873951490752956\n",
      "RMSE, train 0.2555208047251067, test 0.25935063948316023\n",
      "RMSE, train 0.25558843331471565, test 0.2595869379102691\n",
      "RMSE, train 0.2553426737206117, test 0.25948764248327777\n",
      "RMSE, train 0.25537219436298453, test 0.25966970844209686\n",
      "RMSE, train 0.25522980697813535, test 0.25905320491672545\n",
      "RMSE, train 0.25501007586717606, test 0.258838364531186\n",
      "RMSE, train 0.2548304474461944, test 0.2582554718679633\n",
      "RMSE, train 0.25492528471494874, test 0.25818484849181056\n",
      "RMSE, train 0.25497411206484805, test 0.25861171368232444\n",
      "RMSE, train 0.2549472313013769, test 0.25909043540639326\n",
      "RMSE, train 0.25453346949671546, test 0.25807767527655134\n",
      "RMSE, train 0.25461165555903026, test 0.25931985824068715\n",
      "RMSE, train 0.25470221988976965, test 0.25791091773628205\n",
      "RMSE, train 0.25480170097322236, test 0.259809232201458\n",
      "RMSE, train 0.25482920118637625, test 0.2590535940710178\n",
      "RMSE, train 0.2544403135055496, test 0.2578121758689565\n",
      "RMSE, train 0.2543685684401181, test 0.2588707452470606\n",
      "RMSE, train 0.2543683908879757, test 0.25805789306144084\n",
      "RMSE, train 0.2541228692317682, test 0.25834333157736405\n",
      "RMSE, train 0.2542047110656577, test 0.25836288584165334\n",
      "RMSE, train 0.2542672041923769, test 0.2581519389694387\n",
      "RMSE, train 0.2541745864155312, test 0.2580502832477743\n",
      "RMSE, train 0.25431636450511796, test 0.25817871155325045\n",
      "RMSE, train 0.25449522185109313, test 0.25811352907133495\n",
      "RMSE, train 0.25411969267072215, test 0.2578944573717669\n",
      "RMSE, train 0.2542217297239169, test 0.2580334877918574\n",
      "Early stopping at epoch 61 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9793543334095931, test 0.9447126383498564\n",
      "RMSE, train 0.9514908622488503, test 0.9174494071532104\n",
      "RMSE, train 0.8894397202602102, test 0.781912330853737\n",
      "RMSE, train 0.6291612008632708, test 0.4667873609874208\n",
      "RMSE, train 0.41683331288951486, test 0.36328142161591576\n",
      "RMSE, train 0.3448528704995459, test 0.3154372529963316\n",
      "RMSE, train 0.30516608490431607, test 0.2868063425866224\n",
      "RMSE, train 0.28088915994590963, test 0.27032706798133205\n",
      "RMSE, train 0.26697741972267136, test 0.26018236968982017\n",
      "RMSE, train 0.25816139655788084, test 0.25576839873851354\n",
      "RMSE, train 0.25392362481552705, test 0.25381675791942465\n",
      "RMSE, train 0.25073119151321327, test 0.24995912927187094\n",
      "RMSE, train 0.24824683691475016, test 0.2502310046200025\n",
      "RMSE, train 0.2459477882616776, test 0.24823489280070288\n",
      "RMSE, train 0.24568205588489525, test 0.2478995763901937\n",
      "RMSE, train 0.24374302941536116, test 0.24637991202584766\n",
      "RMSE, train 0.24348639650655188, test 0.2461010660913031\n",
      "RMSE, train 0.24304737920357175, test 0.24675346380573207\n",
      "RMSE, train 0.24210791994840647, test 0.24494004009638803\n",
      "RMSE, train 0.2415792055366453, test 0.24431391855922796\n",
      "RMSE, train 0.24146541035618663, test 0.24411241710186005\n",
      "RMSE, train 0.24075641523092245, test 0.24478722565760047\n",
      "RMSE, train 0.24103256822987038, test 0.24409259716838094\n",
      "RMSE, train 0.2405563802573799, test 0.24348162796537756\n",
      "RMSE, train 0.24001705369427184, test 0.24368422339528295\n",
      "RMSE, train 0.23963172056458212, test 0.24459172141248897\n",
      "RMSE, train 0.23930756495264935, test 0.2430052708013583\n",
      "RMSE, train 0.23972106392472242, test 0.24319341955548626\n",
      "RMSE, train 0.2395317125911555, test 0.24300391972064972\n",
      "RMSE, train 0.239530659627077, test 0.24260303289708446\n",
      "RMSE, train 0.23885002153471482, test 0.24340801686048508\n",
      "RMSE, train 0.2390481573183182, test 0.24277516214524286\n",
      "RMSE, train 0.23911594467099048, test 0.24273733504242817\n",
      "RMSE, train 0.23888235810128125, test 0.24258422005479618\n",
      "RMSE, train 0.23873651541831079, test 0.24178163454694263\n",
      "RMSE, train 0.23893290961330588, test 0.24212661941172714\n",
      "RMSE, train 0.23898401095970603, test 0.2424937357841912\n",
      "RMSE, train 0.23871692808822167, test 0.24248819747718714\n",
      "RMSE, train 0.23852721352345688, test 0.24241026655092077\n",
      "RMSE, train 0.23817910771232007, test 0.24235700613866418\n",
      "RMSE, train 0.23840416342882084, test 0.24197934757349854\n",
      "RMSE, train 0.23815349778853173, test 0.24194022103891535\n",
      "RMSE, train 0.23850840256233846, test 0.24185432796761142\n",
      "RMSE, train 0.23834637010639365, test 0.24149145817352555\n",
      "RMSE, train 0.23818998318935228, test 0.2418288089713808\n",
      "RMSE, train 0.23807536074814717, test 0.24191983801833652\n",
      "RMSE, train 0.23816465644920168, test 0.24114273677943115\n",
      "RMSE, train 0.23785271477108158, test 0.24216209326760244\n",
      "RMSE, train 0.2378689117791239, test 0.241963024740502\n",
      "RMSE, train 0.23779687922725007, test 0.24143726984828207\n",
      "RMSE, train 0.23805925835016345, test 0.24181176772562124\n",
      "RMSE, train 0.23817906808877778, test 0.24148607355053142\n",
      "RMSE, train 0.23793871155824542, test 0.24144767287929178\n",
      "RMSE, train 0.237893859124627, test 0.24110399098214458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23795441054731362, test 0.24142784953622495\n",
      "RMSE, train 0.23817607033843838, test 0.24138844291032371\n",
      "RMSE, train 0.23789976783527816, test 0.24203455738596996\n",
      "RMSE, train 0.23773995392824993, test 0.24134187930721349\n",
      "RMSE, train 0.2377571110759885, test 0.2415352915808306\n",
      "RMSE, train 0.2379698639750973, test 0.24127444511247895\n",
      "RMSE, train 0.23764728970271498, test 0.24100267116801213\n",
      "RMSE, train 0.23794330142376838, test 0.2413073312175476\n",
      "RMSE, train 0.23747995037062108, test 0.24167561455298278\n",
      "RMSE, train 0.2377168315131802, test 0.2418050118169542\n",
      "RMSE, train 0.23774219689167236, test 0.24144973618499302\n",
      "RMSE, train 0.23770973856045194, test 0.24192489986702548\n",
      "RMSE, train 0.23793811501919732, test 0.2416587900054657\n",
      "RMSE, train 0.23742433000078872, test 0.2414551131048445\n",
      "RMSE, train 0.23760684456460732, test 0.24157115817070007\n",
      "RMSE, train 0.23771264856635047, test 0.2413036608594959\n",
      "RMSE, train 0.23799517713795024, test 0.24110705582267147\n",
      "Early stopping at epoch 71 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9826392091177647, test 0.9456577819905111\n",
      "RMSE, train 0.9570027993655152, test 0.9169625427041735\n",
      "RMSE, train 0.8962415821022458, test 0.8067335920142276\n",
      "RMSE, train 0.7005458830618391, test 0.5701105426996946\n",
      "RMSE, train 0.5034520096898338, test 0.4355163834989071\n",
      "RMSE, train 0.4058645540008358, test 0.36743482761085033\n",
      "RMSE, train 0.34649035139800677, test 0.3161726149597338\n",
      "RMSE, train 0.3082805297992848, test 0.29105325429035084\n",
      "RMSE, train 0.28477553065565936, test 0.27427882089146544\n",
      "RMSE, train 0.2682219587574857, test 0.2659423767722079\n",
      "RMSE, train 0.26052182971262466, test 0.25924452886517557\n",
      "RMSE, train 0.2540285286365771, test 0.25539406136210474\n",
      "RMSE, train 0.25114170382355294, test 0.2537743080673473\n",
      "RMSE, train 0.24806017550378065, test 0.251482541007655\n",
      "RMSE, train 0.2462147508376564, test 0.2496232906622546\n",
      "RMSE, train 0.24456465247539652, test 0.2463750448077917\n",
      "RMSE, train 0.24227971883900545, test 0.24699438296790635\n",
      "RMSE, train 0.24150893647296756, test 0.246089398195701\n",
      "RMSE, train 0.24133475481944405, test 0.2440237831324339\n",
      "RMSE, train 0.2403727092644228, test 0.24505779373326472\n",
      "RMSE, train 0.23949123821616952, test 0.2447816947741168\n",
      "RMSE, train 0.23992459073435507, test 0.24497937663857425\n",
      "RMSE, train 0.23863923585362942, test 0.2428013328462839\n",
      "RMSE, train 0.23821397966549027, test 0.2431967579094427\n",
      "RMSE, train 0.2375539645455242, test 0.24228987377136946\n",
      "RMSE, train 0.23706230803642397, test 0.24259025563618966\n",
      "RMSE, train 0.23680810026483598, test 0.24136746382074697\n",
      "RMSE, train 0.23674175237388653, test 0.24330336986375706\n",
      "RMSE, train 0.23653807155057496, test 0.24251288401761226\n",
      "RMSE, train 0.23644109076793937, test 0.24230112255151784\n",
      "RMSE, train 0.23647810375898232, test 0.2413347540423274\n",
      "RMSE, train 0.23631980878854889, test 0.24107256451887743\n",
      "RMSE, train 0.23575079077469238, test 0.2408873766128506\n",
      "RMSE, train 0.23594585285077688, test 0.2410826999694109\n",
      "RMSE, train 0.235739259743223, test 0.24165556952357292\n",
      "RMSE, train 0.23542803717464664, test 0.2402425010555557\n",
      "RMSE, train 0.2348474951416319, test 0.24039410866264785\n",
      "RMSE, train 0.2354440436189211, test 0.24043053814343043\n",
      "RMSE, train 0.23496277601111168, test 0.24037746991962194\n",
      "RMSE, train 0.23475143274450613, test 0.2406340234779886\n",
      "RMSE, train 0.23476034003535126, test 0.24032709747552872\n",
      "RMSE, train 0.23487071235195484, test 0.2402503937482834\n",
      "RMSE, train 0.23491501392622138, test 0.23995572195521422\n",
      "RMSE, train 0.23476473022909725, test 0.23981619639588253\n",
      "RMSE, train 0.2350679663920974, test 0.2396391240347709\n",
      "RMSE, train 0.23404308679576533, test 0.23981907538005284\n",
      "RMSE, train 0.23443010296826788, test 0.2393540714734367\n",
      "RMSE, train 0.2343707581361135, test 0.24025873919682844\n",
      "RMSE, train 0.23408617231840662, test 0.23987957781979016\n",
      "RMSE, train 0.23372495275047608, test 0.23902014390166318\n",
      "RMSE, train 0.23404565054217194, test 0.2392614454563175\n",
      "RMSE, train 0.23399192075324216, test 0.23895565846136638\n",
      "RMSE, train 0.23396716784677735, test 0.23910650504486902\n",
      "RMSE, train 0.233636233736487, test 0.24017713139099733\n",
      "RMSE, train 0.23418688001456084, test 0.2392380983967866\n",
      "RMSE, train 0.2337751877788365, test 0.23952700849622488\n",
      "RMSE, train 0.23356443000774757, test 0.23898465053311416\n",
      "RMSE, train 0.23412569334693983, test 0.23959667648055724\n",
      "RMSE, train 0.23357184195570438, test 0.23923368246427604\n",
      "RMSE, train 0.23366633937379633, test 0.23877959485564912\n",
      "RMSE, train 0.23361152641004468, test 0.23914017475077085\n",
      "RMSE, train 0.2334975040231655, test 0.23935959261975118\n",
      "RMSE, train 0.23353996054798948, test 0.2387657519429922\n",
      "RMSE, train 0.2335430440170313, test 0.23921711197389023\n",
      "RMSE, train 0.23348807707461397, test 0.23862158826419286\n",
      "RMSE, train 0.23336284076855854, test 0.23824626420225417\n",
      "RMSE, train 0.2333131863011254, test 0.23829188530466386\n",
      "RMSE, train 0.2333882376064662, test 0.23907305859029293\n",
      "RMSE, train 0.23339921852861875, test 0.2383443018687623\n",
      "RMSE, train 0.2331424673008763, test 0.23836547069783723\n",
      "RMSE, train 0.2331973355839715, test 0.23865205688135965\n",
      "RMSE, train 0.23315980601934047, test 0.2386348938037242\n",
      "RMSE, train 0.23318986007071268, test 0.2387742239183613\n",
      "RMSE, train 0.2331463370253058, test 0.23811117599585227\n",
      "RMSE, train 0.23322312192979203, test 0.23830741670514857\n",
      "RMSE, train 0.23307722819916304, test 0.2380845399041261\n",
      "RMSE, train 0.23295069877098848, test 0.2378054495368685\n",
      "RMSE, train 0.23311885626487483, test 0.23835265396961144\n",
      "RMSE, train 0.23293717588604407, test 0.23815988576305763\n",
      "RMSE, train 0.23308479932009005, test 0.23825547697820834\n",
      "RMSE, train 0.2331622024442116, test 0.23825323847787722\n",
      "RMSE, train 0.2326800459934995, test 0.23839545609163387\n",
      "RMSE, train 0.2331820790349528, test 0.23827314722750867\n",
      "RMSE, train 0.2327723912813565, test 0.23778859579137393\n",
      "RMSE, train 0.2329777518778325, test 0.23803267894046648\n",
      "RMSE, train 0.2333624900556078, test 0.23812797532549926\n",
      "RMSE, train 0.23295546496745548, test 0.2380325554737023\n",
      "RMSE, train 0.23255766314618728, test 0.23798319976776838\n",
      "RMSE, train 0.23287924429430162, test 0.23788010980933905\n",
      "RMSE, train 0.23282889843246776, test 0.2377506737996425\n",
      "RMSE, train 0.23264863191087262, test 0.2386921298291002\n",
      "RMSE, train 0.23313027035956288, test 0.2376789960211941\n",
      "RMSE, train 0.23290593555290454, test 0.2389213311086808\n",
      "RMSE, train 0.2325930984970791, test 0.23851675620036467\n",
      "RMSE, train 0.2325601941035464, test 0.23851997325462954\n",
      "RMSE, train 0.2326863660337099, test 0.23781166385327066\n",
      "RMSE, train 0.23251174539652267, test 0.2389086876064539\n",
      "RMSE, train 0.23281078696380772, test 0.23772449152810232\n",
      "RMSE, train 0.23262561432416662, test 0.23956880957952567\n",
      "RMSE, train 0.2326756986527661, test 0.23848557392401354\n",
      "RMSE, train 0.2326644692480694, test 0.23813859705946275\n",
      "RMSE, train 0.23285120115300928, test 0.2379498803722007\n",
      "Early stopping at epoch 102 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9983699082745316, test 0.954844761376429\n",
      "RMSE, train 0.9613027190812351, test 0.9272838252963442\n",
      "RMSE, train 0.9302552087382757, test 0.8901779567352449\n",
      "RMSE, train 0.8691382999087895, test 0.802688864746479\n",
      "RMSE, train 0.747838597863111, test 0.670352138052083\n",
      "RMSE, train 0.6168586572399932, test 0.5575887943157042\n",
      "RMSE, train 0.5222565237350744, test 0.48111434356130733\n",
      "RMSE, train 0.45491103999189175, test 0.427273898413687\n",
      "RMSE, train 0.4044164398407295, test 0.37795455377511306\n",
      "RMSE, train 0.3636210187723118, test 0.3431363877925006\n",
      "RMSE, train 0.3303612251663558, test 0.31879852952981236\n",
      "RMSE, train 0.30579745933449937, test 0.29927851786517135\n",
      "RMSE, train 0.2892070341591147, test 0.28542317931700234\n",
      "RMSE, train 0.2778898300124847, test 0.2748987360133065\n",
      "RMSE, train 0.26900139035688925, test 0.27082438782008006\n",
      "RMSE, train 0.2614088910643221, test 0.26347541733823643\n",
      "RMSE, train 0.2562827201592019, test 0.260823816663087\n",
      "RMSE, train 0.2529429199133059, test 0.2571415368354682\n",
      "RMSE, train 0.25093751180288554, test 0.2540247062541018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.24858497268996205, test 0.25329994447905607\n",
      "RMSE, train 0.2461192172503413, test 0.25144731862978503\n",
      "RMSE, train 0.24419299321827503, test 0.25113415642820225\n",
      "RMSE, train 0.24337891104897544, test 0.24854412328715275\n",
      "RMSE, train 0.24183150011053295, test 0.24833099348376494\n",
      "RMSE, train 0.2408140719592717, test 0.24779078168700439\n",
      "RMSE, train 0.24017030612763682, test 0.24731219537330396\n",
      "RMSE, train 0.23906856112200356, test 0.2460603111922139\n",
      "RMSE, train 0.2383187904334593, test 0.24609874038383214\n",
      "RMSE, train 0.23779066748607422, test 0.2452672790698331\n",
      "RMSE, train 0.2375307772809544, test 0.2445434471874526\n",
      "RMSE, train 0.23686456363329386, test 0.24539296599951657\n",
      "RMSE, train 0.23629954286047183, test 0.24351590706242454\n",
      "RMSE, train 0.2355557288109236, test 0.24406535291310513\n",
      "RMSE, train 0.23564261609738496, test 0.24352382996467628\n",
      "RMSE, train 0.23503264467844462, test 0.24268700633988236\n",
      "RMSE, train 0.23503430362581332, test 0.242733912184985\n",
      "RMSE, train 0.23498090522359227, test 0.24281839409259834\n",
      "RMSE, train 0.23428533883870084, test 0.24225691578002892\n",
      "RMSE, train 0.23429373314736232, test 0.2422054810355408\n",
      "RMSE, train 0.23367639399682397, test 0.2419224133094152\n",
      "RMSE, train 0.23361553040431007, test 0.24101453357272679\n",
      "RMSE, train 0.23319939383667665, test 0.2409814912261385\n",
      "RMSE, train 0.2331836831307353, test 0.24154785155045866\n",
      "RMSE, train 0.2323382479345886, test 0.24032561435843958\n",
      "RMSE, train 0.23263750616961995, test 0.24111563734935992\n",
      "RMSE, train 0.23260143381022008, test 0.2402569559788463\n",
      "RMSE, train 0.23253716473765945, test 0.240458939111594\n",
      "RMSE, train 0.2323368888321016, test 0.2413991880838317\n",
      "RMSE, train 0.23190356160725825, test 0.24008163313070932\n",
      "RMSE, train 0.23229967556839176, test 0.2399532999655213\n",
      "RMSE, train 0.23149756934211424, test 0.23916566010677454\n",
      "RMSE, train 0.2319088821962002, test 0.2395803208905037\n",
      "RMSE, train 0.23153878839499792, test 0.24003707640098804\n",
      "RMSE, train 0.2313363227109746, test 0.23900056803467298\n",
      "RMSE, train 0.23115804762303974, test 0.23956980157380153\n",
      "RMSE, train 0.23158680634860013, test 0.23937637652411606\n",
      "RMSE, train 0.23136165085952265, test 0.23875184567889782\n",
      "RMSE, train 0.2309836525934541, test 0.2394185046655963\n",
      "RMSE, train 0.2308941529767729, test 0.23876534146491926\n",
      "RMSE, train 0.2309531092935203, test 0.23960777138820802\n",
      "RMSE, train 0.23084852139495113, test 0.23860628135276563\n",
      "RMSE, train 0.2307960998385343, test 0.23902284752840947\n",
      "RMSE, train 0.23070927940691596, test 0.23827801419026923\n",
      "RMSE, train 0.23027208764424825, test 0.23794507348176205\n",
      "RMSE, train 0.23040951526106715, test 0.2388177149825626\n",
      "RMSE, train 0.23056304979440928, test 0.23830312535618292\n",
      "RMSE, train 0.2304954387083613, test 0.23926498748437322\n",
      "RMSE, train 0.23000724464290592, test 0.2380822445407058\n",
      "RMSE, train 0.2299372734533837, test 0.23828453864112045\n",
      "RMSE, train 0.22993514065637566, test 0.23874513895222635\n",
      "RMSE, train 0.2299143821729716, test 0.23812031294360306\n",
      "RMSE, train 0.23002932098646328, test 0.23762779539883738\n",
      "RMSE, train 0.23021474644578174, test 0.2381635591237232\n",
      "RMSE, train 0.22987382656787603, test 0.23804013867570897\n",
      "RMSE, train 0.22971963029910417, test 0.23920059204101562\n",
      "RMSE, train 0.22949019646440566, test 0.2383560553343609\n",
      "RMSE, train 0.2296698622059414, test 0.23776010852871518\n",
      "RMSE, train 0.22923832038795453, test 0.2379612261899794\n",
      "RMSE, train 0.2294798726921851, test 0.23738427971950685\n",
      "RMSE, train 0.2292760168281919, test 0.23804433854541393\n",
      "RMSE, train 0.22972493285363343, test 0.2375976044421244\n",
      "RMSE, train 0.2293547417759021, test 0.23754092674664776\n",
      "RMSE, train 0.22907218865339796, test 0.2378606228816389\n",
      "RMSE, train 0.22887138370196802, test 0.2379350278413657\n",
      "RMSE, train 0.2294230688463505, test 0.2379403222690929\n",
      "RMSE, train 0.22955614572486552, test 0.23802658524176087\n",
      "RMSE, train 0.22924018394393267, test 0.23786061987130327\n",
      "RMSE, train 0.22898153119098877, test 0.23757092308516453\n",
      "RMSE, train 0.22915577309201574, test 0.23798148424336404\n",
      "Early stopping at epoch 89 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9622497471157184, test 0.9344935715198517\n",
      "RMSE, train 0.9248908759394953, test 0.9019499693886709\n",
      "RMSE, train 0.9041713387512964, test 0.8791435421523401\n",
      "RMSE, train 0.8413207456469536, test 0.7554862473980856\n",
      "RMSE, train 0.674838481178461, test 0.5748575433331021\n",
      "RMSE, train 0.5230029208724164, test 0.4592975981659808\n",
      "RMSE, train 0.4398966048620949, test 0.40071629694962907\n",
      "RMSE, train 0.38918817643661147, test 0.3625910567530131\n",
      "RMSE, train 0.352949845766233, test 0.3316846219664913\n",
      "RMSE, train 0.3255079439417882, test 0.3080884934229366\n",
      "RMSE, train 0.30587688528678636, test 0.2952126513345767\n",
      "RMSE, train 0.2945409070177019, test 0.28777179475558007\n",
      "RMSE, train 0.2867825552513284, test 0.2813736680200544\n",
      "RMSE, train 0.28142323437308475, test 0.27844984892566327\n",
      "RMSE, train 0.2768337983053085, test 0.2761120805043285\n",
      "RMSE, train 0.27375087690008576, test 0.2723522462834746\n",
      "RMSE, train 0.2718140185495053, test 0.2714709484223592\n",
      "RMSE, train 0.27031513916190003, test 0.2709453667877084\n",
      "RMSE, train 0.2685834314089176, test 0.2700662814964682\n",
      "RMSE, train 0.268079344152419, test 0.2691484025474322\n",
      "RMSE, train 0.26730842475802447, test 0.2694039561990964\n",
      "RMSE, train 0.26632172869872456, test 0.2676055848093356\n",
      "RMSE, train 0.2654783428023177, test 0.26686695129689525\n",
      "RMSE, train 0.26477440191078777, test 0.26750365960395944\n",
      "RMSE, train 0.2647731523683741, test 0.26659978206379936\n",
      "RMSE, train 0.2643825258166829, test 0.26642933955131953\n",
      "RMSE, train 0.2638183198253478, test 0.26594399509288497\n",
      "RMSE, train 0.263943636528224, test 0.26652568250389425\n",
      "RMSE, train 0.2631720029556554, test 0.2661138163027117\n",
      "RMSE, train 0.26284005095766594, test 0.2655287938097776\n",
      "RMSE, train 0.2631730601376246, test 0.26438000419382324\n",
      "RMSE, train 0.2631894661313739, test 0.26544568422487225\n",
      "RMSE, train 0.2621050541989567, test 0.2662277144648261\n",
      "RMSE, train 0.26248387185748945, test 0.26472166407916503\n",
      "RMSE, train 0.26245939531479, test 0.2657385242439933\n",
      "RMSE, train 0.2620652876794338, test 0.2647802188234814\n",
      "RMSE, train 0.26196427791079213, test 0.2650251372133271\n",
      "RMSE, train 0.2618880539455197, test 0.265007239529642\n",
      "RMSE, train 0.26189171916936055, test 0.26501107594724427\n",
      "RMSE, train 0.2617935361263673, test 0.26457694981057767\n",
      "RMSE, train 0.2611735581366484, test 0.2640780535037235\n",
      "RMSE, train 0.26107014072212303, test 0.26446816476724916\n",
      "RMSE, train 0.2613654028901384, test 0.26400482326240865\n",
      "RMSE, train 0.26152492025174384, test 0.2639081038660922\n",
      "RMSE, train 0.2616973177275874, test 0.2644916409153049\n",
      "RMSE, train 0.2609936547858163, test 0.26442188820091345\n",
      "RMSE, train 0.26132792166688223, test 0.26383189541303503\n",
      "RMSE, train 0.2608438658197064, test 0.2640564628576828\n",
      "RMSE, train 0.2606833737559062, test 0.2642997390890526\n",
      "RMSE, train 0.2611864986560069, test 0.2640207853105109\n",
      "RMSE, train 0.26098069502425586, test 0.2641680234317052\n",
      "RMSE, train 0.2610095641152425, test 0.26409503514483823\n",
      "RMSE, train 0.26092779784163167, test 0.2637633181224435\n",
      "RMSE, train 0.260803753156061, test 0.26405557914305544\n",
      "RMSE, train 0.2607682246006717, test 0.264098281198639\n",
      "RMSE, train 0.2608810493584014, test 0.26417253709445565\n",
      "RMSE, train 0.2604656241957314, test 0.26409979682352586\n",
      "RMSE, train 0.2606152246190497, test 0.2634271107992883\n",
      "RMSE, train 0.2607426457107067, test 0.2636727762676902\n",
      "RMSE, train 0.26094592839848896, test 0.2633906798595089\n",
      "RMSE, train 0.2605004971616032, test 0.26319430667465016\n",
      "RMSE, train 0.26040816193154037, test 0.2642551093535908\n",
      "RMSE, train 0.260648240635464, test 0.26334788018869143\n",
      "RMSE, train 0.26061427700987533, test 0.26379301512645464\n",
      "RMSE, train 0.26056012468150824, test 0.2637619795435566\n",
      "RMSE, train 0.2605127266739026, test 0.26374967434143615\n",
      "RMSE, train 0.2605099675576549, test 0.263106079551123\n",
      "RMSE, train 0.26056829128753056, test 0.2635898439813468\n",
      "RMSE, train 0.26034228399026493, test 0.2638527519874654\n",
      "RMSE, train 0.26048712013674175, test 0.2634697792641187\n",
      "RMSE, train 0.2604989884190323, test 0.26332689922744945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.26030486976065914, test 0.263802282891031\n",
      "RMSE, train 0.2603667151213677, test 0.26403502374887466\n",
      "RMSE, train 0.26003541043105205, test 0.2635385238770711\n",
      "RMSE, train 0.26050798173162565, test 0.26321435467166415\n",
      "RMSE, train 0.2603739052087315, test 0.2633171955407676\n",
      "RMSE, train 0.26003540593607366, test 0.2633987868488845\n",
      "Early stopping at epoch 77 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9278622139917564, test 0.9087975102922191\n",
      "RMSE, train 0.9159655826613149, test 0.8983131201370903\n",
      "RMSE, train 0.8950019643311794, test 0.8532235757164334\n",
      "RMSE, train 0.779965353303148, test 0.6463838333668916\n",
      "RMSE, train 0.546579912273241, test 0.45375306995018666\n",
      "RMSE, train 0.4158540651550212, test 0.3723918704882912\n",
      "RMSE, train 0.3522698154115373, test 0.32498235508151674\n",
      "RMSE, train 0.3141221399646403, test 0.29723602546297984\n",
      "RMSE, train 0.29045270607982726, test 0.2812199543351712\n",
      "RMSE, train 0.2776997035918975, test 0.27263964919940287\n",
      "RMSE, train 0.26833467416449464, test 0.26598351222017536\n",
      "RMSE, train 0.26276230957604263, test 0.26054443146871487\n",
      "RMSE, train 0.2584364120937457, test 0.25977949059527855\n",
      "RMSE, train 0.2561961199827255, test 0.25788418663584667\n",
      "RMSE, train 0.2539350900743671, test 0.2550972878932953\n",
      "RMSE, train 0.25215351629029414, test 0.25465675566507423\n",
      "RMSE, train 0.2514904182238184, test 0.25446009182411694\n",
      "RMSE, train 0.2502230810764742, test 0.2531335850124774\n",
      "RMSE, train 0.24985842792724602, test 0.25296865870123325\n",
      "RMSE, train 0.24933783697347986, test 0.25232697271782417\n",
      "RMSE, train 0.2489493482937985, test 0.2518038511276245\n",
      "RMSE, train 0.24790979662392043, test 0.2507615194372509\n",
      "RMSE, train 0.24782585344749905, test 0.25225006264189015\n",
      "RMSE, train 0.24756546293221207, test 0.2507169123577035\n",
      "RMSE, train 0.24732387619539936, test 0.25088484585285187\n",
      "RMSE, train 0.24689340417425598, test 0.24981062800987908\n",
      "RMSE, train 0.246544866361942, test 0.2499190294224283\n",
      "RMSE, train 0.24653722611582204, test 0.2507924129133639\n",
      "RMSE, train 0.24627499117846197, test 0.2498630053323248\n",
      "RMSE, train 0.24611857302502715, test 0.24993708276230356\n",
      "RMSE, train 0.24590721432190793, test 0.25048526421837186\n",
      "RMSE, train 0.24596587677670131, test 0.25017889206824095\n",
      "RMSE, train 0.24573827659881292, test 0.2500863649274992\n",
      "RMSE, train 0.24595063772930462, test 0.2491660274889158\n",
      "RMSE, train 0.24549709469269795, test 0.24945230820904607\n",
      "RMSE, train 0.24563802528786305, test 0.24898150653942772\n",
      "RMSE, train 0.24508236503651695, test 0.24920400251512942\n",
      "RMSE, train 0.24531157710243437, test 0.24864939749240875\n",
      "RMSE, train 0.24554112325808045, test 0.2491575177596963\n",
      "RMSE, train 0.24525181642256977, test 0.2488437727741573\n",
      "RMSE, train 0.24518785972124452, test 0.24965592130370762\n",
      "RMSE, train 0.24508771980517483, test 0.24899651395237965\n",
      "RMSE, train 0.24450785633485028, test 0.24841567290865857\n",
      "RMSE, train 0.24471718686654562, test 0.2480526443408883\n",
      "RMSE, train 0.24482819785990786, test 0.24876359493836112\n",
      "RMSE, train 0.24447097162658749, test 0.2475654722555824\n",
      "RMSE, train 0.2445926501745884, test 0.24835768043994905\n",
      "RMSE, train 0.24436465937114318, test 0.24880355842735458\n",
      "RMSE, train 0.24453230395185466, test 0.24820723365182462\n",
      "RMSE, train 0.24451015997211392, test 0.24803402527518895\n",
      "RMSE, train 0.24427182830063401, test 0.24835996459359708\n",
      "RMSE, train 0.24436662951978655, test 0.24808857596438863\n",
      "RMSE, train 0.24438139995571914, test 0.24809757769107818\n",
      "RMSE, train 0.2442976537846709, test 0.2481580853462219\n",
      "RMSE, train 0.24416919631563175, test 0.24902084910351296\n",
      "RMSE, train 0.2443516700510766, test 0.2486427339522735\n",
      "Early stopping at epoch 56 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9580156096161214, test 0.9269242084354435\n",
      "RMSE, train 0.9306246016859474, test 0.9031729266184185\n",
      "RMSE, train 0.9109838479302924, test 0.8837988480515436\n",
      "RMSE, train 0.8672942368839889, test 0.7967031532471333\n",
      "RMSE, train 0.7107983595052643, test 0.594112365070833\n",
      "RMSE, train 0.5274347988345698, test 0.4588523323929638\n",
      "RMSE, train 0.42440421705556025, test 0.3799871970480735\n",
      "RMSE, train 0.3574934273356814, test 0.3298529717353506\n",
      "RMSE, train 0.3153585632218908, test 0.29807199182313515\n",
      "RMSE, train 0.29004457075098705, test 0.28317797744492873\n",
      "RMSE, train 0.2748842141820711, test 0.274401676764182\n",
      "RMSE, train 0.26713665173860945, test 0.26899267418668904\n",
      "RMSE, train 0.26126806090498184, test 0.26373320243774206\n",
      "RMSE, train 0.2570477093949981, test 0.26239849394614545\n",
      "RMSE, train 0.2536193306136024, test 0.2582980908385111\n",
      "RMSE, train 0.251681577898729, test 0.2582878004246896\n",
      "RMSE, train 0.25033210047558285, test 0.2548422418329694\n",
      "RMSE, train 0.24845193560347964, test 0.2554058224783031\n",
      "RMSE, train 0.24701941277280517, test 0.25298348465643894\n",
      "RMSE, train 0.24650860059956264, test 0.2518966835026347\n",
      "RMSE, train 0.2457100737990285, test 0.2511180734962498\n",
      "RMSE, train 0.24502662896709057, test 0.2511222102773299\n",
      "RMSE, train 0.24405198119948263, test 0.25000869434907896\n",
      "RMSE, train 0.2437350726247903, test 0.24949070715576138\n",
      "RMSE, train 0.2434859071344538, test 0.2508383624324011\n",
      "RMSE, train 0.2426687722582988, test 0.25020245578857736\n",
      "RMSE, train 0.24265662383605546, test 0.24903300295182323\n",
      "RMSE, train 0.24208519908478443, test 0.24854787363918548\n",
      "RMSE, train 0.24186035943940082, test 0.2481631796567812\n",
      "RMSE, train 0.2413572330244988, test 0.2465036117702449\n",
      "RMSE, train 0.24105305969715118, test 0.247943507422001\n",
      "RMSE, train 0.2409152913788509, test 0.24819078576674156\n",
      "RMSE, train 0.24074595929394924, test 0.24732303592043187\n",
      "RMSE, train 0.24056094754570803, test 0.2473594323484176\n",
      "RMSE, train 0.24072109854408444, test 0.24689918236994962\n",
      "RMSE, train 0.24040230390335948, test 0.24716314030896633\n",
      "RMSE, train 0.24004301221648675, test 0.24688494697623298\n",
      "RMSE, train 0.2397352444684559, test 0.2471293118021904\n",
      "RMSE, train 0.23983495137883942, test 0.24725366212906094\n",
      "RMSE, train 0.23994739002844678, test 0.24649894538275693\n",
      "RMSE, train 0.23977148897043793, test 0.2466401122852203\n",
      "RMSE, train 0.239414129122223, test 0.2465843662209467\n",
      "RMSE, train 0.23950482373681303, test 0.24605647973511197\n",
      "RMSE, train 0.2395610821019908, test 0.24706689493918638\n",
      "RMSE, train 0.23934910924178068, test 0.24598856502716696\n",
      "RMSE, train 0.23917756460172712, test 0.24628770816216775\n",
      "RMSE, train 0.23926051943291463, test 0.24595720519166475\n",
      "RMSE, train 0.23931419268050003, test 0.2462658864369086\n",
      "RMSE, train 0.23898580673697817, test 0.24571135230020646\n",
      "RMSE, train 0.23890079574600998, test 0.24646457018108542\n",
      "RMSE, train 0.23900968815312792, test 0.24625682625748696\n",
      "RMSE, train 0.23911382588704072, test 0.24609986576465293\n",
      "RMSE, train 0.23873141518221844, test 0.24629247407300756\n",
      "RMSE, train 0.23859413379110028, test 0.2460162312886037\n",
      "RMSE, train 0.23884753047618096, test 0.2463285208021829\n",
      "RMSE, train 0.23877863108176287, test 0.2455083232954008\n",
      "RMSE, train 0.23865284804137832, test 0.24577823212934197\n",
      "RMSE, train 0.23855740877678577, test 0.2464811577709443\n",
      "RMSE, train 0.23878204712285053, test 0.24576760309005002\n",
      "RMSE, train 0.2384927129130727, test 0.24591150838847553\n",
      "RMSE, train 0.23844170683969831, test 0.24515818852350252\n",
      "RMSE, train 0.23859849916311657, test 0.24470542425956202\n",
      "RMSE, train 0.23851560046186362, test 0.24522369334457117\n",
      "RMSE, train 0.23829600545723878, test 0.24538959480753733\n",
      "RMSE, train 0.23823442791208557, test 0.2451526574585416\n",
      "RMSE, train 0.23828236314346973, test 0.24491214847892795\n",
      "RMSE, train 0.2384477285793544, test 0.2451464670513748\n",
      "RMSE, train 0.2383841998173517, test 0.24548316111258411\n",
      "RMSE, train 0.23821700962402362, test 0.2452187590095975\n",
      "RMSE, train 0.23811076898879535, test 0.2448220818961432\n",
      "RMSE, train 0.2379910191813392, test 0.2456055986225058\n",
      "RMSE, train 0.23818720085337558, test 0.2452778399264047\n",
      "Early stopping at epoch 72 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.9467318669112041, test 0.9162160356839498\n",
      "RMSE, train 0.9198685592473156, test 0.8921040408313274\n",
      "RMSE, train 0.8892655712787552, test 0.8433630044261614\n",
      "RMSE, train 0.7829625015758505, test 0.6806766589482626\n",
      "RMSE, train 0.5995105106872741, test 0.5229947573194901\n",
      "RMSE, train 0.4704780224898849, test 0.4308695839717984\n",
      "RMSE, train 0.39571622902094716, test 0.36922950980563957\n",
      "RMSE, train 0.3459090068183764, test 0.3321566159526507\n",
      "RMSE, train 0.31170538071580606, test 0.3039233139716089\n",
      "RMSE, train 0.29275658459524917, test 0.2888582594071825\n",
      "RMSE, train 0.27811607199184823, test 0.27791618385041755\n",
      "RMSE, train 0.2701825795300079, test 0.27206881732369464\n",
      "RMSE, train 0.2625160104773863, test 0.2676968704909086\n",
      "RMSE, train 0.25895602052861993, test 0.2621675560561319\n",
      "RMSE, train 0.2554923817891665, test 0.26121333288028836\n",
      "RMSE, train 0.2527800517702343, test 0.2580859794591864\n",
      "RMSE, train 0.250452338219291, test 0.2563868624468644\n",
      "RMSE, train 0.24866275748971736, test 0.2552049298149844\n",
      "RMSE, train 0.24767392757113535, test 0.25283650821074843\n",
      "RMSE, train 0.24625313526602707, test 0.25392035534605384\n",
      "RMSE, train 0.24508306632439295, test 0.2520914499958356\n",
      "RMSE, train 0.24484662534763116, test 0.2517624460160732\n",
      "RMSE, train 0.24329267088511977, test 0.25011592203130323\n",
      "RMSE, train 0.2432120789331619, test 0.2501792435844739\n",
      "RMSE, train 0.242599973662032, test 0.2504326237055163\n",
      "RMSE, train 0.24231102283705364, test 0.2501883110962808\n",
      "RMSE, train 0.24167727257567223, test 0.24903172627091408\n",
      "RMSE, train 0.24117559296163646, test 0.2489499735335509\n",
      "RMSE, train 0.24070422592187168, test 0.2481979033909738\n",
      "RMSE, train 0.24011170420080724, test 0.2477419551772376\n",
      "RMSE, train 0.23999463319025857, test 0.24815336242318153\n",
      "RMSE, train 0.24004924350013637, test 0.2471652990207076\n",
      "RMSE, train 0.23944065471490225, test 0.24701529943073788\n",
      "RMSE, train 0.23960448613371513, test 0.2468525596583883\n",
      "RMSE, train 0.2389772470024499, test 0.24775587596620122\n",
      "RMSE, train 0.2390391808567625, test 0.24714525851110616\n",
      "RMSE, train 0.23827843924965522, test 0.24643550673499703\n",
      "RMSE, train 0.23842424451552255, test 0.24644559466590485\n",
      "RMSE, train 0.2387992390854792, test 0.24604951109116277\n",
      "RMSE, train 0.23830442612219338, test 0.24614719456682602\n",
      "RMSE, train 0.2378351969098804, test 0.24598186214764914\n",
      "RMSE, train 0.23761577847780604, test 0.24621393360818425\n",
      "RMSE, train 0.2373849144111378, test 0.24561720124135414\n",
      "RMSE, train 0.23732647416417044, test 0.24597097979858518\n",
      "RMSE, train 0.23722679487834072, test 0.24515189323574305\n",
      "RMSE, train 0.2371935254019318, test 0.24502050674830875\n",
      "RMSE, train 0.2370901797154937, test 0.24517756405596933\n",
      "RMSE, train 0.23702595273804183, test 0.24511598935350776\n",
      "RMSE, train 0.2368730374734209, test 0.24449973134323955\n",
      "RMSE, train 0.23684684766663444, test 0.24456241074949503\n",
      "RMSE, train 0.23651986192874233, test 0.24418235383927822\n",
      "RMSE, train 0.23666535464651656, test 0.2444913301927348\n",
      "RMSE, train 0.23657105016437444, test 0.24412111301595965\n",
      "RMSE, train 0.23663005864981448, test 0.2454924943546454\n",
      "RMSE, train 0.2363597833824278, test 0.24481790512800217\n",
      "RMSE, train 0.23641813004558737, test 0.24392069674407443\n",
      "RMSE, train 0.23630965335501564, test 0.2453319781149427\n",
      "RMSE, train 0.2360878103610241, test 0.24448025102416673\n",
      "RMSE, train 0.23600445830761785, test 0.24460943338150778\n",
      "RMSE, train 0.23583597253368357, test 0.2437872076407075\n",
      "RMSE, train 0.23575475593708983, test 0.2443242729641497\n",
      "RMSE, train 0.23591859503225845, test 0.24332258058711886\n",
      "RMSE, train 0.23548909615386615, test 0.24409644585102797\n",
      "RMSE, train 0.23548611550770623, test 0.24411827248210707\n",
      "RMSE, train 0.2355701125255137, test 0.24391229140261808\n",
      "RMSE, train 0.23567420782314408, test 0.24365549006809792\n",
      "RMSE, train 0.23559822443157735, test 0.24358651088550687\n",
      "RMSE, train 0.235382328129778, test 0.24367952408889929\n",
      "RMSE, train 0.23549425041284225, test 0.2431648874965807\n",
      "RMSE, train 0.23539125381244552, test 0.24331451952457428\n",
      "RMSE, train 0.23537426024223818, test 0.24356774504606923\n",
      "RMSE, train 0.23501099100468134, test 0.2435798163836201\n",
      "RMSE, train 0.23529371178962968, test 0.243187436213096\n",
      "RMSE, train 0.23540983627540896, test 0.2438182197511196\n",
      "RMSE, train 0.23532589246528318, test 0.24367921116451421\n",
      "RMSE, train 0.23516737831511883, test 0.2442324535610775\n",
      "RMSE, train 0.2348340404304591, test 0.2437798660248518\n",
      "RMSE, train 0.2350876812983041, test 0.24292924270654717\n",
      "RMSE, train 0.2350913185739156, test 0.24300186336040497\n",
      "RMSE, train 0.23471886401224618, test 0.24343169651304683\n",
      "RMSE, train 0.2350209006907964, test 0.24359080024684468\n",
      "RMSE, train 0.23466718520479973, test 0.24303685252865156\n",
      "RMSE, train 0.2348486886482046, test 0.24311375664547086\n",
      "RMSE, train 0.2349252455087021, test 0.24283805365363756\n",
      "RMSE, train 0.2346601022614373, test 0.24293016626810035\n",
      "RMSE, train 0.2346279811151702, test 0.24268441957732043\n",
      "RMSE, train 0.2346704284274819, test 0.24364432444175085\n",
      "RMSE, train 0.23445911788278156, test 0.2429636836362382\n",
      "RMSE, train 0.2348196409416921, test 0.24278241923699775\n",
      "RMSE, train 0.23457280561478452, test 0.24287825605521599\n",
      "RMSE, train 0.23463701114359528, test 0.24317867091546455\n",
      "RMSE, train 0.2345389567616612, test 0.24279128201305866\n",
      "RMSE, train 0.23429183360904154, test 0.24305547634139657\n",
      "RMSE, train 0.23421835094088256, test 0.2428980452629427\n",
      "RMSE, train 0.23428677327253603, test 0.2430568829489251\n",
      "RMSE, train 0.23459797491780435, test 0.24301060289144516\n",
      "Early stopping at epoch 96 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8698394803699585, test 0.8574286709938731\n",
      "RMSE, train 0.8525081361301065, test 0.8458517278943744\n",
      "RMSE, train 0.8400611030769763, test 0.8326001204550266\n",
      "RMSE, train 0.8060961465690131, test 0.7432162272078651\n",
      "RMSE, train 0.6194318101167159, test 0.5042159259319305\n",
      "RMSE, train 0.4564998443999322, test 0.4099236583071096\n",
      "RMSE, train 0.3929825417031909, test 0.3664880841970444\n",
      "RMSE, train 0.3527220663551671, test 0.33652639229382786\n",
      "RMSE, train 0.3266222310741483, test 0.3162540572562388\n",
      "RMSE, train 0.30994368709769904, test 0.3030326930539949\n",
      "RMSE, train 0.3008144920233288, test 0.2980766456042017\n",
      "RMSE, train 0.2950431179247131, test 0.2952849996675338\n",
      "RMSE, train 0.2894785832735448, test 0.29171283609632936\n",
      "RMSE, train 0.2866595300778844, test 0.29059841576963663\n",
      "RMSE, train 0.28439399259152753, test 0.2883878042921424\n",
      "RMSE, train 0.28300447025070524, test 0.28660803687359604\n",
      "RMSE, train 0.2822801408424876, test 0.2865572554458465\n",
      "RMSE, train 0.28098928081054314, test 0.2857307964669807\n",
      "RMSE, train 0.2802324299913606, test 0.28529062640986275\n",
      "RMSE, train 0.27952272508269044, test 0.28431810851075817\n",
      "RMSE, train 0.278690255772574, test 0.2847208520397544\n",
      "RMSE, train 0.2788997634693428, test 0.28368136938661337\n",
      "RMSE, train 0.27830203435909256, test 0.2840672674189721\n",
      "RMSE, train 0.2779029192553107, test 0.28229145319866283\n",
      "RMSE, train 0.276864960432572, test 0.28246953285166193\n",
      "RMSE, train 0.27719203075941873, test 0.2822724699175784\n",
      "RMSE, train 0.27692502237093475, test 0.2824405285396746\n",
      "RMSE, train 0.27640704070430955, test 0.28176992014050484\n",
      "RMSE, train 0.2761426784568882, test 0.28290197984980686\n",
      "RMSE, train 0.2761624799899286, test 0.2824698622737612\n",
      "RMSE, train 0.2759379030312848, test 0.2817609890231064\n",
      "RMSE, train 0.27547336465522876, test 0.2815091566049627\n",
      "RMSE, train 0.27510760805705536, test 0.28228311985731125\n",
      "RMSE, train 0.27546022092205247, test 0.28162324894219637\n",
      "RMSE, train 0.2750189634190146, test 0.28158184460231234\n",
      "RMSE, train 0.27504846142008416, test 0.2813096843393786\n",
      "RMSE, train 0.27482546943854663, test 0.2809813663895641\n",
      "RMSE, train 0.2751346663257395, test 0.28169784215944155\n",
      "RMSE, train 0.2747139162292667, test 0.28097605226295336\n",
      "RMSE, train 0.27458173549512893, test 0.2826929452962109\n",
      "RMSE, train 0.27445391300976407, test 0.2815116542790617\n",
      "RMSE, train 0.27466880661599774, test 0.2800215742151652\n",
      "RMSE, train 0.27446539735742126, test 0.28083864439811024\n",
      "RMSE, train 0.27467279269284933, test 0.28126768741224495\n",
      "RMSE, train 0.274573763114175, test 0.2809058314721499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27440526273125915, test 0.28036647915307966\n",
      "RMSE, train 0.27402189620699496, test 0.2806958608063204\n",
      "RMSE, train 0.27412387842316516, test 0.28131505846977234\n",
      "RMSE, train 0.27444755271369337, test 0.2803592453045504\n",
      "RMSE, train 0.2739286390265089, test 0.2808713199836867\n",
      "RMSE, train 0.2741948056779396, test 0.28061689981924637\n",
      "RMSE, train 0.2744635423738712, test 0.28005464414932896\n",
      "Early stopping at epoch 52 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.889538542304873, test 0.8722343800264761\n",
      "RMSE, train 0.858488895433366, test 0.8430405341157126\n",
      "RMSE, train 0.83523056646099, test 0.8185073596621872\n",
      "RMSE, train 0.7844001748369414, test 0.7256037371421079\n",
      "RMSE, train 0.6357528020715499, test 0.5440294545724851\n",
      "RMSE, train 0.4875135337558028, test 0.44088650679369584\n",
      "RMSE, train 0.41003850463259917, test 0.38383280082580146\n",
      "RMSE, train 0.3608587645495419, test 0.3446820673592594\n",
      "RMSE, train 0.32874882615467893, test 0.3184860512750958\n",
      "RMSE, train 0.30603601289036025, test 0.30329051326721085\n",
      "RMSE, train 0.2930729307668626, test 0.2924325304840683\n",
      "RMSE, train 0.2846708123659874, test 0.28370330462215143\n",
      "RMSE, train 0.2772636231820145, test 0.281911346617095\n",
      "RMSE, train 0.2732007438692811, test 0.277358066324794\n",
      "RMSE, train 0.26936093945006084, test 0.2770705880648499\n",
      "RMSE, train 0.267724506323113, test 0.27407382155230287\n",
      "RMSE, train 0.2665014043784462, test 0.27247093071084505\n",
      "RMSE, train 0.26542594975420175, test 0.2718466017224373\n",
      "RMSE, train 0.26418006520367526, test 0.27139319110354154\n",
      "RMSE, train 0.2628052499262207, test 0.2698863442611257\n",
      "RMSE, train 0.2624633020550146, test 0.2692108951303937\n",
      "RMSE, train 0.26197940642390016, test 0.2694569742734279\n",
      "RMSE, train 0.26164045097982935, test 0.2683697263582037\n",
      "RMSE, train 0.2608130046671816, test 0.2683788978178567\n",
      "RMSE, train 0.25992231675728555, test 0.26768004935268963\n",
      "RMSE, train 0.25989939409387486, test 0.2685411592962545\n",
      "RMSE, train 0.2598478682172138, test 0.2677126629363506\n",
      "RMSE, train 0.25899579512966053, test 0.26635701448545546\n",
      "RMSE, train 0.2589670264333353, test 0.26760361405140765\n",
      "RMSE, train 0.2588904700805788, test 0.26702714964337304\n",
      "RMSE, train 0.258214180779564, test 0.2667551769302526\n",
      "RMSE, train 0.25845764360219375, test 0.2668602381824353\n",
      "RMSE, train 0.2579268045355921, test 0.2658521843339325\n",
      "RMSE, train 0.2580150098544065, test 0.26676552790567415\n",
      "RMSE, train 0.25773959940992663, test 0.2659409446727245\n",
      "RMSE, train 0.2580907586377298, test 0.26586374818185055\n",
      "RMSE, train 0.257501413502768, test 0.26652511434817533\n",
      "RMSE, train 0.25762529637781495, test 0.26676489330759834\n",
      "RMSE, train 0.2576274014508243, test 0.2662627092742045\n",
      "RMSE, train 0.25720612166842005, test 0.2661943740527564\n",
      "RMSE, train 0.25735850338176763, test 0.265474880370525\n",
      "RMSE, train 0.2570988398563167, test 0.2662926107098203\n",
      "RMSE, train 0.25711387733306584, test 0.2651147925799046\n",
      "RMSE, train 0.25728971317343646, test 0.26517726645010326\n",
      "RMSE, train 0.2570848534125918, test 0.26563872643020175\n",
      "RMSE, train 0.25668460097280854, test 0.2648738669146092\n",
      "RMSE, train 0.25695372633468944, test 0.2655747584793546\n",
      "RMSE, train 0.25677954559235294, test 0.2653206439193236\n",
      "RMSE, train 0.25668857597449435, test 0.26525193698909305\n",
      "RMSE, train 0.25661922119257163, test 0.2650316130677494\n",
      "RMSE, train 0.2565058098579736, test 0.2642719771610488\n",
      "RMSE, train 0.2565717658721278, test 0.265468286264927\n",
      "RMSE, train 0.25672948778076554, test 0.2652643712562159\n",
      "RMSE, train 0.25670563032007004, test 0.2649502175937005\n",
      "RMSE, train 0.2562838282953998, test 0.26502817377037957\n",
      "RMSE, train 0.25647609046088204, test 0.26451918318730977\n",
      "RMSE, train 0.2563180985939877, test 0.26573918185649664\n",
      "RMSE, train 0.256385479306159, test 0.26536999164371317\n",
      "RMSE, train 0.25646397050453407, test 0.2646004970467419\n",
      "RMSE, train 0.2562571262163966, test 0.2657126125392564\n",
      "RMSE, train 0.2560956534248831, test 0.26481870431965643\n",
      "Early stopping at epoch 61 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8660403317340479, test 0.8426635343472935\n",
      "RMSE, train 0.8394147818841731, test 0.8181721724352791\n",
      "RMSE, train 0.7911169264208959, test 0.7342105580186381\n",
      "RMSE, train 0.6551362026898708, test 0.5614848217917877\n",
      "RMSE, train 0.4973406296161461, test 0.45019341701442755\n",
      "RMSE, train 0.41198855765924886, test 0.38926278705735806\n",
      "RMSE, train 0.36184245142687527, test 0.3501636695514605\n",
      "RMSE, train 0.32756225007305234, test 0.32127761218733003\n",
      "RMSE, train 0.30406284073894213, test 0.30332009103691693\n",
      "RMSE, train 0.2895339043222527, test 0.29555216489486325\n",
      "RMSE, train 0.2786693303644516, test 0.2876124616386821\n",
      "RMSE, train 0.273061263200223, test 0.2806184929840773\n",
      "RMSE, train 0.2673154446758737, test 0.2775334668101616\n",
      "RMSE, train 0.2656569513813051, test 0.27607840024730534\n",
      "RMSE, train 0.2629231545463594, test 0.27377506526349815\n",
      "RMSE, train 0.2610498455457053, test 0.2715902260495621\n",
      "RMSE, train 0.2597979579359789, test 0.270353396974721\n",
      "RMSE, train 0.2585251318941207, test 0.2697019824414577\n",
      "RMSE, train 0.2579580924148514, test 0.26789785805836464\n",
      "RMSE, train 0.2569421967248169, test 0.2675756298511931\n",
      "RMSE, train 0.25634972984745497, test 0.26762356442733876\n",
      "RMSE, train 0.2555895415875804, test 0.2653914063590244\n",
      "RMSE, train 0.2552606076568436, test 0.2667199692969183\n",
      "RMSE, train 0.2552402419814588, test 0.2667367358520193\n",
      "RMSE, train 0.25455281492366927, test 0.2668612194292754\n",
      "RMSE, train 0.2543793581160684, test 0.26429311048637316\n",
      "RMSE, train 0.25450644636805436, test 0.26542013623182054\n",
      "RMSE, train 0.25388028474431706, test 0.2658332975454701\n",
      "RMSE, train 0.2540587322374987, test 0.2650554165678117\n",
      "RMSE, train 0.2531713039178463, test 0.26382006950748776\n",
      "RMSE, train 0.2532608001857925, test 0.2634409388292183\n",
      "RMSE, train 0.2529707982463678, test 0.26445379896650034\n",
      "RMSE, train 0.2530622725461271, test 0.2655248165998644\n",
      "RMSE, train 0.25285152818414774, test 0.2631645610610258\n",
      "RMSE, train 0.2524993865620212, test 0.26562518257539247\n",
      "RMSE, train 0.251994431726723, test 0.2617489831540191\n",
      "RMSE, train 0.25228025454523445, test 0.2629872791975447\n",
      "RMSE, train 0.251919933247453, test 0.2627196430581287\n",
      "RMSE, train 0.25219190347222986, test 0.26289979042937456\n",
      "RMSE, train 0.2521809305544421, test 0.2626890012072128\n",
      "RMSE, train 0.25150447747628085, test 0.26310766524481544\n",
      "RMSE, train 0.251598833221721, test 0.2630419865684602\n",
      "RMSE, train 0.2513212852905595, test 0.262087108585441\n",
      "RMSE, train 0.2514123542504186, test 0.2639216220783956\n",
      "RMSE, train 0.2513567085716334, test 0.26263005163484404\n",
      "RMSE, train 0.25165512396858875, test 0.2630829858837776\n",
      "Early stopping at epoch 46 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8657731847621681, test 0.8502334614594778\n",
      "RMSE, train 0.8418908369830355, test 0.8262689391771952\n",
      "RMSE, train 0.8232932430553951, test 0.8072249061531491\n",
      "RMSE, train 0.7811260978487945, test 0.7307688461409675\n",
      "RMSE, train 0.6527295668491456, test 0.571932143304083\n",
      "RMSE, train 0.5101801932982679, test 0.4668037143018511\n",
      "RMSE, train 0.4297011854513636, test 0.409364746676551\n",
      "RMSE, train 0.37948066309455913, test 0.3712144434452057\n",
      "RMSE, train 0.34781570290780134, test 0.3426914847559399\n",
      "RMSE, train 0.32214426480213587, test 0.3240645898713006\n",
      "RMSE, train 0.30661881717067524, test 0.3111179204450713\n",
      "RMSE, train 0.29352945181719375, test 0.29972564313146804\n",
      "RMSE, train 0.2841448705151396, test 0.29228265086809796\n",
      "RMSE, train 0.2779750903902671, test 0.28741167883078256\n",
      "RMSE, train 0.2724771024885203, test 0.2823622857530912\n",
      "RMSE, train 0.2686577915261698, test 0.2803377889924579\n",
      "RMSE, train 0.26561386031763895, test 0.2781325990955035\n",
      "RMSE, train 0.2636983503067911, test 0.2769909820622868\n",
      "RMSE, train 0.2611676679868904, test 0.27665887640582193\n",
      "RMSE, train 0.259327605326542, test 0.27413106477922866\n",
      "RMSE, train 0.25882485629413327, test 0.27328095800346797\n",
      "RMSE, train 0.2571152876811529, test 0.2716725278231833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.256344965485871, test 0.2709864892893367\n",
      "RMSE, train 0.2561032512599246, test 0.2702305679519971\n",
      "RMSE, train 0.2552976271293234, test 0.269891627629598\n",
      "RMSE, train 0.2550622305940746, test 0.2704168680641386\n",
      "RMSE, train 0.25405358621534313, test 0.26855899939934413\n",
      "RMSE, train 0.2535920275269814, test 0.26801815066072676\n",
      "RMSE, train 0.25310140032813233, test 0.26713661998510363\n",
      "RMSE, train 0.25235523889970907, test 0.26684099601374733\n",
      "RMSE, train 0.25229737716865025, test 0.26697215090195336\n",
      "RMSE, train 0.2518399887971801, test 0.2662327014737659\n",
      "RMSE, train 0.2515818974319494, test 0.26540312816699346\n",
      "RMSE, train 0.2513014931643427, test 0.2644765022728178\n",
      "RMSE, train 0.25151651206042247, test 0.2644905952943696\n",
      "RMSE, train 0.2506939302075584, test 0.26369382325145935\n",
      "RMSE, train 0.2506220961275769, test 0.2628547140293651\n",
      "RMSE, train 0.25038085717235936, test 0.26561732755766976\n",
      "RMSE, train 0.25008551157870385, test 0.2648459307021565\n",
      "RMSE, train 0.24961875383102025, test 0.2642960551712248\n",
      "RMSE, train 0.24950581993857485, test 0.2641668200492859\n",
      "RMSE, train 0.24908913109662398, test 0.2630045745107863\n",
      "RMSE, train 0.24933608543037405, test 0.2630234893825319\n",
      "RMSE, train 0.24904940138769277, test 0.2632343923052152\n",
      "RMSE, train 0.24888629504451854, test 0.2639820229676035\n",
      "RMSE, train 0.2486540428149411, test 0.26360479609833826\n",
      "RMSE, train 0.24874903000589974, test 0.26262762943903606\n",
      "RMSE, train 0.24824674989817277, test 0.26304114709297816\n",
      "RMSE, train 0.24865613769328176, test 0.263514083955023\n",
      "RMSE, train 0.248331736281233, test 0.26233931614292993\n",
      "RMSE, train 0.2483189318057983, test 0.26251015696260666\n",
      "RMSE, train 0.24749326296251095, test 0.262106058994929\n",
      "RMSE, train 0.24743520157195809, test 0.2609717700216505\n",
      "RMSE, train 0.24754599789082202, test 0.2625268658002218\n",
      "RMSE, train 0.247346277587176, test 0.2619699474838045\n",
      "RMSE, train 0.24773677103121006, test 0.26201021754079395\n",
      "RMSE, train 0.24735993307555781, test 0.2613406353526645\n",
      "RMSE, train 0.2472317820450045, test 0.2616302071346177\n",
      "RMSE, train 0.24735340235046943, test 0.26177413198682997\n",
      "RMSE, train 0.24676048466458797, test 0.2624396786093712\n",
      "RMSE, train 0.24717376310870331, test 0.2610134523775842\n",
      "RMSE, train 0.2471587549885007, test 0.26138017972310384\n",
      "RMSE, train 0.24704047792523376, test 0.2609505012631416\n",
      "RMSE, train 0.246857207057611, test 0.26177164200279446\n",
      "RMSE, train 0.24676843690422345, test 0.26158904913398956\n",
      "RMSE, train 0.24633325029897563, test 0.2616053185529179\n",
      "RMSE, train 0.24609162347175362, test 0.2616334979732831\n",
      "RMSE, train 0.24649827025650003, test 0.25995268954171075\n",
      "RMSE, train 0.2465225420390178, test 0.2619222445620431\n",
      "RMSE, train 0.24648337013959243, test 0.2606266912486818\n",
      "RMSE, train 0.24644513641084945, test 0.2605414993233151\n",
      "RMSE, train 0.2463124753892261, test 0.2606849329339133\n",
      "RMSE, train 0.24614223404072044, test 0.26086198886235556\n",
      "RMSE, train 0.2460708208080893, test 0.2603343357642492\n",
      "RMSE, train 0.2459568811475106, test 0.26023228731420306\n",
      "RMSE, train 0.2462295593036153, test 0.26027543031507067\n",
      "RMSE, train 0.24570870359310243, test 0.2610289517376158\n",
      "RMSE, train 0.24585464476253788, test 0.2611157152387831\n",
      "Early stopping at epoch 78 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7822222026169737, test 0.7799854952879627\n",
      "RMSE, train 0.7532876222087002, test 0.7589482219532283\n",
      "RMSE, train 0.7384419941086058, test 0.7500419523378815\n",
      "RMSE, train 0.7314210370875222, test 0.7439174037991148\n",
      "RMSE, train 0.7221241518308598, test 0.7260978577112911\n",
      "RMSE, train 0.6804057342207519, test 0.6415503467574264\n",
      "RMSE, train 0.5628923509989507, test 0.5062556083154197\n",
      "RMSE, train 0.4595008610513216, test 0.4292061762376265\n",
      "RMSE, train 0.40344672411461624, test 0.38814210349863226\n",
      "RMSE, train 0.3703972260060112, test 0.36397914392779573\n",
      "RMSE, train 0.35070662648578727, test 0.34886337861870276\n",
      "RMSE, train 0.3370046715063104, test 0.34009903458633806\n",
      "RMSE, train 0.3286288003904021, test 0.335700362318694\n",
      "RMSE, train 0.3216666364290895, test 0.33150429165724554\n",
      "RMSE, train 0.31795538473683055, test 0.32660223137248645\n",
      "RMSE, train 0.31591241538961823, test 0.3257318479244155\n",
      "RMSE, train 0.31345120607932214, test 0.32205168827615605\n",
      "RMSE, train 0.31169661187309505, test 0.32343015917623885\n",
      "RMSE, train 0.31068231726479706, test 0.3224631876054436\n",
      "RMSE, train 0.3091255932827742, test 0.32330352880738\n",
      "RMSE, train 0.3083946026114788, test 0.321636650899444\n",
      "RMSE, train 0.3078536130396836, test 0.32115792535772225\n",
      "RMSE, train 0.30695720013313016, test 0.3193781670897898\n",
      "RMSE, train 0.30646611363934423, test 0.3207347471304614\n",
      "RMSE, train 0.3063125931692007, test 0.3178557067206412\n",
      "RMSE, train 0.3054329610104083, test 0.319125429849432\n",
      "RMSE, train 0.30545155616581876, test 0.3169608838630445\n",
      "RMSE, train 0.30536968157169, test 0.3177888068285855\n",
      "RMSE, train 0.3052696372156913, test 0.31749396673356645\n",
      "RMSE, train 0.3041780174944395, test 0.3172417078355346\n",
      "RMSE, train 0.30394882484724, test 0.3167578850430672\n",
      "RMSE, train 0.30390534169225064, test 0.31562426234736585\n",
      "RMSE, train 0.303713447270883, test 0.3164208173149764\n",
      "RMSE, train 0.30417286344145794, test 0.31687505317456793\n",
      "RMSE, train 0.3034962972029497, test 0.3176195245198529\n",
      "RMSE, train 0.30294821212810524, test 0.3169090281231235\n",
      "RMSE, train 0.30301573041890245, test 0.31576900590549817\n",
      "RMSE, train 0.3027764377354993, test 0.3157453958434288\n",
      "RMSE, train 0.30283231464895466, test 0.3161301055941919\n",
      "RMSE, train 0.30304662158261886, test 0.31535730036822235\n",
      "RMSE, train 0.3026589879123972, test 0.315715284058542\n",
      "RMSE, train 0.3023481106335493, test 0.31550172994835207\n",
      "RMSE, train 0.3023980204516926, test 0.31477069342979275\n",
      "RMSE, train 0.3024499876866422, test 0.3155184541687821\n",
      "RMSE, train 0.30197138472262103, test 0.3153380676351412\n",
      "RMSE, train 0.30182855275703235, test 0.3150685589120846\n",
      "RMSE, train 0.3019229347446437, test 0.3158354810392014\n",
      "RMSE, train 0.30233844185662445, test 0.3143222461445163\n",
      "RMSE, train 0.30155897472044657, test 0.3145911768831388\n",
      "RMSE, train 0.30193388294474127, test 0.31478121545579696\n",
      "RMSE, train 0.30148404224577624, test 0.31386942649730526\n",
      "RMSE, train 0.3016609277731049, test 0.31423110206319826\n",
      "RMSE, train 0.30167032191689264, test 0.3140406015545431\n",
      "RMSE, train 0.301568777097758, test 0.3140004769419179\n",
      "RMSE, train 0.30147100354756584, test 0.31430907336750413\n",
      "RMSE, train 0.3012968072972846, test 0.3145707836656859\n",
      "RMSE, train 0.30095623029181895, test 0.31515763368871474\n",
      "RMSE, train 0.3014581731741469, test 0.31378979830428805\n",
      "RMSE, train 0.30136294222111226, test 0.3143717216120826\n",
      "RMSE, train 0.3014210931829252, test 0.3145821112574953\n",
      "RMSE, train 0.3010824041436529, test 0.31444358976200376\n",
      "RMSE, train 0.3011016082064155, test 0.3139042535213509\n",
      "RMSE, train 0.30127221906972107, test 0.3145648194382889\n",
      "RMSE, train 0.30152893365158134, test 0.31355850835039156\n",
      "RMSE, train 0.30112345731637297, test 0.31479709467502553\n",
      "RMSE, train 0.30129453193733335, test 0.31424541876773643\n",
      "RMSE, train 0.30089401269746, test 0.3136097421549787\n",
      "RMSE, train 0.3010179086390218, test 0.3142465974646385\n",
      "RMSE, train 0.30115135473114935, test 0.3140538449239249\n",
      "RMSE, train 0.3007996341709986, test 0.31415453492993056\n",
      "RMSE, train 0.3007323855948623, test 0.31413657948224233\n",
      "RMSE, train 0.3005779337110613, test 0.3142004299043405\n",
      "RMSE, train 0.30071006846457066, test 0.313963793443911\n",
      "RMSE, train 0.30080251242683104, test 0.31339498330848387\n",
      "RMSE, train 0.30086451484696497, test 0.31381582280602116\n",
      "RMSE, train 0.3005783050013638, test 0.3137450558368606\n",
      "RMSE, train 0.30060383539036606, test 0.3139074941476186\n",
      "RMSE, train 0.3004950093683812, test 0.31406055466093197\n",
      "RMSE, train 0.3009279027836247, test 0.31377420551849133\n",
      "RMSE, train 0.3006573196291049, test 0.31329792045583627\n",
      "RMSE, train 0.30015938956755006, test 0.31475124350099853\n",
      "RMSE, train 0.30080612025663145, test 0.31406163537141046\n",
      "RMSE, train 0.3003974048680373, test 0.3141109628809823\n",
      "RMSE, train 0.3007233707566716, test 0.31403970507660295\n",
      "RMSE, train 0.30037762476063007, test 0.31353618821712453\n",
      "RMSE, train 0.30060731446538985, test 0.31319487516326133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.300619694780021, test 0.3135685989953051\n",
      "RMSE, train 0.3002537321344856, test 0.31400875912772286\n",
      "RMSE, train 0.300242265126233, test 0.31366307777587815\n",
      "RMSE, train 0.300443362344448, test 0.31287948290507\n",
      "RMSE, train 0.3003881280025818, test 0.3136647086251866\n",
      "RMSE, train 0.300341348084086, test 0.3130064140064548\n",
      "RMSE, train 0.3003943270678042, test 0.31390656666322186\n",
      "RMSE, train 0.30015511552104157, test 0.3139791049138464\n",
      "RMSE, train 0.3005768668389262, test 0.3156680500868595\n",
      "RMSE, train 0.3003260648119421, test 0.31316652276901286\n",
      "RMSE, train 0.30021833298695993, test 0.3135647304130323\n",
      "RMSE, train 0.300359336335968, test 0.31326359209388194\n",
      "RMSE, train 0.3000557061585354, test 0.31285662723310065\n",
      "RMSE, train 0.3002054773653632, test 0.3141877735503996\n",
      "RMSE, train 0.3003186229024365, test 0.3136134855072908\n",
      "RMSE, train 0.30014899485997293, test 0.3131455899489046\n",
      "RMSE, train 0.30028956192192646, test 0.3132111086989894\n",
      "RMSE, train 0.30051469238142514, test 0.3128634781548471\n",
      "RMSE, train 0.30029395597925396, test 0.3127757927986107\n",
      "RMSE, train 0.30015682551126316, test 0.3131857490298724\n",
      "RMSE, train 0.3001080020569939, test 0.31401141725405296\n",
      "RMSE, train 0.300117609152584, test 0.31357791432828613\n",
      "RMSE, train 0.3002581436432953, test 0.31322508749335704\n",
      "RMSE, train 0.2999149864052211, test 0.3145116296681491\n",
      "RMSE, train 0.3002931292380564, test 0.31378767120115686\n",
      "RMSE, train 0.3005013178788071, test 0.3125502283524985\n",
      "RMSE, train 0.30030087474505884, test 0.3143482807308737\n",
      "RMSE, train 0.30007910655588277, test 0.3131692108481821\n",
      "RMSE, train 0.3002660827925269, test 0.3135430386873207\n",
      "RMSE, train 0.30014994037326215, test 0.31424655276115493\n",
      "RMSE, train 0.3001011258086832, test 0.31374487762499337\n",
      "RMSE, train 0.3000669722379274, test 0.31306241136608703\n",
      "RMSE, train 0.2999234453098698, test 0.31377144609436847\n",
      "RMSE, train 0.3000843158050971, test 0.31334723637561607\n",
      "RMSE, train 0.300239321290718, test 0.3130940996637248\n",
      "RMSE, train 0.30015563392843186, test 0.3135786760937084\n",
      "Early stopping at epoch 122 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7828267133898206, test 0.783723272383213\n",
      "RMSE, train 0.7586986621220907, test 0.7589408084750175\n",
      "RMSE, train 0.731833146903852, test 0.7260363629708687\n",
      "RMSE, train 0.6675846653454232, test 0.6213744630416235\n",
      "RMSE, train 0.5446796320153006, test 0.4972106997544567\n",
      "RMSE, train 0.44566079876338593, test 0.425899491024514\n",
      "RMSE, train 0.3921121082673169, test 0.38960312741498154\n",
      "RMSE, train 0.36074599269965685, test 0.36176946728179854\n",
      "RMSE, train 0.33842822894303487, test 0.34575721217940253\n",
      "RMSE, train 0.3239012672142549, test 0.33434578124433756\n",
      "RMSE, train 0.31519158955926846, test 0.32575786982973415\n",
      "RMSE, train 0.307359913495755, test 0.32089008018374443\n",
      "RMSE, train 0.30251921163965956, test 0.31610274966806173\n",
      "RMSE, train 0.2994856887468786, test 0.314301198348403\n",
      "RMSE, train 0.2966791337562932, test 0.3122920375317335\n",
      "RMSE, train 0.2948146422553544, test 0.30822117378314334\n",
      "RMSE, train 0.29323276550029265, test 0.30930542511244613\n",
      "RMSE, train 0.29193836217275776, test 0.3068483903383215\n",
      "RMSE, train 0.2912333379264432, test 0.30605129338800907\n",
      "RMSE, train 0.28970229181677404, test 0.3061426233810683\n",
      "RMSE, train 0.289153097404374, test 0.3058678514013688\n",
      "RMSE, train 0.28914867450643067, test 0.30631858777875703\n",
      "RMSE, train 0.2876764490372605, test 0.3053528821716706\n",
      "RMSE, train 0.2875861068717157, test 0.3038300334786375\n",
      "RMSE, train 0.2875310861025796, test 0.30185992068921524\n",
      "RMSE, train 0.2869130666508819, test 0.30438663189609844\n",
      "RMSE, train 0.2866352881972838, test 0.3026314688225587\n",
      "RMSE, train 0.2861474317056362, test 0.30351021808261675\n",
      "RMSE, train 0.2862379797028773, test 0.30197803024202585\n",
      "RMSE, train 0.28546425741579795, test 0.3020794227098425\n",
      "RMSE, train 0.2856979126656296, test 0.30114824666331214\n",
      "RMSE, train 0.2855331819843162, test 0.3015732215717435\n",
      "RMSE, train 0.2851034834077864, test 0.3016488580033183\n",
      "RMSE, train 0.2848062952510034, test 0.3013965052862962\n",
      "RMSE, train 0.284747928155191, test 0.3011878828207652\n",
      "RMSE, train 0.28475593271279576, test 0.301703419846793\n",
      "RMSE, train 0.2845222215083512, test 0.30099857846895856\n",
      "RMSE, train 0.28452985297248823, test 0.300337015495946\n",
      "RMSE, train 0.28373346195528004, test 0.301240973174572\n",
      "RMSE, train 0.28457412567704615, test 0.30021865510692197\n",
      "RMSE, train 0.28425495902245695, test 0.3010407568265994\n",
      "RMSE, train 0.2841811784063325, test 0.3003422919039925\n",
      "RMSE, train 0.2839096467753853, test 0.29903597896918654\n",
      "RMSE, train 0.28396323454952, test 0.3001795591165622\n",
      "RMSE, train 0.2838162167957335, test 0.3001431568215291\n",
      "RMSE, train 0.2839898606291925, test 0.30026407819241285\n",
      "RMSE, train 0.28374244701681717, test 0.3006568409812947\n",
      "RMSE, train 0.2833190698440027, test 0.29971908622731763\n",
      "RMSE, train 0.28357638207950975, test 0.2989486465230584\n",
      "RMSE, train 0.28374410872206546, test 0.3004415476073821\n",
      "RMSE, train 0.283392339079368, test 0.2994836485013366\n",
      "RMSE, train 0.28310508969606774, test 0.3003363727281491\n",
      "RMSE, train 0.2832890870143669, test 0.29988348282252747\n",
      "RMSE, train 0.28312661457392907, test 0.29847690494110185\n",
      "RMSE, train 0.2832033392230068, test 0.3000934027756254\n",
      "RMSE, train 0.2833155795103974, test 0.3006156760578354\n",
      "RMSE, train 0.28308929329869725, test 0.2998414843653639\n",
      "RMSE, train 0.2832555900694746, test 0.30114523057515424\n",
      "RMSE, train 0.28311643926332697, test 0.29955948097631335\n",
      "RMSE, train 0.2829492753277523, test 0.2992007080465555\n",
      "RMSE, train 0.2830376788371741, test 0.2993768882006407\n",
      "RMSE, train 0.28306574735677603, test 0.29921663692221045\n",
      "RMSE, train 0.28286719649578584, test 0.2997305557752649\n",
      "RMSE, train 0.2827316356277225, test 0.2996549396775663\n",
      "Early stopping at epoch 64 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7785201927400985, test 0.777045205897755\n",
      "RMSE, train 0.7561140861312012, test 0.7566158798005845\n",
      "RMSE, train 0.7299771190010955, test 0.7196895397371716\n",
      "RMSE, train 0.659455267084898, test 0.6096384012036853\n",
      "RMSE, train 0.5407532104102749, test 0.49994841780927446\n",
      "RMSE, train 0.4540886189738374, test 0.44092189835177525\n",
      "RMSE, train 0.40728575457138516, test 0.4052688204579883\n",
      "RMSE, train 0.3770949410781706, test 0.3841871639092763\n",
      "RMSE, train 0.35608646514602105, test 0.3661274592081706\n",
      "RMSE, train 0.3410413743993343, test 0.3549682782755958\n",
      "RMSE, train 0.3283942652680482, test 0.3429752565092511\n",
      "RMSE, train 0.318677504991264, test 0.3365813543399175\n",
      "RMSE, train 0.3121545133243674, test 0.3303217593166563\n",
      "RMSE, train 0.3062623341208841, test 0.3241781598991818\n",
      "RMSE, train 0.3022328603942439, test 0.31900070375866363\n",
      "RMSE, train 0.2981653303470252, test 0.3156178567144606\n",
      "RMSE, train 0.29434726192462796, test 0.31306541959444684\n",
      "RMSE, train 0.2930349951404124, test 0.3116010073158476\n",
      "RMSE, train 0.2910398208709419, test 0.31075018677446575\n",
      "RMSE, train 0.28970611890692594, test 0.3085587872399224\n",
      "RMSE, train 0.2876825216966819, test 0.30787648922867245\n",
      "RMSE, train 0.28690386240212423, test 0.30614718629254234\n",
      "RMSE, train 0.28607408834917525, test 0.3055678273240725\n",
      "RMSE, train 0.28517165695721247, test 0.30471368266476523\n",
      "RMSE, train 0.2845763883822048, test 0.30492505033810935\n",
      "RMSE, train 0.2840922410597377, test 0.3035959561665853\n",
      "RMSE, train 0.28329179835608703, test 0.30289910982052487\n",
      "RMSE, train 0.28277863911541323, test 0.3027791157364845\n",
      "RMSE, train 0.2825015259961876, test 0.30371878213352627\n",
      "RMSE, train 0.2821616425186476, test 0.30319592191113365\n",
      "RMSE, train 0.28131848569668205, test 0.3005908629960484\n",
      "RMSE, train 0.2815794863228528, test 0.3010062707795037\n",
      "RMSE, train 0.28087766805909714, test 0.30076802720626195\n",
      "RMSE, train 0.2808847859140355, test 0.3013003041346868\n",
      "RMSE, train 0.2804782602263268, test 0.30029991219441093\n",
      "RMSE, train 0.28017047473362516, test 0.30131712473101085\n",
      "RMSE, train 0.27984288881088526, test 0.29982664850023055\n",
      "RMSE, train 0.2796873348260504, test 0.2999220386147499\n",
      "RMSE, train 0.2795171778237402, test 0.300423327088356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27953676148405615, test 0.2993580781751209\n",
      "RMSE, train 0.27961981690154886, test 0.299267231590218\n",
      "RMSE, train 0.2791832025562014, test 0.29916198717223275\n",
      "RMSE, train 0.2794376239381389, test 0.2990141045716074\n",
      "RMSE, train 0.2790824749640056, test 0.29992041173908446\n",
      "RMSE, train 0.27917782440179123, test 0.2983890492055151\n",
      "RMSE, train 0.2787477424684561, test 0.30049813323550756\n",
      "RMSE, train 0.2784617156031318, test 0.29868997633457184\n",
      "RMSE, train 0.27849682739802767, test 0.2997232678863737\n",
      "RMSE, train 0.2785218458050345, test 0.29880874206622443\n",
      "RMSE, train 0.2783024093773808, test 0.2994814117749532\n",
      "RMSE, train 0.2782742833352153, test 0.2985782712697983\n",
      "RMSE, train 0.2783539097183798, test 0.29857026272349885\n",
      "RMSE, train 0.27844163213136064, test 0.29881962686777114\n",
      "RMSE, train 0.27810577325261826, test 0.299848109152582\n",
      "RMSE, train 0.278151558978217, test 0.2994850034515063\n",
      "Early stopping at epoch 55 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7973103480547017, test 0.7880342197723877\n",
      "RMSE, train 0.7558753802397541, test 0.7434769861209087\n",
      "RMSE, train 0.7270874058903192, test 0.7359482065225259\n",
      "RMSE, train 0.7160830300916392, test 0.7225702603658041\n",
      "RMSE, train 0.6955765156174003, test 0.6909245122701694\n",
      "RMSE, train 0.6390128273087499, test 0.6114798684914907\n",
      "RMSE, train 0.5601832470232824, test 0.535044531027476\n",
      "RMSE, train 0.4890569791986935, test 0.47504166379953044\n",
      "RMSE, train 0.43581337813647736, test 0.43246279198389787\n",
      "RMSE, train 0.40076461499353805, test 0.4120571521612314\n",
      "RMSE, train 0.3740514526114657, test 0.3884955476491879\n",
      "RMSE, train 0.3556712078528241, test 0.36989245735681975\n",
      "RMSE, train 0.3412222820464696, test 0.3539512845186087\n",
      "RMSE, train 0.33033971604528456, test 0.34623964283710873\n",
      "RMSE, train 0.3224539885825457, test 0.34073261267099625\n",
      "RMSE, train 0.3147710691731295, test 0.33301243300621325\n",
      "RMSE, train 0.3097255203954156, test 0.3282045420163717\n",
      "RMSE, train 0.30457478218546535, test 0.32235433409611386\n",
      "RMSE, train 0.3003674574730181, test 0.3208456432972199\n",
      "RMSE, train 0.29659319286034486, test 0.316503426585442\n",
      "RMSE, train 0.29403646856639243, test 0.315733498105636\n",
      "RMSE, train 0.29229609278317925, test 0.31312593951439244\n",
      "RMSE, train 0.28979390868888094, test 0.31176826969171184\n",
      "RMSE, train 0.2873810351451981, test 0.3120909402003655\n",
      "RMSE, train 0.28647318287430523, test 0.306298804970888\n",
      "RMSE, train 0.2856354729687313, test 0.31003182858992845\n",
      "RMSE, train 0.28442760322509897, test 0.30798223576484585\n",
      "RMSE, train 0.2838834077119827, test 0.3053959581332329\n",
      "RMSE, train 0.2824841474075555, test 0.30420257456791705\n",
      "RMSE, train 0.28252775962479015, test 0.3052301926490588\n",
      "RMSE, train 0.28150438942084804, test 0.3046552557975818\n",
      "RMSE, train 0.2806672965904634, test 0.3052864567591594\n",
      "RMSE, train 0.2797885889019179, test 0.3040087444659991\n",
      "RMSE, train 0.2799743948695816, test 0.3026578989930642\n",
      "RMSE, train 0.27905834241076793, test 0.30206363189678925\n",
      "RMSE, train 0.2790112710816095, test 0.3029496965882106\n",
      "RMSE, train 0.2786489959075072, test 0.30427213337941045\n",
      "RMSE, train 0.2782610466361417, test 0.30115814468799496\n",
      "RMSE, train 0.27760752566692615, test 0.3033843502784387\n",
      "RMSE, train 0.27746991878172317, test 0.3006690102509963\n",
      "RMSE, train 0.27747128588202585, test 0.3011070021834129\n",
      "RMSE, train 0.27710974685313916, test 0.3013747813992011\n",
      "RMSE, train 0.2768182456029167, test 0.30152582549131834\n",
      "RMSE, train 0.2764288890770291, test 0.3013809948013379\n",
      "RMSE, train 0.27591799459539096, test 0.3000172006014066\n",
      "RMSE, train 0.27588786254419345, test 0.3021556727397136\n",
      "RMSE, train 0.27585109933700147, test 0.30225889422954655\n",
      "RMSE, train 0.27584886430208555, test 0.301850383862471\n",
      "RMSE, train 0.2753206284896607, test 0.3005331598031215\n",
      "RMSE, train 0.2751074164548767, test 0.3009643306334813\n",
      "RMSE, train 0.2752263584055262, test 0.2995371776513564\n",
      "RMSE, train 0.2751252928348345, test 0.2999314652421536\n",
      "RMSE, train 0.275037021187607, test 0.2992333844304085\n",
      "RMSE, train 0.2745108983227026, test 0.2993346338088696\n",
      "RMSE, train 0.2747147315387785, test 0.2993165086477231\n",
      "RMSE, train 0.2743813091906432, test 0.3004919783427165\n",
      "RMSE, train 0.27440148109216184, test 0.2980165978272756\n",
      "RMSE, train 0.27404639045954493, test 0.29831222750437564\n",
      "RMSE, train 0.2737458316707908, test 0.2961186313858399\n",
      "RMSE, train 0.2737506999869213, test 0.299008221580432\n",
      "RMSE, train 0.2739199747641881, test 0.3003350994907893\n",
      "RMSE, train 0.27392904409366975, test 0.29715008651598906\n",
      "RMSE, train 0.2733776370684306, test 0.2978500844194339\n",
      "RMSE, train 0.27347905256109445, test 0.2977347331933486\n",
      "RMSE, train 0.27329375977828124, test 0.29784749371883196\n",
      "RMSE, train 0.2734062735722444, test 0.29770241926113766\n",
      "RMSE, train 0.2732039930478806, test 0.29902142248092556\n",
      "RMSE, train 0.27319039599360706, test 0.2983494330293093\n",
      "RMSE, train 0.2727778859877512, test 0.2984984616438548\n",
      "Early stopping at epoch 69 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.LSTM, data_dir = 'data_synthetic')\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/lstm/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22ea43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9907502387116549, test 0.9386560712610522\n",
      "RMSE, train 0.8976821967146613, test 0.7866217364226619\n",
      "RMSE, train 0.6362604720908192, test 0.4499533919076766\n",
      "RMSE, train 0.377450979804333, test 0.3378798776576596\n",
      "RMSE, train 0.33168671084310225, test 0.3194216766184376\n",
      "RMSE, train 0.31304634736460657, test 0.3020891950976464\n",
      "RMSE, train 0.2977491408115319, test 0.29388127896574234\n",
      "RMSE, train 0.2880613922542734, test 0.2887596287313969\n",
      "RMSE, train 0.2788845102924839, test 0.2808934487402439\n",
      "RMSE, train 0.27491974615650216, test 0.27643900148330197\n",
      "RMSE, train 0.26968246230141446, test 0.27245000233092614\n",
      "RMSE, train 0.26661538562402426, test 0.26973283020479066\n",
      "RMSE, train 0.2637261765099797, test 0.2660460766525038\n",
      "RMSE, train 0.26187251003186696, test 0.26682149630881125\n",
      "RMSE, train 0.25985289388612326, test 0.2639792797666404\n",
      "RMSE, train 0.258023840607155, test 0.2637956874865678\n",
      "RMSE, train 0.2580766771062325, test 0.2662877022258697\n",
      "RMSE, train 0.2563544169745662, test 0.26286161739018654\n",
      "RMSE, train 0.2556520807648836, test 0.26256454207243457\n",
      "RMSE, train 0.2551804384430171, test 0.25989745533274067\n",
      "RMSE, train 0.25491141058180644, test 0.25921035137388015\n",
      "RMSE, train 0.2541481995653258, test 0.2612549853661368\n",
      "RMSE, train 0.25366541011472465, test 0.2594541409803975\n",
      "RMSE, train 0.25346731111819565, test 0.2602176639822222\n",
      "RMSE, train 0.25318019192209357, test 0.2574699513253666\n",
      "RMSE, train 0.2529689346554251, test 0.25820058650307115\n",
      "RMSE, train 0.2525721126983288, test 0.2582927495241165\n",
      "RMSE, train 0.25269013091097237, test 0.2593850920036916\n",
      "RMSE, train 0.2523453545134529, test 0.25961431175951033\n",
      "RMSE, train 0.2524445501741449, test 0.25896093573781753\n",
      "RMSE, train 0.25285418578994134, test 0.2576545202924359\n",
      "RMSE, train 0.252232339012293, test 0.25708543869756884\n",
      "RMSE, train 0.25247169584919343, test 0.2580688068222615\n",
      "RMSE, train 0.25190075068723544, test 0.2570392853550373\n",
      "RMSE, train 0.2519046592529819, test 0.2574225710404496\n",
      "RMSE, train 0.25164666749802034, test 0.25832814014246386\n",
      "RMSE, train 0.2518601091689036, test 0.25839243108226406\n",
      "RMSE, train 0.25158564814112405, test 0.2565278362843298\n",
      "RMSE, train 0.2517635485989303, test 0.25679435076252105\n",
      "RMSE, train 0.25175092816941824, test 0.25793722674490943\n",
      "RMSE, train 0.2514526522589531, test 0.2568850999157275\n",
      "RMSE, train 0.25190337837154686, test 0.2586075406401388\n",
      "RMSE, train 0.2514934425238564, test 0.25702636989374317\n",
      "RMSE, train 0.25161554543632764, test 0.257710273227384\n",
      "RMSE, train 0.2515453659881481, test 0.2566690512241856\n",
      "RMSE, train 0.251577938233204, test 0.257719186885703\n",
      "RMSE, train 0.25147455781992717, test 0.25846402599446233\n",
      "RMSE, train 0.2515557720344293, test 0.25752189172612083\n",
      "Early stopping at epoch 48 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9815063273255159, test 0.9190977129561841\n",
      "RMSE, train 0.8535442334196346, test 0.7058984395886255\n",
      "RMSE, train 0.5254385810390658, test 0.36607727777859395\n",
      "RMSE, train 0.3447373863535854, test 0.320170230178301\n",
      "RMSE, train 0.3134953994228531, test 0.2990828225435304\n",
      "RMSE, train 0.28944047000485396, test 0.277144908535579\n",
      "RMSE, train 0.2746180011042458, test 0.2713582544041074\n",
      "RMSE, train 0.2644361458824352, test 0.26138924807310104\n",
      "RMSE, train 0.25714262948948363, test 0.2568634547108461\n",
      "RMSE, train 0.25198132913514426, test 0.2526921889136645\n",
      "RMSE, train 0.24798125209595992, test 0.2540438085301848\n",
      "RMSE, train 0.24672487587762265, test 0.24940211227363793\n",
      "RMSE, train 0.24526065594030294, test 0.2473897659951005\n",
      "RMSE, train 0.24365207371924089, test 0.24886443810768363\n",
      "RMSE, train 0.24122182685534962, test 0.24632380964342226\n",
      "RMSE, train 0.24116765378940444, test 0.24574678791455987\n",
      "RMSE, train 0.24096157606917354, test 0.2443787039311464\n",
      "RMSE, train 0.24079184211519084, test 0.24564876918457756\n",
      "RMSE, train 0.24007138855725166, test 0.24489682740416407\n",
      "RMSE, train 0.2389391509265552, test 0.24478312193854782\n",
      "RMSE, train 0.2387422587013679, test 0.24279863812214086\n",
      "RMSE, train 0.23882955808931516, test 0.2421017620435431\n",
      "RMSE, train 0.23741813768681727, test 0.24183144894513217\n",
      "RMSE, train 0.23797007761744834, test 0.2413747773067025\n",
      "RMSE, train 0.23821928803073733, test 0.2421706062703093\n",
      "RMSE, train 0.23667293794543637, test 0.24249860127110126\n",
      "RMSE, train 0.23614984578811204, test 0.2424717743165237\n",
      "RMSE, train 0.23664574465348653, test 0.2415127838569239\n",
      "RMSE, train 0.23637561212003472, test 0.24073275702058777\n",
      "RMSE, train 0.2362092434756669, test 0.24153335374002613\n",
      "RMSE, train 0.2357635941612817, test 0.24196003537532712\n",
      "RMSE, train 0.2365152588046273, test 0.2427769177708744\n",
      "RMSE, train 0.23701949749398327, test 0.24083654330042767\n",
      "RMSE, train 0.23615441223991063, test 0.23996389521793884\n",
      "RMSE, train 0.2354362251968519, test 0.2401375905418199\n",
      "RMSE, train 0.23608826948442924, test 0.2449421844452866\n",
      "RMSE, train 0.2356948776223399, test 0.24104036316891347\n",
      "RMSE, train 0.23518618490350873, test 0.24032332976002338\n",
      "RMSE, train 0.23508593043395382, test 0.24140711769092182\n",
      "RMSE, train 0.23527741303991692, test 0.23968957339929156\n",
      "RMSE, train 0.23573470919540054, test 0.2399052824547961\n",
      "RMSE, train 0.2352266321901368, test 0.23934300834974967\n",
      "RMSE, train 0.2358164809010772, test 0.23967611838963407\n",
      "RMSE, train 0.23492023062247497, test 0.24251323119421636\n",
      "RMSE, train 0.23504307656454654, test 0.24064329303493184\n",
      "RMSE, train 0.23533988314179274, test 0.24214292459251466\n",
      "RMSE, train 0.2349220252169771, test 0.24192545008807143\n",
      "RMSE, train 0.2352592847517386, test 0.24091295460777834\n",
      "RMSE, train 0.23464965334667368, test 0.24259363398079045\n",
      "RMSE, train 0.23491343140964083, test 0.24004913250769466\n",
      "RMSE, train 0.23473396601705898, test 0.24080387293553548\n",
      "RMSE, train 0.23466373014787914, test 0.23983903124559025\n",
      "Early stopping at epoch 52 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9661376866450442, test 0.8865000072278475\n",
      "RMSE, train 0.8090361305899711, test 0.665399550345906\n",
      "RMSE, train 0.5310246146945302, test 0.4134079134255125\n",
      "RMSE, train 0.375663524243369, test 0.3487770459369609\n",
      "RMSE, train 0.3330361107185578, test 0.32119938861905484\n",
      "RMSE, train 0.30814379849222934, test 0.30168436820569794\n",
      "RMSE, train 0.2913855945568349, test 0.28713641067345935\n",
      "RMSE, train 0.2770790975294642, test 0.2779212131312019\n",
      "RMSE, train 0.2685986353453797, test 0.27076962799356696\n",
      "RMSE, train 0.2616699639954038, test 0.2629535432186043\n",
      "RMSE, train 0.25610405063705405, test 0.2593267284202994\n",
      "RMSE, train 0.25290683350329207, test 0.2553855278774312\n",
      "RMSE, train 0.24796407977972967, test 0.2559055622601718\n",
      "RMSE, train 0.24738487485311686, test 0.25404720858000873\n",
      "RMSE, train 0.24645091502714767, test 0.25187366285867857\n",
      "RMSE, train 0.2450517642536143, test 0.2535630100521079\n",
      "RMSE, train 0.24256432847554749, test 0.2490461075253654\n",
      "RMSE, train 0.24216232993709508, test 0.24828267999385534\n",
      "RMSE, train 0.24165445615424277, test 0.24776640103051537\n",
      "RMSE, train 0.24143525994599246, test 0.2458641493791028\n",
      "RMSE, train 0.24028809498876397, test 0.2458055433735513\n",
      "RMSE, train 0.24055966204290452, test 0.24375092120547043\n",
      "RMSE, train 0.23920938056478622, test 0.24525000141900882\n",
      "RMSE, train 0.23869205858788764, test 0.24350273334666303\n",
      "RMSE, train 0.23829843949026136, test 0.24424492391316513\n",
      "RMSE, train 0.2378461250840728, test 0.24345410406066662\n",
      "RMSE, train 0.23768811337729254, test 0.2434738946326992\n",
      "RMSE, train 0.23714218941578732, test 0.24299530364703714\n",
      "RMSE, train 0.2368951590775427, test 0.2407519747421407\n",
      "RMSE, train 0.23584161692463768, test 0.2410441961858356\n",
      "RMSE, train 0.23630295361854883, test 0.24173130833527498\n",
      "RMSE, train 0.23617303020346647, test 0.24389212539321498\n",
      "RMSE, train 0.2363412082989587, test 0.243584011468971\n",
      "RMSE, train 0.23521006614096893, test 0.240960955619812\n",
      "RMSE, train 0.2358580181625352, test 0.2406814162407005\n",
      "RMSE, train 0.23537171487487965, test 0.24042242281792456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23458517566799864, test 0.241803226829098\n",
      "RMSE, train 0.23439139998289568, test 0.24143813269441589\n",
      "RMSE, train 0.23344264157227615, test 0.24002829024143385\n",
      "RMSE, train 0.23443938744093565, test 0.23977542956147277\n",
      "RMSE, train 0.23494893779505543, test 0.24143778728811363\n",
      "RMSE, train 0.23459986281166198, test 0.24004925558702989\n",
      "RMSE, train 0.23325318196562053, test 0.24082858507570468\n",
      "RMSE, train 0.23415344599276972, test 0.24062658865985118\n",
      "RMSE, train 0.23348137733143276, test 0.24043586915522291\n",
      "RMSE, train 0.2329234239865722, test 0.24030100626119397\n",
      "RMSE, train 0.2325294830842313, test 0.24087799275130556\n",
      "RMSE, train 0.23338001408874354, test 0.23964681208395122\n",
      "RMSE, train 0.23361089830396017, test 0.23921574063991247\n",
      "RMSE, train 0.23274570056942226, test 0.2396943200575678\n",
      "RMSE, train 0.2325119359025569, test 0.2392689298773021\n",
      "RMSE, train 0.23226331889248097, test 0.2394401615387515\n",
      "RMSE, train 0.23302388631268098, test 0.23783432803394502\n",
      "RMSE, train 0.23251874943468362, test 0.23868337142885776\n",
      "RMSE, train 0.23266178684066863, test 0.2396868420274634\n",
      "RMSE, train 0.2317800374904167, test 0.23840906536369993\n",
      "RMSE, train 0.23133978292123594, test 0.23860351368784904\n",
      "RMSE, train 0.23187036751938273, test 0.23730606180534028\n",
      "RMSE, train 0.232349349999987, test 0.23893402124706067\n",
      "RMSE, train 0.2318947745570496, test 0.23787720344568553\n",
      "RMSE, train 0.23156574984857523, test 0.24011900275945663\n",
      "RMSE, train 0.2317385607436776, test 0.23705572804860903\n",
      "RMSE, train 0.23159530517389018, test 0.23743757775478197\n",
      "RMSE, train 0.2314279294852763, test 0.23774755615414234\n",
      "RMSE, train 0.23127533044260956, test 0.23742434147157168\n",
      "RMSE, train 0.2316495149310972, test 0.23782668262720108\n",
      "RMSE, train 0.23181203404850542, test 0.23572030055679774\n",
      "RMSE, train 0.2313725096521093, test 0.238570502518039\n",
      "RMSE, train 0.2309424587722018, test 0.23751173952692434\n",
      "RMSE, train 0.2311732923584198, test 0.23628952785542137\n",
      "RMSE, train 0.23129031910443865, test 0.2381897193559429\n",
      "RMSE, train 0.23095454936469795, test 0.23843810857649436\n",
      "RMSE, train 0.23091883232979887, test 0.2375988553751979\n",
      "RMSE, train 0.23078675399711138, test 0.23813688872676148\n",
      "RMSE, train 0.23105299379080851, test 0.23726888464992507\n",
      "RMSE, train 0.23231092549717502, test 0.2377057178762921\n",
      "RMSE, train 0.230193536323525, test 0.23751304455493627\n",
      "Early stopping at epoch 77 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9656406287503982, test 0.8909705412738463\n",
      "RMSE, train 0.8264096165187035, test 0.693769682856167\n",
      "RMSE, train 0.5689773024337673, test 0.43453192360260906\n",
      "RMSE, train 0.39382820663560264, test 0.36463187941733527\n",
      "RMSE, train 0.347651782816805, test 0.33789397527774173\n",
      "RMSE, train 0.3249116359291896, test 0.31529010657001943\n",
      "RMSE, train 0.30556098291725986, test 0.3015028251444592\n",
      "RMSE, train 0.29306701492509296, test 0.2958404981330329\n",
      "RMSE, train 0.2834078809668739, test 0.2863724187893026\n",
      "RMSE, train 0.27520799949800767, test 0.2825749031468934\n",
      "RMSE, train 0.27004290510831414, test 0.27540808872264977\n",
      "RMSE, train 0.266005931986687, test 0.27234577110000685\n",
      "RMSE, train 0.2611040301567615, test 0.2674107151288612\n",
      "RMSE, train 0.2573833628635418, test 0.2651171771919026\n",
      "RMSE, train 0.25489149687184925, test 0.2663194036074713\n",
      "RMSE, train 0.2520976294374409, test 0.26314686589381275\n",
      "RMSE, train 0.2494074819267223, test 0.2579713425799912\n",
      "RMSE, train 0.2499514309987248, test 0.26132455950274186\n",
      "RMSE, train 0.24827893529985287, test 0.2573315398219754\n",
      "RMSE, train 0.24845304713542252, test 0.2548617467868562\n",
      "RMSE, train 0.24735164204901328, test 0.2551107332110405\n",
      "RMSE, train 0.24550213904824633, test 0.2558646834656304\n",
      "RMSE, train 0.24345123374874666, test 0.2525528427578655\n",
      "RMSE, train 0.24363513426023906, test 0.25484852711944017\n",
      "RMSE, train 0.24271392030974845, test 0.25426815881156456\n",
      "RMSE, train 0.24184720131050716, test 0.2531111558862761\n",
      "RMSE, train 0.2411977600368509, test 0.2515873564224617\n",
      "RMSE, train 0.23953206622017312, test 0.2509800955361011\n",
      "RMSE, train 0.23964593975598034, test 0.24753404043468774\n",
      "RMSE, train 0.24040544847457676, test 0.25050046820850935\n",
      "RMSE, train 0.23810500335081666, test 0.25032537488960754\n",
      "RMSE, train 0.23886362112934095, test 0.25025955887109624\n",
      "RMSE, train 0.23762947865061657, test 0.24929980904448265\n",
      "RMSE, train 0.23685370179377763, test 0.24820448633502512\n",
      "RMSE, train 0.2368379295370175, test 0.246163260995173\n",
      "RMSE, train 0.238300246491068, test 0.2469271907911581\n",
      "RMSE, train 0.23707717776227397, test 0.24580261600660344\n",
      "RMSE, train 0.23562419576334784, test 0.24698946668821223\n",
      "RMSE, train 0.23526231480455626, test 0.24629615437166363\n",
      "RMSE, train 0.2352739534827576, test 0.24573504705639446\n",
      "RMSE, train 0.2346147682900076, test 0.24619465401651813\n",
      "RMSE, train 0.23525974254050516, test 0.24385408071034095\n",
      "RMSE, train 0.23557424916928024, test 0.2456529438495636\n",
      "RMSE, train 0.2342021520247323, test 0.24445751864536136\n",
      "RMSE, train 0.23513307018752314, test 0.2458459649454145\n",
      "RMSE, train 0.23376243276997227, test 0.2441103421882087\n",
      "RMSE, train 0.23438429345236758, test 0.24536746601555862\n",
      "RMSE, train 0.23296495119825467, test 0.2447624714935527\n",
      "RMSE, train 0.234108238327617, test 0.24375796303445219\n",
      "RMSE, train 0.232421035929483, test 0.2432048500460737\n",
      "RMSE, train 0.23234431299787717, test 0.2464020866535458\n",
      "RMSE, train 0.23260706661353533, test 0.24281882144072475\n",
      "RMSE, train 0.23172579855082429, test 0.24267721482936075\n",
      "RMSE, train 0.23249119064972906, test 0.24447880305495917\n",
      "RMSE, train 0.23326346246183347, test 0.24197505451008386\n",
      "RMSE, train 0.23249432734416037, test 0.2436014897390908\n",
      "RMSE, train 0.23162654120483944, test 0.2432980053857261\n",
      "RMSE, train 0.23222515223490026, test 0.24456089968774833\n",
      "RMSE, train 0.23230644804481107, test 0.24124089570022098\n",
      "RMSE, train 0.23204110651710438, test 0.24155497543659865\n",
      "RMSE, train 0.2312689540031986, test 0.24100548445301898\n",
      "RMSE, train 0.23112446069717407, test 0.24179698789820953\n",
      "RMSE, train 0.2309715222558429, test 0.24207571842799\n",
      "RMSE, train 0.23042146409895084, test 0.24077837497872465\n",
      "RMSE, train 0.22960396089673327, test 0.24288623093389997\n",
      "RMSE, train 0.2309124014186973, test 0.24046872395510768\n",
      "RMSE, train 0.230680805597641, test 0.24201994842174007\n",
      "RMSE, train 0.23063302541547287, test 0.24304250028787874\n",
      "RMSE, train 0.22977055991535256, test 0.24226309052285025\n",
      "RMSE, train 0.23042995290639576, test 0.2418704517185688\n",
      "RMSE, train 0.22983245011018966, test 0.2418211664931447\n",
      "RMSE, train 0.23038249085868456, test 0.24300376048275069\n",
      "RMSE, train 0.22977753805089965, test 0.24161523858121797\n",
      "RMSE, train 0.22955305420911398, test 0.24238577514302498\n",
      "RMSE, train 0.22959689959563617, test 0.240813009367854\n",
      "RMSE, train 0.2293347633468223, test 0.24021238205479642\n",
      "RMSE, train 0.22908109479843858, test 0.242559385796388\n",
      "RMSE, train 0.22945292727901714, test 0.24287686029485628\n",
      "RMSE, train 0.22874048898143245, test 0.241756170111544\n",
      "RMSE, train 0.22935641439618246, test 0.24046554577116871\n",
      "RMSE, train 0.22882891010697531, test 0.24124458958120906\n",
      "RMSE, train 0.2280498873486866, test 0.2407358789122572\n",
      "RMSE, train 0.2293198871868607, test 0.24005470519848898\n",
      "RMSE, train 0.2283023503166679, test 0.2422168320592712\n",
      "RMSE, train 0.2288819167736322, test 0.2395210953465864\n",
      "RMSE, train 0.22871637289236724, test 0.23933723415522015\n",
      "RMSE, train 0.22897127802374823, test 0.24051343131006933\n",
      "RMSE, train 0.2284216909960517, test 0.23942922559731147\n",
      "RMSE, train 0.22742571534148834, test 0.2403338025597965\n",
      "RMSE, train 0.22831822120915735, test 0.23910622824640834\n",
      "RMSE, train 0.22866019844866595, test 0.24034269095635882\n",
      "RMSE, train 0.22851965275897615, test 0.2393959830789005\n",
      "RMSE, train 0.22827069781418347, test 0.2386407172855209\n",
      "RMSE, train 0.22753498473855932, test 0.24113678128695956\n",
      "RMSE, train 0.22765736488140853, test 0.2387895177976758\n",
      "RMSE, train 0.22817978771461223, test 0.2400873582444939\n",
      "RMSE, train 0.22851246193513666, test 0.23786324985763607\n",
      "RMSE, train 0.2278584287744149, test 0.23849212378263474\n",
      "RMSE, train 0.22753020832959678, test 0.2406345766549017\n",
      "RMSE, train 0.2275755982623749, test 0.23836204694474444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.22694603113684278, test 0.2406834114123793\n",
      "RMSE, train 0.22724092979348645, test 0.2380953502713465\n",
      "RMSE, train 0.2270600332885198, test 0.239844433817209\n",
      "RMSE, train 0.2278697499405228, test 0.23909249083668577\n",
      "RMSE, train 0.22770182912844747, test 0.23834282839122942\n",
      "RMSE, train 0.22679707363496818, test 0.24014714732766151\n",
      "RMSE, train 0.2271242438857766, test 0.23960252719766953\n",
      "Early stopping at epoch 107 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9469204260817459, test 0.9005578938594534\n",
      "RMSE, train 0.8407680031152502, test 0.6958865129258022\n",
      "RMSE, train 0.518542883677348, test 0.381174924698743\n",
      "RMSE, train 0.3533693289444331, test 0.32989912141453137\n",
      "RMSE, train 0.31829932292983415, test 0.3009131948563678\n",
      "RMSE, train 0.29386817871202386, test 0.2843111807649786\n",
      "RMSE, train 0.2807775366330339, test 0.2773606564141502\n",
      "RMSE, train 0.2715898513373348, test 0.2700951263185375\n",
      "RMSE, train 0.2667514619928214, test 0.2670871912201574\n",
      "RMSE, train 0.2637468979904248, test 0.2654526089587487\n",
      "RMSE, train 0.26127435260963056, test 0.2634391007590885\n",
      "RMSE, train 0.2601831468543218, test 0.2620124198681067\n",
      "RMSE, train 0.2594224509873217, test 0.2628570973626838\n",
      "RMSE, train 0.2585686502617694, test 0.26226727836880803\n",
      "RMSE, train 0.25831738204484983, test 0.2604909097113885\n",
      "RMSE, train 0.2573971331059452, test 0.2610941231250763\n",
      "RMSE, train 0.25721492822612485, test 0.25988096195804183\n",
      "RMSE, train 0.256766832073129, test 0.2597318595844852\n",
      "RMSE, train 0.25682385449087425, test 0.25896213825576564\n",
      "RMSE, train 0.2558483567329184, test 0.26017597588625824\n",
      "RMSE, train 0.256017699266874, test 0.2597766843709079\n",
      "RMSE, train 0.25584035240594416, test 0.2599865813885838\n",
      "RMSE, train 0.25541764807196393, test 0.2593228440146801\n",
      "RMSE, train 0.2557307685455007, test 0.25908455326537455\n",
      "RMSE, train 0.25516106921338266, test 0.2597449788869905\n",
      "RMSE, train 0.2552989012591781, test 0.25910138086346557\n",
      "RMSE, train 0.25510268820629967, test 0.25881070292685643\n",
      "RMSE, train 0.2548369926310355, test 0.25913399852011815\n",
      "RMSE, train 0.25519193660828376, test 0.2585409390778581\n",
      "RMSE, train 0.25519110821187496, test 0.2589376908688506\n",
      "RMSE, train 0.2547563945934657, test 0.25864135418549056\n",
      "RMSE, train 0.2546319793308935, test 0.2581251415093083\n",
      "RMSE, train 0.2549101374742965, test 0.25848125315402165\n",
      "RMSE, train 0.25475038921520593, test 0.2587889145967389\n",
      "RMSE, train 0.25464272006384786, test 0.25824703793387765\n",
      "RMSE, train 0.25468709358885405, test 0.2587045480397122\n",
      "RMSE, train 0.2544547221172721, test 0.2584505193243342\n",
      "RMSE, train 0.25470768447004016, test 0.25830536526589354\n",
      "RMSE, train 0.25435692600665555, test 0.2580592930316925\n",
      "RMSE, train 0.2544312575351327, test 0.25817182943348055\n",
      "RMSE, train 0.25443334018270813, test 0.25769540950779085\n",
      "RMSE, train 0.2542834229647152, test 0.2581622675676976\n",
      "RMSE, train 0.25446810050597113, test 0.2585798520440898\n",
      "RMSE, train 0.2540825105782959, test 0.2581235201151903\n",
      "RMSE, train 0.2543044453787227, test 0.2577744107847371\n",
      "RMSE, train 0.2541232105164278, test 0.2578045129776001\n",
      "RMSE, train 0.25414097426278937, test 0.25774669019151325\n",
      "RMSE, train 0.2542256388753172, test 0.25780894711983104\n",
      "RMSE, train 0.25406440849145573, test 0.25822103824004655\n",
      "RMSE, train 0.25430429819971323, test 0.2579928395176722\n",
      "RMSE, train 0.25413715187460184, test 0.25814333336412415\n",
      "Early stopping at epoch 51 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.0103475548757994, test 0.9548644433587284\n",
      "RMSE, train 0.9374514243696347, test 0.8580467675702047\n",
      "RMSE, train 0.7284948741478369, test 0.5264949889506324\n",
      "RMSE, train 0.4365782430472453, test 0.3629788604833312\n",
      "RMSE, train 0.34836679118231306, test 0.3179133476342185\n",
      "RMSE, train 0.3086326916909907, test 0.2913821974800805\n",
      "RMSE, train 0.28356988447879955, test 0.27290868443452704\n",
      "RMSE, train 0.26885408326244553, test 0.26373358487577764\n",
      "RMSE, train 0.2609888036265846, test 0.2588978472907664\n",
      "RMSE, train 0.25480924983901426, test 0.25403058806718404\n",
      "RMSE, train 0.25206183749905303, test 0.25252253675864916\n",
      "RMSE, train 0.24926013068473044, test 0.2507871150717897\n",
      "RMSE, train 0.2475859155524368, test 0.2500219949978893\n",
      "RMSE, train 0.2460341022219047, test 0.24824572657629596\n",
      "RMSE, train 0.24511244132622215, test 0.24794335309731758\n",
      "RMSE, train 0.24417961650520317, test 0.24732515064336485\n",
      "RMSE, train 0.24306705110698693, test 0.2456732998460026\n",
      "RMSE, train 0.24269407673561869, test 0.24486084156117197\n",
      "RMSE, train 0.24210573003188637, test 0.245103610647937\n",
      "RMSE, train 0.24147977021114886, test 0.2449212493532795\n",
      "RMSE, train 0.2414974456976268, test 0.244382661530527\n",
      "RMSE, train 0.2405300854959271, test 0.24452032868639897\n",
      "RMSE, train 0.2410171822575498, test 0.2441998803514545\n",
      "RMSE, train 0.24036657576226006, test 0.24418233574952108\n",
      "RMSE, train 0.24005629248486077, test 0.2433879442386708\n",
      "RMSE, train 0.2395974690756522, test 0.2435533624079268\n",
      "RMSE, train 0.23970062978380968, test 0.24353582980269092\n",
      "RMSE, train 0.23955618239138737, test 0.24288843142784247\n",
      "RMSE, train 0.2395395798193029, test 0.24324890807018443\n",
      "RMSE, train 0.2393102265955988, test 0.24267674161721084\n",
      "RMSE, train 0.23901512504609163, test 0.2435553925017179\n",
      "RMSE, train 0.23932614534600707, test 0.2426714931251639\n",
      "RMSE, train 0.2395369890492317, test 0.2423970429068905\n",
      "RMSE, train 0.23926115263838413, test 0.24229841729847051\n",
      "RMSE, train 0.23844233613984644, test 0.2432180064714561\n",
      "RMSE, train 0.2387314612769391, test 0.2429001799831956\n",
      "RMSE, train 0.2386447676757643, test 0.2429499397591009\n",
      "RMSE, train 0.238883020710354, test 0.24286715875742798\n",
      "RMSE, train 0.2385964581727489, test 0.2425072174203598\n",
      "RMSE, train 0.23863563668136753, test 0.24181798706620428\n",
      "RMSE, train 0.23817407235133747, test 0.24186403670553433\n",
      "RMSE, train 0.2384741888804869, test 0.24186619219638533\n",
      "RMSE, train 0.23841933379611693, test 0.2420515229893943\n",
      "RMSE, train 0.23851993375203825, test 0.24166968578504303\n",
      "RMSE, train 0.23862265601507887, test 0.24174615223023851\n",
      "RMSE, train 0.23868795558194483, test 0.24202335385952967\n",
      "RMSE, train 0.2381074487362519, test 0.2424874204700276\n",
      "RMSE, train 0.23828577878307705, test 0.24219625518988755\n",
      "RMSE, train 0.2381097988710423, test 0.24218460387092525\n",
      "RMSE, train 0.23835630576349487, test 0.24228751634137105\n",
      "RMSE, train 0.23802104019675374, test 0.2416599088553655\n",
      "RMSE, train 0.2381637866708858, test 0.2420382513585737\n",
      "RMSE, train 0.23824249598975025, test 0.24196372320086268\n",
      "RMSE, train 0.23811561050863306, test 0.24207097910723444\n",
      "RMSE, train 0.23810285366763753, test 0.2420966909345934\n",
      "RMSE, train 0.23793569749051874, test 0.24203604889118066\n",
      "RMSE, train 0.23828153284497497, test 0.24113310557805887\n",
      "RMSE, train 0.23803998218957056, test 0.2417808748402838\n",
      "RMSE, train 0.2380971003416156, test 0.24169535644478718\n",
      "RMSE, train 0.23796766180514303, test 0.2420455865183119\n",
      "RMSE, train 0.2380859871233298, test 0.2412224922139766\n",
      "RMSE, train 0.23790191501871613, test 0.2415950293258085\n",
      "RMSE, train 0.2378652074859162, test 0.24195224715996597\n",
      "RMSE, train 0.2378827560354363, test 0.24171192464181931\n",
      "RMSE, train 0.23783894154158505, test 0.24149394174248484\n",
      "RMSE, train 0.2378591884943572, test 0.24197462403168113\n",
      "RMSE, train 0.2377009677800758, test 0.241156914729183\n",
      "Early stopping at epoch 67 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9616715162667834, test 0.9052244728165013\n",
      "RMSE, train 0.8441788225651826, test 0.7153854992772851\n",
      "RMSE, train 0.5902962695019957, test 0.4593631500112159\n",
      "RMSE, train 0.4081663263389488, test 0.37039425862686975\n",
      "RMSE, train 0.35195369979524926, test 0.3336231266813619\n",
      "RMSE, train 0.31743563763586263, test 0.30367056040891577\n",
      "RMSE, train 0.29304861227022017, test 0.28592258172907997\n",
      "RMSE, train 0.27693100978086715, test 0.27324126940220594\n",
      "RMSE, train 0.2656696994579955, test 0.2648833275639585\n",
      "RMSE, train 0.2583786018338858, test 0.2580655793260251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2538734461811893, test 0.25520823683057514\n",
      "RMSE, train 0.25026947272888717, test 0.2516463653051427\n",
      "RMSE, train 0.24719820822505909, test 0.25010568143001627\n",
      "RMSE, train 0.24530914260281456, test 0.2496597994385021\n",
      "RMSE, train 0.24369129947587556, test 0.24660991398351534\n",
      "RMSE, train 0.24199623418139996, test 0.24653592772249663\n",
      "RMSE, train 0.24162289451539906, test 0.24467862410736935\n",
      "RMSE, train 0.2405020093995761, test 0.24575411089296853\n",
      "RMSE, train 0.23945163534487515, test 0.24404984592859233\n",
      "RMSE, train 0.23937150560043477, test 0.24371535370924644\n",
      "RMSE, train 0.23937164552201373, test 0.24304681510797568\n",
      "RMSE, train 0.23838887995104904, test 0.2423389766897474\n",
      "RMSE, train 0.2381797618271219, test 0.24329601600766182\n",
      "RMSE, train 0.23765600772984408, test 0.24186727750514234\n",
      "RMSE, train 0.23760158570243903, test 0.24211784971079656\n",
      "RMSE, train 0.23721548181213845, test 0.24330665663416898\n",
      "RMSE, train 0.23685553773815596, test 0.24115488678216934\n",
      "RMSE, train 0.23659482997616912, test 0.24098531848617963\n",
      "RMSE, train 0.2368960305236783, test 0.24217449195150817\n",
      "RMSE, train 0.23626090134930247, test 0.2416533094697765\n",
      "RMSE, train 0.23684617454969287, test 0.24121782995228255\n",
      "RMSE, train 0.2363679329489311, test 0.2412443808945162\n",
      "RMSE, train 0.23594707662893016, test 0.24067043819065606\n",
      "RMSE, train 0.23609522731735297, test 0.2413868290771331\n",
      "RMSE, train 0.23607939913511797, test 0.2408116034099034\n",
      "RMSE, train 0.23579213945174787, test 0.24089759947466\n",
      "RMSE, train 0.23554872807464308, test 0.24153408554515668\n",
      "RMSE, train 0.23549760095693967, test 0.24035341305924313\n",
      "RMSE, train 0.23595131495419672, test 0.24027943451489722\n",
      "RMSE, train 0.23490043549366246, test 0.2402646742495043\n",
      "RMSE, train 0.23524635189369095, test 0.24026318280292408\n",
      "RMSE, train 0.23512835774676213, test 0.24040672755134956\n",
      "RMSE, train 0.2353646318247635, test 0.24067074938544206\n",
      "RMSE, train 0.23500280153647488, test 0.23963986709713936\n",
      "RMSE, train 0.23470882087751152, test 0.23956035170704126\n",
      "RMSE, train 0.23514598864485756, test 0.2397566662569131\n",
      "RMSE, train 0.2349292508657202, test 0.2396546330835138\n",
      "RMSE, train 0.2345892000042535, test 0.24145029139305865\n",
      "RMSE, train 0.2348951257132237, test 0.2389118526397007\n",
      "RMSE, train 0.2345507288095998, test 0.23995936089860542\n",
      "RMSE, train 0.23414839138652244, test 0.23929242590176208\n",
      "RMSE, train 0.23429584772628376, test 0.2395605712330767\n",
      "RMSE, train 0.2343545981027462, test 0.23913108836859465\n",
      "RMSE, train 0.2340552041992902, test 0.23987514565565757\n",
      "RMSE, train 0.23437178758234758, test 0.23930614800857647\n",
      "RMSE, train 0.23412220072902107, test 0.2395868135083999\n",
      "RMSE, train 0.2339836295069173, test 0.23890707468880074\n",
      "RMSE, train 0.23408352413208655, test 0.23926399661494152\n",
      "RMSE, train 0.23385337170432596, test 0.23985775972583465\n",
      "RMSE, train 0.23352869604927262, test 0.23832683358341455\n",
      "RMSE, train 0.233676235108334, test 0.23926152701356582\n",
      "RMSE, train 0.234087939388352, test 0.23836035361247404\n",
      "RMSE, train 0.23396064610522815, test 0.23892387747764587\n",
      "RMSE, train 0.23377785089878214, test 0.23896875445331847\n",
      "RMSE, train 0.23390861670435903, test 0.23895616377038614\n",
      "RMSE, train 0.23375613828370254, test 0.23861798657370464\n",
      "RMSE, train 0.2338382246902046, test 0.23966705878930433\n",
      "RMSE, train 0.2337063983374951, test 0.23896066112709896\n",
      "RMSE, train 0.23341444745043005, test 0.23862445341157063\n",
      "RMSE, train 0.23357197723487363, test 0.23893570913267986\n",
      "Early stopping at epoch 70 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.0057647478901086, test 0.9513030509756069\n",
      "RMSE, train 0.9539518252124414, test 0.9170586707616093\n",
      "RMSE, train 0.8961154081856417, test 0.8179104556941023\n",
      "RMSE, train 0.740463044794964, test 0.6242998212274878\n",
      "RMSE, train 0.5463225797802429, test 0.46815678958940987\n",
      "RMSE, train 0.4295454152055941, test 0.38999960639260034\n",
      "RMSE, train 0.3673593224843732, test 0.34921079046196407\n",
      "RMSE, train 0.33118606491747576, test 0.3154894369419175\n",
      "RMSE, train 0.30662706709286985, test 0.29805438656999605\n",
      "RMSE, train 0.2889787297522818, test 0.28586144354006254\n",
      "RMSE, train 0.2758557318110921, test 0.27485575203341667\n",
      "RMSE, train 0.26711659727294756, test 0.26918774241148824\n",
      "RMSE, train 0.26122723680107984, test 0.26494074379554905\n",
      "RMSE, train 0.2564334406319341, test 0.26162300973829594\n",
      "RMSE, train 0.25291290431121743, test 0.2596607163096919\n",
      "RMSE, train 0.2504047803526111, test 0.2566434515245033\n",
      "RMSE, train 0.2482432714665723, test 0.25328074862258604\n",
      "RMSE, train 0.24704038488398555, test 0.25422822616317053\n",
      "RMSE, train 0.24458747985602008, test 0.25223179884029157\n",
      "RMSE, train 0.2440977976054026, test 0.25094920773096757\n",
      "RMSE, train 0.24305246070865313, test 0.25033745771706706\n",
      "RMSE, train 0.24225686607121838, test 0.24977359777749186\n",
      "RMSE, train 0.24132749809904028, test 0.24982948781866016\n",
      "RMSE, train 0.2402293114834135, test 0.2484417517076839\n",
      "RMSE, train 0.2399295325092698, test 0.24753493612462824\n",
      "RMSE, train 0.23902555254531666, test 0.2468838890393575\n",
      "RMSE, train 0.23863770344583796, test 0.24579750046585547\n",
      "RMSE, train 0.23813756976121794, test 0.2467052966657311\n",
      "RMSE, train 0.23808147581544656, test 0.24640447774318733\n",
      "RMSE, train 0.23675200168252866, test 0.24631554189354482\n",
      "RMSE, train 0.23720219418005722, test 0.24542906895430402\n",
      "RMSE, train 0.23608207327375202, test 0.244673166612182\n",
      "RMSE, train 0.23621934706978226, test 0.24502186251409125\n",
      "RMSE, train 0.23552995329964133, test 0.24293439270872058\n",
      "RMSE, train 0.23516381807024148, test 0.24482498641568\n",
      "RMSE, train 0.23536436671441224, test 0.24360707342022597\n",
      "RMSE, train 0.23434806132374883, test 0.2437356161047714\n",
      "RMSE, train 0.23478378231630348, test 0.2439291982939749\n",
      "RMSE, train 0.2348199838676779, test 0.2430940940223559\n",
      "RMSE, train 0.23445012010542862, test 0.24316544439455476\n",
      "RMSE, train 0.234044695942501, test 0.24278904392261696\n",
      "RMSE, train 0.23367554528643275, test 0.242195853229725\n",
      "RMSE, train 0.2339443993597567, test 0.24208627204702357\n",
      "RMSE, train 0.23333437675223082, test 0.24266104279744505\n",
      "RMSE, train 0.2336293156543396, test 0.24190061863022622\n",
      "RMSE, train 0.2330776246077857, test 0.24252371354536575\n",
      "RMSE, train 0.23305408846049552, test 0.24201701250341204\n",
      "RMSE, train 0.23279297115021638, test 0.24251284006268087\n",
      "RMSE, train 0.23233823394425632, test 0.2417194242730285\n",
      "RMSE, train 0.2327144915433851, test 0.24174914456377125\n",
      "RMSE, train 0.23253296833020842, test 0.2420952526306865\n",
      "RMSE, train 0.23240983271219912, test 0.24124907378596488\n",
      "RMSE, train 0.23214991150246272, test 0.2412189177491448\n",
      "RMSE, train 0.23182977408097835, test 0.24106289657077404\n",
      "RMSE, train 0.2317114257433595, test 0.240743035017842\n",
      "RMSE, train 0.23214563956907733, test 0.2410043476506917\n",
      "RMSE, train 0.23196249515328254, test 0.23997098056956975\n",
      "RMSE, train 0.2316216162626784, test 0.24055145394922506\n",
      "RMSE, train 0.2316369983051109, test 0.24137547145588228\n",
      "RMSE, train 0.23197168709304922, test 0.24148184949099416\n",
      "RMSE, train 0.2315800657044996, test 0.24080379021288167\n",
      "RMSE, train 0.23123416078702744, test 0.2413386469236528\n",
      "RMSE, train 0.23137537920096102, test 0.23973736272315788\n",
      "RMSE, train 0.23139044700741476, test 0.24032885438264018\n",
      "RMSE, train 0.23058839947495308, test 0.2401307797191119\n",
      "RMSE, train 0.2310563540837584, test 0.2405338061578346\n",
      "RMSE, train 0.23078269269180765, test 0.23969552101510944\n",
      "RMSE, train 0.2305981811946645, test 0.23936230516192888\n",
      "RMSE, train 0.230858293933507, test 0.2396195869554173\n",
      "RMSE, train 0.23045413451118982, test 0.24061553195269422\n",
      "RMSE, train 0.23053229693095667, test 0.24000827832655472\n",
      "RMSE, train 0.23036881130015646, test 0.23946741930764132\n",
      "RMSE, train 0.23060656828956091, test 0.23949716052021644\n",
      "RMSE, train 0.23047783661150992, test 0.23936524249688543\n",
      "RMSE, train 0.23019209580637132, test 0.23953169810049463\n",
      "RMSE, train 0.23026598403389706, test 0.23972191097158374\n",
      "RMSE, train 0.2301503597305573, test 0.2395851467594956\n",
      "RMSE, train 0.2300289717382207, test 0.23981166262217243\n",
      "Early stopping at epoch 78 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.9090156157400983, test 0.8738224597300513\n",
      "RMSE, train 0.8142194155572859, test 0.6837748859898519\n",
      "RMSE, train 0.5341066705170742, test 0.406227185059402\n",
      "RMSE, train 0.3782825957029319, test 0.34666530939482026\n",
      "RMSE, train 0.3379492714446931, test 0.3164756248815585\n",
      "RMSE, train 0.3129592882700203, test 0.29976537230156236\n",
      "RMSE, train 0.29583688418973575, test 0.28766970791048924\n",
      "RMSE, train 0.28340970407709604, test 0.2789239624546746\n",
      "RMSE, train 0.27691725278196255, test 0.27405152558270146\n",
      "RMSE, train 0.27270322068294217, test 0.27224765137090523\n",
      "RMSE, train 0.2696154815229503, test 0.2702970040046563\n",
      "RMSE, train 0.26808934594111994, test 0.2691128488819478\n",
      "RMSE, train 0.2668596139747249, test 0.2678533865738723\n",
      "RMSE, train 0.2663215100457353, test 0.2674266572220851\n",
      "RMSE, train 0.2648495011462653, test 0.26803059257188083\n",
      "RMSE, train 0.26445023570794707, test 0.26682368085040886\n",
      "RMSE, train 0.26405184214149624, test 0.26571609698614834\n",
      "RMSE, train 0.2638689136086417, test 0.2663798658019405\n",
      "RMSE, train 0.2631706761365587, test 0.265521825243861\n",
      "RMSE, train 0.2630089041738471, test 0.2660256038277836\n",
      "RMSE, train 0.26275588562789043, test 0.2651658443323636\n",
      "RMSE, train 0.262357254905149, test 0.2645816565570185\n",
      "RMSE, train 0.26203042204099253, test 0.2648043978517338\n",
      "RMSE, train 0.26202711592282146, test 0.2648362138513791\n",
      "RMSE, train 0.2618222099013072, test 0.26418750985699185\n",
      "RMSE, train 0.261646532876925, test 0.26494332579738\n",
      "RMSE, train 0.2616373637059996, test 0.2643815857374062\n",
      "RMSE, train 0.2613994418527962, test 0.2647514735995713\n",
      "RMSE, train 0.26140213853194694, test 0.2642539167555712\n",
      "RMSE, train 0.260873721927897, test 0.2641716969467826\n",
      "RMSE, train 0.2610653146547227, test 0.2646620466800059\n",
      "RMSE, train 0.261027767484592, test 0.2639126301569454\n",
      "RMSE, train 0.26093785732615093, test 0.2643978767475839\n",
      "RMSE, train 0.26079583789937755, test 0.2636855365866322\n",
      "RMSE, train 0.26088466264369076, test 0.2636447731973761\n",
      "RMSE, train 0.26077099855650554, test 0.26398630149788777\n",
      "RMSE, train 0.2604515134426188, test 0.2641751415143579\n",
      "RMSE, train 0.26037768431562036, test 0.2637907623992128\n",
      "RMSE, train 0.26034003868699074, test 0.2638126951405558\n",
      "RMSE, train 0.2605450884246629, test 0.2633089742670625\n",
      "RMSE, train 0.2607844837687232, test 0.2632555560035221\n",
      "RMSE, train 0.2602073969550369, test 0.26387328919717823\n",
      "RMSE, train 0.2603263997834576, test 0.2635919363316843\n",
      "RMSE, train 0.2601898208198961, test 0.2639444185010457\n",
      "RMSE, train 0.26022575598610337, test 0.2638166911773763\n",
      "RMSE, train 0.2603085735304789, test 0.2632244076516669\n",
      "RMSE, train 0.2603202707572909, test 0.2630349790393296\n",
      "RMSE, train 0.26017012283944885, test 0.2634274635021969\n",
      "RMSE, train 0.2599594545327435, test 0.26324013620615005\n",
      "RMSE, train 0.25981224032719274, test 0.26335707104812234\n",
      "RMSE, train 0.25998358471580774, test 0.26344179879810853\n",
      "RMSE, train 0.2598644959286225, test 0.2632338317521548\n",
      "RMSE, train 0.25979932277532647, test 0.26300079489158373\n",
      "RMSE, train 0.2599774100933193, test 0.26324824862560986\n",
      "RMSE, train 0.2600247023149955, test 0.2635667427616604\n",
      "RMSE, train 0.25986408725504045, test 0.2632144839834359\n",
      "RMSE, train 0.25978922419065287, test 0.2631853259468483\n",
      "RMSE, train 0.26004042122359117, test 0.2629617447570219\n",
      "RMSE, train 0.25996328622472187, test 0.26301018969487333\n",
      "RMSE, train 0.2599069310798625, test 0.2632967070755312\n",
      "RMSE, train 0.2599096103948503, test 0.26274549670643726\n",
      "RMSE, train 0.2598151614473871, test 0.2633260142500118\n",
      "RMSE, train 0.2601183277577901, test 0.26259668184033896\n",
      "RMSE, train 0.25985588949204474, test 0.2629700299289267\n",
      "RMSE, train 0.25978490433170776, test 0.26322806386624353\n",
      "RMSE, train 0.2600009183684164, test 0.26291858291221876\n",
      "RMSE, train 0.25971345692749853, test 0.2631620503330635\n",
      "RMSE, train 0.2597475379767004, test 0.2629987544427484\n",
      "RMSE, train 0.25966595593562797, test 0.26304485358424107\n",
      "RMSE, train 0.2597431650092779, test 0.2631685947210102\n",
      "RMSE, train 0.2598072007483195, test 0.2628156804179741\n",
      "RMSE, train 0.2597957836879679, test 0.2631516464180865\n",
      "RMSE, train 0.2598202302744073, test 0.26260528662952326\n",
      "Early stopping at epoch 73 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9754622674798257, test 0.9336159053056137\n",
      "RMSE, train 0.9217207983547462, test 0.8842890822369119\n",
      "RMSE, train 0.8282782841007168, test 0.7066918300545734\n",
      "RMSE, train 0.5727786634378372, test 0.4436694692010465\n",
      "RMSE, train 0.40235660878462903, test 0.36011992304221446\n",
      "RMSE, train 0.34790535125636246, test 0.32317955856737884\n",
      "RMSE, train 0.31152173367402103, test 0.29636603269888007\n",
      "RMSE, train 0.28841995724700314, test 0.2785390075134194\n",
      "RMSE, train 0.27523463262114556, test 0.27134546559789907\n",
      "RMSE, train 0.267707299116817, test 0.26527781408766044\n",
      "RMSE, train 0.2619513084680918, test 0.2605088490506877\n",
      "RMSE, train 0.2587584522879048, test 0.2591566801071167\n",
      "RMSE, train 0.2564566223990892, test 0.25910516497881514\n",
      "RMSE, train 0.2544599790165632, test 0.25652586480845574\n",
      "RMSE, train 0.25243045740826114, test 0.25487654001816457\n",
      "RMSE, train 0.25104881826226627, test 0.253046928929246\n",
      "RMSE, train 0.24951212943359546, test 0.25262753782065017\n",
      "RMSE, train 0.24968799796833355, test 0.2518171867598658\n",
      "RMSE, train 0.24867284744028834, test 0.251443174092666\n",
      "RMSE, train 0.24787771284200583, test 0.2511936515569687\n",
      "RMSE, train 0.24749259084399844, test 0.25030690703703007\n",
      "RMSE, train 0.24669945445663105, test 0.2502793164356895\n",
      "RMSE, train 0.24658747200879827, test 0.2501680770645971\n",
      "RMSE, train 0.24636339853397093, test 0.24972583405349566\n",
      "RMSE, train 0.24609171622877668, test 0.2492103107597517\n",
      "RMSE, train 0.245554119348526, test 0.24915488375269848\n",
      "RMSE, train 0.24602480719929795, test 0.2490208662074545\n",
      "RMSE, train 0.24581031817666033, test 0.24902098904485287\n",
      "RMSE, train 0.24555768493381022, test 0.2494493972996007\n",
      "RMSE, train 0.2452267944622951, test 0.248214913321578\n",
      "RMSE, train 0.24493901947248262, test 0.24843556686587956\n",
      "RMSE, train 0.24482789091496965, test 0.24781763100105783\n",
      "RMSE, train 0.2449851806756038, test 0.2484494730182316\n",
      "RMSE, train 0.24481718390863666, test 0.24900957229344742\n",
      "RMSE, train 0.24459578660010278, test 0.24859294684036917\n",
      "RMSE, train 0.24466462718073728, test 0.24822890732599343\n",
      "RMSE, train 0.24477970239463126, test 0.24741048061329385\n",
      "RMSE, train 0.24461765195027532, test 0.24859692752361298\n",
      "RMSE, train 0.24453415470138476, test 0.24763632092786872\n",
      "RMSE, train 0.24424269270238855, test 0.24817890434161477\n",
      "RMSE, train 0.24435804262282743, test 0.24839076140652533\n",
      "RMSE, train 0.24420898431425642, test 0.24754561017388882\n",
      "RMSE, train 0.24422440268178403, test 0.24805215117724044\n",
      "RMSE, train 0.24424570950732868, test 0.24802537793698518\n",
      "RMSE, train 0.24388086020693403, test 0.24760847000972083\n",
      "RMSE, train 0.24398321925707936, test 0.24741110957187154\n",
      "RMSE, train 0.24440504841490662, test 0.24779733302800552\n",
      "Early stopping at epoch 47 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9255046379405821, test 0.8871862543832272\n",
      "RMSE, train 0.8587586797539963, test 0.7739555720889241\n",
      "RMSE, train 0.6333484014855372, test 0.47028952563574555\n",
      "RMSE, train 0.4036554534472692, test 0.36309588119524333\n",
      "RMSE, train 0.34172363522475074, test 0.32518071113923275\n",
      "RMSE, train 0.3096413157312325, test 0.30345777032572196\n",
      "RMSE, train 0.2890444464079468, test 0.28531475091746095\n",
      "RMSE, train 0.2753176510400836, test 0.2757695135446863\n",
      "RMSE, train 0.26731175077335717, test 0.2685952119597601\n",
      "RMSE, train 0.2608240680109225, test 0.2644139662248279\n",
      "RMSE, train 0.2562201875074027, test 0.2606833964039426\n",
      "RMSE, train 0.25391434985025046, test 0.26010818396686414\n",
      "RMSE, train 0.25177628810897534, test 0.2566322234519031\n",
      "RMSE, train 0.24951950353758218, test 0.2560862965813471\n",
      "RMSE, train 0.24883441179322555, test 0.25382184927616647\n",
      "RMSE, train 0.24736222046774065, test 0.25372653393023603\n",
      "RMSE, train 0.24651222869820658, test 0.2532124083249941\n",
      "RMSE, train 0.24585342878317085, test 0.2526325773481929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.24571854143399294, test 0.2512358737374664\n",
      "RMSE, train 0.24488821478702563, test 0.25186974124624095\n",
      "RMSE, train 0.24408446429422617, test 0.2518850812397966\n",
      "RMSE, train 0.2439133452393549, test 0.2503236838437002\n",
      "RMSE, train 0.24358082916838172, test 0.25011525268948404\n",
      "RMSE, train 0.2433008056451387, test 0.25025207528827387\n",
      "RMSE, train 0.24246575352589644, test 0.25039167004987734\n",
      "RMSE, train 0.24256302075535727, test 0.25044931225273587\n",
      "RMSE, train 0.2422120554431137, test 0.24863589684897608\n",
      "RMSE, train 0.2423970771811468, test 0.24871069479972943\n",
      "RMSE, train 0.2419540601460923, test 0.24910711353525108\n",
      "RMSE, train 0.2417438670391459, test 0.24788231177067538\n",
      "RMSE, train 0.24139289086843285, test 0.24844953745876977\n",
      "RMSE, train 0.24125314246645957, test 0.24855673012383486\n",
      "RMSE, train 0.241168335882003, test 0.2482180085477479\n",
      "RMSE, train 0.2408021665073831, test 0.24796182737437958\n",
      "RMSE, train 0.240833442808534, test 0.24777157591023577\n",
      "RMSE, train 0.24080745869153283, test 0.24694942648804516\n",
      "RMSE, train 0.24062512414070522, test 0.2472253581252667\n",
      "RMSE, train 0.24047214273914627, test 0.24732295102482543\n",
      "RMSE, train 0.2403733614047012, test 0.24788686058936862\n",
      "RMSE, train 0.23999667952814444, test 0.24751662045990655\n",
      "RMSE, train 0.24012232347988763, test 0.24716361988028254\n",
      "RMSE, train 0.23991694792503734, test 0.2468443038540149\n",
      "RMSE, train 0.23975465994645662, test 0.24858738140228692\n",
      "RMSE, train 0.2399436856198204, test 0.24696048971163023\n",
      "RMSE, train 0.23998605309580473, test 0.2476032603224483\n",
      "RMSE, train 0.23978351624557256, test 0.2473721848715336\n",
      "RMSE, train 0.23973385528598665, test 0.2470669952827856\n",
      "RMSE, train 0.23951175591737164, test 0.24663076802678063\n",
      "RMSE, train 0.2397032998535665, test 0.2463351909173738\n",
      "RMSE, train 0.2394923709433175, test 0.24638484732820354\n",
      "RMSE, train 0.23937850101379002, test 0.24627670085211412\n",
      "RMSE, train 0.2391550942186283, test 0.24663402399885545\n",
      "RMSE, train 0.23948955803174074, test 0.24654491532833203\n",
      "RMSE, train 0.23914477940765733, test 0.24781531765373474\n",
      "RMSE, train 0.23910674302433638, test 0.24584285778190018\n",
      "RMSE, train 0.23889357710232115, test 0.24688267434408906\n",
      "RMSE, train 0.2389542491847624, test 0.24672624222729184\n",
      "RMSE, train 0.23867486945182217, test 0.2455334597771321\n",
      "RMSE, train 0.2388990893959999, test 0.2453806526070341\n",
      "RMSE, train 0.23896308584063577, test 0.2467236613188315\n",
      "RMSE, train 0.2388244864651975, test 0.24580308015740246\n",
      "RMSE, train 0.23910942015492861, test 0.24597597764719517\n",
      "RMSE, train 0.2387510035938746, test 0.2460610900723606\n",
      "RMSE, train 0.23873204510709095, test 0.24629013363374483\n",
      "RMSE, train 0.23865563850098126, test 0.24586055571332985\n",
      "RMSE, train 0.23872394522342982, test 0.24625134468078613\n",
      "RMSE, train 0.23857126344880716, test 0.24640392847017412\n",
      "RMSE, train 0.23859908622209267, test 0.24677405731940488\n",
      "RMSE, train 0.23870320300751202, test 0.24675433118955806\n",
      "Early stopping at epoch 69 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9438637460422035, test 0.9017410067220529\n",
      "RMSE, train 0.8792836062534891, test 0.8117199403544267\n",
      "RMSE, train 0.707384791639116, test 0.5764820432911316\n",
      "RMSE, train 0.49431364178055465, test 0.43715588841587305\n",
      "RMSE, train 0.40001569289450695, test 0.3822078403706352\n",
      "RMSE, train 0.35469381740749484, test 0.34481578165044385\n",
      "RMSE, train 0.3276861085735186, test 0.32312718282143277\n",
      "RMSE, train 0.30798908605268505, test 0.30615365877747536\n",
      "RMSE, train 0.29460771137265246, test 0.2949596267814438\n",
      "RMSE, train 0.2833151753728438, test 0.28662853486215073\n",
      "RMSE, train 0.2773324945809865, test 0.2801383212208748\n",
      "RMSE, train 0.2722660801326386, test 0.27866488229483366\n",
      "RMSE, train 0.26775494488802826, test 0.2747856730905672\n",
      "RMSE, train 0.26367881416220856, test 0.2702110555643837\n",
      "RMSE, train 0.26141328247960166, test 0.2688887858142455\n",
      "RMSE, train 0.25917217850384083, test 0.2670471474217872\n",
      "RMSE, train 0.25766749838084885, test 0.26496717721844715\n",
      "RMSE, train 0.2556228956790886, test 0.26317111759757\n",
      "RMSE, train 0.2529426748403395, test 0.2632903230066101\n",
      "RMSE, train 0.2519739419974462, test 0.26070313217739266\n",
      "RMSE, train 0.2508401197541242, test 0.2586594571669896\n",
      "RMSE, train 0.25046484909876426, test 0.25857990235090256\n",
      "RMSE, train 0.24856997804358752, test 0.2594437360142668\n",
      "RMSE, train 0.2485287557120877, test 0.25651061193396646\n",
      "RMSE, train 0.24797258070773548, test 0.25544799119234085\n",
      "RMSE, train 0.24695409431752532, test 0.25661748833954334\n",
      "RMSE, train 0.2462162696803459, test 0.25469154631718993\n",
      "RMSE, train 0.24591177758393865, test 0.2549289309730132\n",
      "RMSE, train 0.24475578267616455, test 0.25305487991621095\n",
      "RMSE, train 0.2446306450950979, test 0.2544927193472783\n",
      "RMSE, train 0.2437634210318628, test 0.25349370188390213\n",
      "RMSE, train 0.24373967170414298, test 0.2517997751322885\n",
      "RMSE, train 0.24302387662758732, test 0.25159788395588595\n",
      "RMSE, train 0.24252164307417293, test 0.2515101993146042\n",
      "RMSE, train 0.2421818676997315, test 0.2507446926708023\n",
      "RMSE, train 0.24192586311637754, test 0.2505695967314144\n",
      "RMSE, train 0.2419254459591225, test 0.2506027108368774\n",
      "RMSE, train 0.24159493688682113, test 0.24877063852424422\n",
      "RMSE, train 0.24101156259726997, test 0.24926466091225544\n",
      "RMSE, train 0.2410363167750113, test 0.24970941292122006\n",
      "RMSE, train 0.24076034930167775, test 0.24947284969190756\n",
      "RMSE, train 0.24041878740594844, test 0.24891405164574584\n",
      "RMSE, train 0.2404683998061551, test 0.2487283468556901\n",
      "RMSE, train 0.24027812300306378, test 0.2488836570022007\n",
      "RMSE, train 0.23976851819139539, test 0.24857240822166204\n",
      "RMSE, train 0.23927906283525505, test 0.24773644345502058\n",
      "RMSE, train 0.23897437977068353, test 0.24788666997725764\n",
      "RMSE, train 0.23922492296557235, test 0.24758674840753278\n",
      "RMSE, train 0.2388653102697748, test 0.2475524873783191\n",
      "RMSE, train 0.23856093877493734, test 0.24729574782152972\n",
      "RMSE, train 0.23847170181647695, test 0.24671460331107178\n",
      "RMSE, train 0.23839459741356397, test 0.24625272614260516\n",
      "RMSE, train 0.2383064604317299, test 0.24780911020934582\n",
      "RMSE, train 0.23820552700246223, test 0.24699521670117974\n",
      "RMSE, train 0.23790206846715223, test 0.24656810285523534\n",
      "RMSE, train 0.23778005136233388, test 0.24702816472078362\n",
      "RMSE, train 0.23763460869138892, test 0.24611941336964568\n",
      "RMSE, train 0.23804516578563537, test 0.24704879180838665\n",
      "RMSE, train 0.23742687344701605, test 0.24532243112723032\n",
      "RMSE, train 0.23732683608176733, test 0.24580016390730938\n",
      "RMSE, train 0.23723299090157857, test 0.24636490643024445\n",
      "RMSE, train 0.23742565964207504, test 0.24566897905121246\n",
      "RMSE, train 0.23702362074394417, test 0.24546197522431612\n",
      "RMSE, train 0.23708588197225272, test 0.24683358675489822\n",
      "RMSE, train 0.23691988751442747, test 0.2456479884373645\n",
      "RMSE, train 0.2366325223084652, test 0.24642919407536587\n",
      "RMSE, train 0.23645371646441596, test 0.24513190099969506\n",
      "RMSE, train 0.23645886549293393, test 0.2454976630397141\n",
      "RMSE, train 0.23667841920196409, test 0.2455582128216823\n",
      "RMSE, train 0.23629238723654938, test 0.2447240826052924\n",
      "RMSE, train 0.23617521229416433, test 0.2457203397837778\n",
      "RMSE, train 0.23635069160449385, test 0.24497073128198585\n",
      "RMSE, train 0.23584983343578347, test 0.24531457697351775\n",
      "RMSE, train 0.23602615071065497, test 0.24537487126265964\n",
      "RMSE, train 0.2359699011977875, test 0.24496883262569705\n",
      "RMSE, train 0.23607619991055642, test 0.24486795393750072\n",
      "RMSE, train 0.23587054954935807, test 0.2446926829094688\n",
      "RMSE, train 0.23564722505633276, test 0.24490795889869332\n",
      "RMSE, train 0.23591339046304877, test 0.24447647746031484\n",
      "RMSE, train 0.23551584625936517, test 0.24432924467449388\n",
      "RMSE, train 0.23580621946791205, test 0.24440284430359802\n",
      "RMSE, train 0.23538208440548242, test 0.2444587373174727\n",
      "RMSE, train 0.23561732772022786, test 0.24391797091811895\n",
      "RMSE, train 0.23560173403133045, test 0.24447061276684204\n",
      "RMSE, train 0.23546858018997943, test 0.24468443434064588\n",
      "RMSE, train 0.2351893846585293, test 0.2442103101251026\n",
      "RMSE, train 0.235355658136835, test 0.24476207063222924\n",
      "RMSE, train 0.23523046320887528, test 0.24403064899767438\n",
      "RMSE, train 0.23525157239702013, test 0.2440498770835499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23532730732301269, test 0.2442923366713027\n",
      "RMSE, train 0.23488656085247944, test 0.24459343667452535\n",
      "RMSE, train 0.23493557355620645, test 0.2436818222825726\n",
      "RMSE, train 0.23482871465761251, test 0.24445082464565834\n",
      "RMSE, train 0.23503832654519516, test 0.24385849852114916\n",
      "RMSE, train 0.23477539450231225, test 0.243806851717333\n",
      "RMSE, train 0.23466803193694413, test 0.24416743700082102\n",
      "RMSE, train 0.23461719365282493, test 0.24384057894349098\n",
      "RMSE, train 0.23455684899230195, test 0.24392780987545848\n",
      "RMSE, train 0.23465223015859873, test 0.24404851300641894\n",
      "RMSE, train 0.23482190241867845, test 0.2438637629772226\n",
      "RMSE, train 0.2345321438830308, test 0.24331754663338265\n",
      "RMSE, train 0.2346785320251277, test 0.24365111021324992\n",
      "RMSE, train 0.23442125881109574, test 0.24346107756718993\n",
      "RMSE, train 0.23442788602727832, test 0.24334660281116763\n",
      "RMSE, train 0.23437539047815584, test 0.24343880529825887\n",
      "RMSE, train 0.23425675033017843, test 0.24366153357550502\n",
      "RMSE, train 0.2343888689171184, test 0.24290876928716898\n",
      "RMSE, train 0.23424401924465643, test 0.24357512624313435\n",
      "RMSE, train 0.2341856634752317, test 0.24374482423687974\n",
      "RMSE, train 0.2342685055025298, test 0.24394959242393574\n",
      "RMSE, train 0.23417979580434886, test 0.2438082741573453\n",
      "RMSE, train 0.23413465695098193, test 0.24390627335136136\n",
      "RMSE, train 0.23404945700307084, test 0.2438266258686781\n",
      "RMSE, train 0.23410926153412973, test 0.24359063059091568\n",
      "RMSE, train 0.23408584887481698, test 0.24369974667206407\n",
      "RMSE, train 0.23401377466742437, test 0.24332291136185327\n",
      "RMSE, train 0.23406786084024592, test 0.24291545897722244\n",
      "Early stopping at epoch 117 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8852949741099655, test 0.8574439361691475\n",
      "RMSE, train 0.8383984335886887, test 0.8082225556884494\n",
      "RMSE, train 0.7229458159221284, test 0.5882695162934917\n",
      "RMSE, train 0.47901331579763123, test 0.4118259831198624\n",
      "RMSE, train 0.38475294239121066, test 0.36510382406413555\n",
      "RMSE, train 0.35169696736439643, test 0.3418846952595881\n",
      "RMSE, train 0.33095421380726603, test 0.3240012688828366\n",
      "RMSE, train 0.3150454626818368, test 0.31238382974905626\n",
      "RMSE, train 0.30330033408790374, test 0.3022053466577615\n",
      "RMSE, train 0.2944019680968557, test 0.295368184734668\n",
      "RMSE, train 0.28847012547106526, test 0.2897417432229434\n",
      "RMSE, train 0.28395132028978637, test 0.2877859922924212\n",
      "RMSE, train 0.28144227283193135, test 0.2851052282910262\n",
      "RMSE, train 0.2800463079951687, test 0.285618589126638\n",
      "RMSE, train 0.27870093568477755, test 0.28415028538022724\n",
      "RMSE, train 0.2774151319512095, test 0.28255134767719675\n",
      "RMSE, train 0.27741832420846735, test 0.2824302532577089\n",
      "RMSE, train 0.2766333108439165, test 0.28235416766256094\n",
      "RMSE, train 0.2763734841658399, test 0.2827774954161474\n",
      "RMSE, train 0.27589679368181164, test 0.28320382721722126\n",
      "RMSE, train 0.275854482662444, test 0.2825334489877735\n",
      "RMSE, train 0.2757447776191894, test 0.2821530546726925\n",
      "RMSE, train 0.27591986162080745, test 0.28211259056947063\n",
      "RMSE, train 0.27524241042163117, test 0.2819551905351026\n",
      "RMSE, train 0.2752948429005338, test 0.28246583683150156\n",
      "RMSE, train 0.27485297863779506, test 0.2814569479918906\n",
      "RMSE, train 0.27508463085606727, test 0.2813104066465582\n",
      "RMSE, train 0.27504746969748683, test 0.2808614543506077\n",
      "RMSE, train 0.27484359954177423, test 0.28141869311886175\n",
      "RMSE, train 0.2746752169397142, test 0.2811653124434607\n",
      "RMSE, train 0.2747882082246747, test 0.2807778593684946\n",
      "RMSE, train 0.27453543034773764, test 0.2807215128892234\n",
      "RMSE, train 0.2745471264931631, test 0.28059274503695114\n",
      "RMSE, train 0.27449013081770834, test 0.2809909898787737\n",
      "RMSE, train 0.2745811790552534, test 0.2802733995818666\n",
      "RMSE, train 0.27425997183213824, test 0.2811590022008334\n",
      "RMSE, train 0.27414514682781205, test 0.28040996765983955\n",
      "RMSE, train 0.2744769233244437, test 0.2806426012622459\n",
      "RMSE, train 0.27416458566853685, test 0.28040162567049265\n",
      "RMSE, train 0.27400120898009905, test 0.28059028514793943\n",
      "RMSE, train 0.2742261021744971, test 0.2804659340264542\n",
      "RMSE, train 0.27402398223970453, test 0.28052712072219166\n",
      "RMSE, train 0.27392186055645706, test 0.28079700297010796\n",
      "RMSE, train 0.27403570838223873, test 0.280347229779831\n",
      "RMSE, train 0.27349132529920483, test 0.28039384886090246\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8970926321140854, test 0.8669356102243476\n",
      "RMSE, train 0.8405862685810824, test 0.7971620887791345\n",
      "RMSE, train 0.7146007866335556, test 0.6030244023428051\n",
      "RMSE, train 0.5081106995654213, test 0.4296677323109513\n",
      "RMSE, train 0.39498960176658204, test 0.3674525030709188\n",
      "RMSE, train 0.3504331209467131, test 0.33753061732020945\n",
      "RMSE, train 0.32308795657259465, test 0.31477990322703614\n",
      "RMSE, train 0.30351398574530813, test 0.3015400048242797\n",
      "RMSE, train 0.29128500565285104, test 0.29171822978815903\n",
      "RMSE, train 0.28267607891372504, test 0.28485276338157306\n",
      "RMSE, train 0.27579763655304373, test 0.28036607692547894\n",
      "RMSE, train 0.27178811041362616, test 0.2768800786328972\n",
      "RMSE, train 0.26880681748614715, test 0.27475174577957995\n",
      "RMSE, train 0.2668779383459433, test 0.2727631152769841\n",
      "RMSE, train 0.2652191298224466, test 0.2721281979882389\n",
      "RMSE, train 0.2634609398419547, test 0.27070437002619474\n",
      "RMSE, train 0.26282229117481165, test 0.2703249301385442\n",
      "RMSE, train 0.2619706616473839, test 0.2691342986504966\n",
      "RMSE, train 0.2611847399262035, test 0.26970793812646776\n",
      "RMSE, train 0.2609901880269093, test 0.269287041841297\n",
      "RMSE, train 0.2606551710332456, test 0.2680879929743776\n",
      "RMSE, train 0.2601790918630335, test 0.2677916493437706\n",
      "RMSE, train 0.2597177295607302, test 0.2691055988773293\n",
      "RMSE, train 0.25930075454337714, test 0.268078685763779\n",
      "RMSE, train 0.25945759768443255, test 0.2676468439605258\n",
      "RMSE, train 0.25898258528367285, test 0.2666111115468751\n",
      "RMSE, train 0.2588242229926212, test 0.2668086876836392\n",
      "RMSE, train 0.25835833641712974, test 0.2666731491821622\n",
      "RMSE, train 0.25798927200749316, test 0.2661051201984423\n",
      "RMSE, train 0.2583704420737087, test 0.266978252098101\n",
      "RMSE, train 0.25813018687637396, test 0.266371367174551\n",
      "RMSE, train 0.25779097731070666, test 0.2674129731064543\n",
      "RMSE, train 0.257810468363655, test 0.2661274716668173\n",
      "RMSE, train 0.2575519785886388, test 0.26649296762199576\n",
      "RMSE, train 0.2573584349567046, test 0.2658311875041472\n",
      "RMSE, train 0.25770021931606557, test 0.26622073119933454\n",
      "RMSE, train 0.25735278661475586, test 0.2658284038578698\n",
      "RMSE, train 0.2571757783937882, test 0.26636033566719897\n",
      "RMSE, train 0.25713964575074716, test 0.2651320638459757\n",
      "RMSE, train 0.25726334937752093, test 0.266131731621716\n",
      "RMSE, train 0.2572942436944209, test 0.2660113128773663\n",
      "RMSE, train 0.25734381110411586, test 0.26577945504713496\n",
      "RMSE, train 0.2571878570211308, test 0.2652399293873288\n",
      "RMSE, train 0.25692439961326496, test 0.2666478832380487\n",
      "RMSE, train 0.2568650074937953, test 0.2655232186437747\n",
      "RMSE, train 0.25669029355049133, test 0.2657033664370895\n",
      "RMSE, train 0.25669095501504136, test 0.2652937984521236\n",
      "RMSE, train 0.25694858593523767, test 0.26522211525418343\n",
      "RMSE, train 0.2568573548120234, test 0.26573383124596484\n",
      "Early stopping at epoch 49 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8592088537516334, test 0.8311698158967842\n",
      "RMSE, train 0.8015624352702052, test 0.7461392014350706\n",
      "RMSE, train 0.6711270051019492, test 0.5715503319374566\n",
      "RMSE, train 0.4921995385808786, test 0.43349999565522646\n",
      "RMSE, train 0.3970213959307682, test 0.37941123212425454\n",
      "RMSE, train 0.3490004619481728, test 0.3372979813698426\n",
      "RMSE, train 0.3204849274948487, test 0.3147283235510576\n",
      "RMSE, train 0.29952533578504575, test 0.3009713148897134\n",
      "RMSE, train 0.2858438450409511, test 0.290872533633871\n",
      "RMSE, train 0.27686047274398123, test 0.2838844373388198\n",
      "RMSE, train 0.2711954222651389, test 0.2788112879667467\n",
      "RMSE, train 0.2672084228726294, test 0.27853004316103114\n",
      "RMSE, train 0.2642020610760623, test 0.2740860224059484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2625604033328575, test 0.27273713833498725\n",
      "RMSE, train 0.2605051571003332, test 0.2734880453174554\n",
      "RMSE, train 0.2599882176964413, test 0.27090706842616924\n",
      "RMSE, train 0.2586340892201648, test 0.2708354318894229\n",
      "RMSE, train 0.25819641599462606, test 0.2684628705955246\n",
      "RMSE, train 0.2576579930451024, test 0.26734933025628616\n",
      "RMSE, train 0.2566848047909431, test 0.2690891379002229\n",
      "RMSE, train 0.2560813759681448, test 0.26782133249403206\n",
      "RMSE, train 0.2558247133416971, test 0.2671501159089283\n",
      "RMSE, train 0.25524091079937306, test 0.26685064105154244\n",
      "RMSE, train 0.2544097852961751, test 0.2671691808596398\n",
      "RMSE, train 0.2549134819213115, test 0.2661020590842349\n",
      "RMSE, train 0.25386653858239183, test 0.2662592292989342\n",
      "RMSE, train 0.2537950725071221, test 0.266166620607515\n",
      "RMSE, train 0.2535607474645923, test 0.26467371768164405\n",
      "RMSE, train 0.25332094006895167, test 0.2650083777973953\n",
      "RMSE, train 0.2533164737201926, test 0.2644478625174865\n",
      "RMSE, train 0.2531852328225156, test 0.26488298684069256\n",
      "RMSE, train 0.2529265325950047, test 0.2641351996984297\n",
      "RMSE, train 0.25266133514266115, test 0.2627870635789575\n",
      "RMSE, train 0.2524077830362773, test 0.2651938654265357\n",
      "RMSE, train 0.2526990928446029, test 0.2640798071634422\n",
      "RMSE, train 0.25266739173909547, test 0.26320632380767933\n",
      "RMSE, train 0.2522766800008873, test 0.26496838293607955\n",
      "RMSE, train 0.2522762497785256, test 0.2641979855241127\n",
      "RMSE, train 0.2522505184462971, test 0.263233480667605\n",
      "RMSE, train 0.2516866831414207, test 0.26308882945370904\n",
      "RMSE, train 0.25210709310625623, test 0.26305400804408546\n",
      "RMSE, train 0.2519043617463735, test 0.2650350481271744\n",
      "RMSE, train 0.2519633468072375, test 0.26312090933901594\n",
      "Early stopping at epoch 43 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8901104888504727, test 0.8594292879104615\n",
      "RMSE, train 0.848779478805727, test 0.8268076618512471\n",
      "RMSE, train 0.8019769599816869, test 0.7547184983889262\n",
      "RMSE, train 0.6719229539449646, test 0.5810639474127027\n",
      "RMSE, train 0.5098475976131676, test 0.4581919527716107\n",
      "RMSE, train 0.4175012757514686, test 0.39870165917608474\n",
      "RMSE, train 0.370054101044277, test 0.36367021434836916\n",
      "RMSE, train 0.3400316487425421, test 0.3389172050688002\n",
      "RMSE, train 0.3183545647766391, test 0.3208092623286777\n",
      "RMSE, train 0.3040408115743627, test 0.30760460197925565\n",
      "RMSE, train 0.29157242006208056, test 0.30062079711092843\n",
      "RMSE, train 0.2847333613512008, test 0.294040795829561\n",
      "RMSE, train 0.2777002803639903, test 0.2883412669102351\n",
      "RMSE, train 0.2729524284440552, test 0.2858191829588678\n",
      "RMSE, train 0.26906511890438367, test 0.282687550286452\n",
      "RMSE, train 0.2664269086806922, test 0.2803528087006675\n",
      "RMSE, train 0.2643979119885, test 0.27752514315976035\n",
      "RMSE, train 0.2620878728894853, test 0.2778780038158099\n",
      "RMSE, train 0.26052927617435506, test 0.2748151184784042\n",
      "RMSE, train 0.25967748684060543, test 0.27391659170389177\n",
      "RMSE, train 0.25814347362743234, test 0.27302957508299086\n",
      "RMSE, train 0.257720170718319, test 0.2715595319867134\n",
      "RMSE, train 0.25648260711017, test 0.2719274361928304\n",
      "RMSE, train 0.25629257718025833, test 0.2712081904212634\n",
      "RMSE, train 0.25544371409718236, test 0.27094524171617296\n",
      "RMSE, train 0.25497892462821664, test 0.2698897721038924\n",
      "RMSE, train 0.2545238536885485, test 0.2693788821498553\n",
      "RMSE, train 0.25378368280807917, test 0.26827339596218536\n",
      "RMSE, train 0.252940094133593, test 0.2687061814798249\n",
      "RMSE, train 0.25266469850373074, test 0.2683378756046295\n",
      "RMSE, train 0.2526335190087958, test 0.26693091607756086\n",
      "RMSE, train 0.252171640487694, test 0.26624326623148387\n",
      "RMSE, train 0.2516917012370822, test 0.26767162448830073\n",
      "RMSE, train 0.2514379636216356, test 0.2664754735098945\n",
      "RMSE, train 0.2513555078252628, test 0.26585204866197376\n",
      "RMSE, train 0.25097543342576195, test 0.2663491611679395\n",
      "RMSE, train 0.25098051942101707, test 0.2651656357778443\n",
      "RMSE, train 0.25065871619310665, test 0.2654234516951773\n",
      "RMSE, train 0.2504102207740362, test 0.2648551536930932\n",
      "RMSE, train 0.25038359292112594, test 0.26624206172095405\n",
      "RMSE, train 0.2501037128450414, test 0.2651948524845971\n",
      "RMSE, train 0.25003406734800726, test 0.26438351306650376\n",
      "RMSE, train 0.2498669849251801, test 0.2646820280287001\n",
      "RMSE, train 0.24947437214240872, test 0.26580357948939004\n",
      "RMSE, train 0.24936706884048698, test 0.26320019480254914\n",
      "RMSE, train 0.24926660424776154, test 0.26420302705632315\n",
      "RMSE, train 0.24901738927531436, test 0.26377498822079765\n",
      "RMSE, train 0.2488591556118505, test 0.26342247426509857\n",
      "RMSE, train 0.24869436109965704, test 0.2635585836238331\n",
      "RMSE, train 0.24886965852060086, test 0.26421052813529966\n",
      "RMSE, train 0.24836869963577815, test 0.2636061386929618\n",
      "RMSE, train 0.24840252266097262, test 0.2630986159046491\n",
      "RMSE, train 0.24860284708420222, test 0.26289246165090135\n",
      "RMSE, train 0.248204445903192, test 0.2630170022447904\n",
      "RMSE, train 0.24812739223964772, test 0.26261910167005326\n",
      "RMSE, train 0.24806161232875043, test 0.26295429286029603\n",
      "RMSE, train 0.24801431367339472, test 0.2628301994668113\n",
      "RMSE, train 0.24782147814803368, test 0.2626969251367781\n",
      "RMSE, train 0.2475837629760372, test 0.2633956495258543\n",
      "RMSE, train 0.24762807300469947, test 0.26190937840276296\n",
      "RMSE, train 0.24747713420268982, test 0.26323058274057176\n",
      "RMSE, train 0.2474566194005411, test 0.2628452327516344\n",
      "RMSE, train 0.2474179456658119, test 0.261985605623987\n",
      "RMSE, train 0.24733528229746857, test 0.26301062322325175\n",
      "RMSE, train 0.2473828206968436, test 0.2629453483555052\n",
      "RMSE, train 0.24730399042126947, test 0.26196554518408244\n",
      "RMSE, train 0.2471414976765846, test 0.26178261687358223\n",
      "RMSE, train 0.24730264578225478, test 0.26178513036833867\n",
      "RMSE, train 0.2470350976019214, test 0.26239504367113115\n",
      "RMSE, train 0.24693117124051098, test 0.2618578938974275\n",
      "RMSE, train 0.24700895867579067, test 0.2617951583531168\n",
      "RMSE, train 0.24669733221800821, test 0.26156245867411293\n",
      "RMSE, train 0.24665667835592903, test 0.26229356626669564\n",
      "RMSE, train 0.2467164383985283, test 0.26106223381227917\n",
      "RMSE, train 0.24657947772918043, test 0.2617303687665198\n",
      "RMSE, train 0.24657269613440788, test 0.26132658421993255\n",
      "RMSE, train 0.24650076935394113, test 0.26114999105532966\n",
      "RMSE, train 0.24674074773518545, test 0.26130256636275184\n",
      "RMSE, train 0.24660891362759624, test 0.26096057842175163\n",
      "RMSE, train 0.24669415441484785, test 0.26101555592483944\n",
      "RMSE, train 0.24613900880286635, test 0.26137195510996714\n",
      "RMSE, train 0.24617621639989457, test 0.2607315022084448\n",
      "RMSE, train 0.24619051340133996, test 0.26199182851447\n",
      "RMSE, train 0.24616329809726087, test 0.2614844911628299\n",
      "RMSE, train 0.2460885541940314, test 0.26061278962426715\n",
      "RMSE, train 0.2460693059504193, test 0.26079792595571943\n",
      "RMSE, train 0.24571789491851376, test 0.2607154803143607\n",
      "RMSE, train 0.24587454845641823, test 0.26061747819185255\n",
      "RMSE, train 0.2458180714087345, test 0.2608523855606715\n",
      "RMSE, train 0.24566602044189073, test 0.26085427171654174\n",
      "RMSE, train 0.24575968480335092, test 0.26152524136834676\n",
      "RMSE, train 0.24599147822979003, test 0.2611490802632438\n",
      "RMSE, train 0.2456138037205385, test 0.26140033404032387\n",
      "RMSE, train 0.24592292184296322, test 0.2603921650184525\n",
      "RMSE, train 0.24564020219196206, test 0.2604549154639244\n",
      "RMSE, train 0.24547539301959653, test 0.26000664449400374\n",
      "RMSE, train 0.2456828274254529, test 0.26075682590405147\n",
      "RMSE, train 0.24569813216310948, test 0.26089968929688134\n",
      "RMSE, train 0.2455638743073471, test 0.2602930820650525\n",
      "RMSE, train 0.2452726231591721, test 0.2596092879772186\n",
      "RMSE, train 0.2454226511829304, test 0.2603650540113449\n",
      "RMSE, train 0.2453533249563284, test 0.25963613390922546\n",
      "RMSE, train 0.24527552398549257, test 0.26070821202463573\n",
      "RMSE, train 0.2451755361495956, test 0.2609856145249473\n",
      "RMSE, train 0.24496455836006895, test 0.26088813377751247\n",
      "RMSE, train 0.24526283430121337, test 0.26030255456765494\n",
      "RMSE, train 0.2452440085517107, test 0.260423962937461\n",
      "RMSE, train 0.2449587974345909, test 0.2603940314716763\n",
      "RMSE, train 0.24508644270929045, test 0.26036113633049857\n",
      "RMSE, train 0.24486370211984268, test 0.259626551800304\n",
      "Early stopping at epoch 110 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.8143742823367597, test 0.7963239478342461\n",
      "RMSE, train 0.7606328436535553, test 0.7530949669654923\n",
      "RMSE, train 0.7083994340342823, test 0.6757435961203142\n",
      "RMSE, train 0.5936380473937848, test 0.5304151460377857\n",
      "RMSE, train 0.4726528038605501, test 0.4383739443740459\n",
      "RMSE, train 0.40744844414202686, test 0.39387672146161395\n",
      "RMSE, train 0.3737929925358966, test 0.37003331142242507\n",
      "RMSE, train 0.3540461177056459, test 0.35466574930181405\n",
      "RMSE, train 0.3413366630199777, test 0.34540989483245693\n",
      "RMSE, train 0.33150503913755813, test 0.3378639317522145\n",
      "RMSE, train 0.32463311019619984, test 0.3334840773934066\n",
      "RMSE, train 0.31945543322703074, test 0.3285476303461826\n",
      "RMSE, train 0.3159376049100041, test 0.32536381242251156\n",
      "RMSE, train 0.3125365009954914, test 0.3231757572202971\n",
      "RMSE, train 0.3104197880239533, test 0.3212637783903064\n",
      "RMSE, train 0.30867329706189683, test 0.3199249424717643\n",
      "RMSE, train 0.307686489412429, test 0.31821884109516335\n",
      "RMSE, train 0.3064372443336729, test 0.3172637802181822\n",
      "RMSE, train 0.3053620138494776, test 0.3165685978501734\n",
      "RMSE, train 0.3049644516703552, test 0.3179358084394474\n",
      "RMSE, train 0.3038661854482805, test 0.31705453600546324\n",
      "RMSE, train 0.30357834044616205, test 0.3160674162585326\n",
      "RMSE, train 0.30338692501150893, test 0.3154101657747018\n",
      "RMSE, train 0.30311421179246784, test 0.31587518224812516\n",
      "RMSE, train 0.3022011614297596, test 0.31549133435644283\n",
      "RMSE, train 0.3019425285693194, test 0.31420648158198655\n",
      "RMSE, train 0.30218075725880694, test 0.3150699698563778\n",
      "RMSE, train 0.30175410553557946, test 0.3146404943080864\n",
      "RMSE, train 0.3020198116019769, test 0.3142129708119113\n",
      "RMSE, train 0.3016481423946348, test 0.3146739162579931\n",
      "RMSE, train 0.3017896989811312, test 0.31328352743929083\n",
      "RMSE, train 0.30143821847905156, test 0.31349509653418955\n",
      "RMSE, train 0.3014096518964814, test 0.31452265923673456\n",
      "RMSE, train 0.3011541931291081, test 0.3140603370136685\n",
      "RMSE, train 0.30142826811025664, test 0.314265723330806\n",
      "RMSE, train 0.30115842024971046, test 0.3135701318581899\n",
      "RMSE, train 0.301121992594164, test 0.313186511246845\n",
      "RMSE, train 0.3006577609803682, test 0.31350525882509017\n",
      "RMSE, train 0.3009002160253618, test 0.3138880759778649\n",
      "RMSE, train 0.30073844909230774, test 0.31386178822228405\n",
      "RMSE, train 0.30109496764419713, test 0.3133219980230235\n",
      "RMSE, train 0.30081089493114965, test 0.3140458231321489\n",
      "RMSE, train 0.30079056756129186, test 0.3133811258306407\n",
      "RMSE, train 0.30048600775542644, test 0.3130949961416649\n",
      "RMSE, train 0.3001965457769361, test 0.3134809542785991\n",
      "RMSE, train 0.3007602004156719, test 0.3132087913426486\n",
      "RMSE, train 0.3005149982013446, test 0.3135466551539874\n",
      "RMSE, train 0.30031514590410263, test 0.31415310908447613\n",
      "RMSE, train 0.30054721939388873, test 0.3131108958311755\n",
      "RMSE, train 0.3006122250355835, test 0.31301674969268567\n",
      "RMSE, train 0.30060781593136215, test 0.3126439404005956\n",
      "RMSE, train 0.30031945059089615, test 0.31263019280000165\n",
      "RMSE, train 0.3001067575003524, test 0.31337749702159806\n",
      "RMSE, train 0.30028916480051565, test 0.31416925607305585\n",
      "RMSE, train 0.3001116643907971, test 0.31282291659201034\n",
      "RMSE, train 0.30018982597260135, test 0.31343842591300153\n",
      "RMSE, train 0.3002340660264265, test 0.3130659590465854\n",
      "RMSE, train 0.3004987240201978, test 0.31301755495745726\n",
      "RMSE, train 0.30012033642941405, test 0.31306406975996615\n",
      "RMSE, train 0.3001326340407789, test 0.31279773152235785\n",
      "RMSE, train 0.3000502246807723, test 0.3132998293096369\n",
      "RMSE, train 0.300196780661499, test 0.3127816037999259\n",
      "Early stopping at epoch 62 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.783292689859265, test 0.7767172399908304\n",
      "RMSE, train 0.7445798891812864, test 0.7345760793735584\n",
      "RMSE, train 0.6661439434145436, test 0.5960138086229563\n",
      "RMSE, train 0.5084238630352598, test 0.4525048133606712\n",
      "RMSE, train 0.40797566750434916, test 0.38986900852372247\n",
      "RMSE, train 0.36249250474602285, test 0.36233264952898026\n",
      "RMSE, train 0.3395114049616486, test 0.34575675303737324\n",
      "RMSE, train 0.325618462956915, test 0.33698138656715554\n",
      "RMSE, train 0.3158631090338182, test 0.3306382664789756\n",
      "RMSE, train 0.3082596774429384, test 0.32350799161940813\n",
      "RMSE, train 0.30296872616416276, test 0.3177840979769826\n",
      "RMSE, train 0.2990827096833123, test 0.3147686935650806\n",
      "RMSE, train 0.29612037716339334, test 0.31258421624079347\n",
      "RMSE, train 0.293294360917626, test 0.3090400610429545\n",
      "RMSE, train 0.2910462899716816, test 0.3075378236050407\n",
      "RMSE, train 0.28974586789204615, test 0.30565532157197595\n",
      "RMSE, train 0.2886335038852812, test 0.3058714770401518\n",
      "RMSE, train 0.2877133914993869, test 0.30441001430153847\n",
      "RMSE, train 0.2871919233314317, test 0.30364949768409133\n",
      "RMSE, train 0.28634975929603435, test 0.3023676661153634\n",
      "RMSE, train 0.28594391157079224, test 0.302417515621831\n",
      "RMSE, train 0.2856202195163327, test 0.3017645177120964\n",
      "RMSE, train 0.2852319409374637, test 0.30211212718859315\n",
      "RMSE, train 0.2849226846839442, test 0.30204764008522034\n",
      "RMSE, train 0.2849083177444309, test 0.3008037148974836\n",
      "RMSE, train 0.2846065184684715, test 0.30166629577676457\n",
      "RMSE, train 0.28457496416839684, test 0.30070221253360313\n",
      "RMSE, train 0.2844531060092979, test 0.30050882091745734\n",
      "RMSE, train 0.2841519406723856, test 0.3008978657114009\n",
      "RMSE, train 0.2842026279505455, test 0.3005822788303097\n",
      "RMSE, train 0.28409465304528825, test 0.29958917216087383\n",
      "RMSE, train 0.2838245893292355, test 0.2998017892241478\n",
      "RMSE, train 0.2836454628468162, test 0.2995267764975627\n",
      "RMSE, train 0.28366338111685985, test 0.30060646729543805\n",
      "RMSE, train 0.2836747828381832, test 0.2994548254646361\n",
      "RMSE, train 0.28341177045696914, test 0.29927024493614834\n",
      "RMSE, train 0.28341549623644713, test 0.3000951449697216\n",
      "RMSE, train 0.2835005443129275, test 0.2997215560947855\n",
      "RMSE, train 0.2833545786338021, test 0.2999743251129985\n",
      "RMSE, train 0.2831100049343976, test 0.2996446938874821\n",
      "RMSE, train 0.28321518052858535, test 0.2993712197057903\n",
      "RMSE, train 0.2831744379316918, test 0.2988857234207292\n",
      "RMSE, train 0.28314037812930165, test 0.2994856413764258\n",
      "RMSE, train 0.28298593632350066, test 0.2991860918700695\n",
      "RMSE, train 0.2830285741900555, test 0.2995858653448522\n",
      "RMSE, train 0.28302694379229737, test 0.29932904879872996\n",
      "RMSE, train 0.28297812702378844, test 0.29922417147705954\n",
      "RMSE, train 0.2828669025741442, test 0.29792565867925686\n",
      "RMSE, train 0.28287050489223364, test 0.2990043661557138\n",
      "RMSE, train 0.2829010076068266, test 0.2978660762310028\n",
      "RMSE, train 0.2827455980910195, test 0.2989992802031338\n",
      "RMSE, train 0.2828330149253209, test 0.29900606876860064\n",
      "RMSE, train 0.28257029590131055, test 0.29873657583569485\n",
      "RMSE, train 0.2827983683708942, test 0.2984614830153684\n",
      "RMSE, train 0.28281563693525813, test 0.2989789228886366\n",
      "RMSE, train 0.2825963817010022, test 0.29829628268877667\n",
      "RMSE, train 0.2824932442545289, test 0.2991712037473917\n",
      "RMSE, train 0.2826087721294225, test 0.2995475400239229\n",
      "RMSE, train 0.28258803114295006, test 0.2980210442716877\n",
      "RMSE, train 0.28229762561092475, test 0.2992433002218604\n",
      "Early stopping at epoch 60 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7905129492282867, test 0.7812900536590153\n",
      "RMSE, train 0.7574802561590293, test 0.7598827759424845\n",
      "RMSE, train 0.7282410689762661, test 0.7124351173639297\n",
      "RMSE, train 0.6495004604768881, test 0.6005223943127527\n",
      "RMSE, train 0.5258344814301822, test 0.4833043866687351\n",
      "RMSE, train 0.42585415893166534, test 0.4143012785249286\n",
      "RMSE, train 0.37322400490228697, test 0.3756042457289166\n",
      "RMSE, train 0.3437994859128628, test 0.35688773757881587\n",
      "RMSE, train 0.3259804107429525, test 0.3409810980161031\n",
      "RMSE, train 0.31399494076192863, test 0.330684424440066\n",
      "RMSE, train 0.30452039588815116, test 0.32210193889008626\n",
      "RMSE, train 0.29901255900165785, test 0.31707052919599743\n",
      "RMSE, train 0.29518416017856236, test 0.3152416255739\n",
      "RMSE, train 0.2924008436922757, test 0.3122508701350954\n",
      "RMSE, train 0.2897896144107346, test 0.30792459961440827\n",
      "RMSE, train 0.28876950087733666, test 0.30897178186310664\n",
      "RMSE, train 0.2872092160735169, test 0.30639736900726955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.28619846946627625, test 0.30602557162443794\n",
      "RMSE, train 0.2851303433873904, test 0.305148254831632\n",
      "RMSE, train 0.28432778985995166, test 0.3050811308953497\n",
      "RMSE, train 0.28437939836490506, test 0.3044442865583632\n",
      "RMSE, train 0.2833286533056886, test 0.3035208193792237\n",
      "RMSE, train 0.2822598541843281, test 0.3029186064998309\n",
      "RMSE, train 0.2817931699383291, test 0.3016067428721322\n",
      "RMSE, train 0.2815757754517373, test 0.301959447728263\n",
      "RMSE, train 0.2815323176811326, test 0.3014249308241738\n",
      "RMSE, train 0.2810948174999088, test 0.30100668602519565\n",
      "RMSE, train 0.2808721916614517, test 0.3015024193459087\n",
      "RMSE, train 0.28057768969040997, test 0.3003121193912294\n",
      "RMSE, train 0.28033100984327874, test 0.30031443470054203\n",
      "RMSE, train 0.28022405722070576, test 0.30092398871978127\n",
      "RMSE, train 0.2796660651656174, test 0.3002782811721166\n",
      "RMSE, train 0.2794861535258049, test 0.3004471181167497\n",
      "RMSE, train 0.2794794713390484, test 0.3001886299914784\n",
      "RMSE, train 0.2792531689302619, test 0.29977403200334973\n",
      "RMSE, train 0.27910013966804564, test 0.2995685592293739\n",
      "RMSE, train 0.27920059859752655, test 0.29911890427271526\n",
      "RMSE, train 0.2786917947935608, test 0.29809997114870285\n",
      "RMSE, train 0.2789453483736419, test 0.30025962740182877\n",
      "RMSE, train 0.27867632618329596, test 0.3015838932659891\n",
      "RMSE, train 0.27860224757072416, test 0.3000436716609531\n",
      "RMSE, train 0.2787417150491653, test 0.29920341306262543\n",
      "RMSE, train 0.27847062380648047, test 0.29853061470720504\n",
      "RMSE, train 0.27820470615859944, test 0.29957026475005677\n",
      "RMSE, train 0.2781437031743983, test 0.2987280284365018\n",
      "RMSE, train 0.27833711663185745, test 0.30002757277753617\n",
      "RMSE, train 0.2782967776220764, test 0.2991475683119562\n",
      "RMSE, train 0.27799447503372665, test 0.29786213917864696\n",
      "RMSE, train 0.27824421034186997, test 0.29749589098824397\n",
      "RMSE, train 0.27794598826179606, test 0.2985876320136918\n",
      "RMSE, train 0.2777871864262938, test 0.2992490576373206\n",
      "RMSE, train 0.27773875925900804, test 0.29745518465836845\n",
      "RMSE, train 0.2778471573343817, test 0.29779926339785256\n",
      "RMSE, train 0.2776785358746418, test 0.2986229848530557\n",
      "RMSE, train 0.2774617269113057, test 0.2978399900926484\n",
      "RMSE, train 0.2772213895767526, test 0.2985916607909732\n",
      "RMSE, train 0.27721741430039676, test 0.29832208537393146\n",
      "RMSE, train 0.27747870029786204, test 0.29817240072621237\n",
      "RMSE, train 0.277177103446179, test 0.297663841313786\n",
      "RMSE, train 0.27718906899828794, test 0.29815253830618327\n",
      "RMSE, train 0.2772562467264679, test 0.29799349539809755\n",
      "RMSE, train 0.27750507286295417, test 0.2992704068621\n",
      "Early stopping at epoch 62 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7744521095745289, test 0.7630298130023174\n",
      "RMSE, train 0.7367452511163516, test 0.7284601105329318\n",
      "RMSE, train 0.6876280378329791, test 0.6565101643403372\n",
      "RMSE, train 0.5958676095877853, test 0.5550300700542254\n",
      "RMSE, train 0.491363855258698, test 0.4638794549764731\n",
      "RMSE, train 0.41897102169158673, test 0.4146281763529166\n",
      "RMSE, train 0.3757565483868679, test 0.3830460745554704\n",
      "RMSE, train 0.34870837652051934, test 0.36022790731527865\n",
      "RMSE, train 0.33232977772798866, test 0.3484968458994841\n",
      "RMSE, train 0.3221919066345209, test 0.34228354616042894\n",
      "RMSE, train 0.3142667112877807, test 0.3335426919735395\n",
      "RMSE, train 0.3091192538864516, test 0.3296783050665489\n",
      "RMSE, train 0.3040335576203753, test 0.3240908361398257\n",
      "RMSE, train 0.2997358345725455, test 0.32244393611565614\n",
      "RMSE, train 0.2966305805236751, test 0.31886292420900786\n",
      "RMSE, train 0.29446121627853666, test 0.3168096817456759\n",
      "RMSE, train 0.2922969416851567, test 0.3155895532705845\n",
      "RMSE, train 0.2903562347836955, test 0.31068737250872147\n",
      "RMSE, train 0.2883748180026949, test 0.3119418691748228\n",
      "RMSE, train 0.28689204207461944, test 0.31019684997124547\n",
      "RMSE, train 0.28570840087635124, test 0.3090455012443738\n",
      "RMSE, train 0.28496033872399373, test 0.30625318945982516\n",
      "RMSE, train 0.28331944211806837, test 0.30611897928592485\n",
      "RMSE, train 0.2830055357882538, test 0.30580165141668075\n",
      "RMSE, train 0.2816709975865771, test 0.30609993120798695\n",
      "RMSE, train 0.2814124650394434, test 0.30576821817801547\n",
      "RMSE, train 0.28093324578439705, test 0.3042864681054384\n",
      "RMSE, train 0.2802419649941899, test 0.30329865790330446\n",
      "RMSE, train 0.27968844567132517, test 0.3044735407217955\n",
      "RMSE, train 0.2792337000184341, test 0.3037857921459736\n",
      "RMSE, train 0.2789050142898738, test 0.3023853307733169\n",
      "RMSE, train 0.27864841847590566, test 0.30195298408850646\n",
      "RMSE, train 0.2773623198642166, test 0.3034006204360571\n",
      "RMSE, train 0.2777122681571687, test 0.3012027117686394\n",
      "RMSE, train 0.2772796499394925, test 0.30273219522757405\n",
      "RMSE, train 0.2767509462955956, test 0.3014844871866397\n",
      "RMSE, train 0.2769636116759428, test 0.3007245258643077\n",
      "RMSE, train 0.2770145112573172, test 0.3018673039399661\n",
      "RMSE, train 0.27653559086107393, test 0.3031306167443593\n",
      "RMSE, train 0.2761780397728596, test 0.30175505845974654\n",
      "RMSE, train 0.27620840439358235, test 0.3031037335212414\n",
      "RMSE, train 0.27557677494773986, test 0.2998933847516011\n",
      "RMSE, train 0.27550509404913287, test 0.3023019818923412\n",
      "RMSE, train 0.27556385085961527, test 0.3043691936211708\n",
      "RMSE, train 0.2749994155773864, test 0.3010056420014455\n",
      "RMSE, train 0.27524816599961754, test 0.3005987285421445\n",
      "RMSE, train 0.274332996144473, test 0.30052878650335163\n",
      "RMSE, train 0.27435308592713137, test 0.2989299755830031\n",
      "RMSE, train 0.2745124505037831, test 0.2981094488730797\n",
      "RMSE, train 0.2740777098222685, test 0.2992742611811711\n",
      "RMSE, train 0.2744136022815823, test 0.2995073140049592\n",
      "RMSE, train 0.27430181205272675, test 0.29983199139436084\n",
      "RMSE, train 0.2743897375845092, test 0.30061065157254535\n",
      "RMSE, train 0.2735465555640396, test 0.2984410169032904\n",
      "RMSE, train 0.27369705427472835, test 0.3026718189701056\n",
      "RMSE, train 0.2738759382120174, test 0.29916557363974744\n",
      "RMSE, train 0.2736980380298935, test 0.29813435941170424\n",
      "RMSE, train 0.2736171709135685, test 0.2970088934287047\n",
      "RMSE, train 0.27321505179843425, test 0.300600121036554\n",
      "RMSE, train 0.27301041053091624, test 0.30041490628933293\n",
      "RMSE, train 0.27296439551304436, test 0.3045604956837801\n",
      "RMSE, train 0.2728558143722677, test 0.2991763645639786\n",
      "RMSE, train 0.2727208267491183, test 0.2987830807001163\n",
      "RMSE, train 0.272727545873027, test 0.2985306076514415\n",
      "RMSE, train 0.2729428964333371, test 0.29782291539968586\n",
      "RMSE, train 0.2724366019076647, test 0.298813423094077\n",
      "RMSE, train 0.2722236538230444, test 0.2987619934555812\n",
      "RMSE, train 0.2721142700620901, test 0.29796343640639233\n",
      "Early stopping at epoch 68 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.GRU, data_dir = 'data_synthetic')\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/gru/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b9c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.31795751992539456, test 0.3054342558307032\n",
      "RMSE, train 0.2894209169086967, test 0.2933209931417819\n",
      "RMSE, train 0.28108034377159336, test 0.2875883170673924\n",
      "RMSE, train 0.2757862913219825, test 0.28161916893816763\n",
      "RMSE, train 0.2716373140986258, test 0.2781101895436164\n",
      "RMSE, train 0.2681102402390463, test 0.27418041048992065\n",
      "RMSE, train 0.2652124869287485, test 0.27173789698750744\n",
      "RMSE, train 0.2627248167844394, test 0.26817674394096097\n",
      "RMSE, train 0.26071039654991846, test 0.26775009846014364\n",
      "RMSE, train 0.259107081315263, test 0.2650989954990725\n",
      "RMSE, train 0.2577192061709557, test 0.26413784428469594\n",
      "RMSE, train 0.2565742111783254, test 0.261921881067176\n",
      "RMSE, train 0.2556801012352757, test 0.2632414417401437\n",
      "RMSE, train 0.2549539667668314, test 0.2612576136185277\n",
      "RMSE, train 0.25440933079764305, test 0.259830686894636\n",
      "RMSE, train 0.25391964969250996, test 0.26015454662903664\n",
      "RMSE, train 0.25366097616525035, test 0.2599799339809725\n",
      "RMSE, train 0.253266399674736, test 0.26030274708905526\n",
      "RMSE, train 0.2530297941193279, test 0.25852457265700063\n",
      "RMSE, train 0.25289821498125437, test 0.2584293785114442\n",
      "RMSE, train 0.252701518313569, test 0.2586879209885674\n",
      "RMSE, train 0.2526081359168522, test 0.2577565928260165\n",
      "RMSE, train 0.2525807941855178, test 0.258006434406965\n",
      "RMSE, train 0.2524906826967543, test 0.2577854950701998\n",
      "RMSE, train 0.25239764093587047, test 0.2595306602456877\n",
      "RMSE, train 0.2523728118613068, test 0.2576366171481148\n",
      "RMSE, train 0.2524340043632174, test 0.25861608369215844\n",
      "RMSE, train 0.25234484110071725, test 0.25745526448853556\n",
      "RMSE, train 0.2522985662072308, test 0.25816280935560504\n",
      "RMSE, train 0.2523132917938732, test 0.25826215876206277\n",
      "RMSE, train 0.2523451063472763, test 0.2579675662902094\n",
      "RMSE, train 0.25226590935538407, test 0.25777791284265056\n",
      "RMSE, train 0.2522225948013807, test 0.2579200036463238\n",
      "RMSE, train 0.25226772997690283, test 0.2582743376373283\n",
      "RMSE, train 0.2522796786320304, test 0.2578279174143268\n",
      "RMSE, train 0.2522502929384529, test 0.25769409128735143\n",
      "RMSE, train 0.25218992378459615, test 0.2574029999875253\n",
      "RMSE, train 0.2522309055412004, test 0.25764709849271084\n",
      "RMSE, train 0.25231720813413855, test 0.2576806845684205\n",
      "RMSE, train 0.2522419968936519, test 0.2575076841899464\n",
      "RMSE, train 0.25216878578066826, test 0.2590094892488372\n",
      "RMSE, train 0.25225281725700194, test 0.25740264410213115\n",
      "RMSE, train 0.2521996513421356, test 0.25786604299660654\n",
      "RMSE, train 0.2523215382908408, test 0.2577949928780717\n",
      "RMSE, train 0.252223794698244, test 0.2580433951150025\n",
      "RMSE, train 0.25226203480315773, test 0.25822590099227044\n",
      "RMSE, train 0.25227151011584303, test 0.2584301080074041\n",
      "RMSE, train 0.25228213701441354, test 0.2574621542927719\n",
      "RMSE, train 0.2521726820367598, test 0.2578674655768179\n",
      "RMSE, train 0.25220152570796106, test 0.257363366263528\n",
      "RMSE, train 0.25218874447253853, test 0.2585367089317691\n",
      "RMSE, train 0.25220435560338583, test 0.257533753951711\n",
      "RMSE, train 0.25220619731034216, test 0.25778606017270395\n",
      "RMSE, train 0.25218372244255344, test 0.2580903498756309\n",
      "RMSE, train 0.2522481632209107, test 0.2570263303575977\n",
      "RMSE, train 0.2522067576646805, test 0.2572439886148899\n",
      "RMSE, train 0.2522307386099114, test 0.25833252540999846\n",
      "RMSE, train 0.2521939226702268, test 0.25793069216512865\n",
      "RMSE, train 0.2522224650788213, test 0.25785141618501756\n",
      "RMSE, train 0.2523311980422071, test 0.2574547125447181\n",
      "RMSE, train 0.2522139112674907, test 0.25755540389687787\n",
      "RMSE, train 0.2522443694471135, test 0.25864196718940813\n",
      "RMSE, train 0.2522154205695914, test 0.25732564217140597\n",
      "RMSE, train 0.252199771331822, test 0.2583367450222854\n",
      "RMSE, train 0.25223585927910486, test 0.25931385291680215\n",
      "Early stopping at epoch 65 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.6465811116191057, test 0.4502573044093187\n",
      "RMSE, train 0.35831750501022647, test 0.2957496232976598\n",
      "RMSE, train 0.26755844368806736, test 0.2567592087117108\n",
      "RMSE, train 0.24779437871476417, test 0.2512676570533721\n",
      "RMSE, train 0.24464601902705937, test 0.24948571862514354\n",
      "RMSE, train 0.24341020019732507, test 0.2486924506908606\n",
      "RMSE, train 0.2424008467268606, test 0.2474312712092045\n",
      "RMSE, train 0.2408971892375695, test 0.24657434766942804\n",
      "RMSE, train 0.2404103398715195, test 0.24534176450130368\n",
      "RMSE, train 0.23886411695888168, test 0.24321815691703608\n",
      "RMSE, train 0.2382192729636725, test 0.24283556147547794\n",
      "RMSE, train 0.2371589559533818, test 0.2427289951438746\n",
      "RMSE, train 0.23651649653609946, test 0.2414360146754044\n",
      "RMSE, train 0.23628379461856988, test 0.24110264004754625\n",
      "RMSE, train 0.23589225727235258, test 0.2421228010053477\n",
      "RMSE, train 0.235234261991886, test 0.2413490723726178\n",
      "RMSE, train 0.23536454831902315, test 0.24077868116788628\n",
      "RMSE, train 0.23521731843651547, test 0.23970831721282201\n",
      "RMSE, train 0.23482227237963002, test 0.24026396698202968\n",
      "RMSE, train 0.23470177932789452, test 0.23921252861003245\n",
      "RMSE, train 0.23460472943751434, test 0.2395446709364899\n",
      "RMSE, train 0.23460542118018454, test 0.23894529247825796\n",
      "RMSE, train 0.23450506175396896, test 0.2400471051492967\n",
      "RMSE, train 0.2348027507122229, test 0.2383880317211151\n",
      "RMSE, train 0.23461745208815524, test 0.238833730624727\n",
      "RMSE, train 0.23471107226815302, test 0.23889713500403176\n",
      "RMSE, train 0.23483574606086077, test 0.23873220562688574\n",
      "RMSE, train 0.23437317610088632, test 0.23978869875600514\n",
      "RMSE, train 0.23418744274901476, test 0.2389088438069525\n",
      "RMSE, train 0.2342548580003171, test 0.23970187104437962\n",
      "RMSE, train 0.23462669459371432, test 0.23833280142920077\n",
      "RMSE, train 0.2344018689051331, test 0.2399574779897682\n",
      "RMSE, train 0.23426951869175985, test 0.24205013832523803\n",
      "RMSE, train 0.23461401643540694, test 0.23951109849717006\n",
      "RMSE, train 0.2342393100563331, test 0.24142941974165025\n",
      "RMSE, train 0.23471552524187786, test 0.2385749356313185\n",
      "RMSE, train 0.23431507354745498, test 0.23862719812915345\n",
      "RMSE, train 0.23425627270570168, test 0.2390592014494021\n",
      "RMSE, train 0.2344384645583176, test 0.2387429094019015\n",
      "RMSE, train 0.23411257948862155, test 0.23871225020117012\n",
      "RMSE, train 0.23452553344581292, test 0.23831860807316363\n",
      "RMSE, train 0.23424412239237352, test 0.23816504526483126\n",
      "RMSE, train 0.23417750583124547, test 0.23995306878543096\n",
      "RMSE, train 0.2343611253448102, test 0.24015360356362397\n",
      "RMSE, train 0.2344200586379781, test 0.23822389327543825\n",
      "RMSE, train 0.23423359503871516, test 0.24009189569999365\n",
      "RMSE, train 0.23449250444890515, test 0.2391590751892279\n",
      "RMSE, train 0.23429254656619872, test 0.23889993001853138\n",
      "RMSE, train 0.23457196707788266, test 0.23948315321660238\n",
      "RMSE, train 0.23439462837359684, test 0.23917950652847605\n",
      "RMSE, train 0.2343530334109961, test 0.23850770565596494\n",
      "RMSE, train 0.23478764579122366, test 0.23771815349863581\n",
      "RMSE, train 0.2342383194458388, test 0.23932598919168976\n",
      "RMSE, train 0.23423144934691398, test 0.24025829949162222\n",
      "RMSE, train 0.2342023885533636, test 0.2379638529267193\n",
      "RMSE, train 0.23437306802222121, test 0.23817585568782712\n",
      "RMSE, train 0.2344857290206168, test 0.23954869843711538\n",
      "RMSE, train 0.23428752792147006, test 0.23860796343935423\n",
      "RMSE, train 0.23434993823771536, test 0.23968609256192672\n",
      "RMSE, train 0.23449882697540256, test 0.23931642498605507\n",
      "RMSE, train 0.23468276132878504, test 0.23852385949989982\n",
      "RMSE, train 0.23430431233002588, test 0.24038740930971036\n",
      "Early stopping at epoch 62 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.4539302739062543, test 0.3476860936273608\n",
      "RMSE, train 0.32145868495964547, test 0.3174567051362573\n",
      "RMSE, train 0.30209247942672357, test 0.30125152607235994\n",
      "RMSE, train 0.2873985439475411, test 0.2883077288667361\n",
      "RMSE, train 0.2761500577873258, test 0.27803230259502143\n",
      "RMSE, train 0.26692660465868295, test 0.26956828147695777\n",
      "RMSE, train 0.25913751098329324, test 0.2630427313739793\n",
      "RMSE, train 0.2536695023684868, test 0.2572150542809252\n",
      "RMSE, train 0.24842718253130597, test 0.25287666119504393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2449350825695595, test 0.24912349056256444\n",
      "RMSE, train 0.24141406525236203, test 0.2463785688343801\n",
      "RMSE, train 0.2389384890670207, test 0.2439918363172757\n",
      "RMSE, train 0.23706347339633685, test 0.24220386624597667\n",
      "RMSE, train 0.23535017747042783, test 0.2406411146124204\n",
      "RMSE, train 0.2348232676288975, test 0.2398481823896107\n",
      "RMSE, train 0.23305256729885968, test 0.23872376658153116\n",
      "RMSE, train 0.23257765547235384, test 0.23816471631851113\n",
      "RMSE, train 0.23160786462475114, test 0.23750187456607819\n",
      "RMSE, train 0.2318727604425284, test 0.2369992930376739\n",
      "RMSE, train 0.2310134300640397, test 0.23737259411759543\n",
      "RMSE, train 0.23087152932434957, test 0.236451244014397\n",
      "RMSE, train 0.23092906499531732, test 0.23661275632810175\n",
      "RMSE, train 0.23073206910255875, test 0.23602996498607753\n",
      "RMSE, train 0.23047864356084163, test 0.23633949105676852\n",
      "RMSE, train 0.2303929328441874, test 0.23601213019145162\n",
      "RMSE, train 0.2302758531656855, test 0.23593459631267347\n",
      "RMSE, train 0.2303006254724348, test 0.23570204382402854\n",
      "RMSE, train 0.23013037427274913, test 0.23574615969208249\n",
      "RMSE, train 0.23001183826786115, test 0.23584692421973796\n",
      "RMSE, train 0.229791079757056, test 0.23582249860230245\n",
      "RMSE, train 0.22970605751217554, test 0.2358870703661651\n",
      "RMSE, train 0.2301504020688376, test 0.23557864658926664\n",
      "RMSE, train 0.22999058103065756, test 0.23585969150850647\n",
      "RMSE, train 0.22984820963350186, test 0.23545420673071293\n",
      "RMSE, train 0.22985417141652564, test 0.2356464305337061\n",
      "RMSE, train 0.22974429236673344, test 0.23545613858783454\n",
      "RMSE, train 0.2299900616981836, test 0.2354850630488312\n",
      "RMSE, train 0.22987532474275338, test 0.2354964420460818\n",
      "RMSE, train 0.2298100877767687, test 0.23593600342671076\n",
      "RMSE, train 0.2297757275895015, test 0.2355335772429642\n",
      "RMSE, train 0.2298178407651529, test 0.23549131264812068\n",
      "RMSE, train 0.22977645102657998, test 0.235487716958711\n",
      "RMSE, train 0.2296410511011508, test 0.2354608598377621\n",
      "RMSE, train 0.2300312208659105, test 0.2354619797123106\n",
      "Early stopping at epoch 44 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.5407195553930392, test 0.34071022578898597\n",
      "RMSE, train 0.32435844525659285, test 0.3151106893577996\n",
      "RMSE, train 0.3053364199641781, test 0.30148473221297356\n",
      "RMSE, train 0.29332251875241216, test 0.2911330633888058\n",
      "RMSE, train 0.28415560789921973, test 0.28345681463970857\n",
      "RMSE, train 0.27747394025396904, test 0.2766590040980601\n",
      "RMSE, train 0.2698093249967104, test 0.2701671124965537\n",
      "RMSE, train 0.2647193413859051, test 0.26314177071931316\n",
      "RMSE, train 0.2584855729682918, test 0.2581155862586171\n",
      "RMSE, train 0.2528163724554467, test 0.2543800690887021\n",
      "RMSE, train 0.24882091085708796, test 0.25004107505083084\n",
      "RMSE, train 0.2446556330474009, test 0.24706936496145585\n",
      "RMSE, train 0.24129439229790237, test 0.24433463220210636\n",
      "RMSE, train 0.2390851938745856, test 0.24220810333887735\n",
      "RMSE, train 0.23697847812514317, test 0.2403305285409385\n",
      "RMSE, train 0.23523637529702632, test 0.23946606733051\n",
      "RMSE, train 0.23359826310295478, test 0.23875744816134958\n",
      "RMSE, train 0.23276927263469285, test 0.23750944048458456\n",
      "RMSE, train 0.23220438945833993, test 0.23728299973642125\n",
      "RMSE, train 0.2309822286512516, test 0.23651704075289706\n",
      "RMSE, train 0.23067114361715202, test 0.23610361811577105\n",
      "RMSE, train 0.2301199511760459, test 0.23727003638358676\n",
      "RMSE, train 0.22954489713921467, test 0.23510735511195427\n",
      "RMSE, train 0.22944454902111772, test 0.2347794931162806\n",
      "RMSE, train 0.2294858236372613, test 0.23495487167554743\n",
      "RMSE, train 0.2290150333453761, test 0.2345239296555519\n",
      "RMSE, train 0.22888296309120615, test 0.23510916808656618\n",
      "RMSE, train 0.22937271585754676, test 0.2347860448792869\n",
      "RMSE, train 0.22870392012709934, test 0.23501061596998982\n",
      "RMSE, train 0.22867030106253727, test 0.2346269724269708\n",
      "RMSE, train 0.22857656424113845, test 0.2348050572270272\n",
      "RMSE, train 0.22862978229801523, test 0.23425202210452042\n",
      "RMSE, train 0.22866396501055766, test 0.23459278288133004\n",
      "RMSE, train 0.22826885995688473, test 0.2343201101118443\n",
      "RMSE, train 0.22827352885699215, test 0.2344342149501922\n",
      "RMSE, train 0.22869215011241043, test 0.23549295808462536\n",
      "RMSE, train 0.22826220306761225, test 0.23421240948578892\n",
      "RMSE, train 0.22846236807207504, test 0.23476138163138838\n",
      "RMSE, train 0.22826934901015003, test 0.2347219946483771\n",
      "RMSE, train 0.22877537181738739, test 0.23621702354912663\n",
      "RMSE, train 0.22823747852039222, test 0.23558905720710754\n",
      "RMSE, train 0.22833265124115568, test 0.23447878483463735\n",
      "RMSE, train 0.2285939144561854, test 0.2350953127823624\n",
      "RMSE, train 0.22834577084227792, test 0.23480593741816633\n",
      "RMSE, train 0.22831878179866544, test 0.23548313230276108\n",
      "RMSE, train 0.22857483367931303, test 0.23494482916944168\n",
      "RMSE, train 0.2285359352649254, test 0.23460534529066554\n",
      "Early stopping at epoch 47 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.9668087446160856, test 1.6987612040574886\n",
      "RMSE, train 1.5292077044085148, test 1.3219836344403668\n",
      "RMSE, train 1.1882521256564125, test 1.0281153631604407\n",
      "RMSE, train 0.9248282952654746, test 0.8038685375993903\n",
      "RMSE, train 0.7259382003497693, test 0.6368923576410151\n",
      "RMSE, train 0.5790068623159201, test 0.515246508781575\n",
      "RMSE, train 0.47327227517962456, test 0.42923522340364695\n",
      "RMSE, train 0.399573465989482, test 0.37063051427691435\n",
      "RMSE, train 0.3503856211900711, test 0.3323391902545267\n",
      "RMSE, train 0.3188878744840622, test 0.30847359762704074\n",
      "RMSE, train 0.2995673149163204, test 0.29443073383540164\n",
      "RMSE, train 0.28821689545387225, test 0.2860965312512453\n",
      "RMSE, train 0.2815334550856102, test 0.28114122965119104\n",
      "RMSE, train 0.2771878091378077, test 0.27753165142595276\n",
      "RMSE, train 0.2738086756078466, test 0.2745806078526599\n",
      "RMSE, train 0.27088095400963097, test 0.27196375212886115\n",
      "RMSE, train 0.26830245629553834, test 0.26951627384039983\n",
      "RMSE, train 0.2660415559826839, test 0.26748724897538334\n",
      "RMSE, train 0.26410323883136433, test 0.265644837386352\n",
      "RMSE, train 0.262469875536138, test 0.26423856800745343\n",
      "RMSE, train 0.2610881918620679, test 0.26303967119248445\n",
      "RMSE, train 0.2599677000074617, test 0.2621969623752862\n",
      "RMSE, train 0.25909153155742154, test 0.26142878276257475\n",
      "RMSE, train 0.2583405540715302, test 0.2607779643259758\n",
      "RMSE, train 0.2577471266831121, test 0.2603153655351686\n",
      "RMSE, train 0.2573024593293667, test 0.2599529524233716\n",
      "RMSE, train 0.2568869254281444, test 0.25966664360574454\n",
      "RMSE, train 0.25661223546992384, test 0.2593923776356642\n",
      "RMSE, train 0.2564329642862562, test 0.2591565689764732\n",
      "RMSE, train 0.25621393154705724, test 0.25909087616057436\n",
      "RMSE, train 0.25611061299399984, test 0.25904498144614796\n",
      "RMSE, train 0.25595751395749466, test 0.25891075535746644\n",
      "RMSE, train 0.2558734462025665, test 0.2588510170948407\n",
      "RMSE, train 0.25585528706470806, test 0.25882263789492205\n",
      "RMSE, train 0.25575277515717093, test 0.2588005355320686\n",
      "RMSE, train 0.2557204495815019, test 0.25880946428322593\n",
      "RMSE, train 0.25567301567043027, test 0.25881723443831295\n",
      "RMSE, train 0.2556415049118861, test 0.25873308499489933\n",
      "RMSE, train 0.2556330911935337, test 0.25876342449799056\n",
      "RMSE, train 0.25566029915165517, test 0.2587908980521289\n",
      "RMSE, train 0.25559361906902445, test 0.2587700147520412\n",
      "RMSE, train 0.2556076847136982, test 0.2587762823528495\n",
      "RMSE, train 0.25556215136161736, test 0.25874431628333633\n",
      "RMSE, train 0.25560478226191574, test 0.2586850756702344\n",
      "RMSE, train 0.25558734174457287, test 0.2587412040341984\n",
      "RMSE, train 0.2555586637087887, test 0.2587713506842448\n",
      "RMSE, train 0.25556430334766067, test 0.2587648197885387\n",
      "RMSE, train 0.2555874607135211, test 0.25877549850251064\n",
      "RMSE, train 0.25556724476477793, test 0.25879279604135463\n",
      "RMSE, train 0.25557018738360177, test 0.2587500282309272\n",
      "RMSE, train 0.25557179052022194, test 0.25874473696405237\n",
      "RMSE, train 0.2555563754492229, test 0.258804127573967\n",
      "RMSE, train 0.2555811433121562, test 0.25888681731933405\n",
      "RMSE, train 0.2555567646519311, test 0.2588096704364808\n",
      "Early stopping at epoch 54 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.7017327920833895, test 0.541326735484398\n",
      "RMSE, train 0.46239689885338475, test 0.39435921255814826\n",
      "RMSE, train 0.3605923716071223, test 0.3320596815418389\n",
      "RMSE, train 0.31640392754319285, test 0.30456341159040645\n",
      "RMSE, train 0.2959606931968169, test 0.290922985112263\n",
      "RMSE, train 0.28482702497608403, test 0.2828003418142513\n",
      "RMSE, train 0.27739556490882367, test 0.2760230830665362\n",
      "RMSE, train 0.27142486779773534, test 0.2706659022024122\n",
      "RMSE, train 0.26615604481174926, test 0.2657588220248788\n",
      "RMSE, train 0.261530616620848, test 0.2617278003086478\n",
      "RMSE, train 0.25750411745191604, test 0.2579904912134348\n",
      "RMSE, train 0.2542952146104052, test 0.2550847627601381\n",
      "RMSE, train 0.25117051022604475, test 0.25241487687927183\n",
      "RMSE, train 0.24875424799224563, test 0.25018110656637255\n",
      "RMSE, train 0.24659842532897783, test 0.24841208023540043\n",
      "RMSE, train 0.24511501996600923, test 0.24705459329031282\n",
      "RMSE, train 0.24371094216615702, test 0.24599586477724172\n",
      "RMSE, train 0.24255119608946082, test 0.2450100461305198\n",
      "RMSE, train 0.24191400550367417, test 0.24429866608421683\n",
      "RMSE, train 0.24115154501204647, test 0.24378794254892963\n",
      "RMSE, train 0.24077951578685075, test 0.24340387092808546\n",
      "RMSE, train 0.24029256794447743, test 0.24320112471863375\n",
      "RMSE, train 0.23999669566011625, test 0.2428814690496962\n",
      "RMSE, train 0.23962056282753788, test 0.24264339774341906\n",
      "RMSE, train 0.23961781411747302, test 0.24251271708536956\n",
      "RMSE, train 0.23939905977569337, test 0.24220642662149364\n",
      "RMSE, train 0.2392753487037233, test 0.24224676570649875\n",
      "RMSE, train 0.23944793404503303, test 0.24227056728076127\n",
      "RMSE, train 0.2391156839006696, test 0.2423296851121773\n",
      "RMSE, train 0.2392149948445726, test 0.24225529712640634\n",
      "RMSE, train 0.23913459744581506, test 0.24219532298334576\n",
      "RMSE, train 0.2391125816882642, test 0.24209396035994513\n",
      "RMSE, train 0.23909774428803074, test 0.24217818134416969\n",
      "RMSE, train 0.23880617782350413, test 0.2420943931250249\n",
      "RMSE, train 0.23889177280270363, test 0.2422655058109154\n",
      "RMSE, train 0.2389567531953173, test 0.24207212119284321\n",
      "RMSE, train 0.23869471215019541, test 0.24214903858758635\n",
      "RMSE, train 0.2388437716983074, test 0.24217354885097278\n",
      "RMSE, train 0.23873730591875464, test 0.2422543937119387\n",
      "RMSE, train 0.23903219657372837, test 0.24211856735459827\n",
      "RMSE, train 0.23908713752450036, test 0.24208685743101574\n",
      "RMSE, train 0.23898545267783905, test 0.2421812475737879\n",
      "RMSE, train 0.23885920145048584, test 0.24218292218648782\n",
      "RMSE, train 0.23896955353908303, test 0.2421732227933609\n",
      "RMSE, train 0.2388737127492743, test 0.24219551076323298\n",
      "RMSE, train 0.23877737723475645, test 0.2422621788109763\n",
      "Early stopping at epoch 46 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.7463833729296209, test 0.5237424873879978\n",
      "RMSE, train 0.4331774662262993, test 0.37800183093973566\n",
      "RMSE, train 0.34728573873022284, test 0.3363437338599137\n",
      "RMSE, train 0.3179136357535983, test 0.3180899191647768\n",
      "RMSE, train 0.3022721432847395, test 0.3045382199010679\n",
      "RMSE, train 0.29068956619903674, test 0.2943772937038115\n",
      "RMSE, train 0.2812225968619577, test 0.2854003773203918\n",
      "RMSE, train 0.2734989807951165, test 0.2785639291895287\n",
      "RMSE, train 0.2667658076112307, test 0.27181733239974293\n",
      "RMSE, train 0.2614530520371622, test 0.2668366822014962\n",
      "RMSE, train 0.2565703002455967, test 0.2621253704918282\n",
      "RMSE, train 0.2524226171518463, test 0.25773149928344147\n",
      "RMSE, train 0.24884495934499895, test 0.25447201875171493\n",
      "RMSE, train 0.24610475192662157, test 0.2516844818102462\n",
      "RMSE, train 0.24368051814487557, test 0.2491720419909273\n",
      "RMSE, train 0.2415869435648513, test 0.24766084924340248\n",
      "RMSE, train 0.24021313019697443, test 0.2458059662686927\n",
      "RMSE, train 0.23881999768462836, test 0.24451845698058605\n",
      "RMSE, train 0.23795565115470513, test 0.24389613419771194\n",
      "RMSE, train 0.23719831580430076, test 0.2425904210124697\n",
      "RMSE, train 0.23638768198703108, test 0.24235175882599183\n",
      "RMSE, train 0.23595618234220933, test 0.24184838389711721\n",
      "RMSE, train 0.23564615608690093, test 0.24154544368918454\n",
      "RMSE, train 0.23537750944722452, test 0.2412150748340147\n",
      "RMSE, train 0.2350326198638135, test 0.24081384044672763\n",
      "RMSE, train 0.23489508951541385, test 0.24068961359028304\n",
      "RMSE, train 0.23472287591895766, test 0.2404070392783199\n",
      "RMSE, train 0.23458675631121093, test 0.24060811674488441\n",
      "RMSE, train 0.23461579312296474, test 0.24013561396194355\n",
      "RMSE, train 0.2344249059367024, test 0.24033314628260477\n",
      "RMSE, train 0.23444920099768504, test 0.24044964941484587\n",
      "RMSE, train 0.23428193030144395, test 0.24048802363021032\n",
      "RMSE, train 0.2342477352855512, test 0.23996942769736052\n",
      "RMSE, train 0.23436316445242605, test 0.2401021502113768\n",
      "RMSE, train 0.23425492968954031, test 0.2397337533267481\n",
      "RMSE, train 0.2343069343200696, test 0.239875311697168\n",
      "RMSE, train 0.23429262371883933, test 0.23958606086671352\n",
      "RMSE, train 0.23424040969290766, test 0.24016240172620332\n",
      "RMSE, train 0.23429826233122084, test 0.23999002908489533\n",
      "RMSE, train 0.2343566223881603, test 0.23992689313100918\n",
      "RMSE, train 0.23417542917016804, test 0.24005332442798785\n",
      "RMSE, train 0.2342041130289273, test 0.23998224189771072\n",
      "RMSE, train 0.23430674849382413, test 0.23966179096273013\n",
      "RMSE, train 0.23421031239895, test 0.2396610855524029\n",
      "RMSE, train 0.2343540297159702, test 0.23997895220028503\n",
      "RMSE, train 0.23414557925496485, test 0.23975170802857196\n",
      "RMSE, train 0.23417552815413423, test 0.24008365081889288\n",
      "Early stopping at epoch 47 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.6957643555982772, test 0.45095358352468473\n",
      "RMSE, train 0.39245401552370535, test 0.36839889486630756\n",
      "RMSE, train 0.3382224277718434, test 0.33221215280619537\n",
      "RMSE, train 0.3077434093707348, test 0.3085668377503\n",
      "RMSE, train 0.2888275215124443, test 0.2935985815946502\n",
      "RMSE, train 0.276873296149494, test 0.28363006975915694\n",
      "RMSE, train 0.2684073212094295, test 0.2760111192862193\n",
      "RMSE, train 0.2620092607069132, test 0.27024447345974467\n",
      "RMSE, train 0.2570006569760936, test 0.26528260247273877\n",
      "RMSE, train 0.2525873657835142, test 0.26074644095367855\n",
      "RMSE, train 0.24898496332116116, test 0.2573714971241325\n",
      "RMSE, train 0.24594785666553198, test 0.2542099826263659\n",
      "RMSE, train 0.24302540985471172, test 0.25131547616587746\n",
      "RMSE, train 0.24113837416422687, test 0.24920997670804612\n",
      "RMSE, train 0.2391690035831083, test 0.24710585101686341\n",
      "RMSE, train 0.23768386940647163, test 0.24562287601557645\n",
      "RMSE, train 0.23654780633437897, test 0.24431835024645834\n",
      "RMSE, train 0.23537368114245258, test 0.2438141033805982\n",
      "RMSE, train 0.23465201207652944, test 0.24272549197529303\n",
      "RMSE, train 0.23409647878924325, test 0.2421894067465657\n",
      "RMSE, train 0.23353841948188606, test 0.24176985145819307\n",
      "RMSE, train 0.23317674724134665, test 0.24098772051358464\n",
      "RMSE, train 0.23276884715393878, test 0.24095093782501992\n",
      "RMSE, train 0.2325813283182881, test 0.24058678400034855\n",
      "RMSE, train 0.23234377491736471, test 0.24030968005006964\n",
      "RMSE, train 0.2323996106249196, test 0.24001819467303728\n",
      "RMSE, train 0.23209756539911397, test 0.24016949654829622\n",
      "RMSE, train 0.23208504350523493, test 0.2399051743324357\n",
      "RMSE, train 0.23193068838789876, test 0.23982263529541517\n",
      "RMSE, train 0.2318637271600714, test 0.23953955342071226\n",
      "RMSE, train 0.2319402459708286, test 0.23950692349010044\n",
      "RMSE, train 0.23170594393769803, test 0.23947780722319478\n",
      "RMSE, train 0.23173076278714505, test 0.23953970183025708\n",
      "RMSE, train 0.23163348858980212, test 0.2397729986243778\n",
      "RMSE, train 0.23161727448693115, test 0.2392715101290231\n",
      "RMSE, train 0.23176453377331965, test 0.2394731001119421\n",
      "RMSE, train 0.23168573155088354, test 0.2393396319162966\n",
      "RMSE, train 0.23174990498640718, test 0.23942626546127627\n",
      "RMSE, train 0.23186152160604892, test 0.2393480959263715\n",
      "RMSE, train 0.23151698136533677, test 0.2398060021376369\n",
      "RMSE, train 0.23196562184681227, test 0.2393307008526542\n",
      "RMSE, train 0.2315967413061697, test 0.2393286782081681\n",
      "RMSE, train 0.23150853546732503, test 0.23922778997156355\n",
      "RMSE, train 0.23164544263649686, test 0.23937686058607968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2317171658601038, test 0.23916686484307953\n",
      "RMSE, train 0.2317454716541365, test 0.2395437943814981\n",
      "RMSE, train 0.2316940250854329, test 0.23924273312693894\n",
      "RMSE, train 0.23155200794739944, test 0.23933710037457823\n",
      "RMSE, train 0.23157533230874824, test 0.2392803429052083\n",
      "RMSE, train 0.23155573724534517, test 0.23916462078841047\n",
      "RMSE, train 0.2316147608541335, test 0.23928759660985735\n",
      "RMSE, train 0.23154457704070727, test 0.23936637287790125\n",
      "RMSE, train 0.23161672937403682, test 0.23921500808662838\n",
      "RMSE, train 0.23164698791241586, test 0.23926472257484088\n",
      "RMSE, train 0.23145901522892903, test 0.2392836870870205\n",
      "RMSE, train 0.2315869503324364, test 0.2392964462439219\n",
      "RMSE, train 0.23156325001734102, test 0.23916664418548045\n",
      "RMSE, train 0.23162393694547687, test 0.23911496364709103\n",
      "RMSE, train 0.23168131282830878, test 0.23941467672285408\n",
      "RMSE, train 0.2316207291153066, test 0.2392942387648303\n",
      "RMSE, train 0.23158742676882987, test 0.23925127962020912\n",
      "RMSE, train 0.23169618141826032, test 0.23927081820338664\n",
      "RMSE, train 0.23155819961669102, test 0.239423220657339\n",
      "RMSE, train 0.23163312345670314, test 0.2393217616611057\n",
      "RMSE, train 0.23148594432325992, test 0.23934343141136746\n",
      "RMSE, train 0.23155484758408554, test 0.23923950123064447\n",
      "RMSE, train 0.23155255029137387, test 0.23921307635427724\n",
      "RMSE, train 0.23151202514439748, test 0.23943484461668765\n",
      "Early stopping at epoch 68 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.3160473119375133, test 1.1544765496658067\n",
      "RMSE, train 1.0272866320018925, test 0.9075864482734163\n",
      "RMSE, train 0.8124040197734991, test 0.7258078460976228\n",
      "RMSE, train 0.6552484996678415, test 0.5929888529797732\n",
      "RMSE, train 0.5409722763521612, test 0.4976877572677903\n",
      "RMSE, train 0.45937968722798606, test 0.43017020594265504\n",
      "RMSE, train 0.4022300344976512, test 0.38361378948567276\n",
      "RMSE, train 0.36330479654398834, test 0.35161910622806875\n",
      "RMSE, train 0.33622414883503243, test 0.330075395561881\n",
      "RMSE, train 0.31838013404164434, test 0.31549893092300935\n",
      "RMSE, train 0.30627366158464725, test 0.3057934513031426\n",
      "RMSE, train 0.2980697689778056, test 0.29870708135225005\n",
      "RMSE, train 0.29228875709097246, test 0.2933195849596444\n",
      "RMSE, train 0.28732477978241344, test 0.2888733975715556\n",
      "RMSE, train 0.28336132422459026, test 0.28508915575379035\n",
      "RMSE, train 0.2801048643271293, test 0.28162746396610294\n",
      "RMSE, train 0.2768807532496689, test 0.27864355038283234\n",
      "RMSE, train 0.27432140363149404, test 0.2760581948747069\n",
      "RMSE, train 0.27219922905249044, test 0.27383929086943803\n",
      "RMSE, train 0.27021027861301566, test 0.27224154164225367\n",
      "RMSE, train 0.2687804643218675, test 0.27084935860613646\n",
      "RMSE, train 0.2675107417027812, test 0.2694224808680809\n",
      "RMSE, train 0.2663426952174872, test 0.26848627487986776\n",
      "RMSE, train 0.2656184437661624, test 0.26762237336676\n",
      "RMSE, train 0.26488263889654606, test 0.26702429013232054\n",
      "RMSE, train 0.26429873033742274, test 0.2664200400902053\n",
      "RMSE, train 0.2639231119027808, test 0.266140728810076\n",
      "RMSE, train 0.2634492148914613, test 0.2655652447019593\n",
      "RMSE, train 0.26331432366913016, test 0.2654723804128372\n",
      "RMSE, train 0.26287921982978985, test 0.2652405769390575\n",
      "RMSE, train 0.26282889556047345, test 0.2649275040474989\n",
      "RMSE, train 0.2626611603316197, test 0.26494874603162377\n",
      "RMSE, train 0.26243959401141514, test 0.2647577116297463\n",
      "RMSE, train 0.2623966798063152, test 0.2646984204144801\n",
      "RMSE, train 0.2624164605128371, test 0.26463228691432433\n",
      "RMSE, train 0.2624524655359343, test 0.264496386177459\n",
      "RMSE, train 0.2622288557246697, test 0.2645069130901563\n",
      "RMSE, train 0.2623761494543927, test 0.26439119761778135\n",
      "RMSE, train 0.26243691820620507, test 0.26432529432793794\n",
      "RMSE, train 0.2623610027627019, test 0.26446601344367204\n",
      "RMSE, train 0.2623881922403643, test 0.2643663042177588\n",
      "RMSE, train 0.2622952310075937, test 0.2643116953766952\n",
      "RMSE, train 0.2622076345930907, test 0.2643871045971321\n",
      "RMSE, train 0.2623316322353261, test 0.26437562805111126\n",
      "RMSE, train 0.2622585346814522, test 0.2644090063996234\n",
      "RMSE, train 0.26233233379061555, test 0.2643754176669202\n",
      "RMSE, train 0.26230898638032685, test 0.2643903745180469\n",
      "RMSE, train 0.262233693676054, test 0.2643374468562967\n",
      "RMSE, train 0.26214662542151024, test 0.26430610428422185\n",
      "RMSE, train 0.2620798637859585, test 0.26432614811396193\n",
      "RMSE, train 0.2622091785873756, test 0.26447254836054174\n",
      "RMSE, train 0.2621033975839122, test 0.26436224718720225\n",
      "RMSE, train 0.26219060453624765, test 0.2644247503603919\n",
      "RMSE, train 0.2622621766915006, test 0.26438173853744895\n",
      "RMSE, train 0.2622852486458199, test 0.26436987961247815\n",
      "RMSE, train 0.2621353977967885, test 0.2642608987072767\n",
      "RMSE, train 0.2621023005013131, test 0.2644121732752202\n",
      "RMSE, train 0.26221570083178763, test 0.2644213968414371\n",
      "RMSE, train 0.26235363595495537, test 0.2643673899820295\n",
      "RMSE, train 0.26206195499163026, test 0.26432715217440816\n",
      "RMSE, train 0.26218736959883004, test 0.26441643513360263\n",
      "RMSE, train 0.26214084007646427, test 0.2643181482108973\n",
      "RMSE, train 0.262181215480832, test 0.26444446926904935\n",
      "RMSE, train 0.26208461454707727, test 0.2643803778593823\n",
      "RMSE, train 0.26216985257573366, test 0.26434492521871955\n",
      "RMSE, train 0.26220269547390546, test 0.2644231484855636\n",
      "Early stopping at epoch 66 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9214887209632088, test 0.7045945499254309\n",
      "RMSE, train 0.5763313288774713, test 0.4721710396849591\n",
      "RMSE, train 0.4126721185230652, test 0.368371412805889\n",
      "RMSE, train 0.34165772896916496, test 0.3255166110785111\n",
      "RMSE, train 0.31207577469748804, test 0.3077149461144986\n",
      "RMSE, train 0.29882363424559305, test 0.298849105446235\n",
      "RMSE, train 0.2910055278656083, test 0.29195328808349114\n",
      "RMSE, train 0.28485474664314536, test 0.28637095288090086\n",
      "RMSE, train 0.2792855888731667, test 0.2807914021222488\n",
      "RMSE, train 0.274155856507599, test 0.2757986524830694\n",
      "RMSE, train 0.2695159985191503, test 0.2712961430134981\n",
      "RMSE, train 0.2653356222969711, test 0.26734867432843085\n",
      "RMSE, train 0.26170717021588813, test 0.26397802337356235\n",
      "RMSE, train 0.2585619520989193, test 0.26122785495675127\n",
      "RMSE, train 0.2559231109363511, test 0.25867457947005396\n",
      "RMSE, train 0.2537219865749849, test 0.25642849491990133\n",
      "RMSE, train 0.2519581073661772, test 0.25509867940260017\n",
      "RMSE, train 0.2505125795073823, test 0.2534006020297175\n",
      "RMSE, train 0.24938316649565526, test 0.2524403118568918\n",
      "RMSE, train 0.24847195409791992, test 0.2517790991327037\n",
      "RMSE, train 0.24773475821990115, test 0.2510807665793792\n",
      "RMSE, train 0.24717152507821466, test 0.2506215124026589\n",
      "RMSE, train 0.2467140785701209, test 0.2498781003381895\n",
      "RMSE, train 0.24637331919558741, test 0.2497231714103533\n",
      "RMSE, train 0.24608589734114913, test 0.24949947180955306\n",
      "RMSE, train 0.2458761067084193, test 0.24941088285135185\n",
      "RMSE, train 0.24572794667727882, test 0.24907379785309666\n",
      "RMSE, train 0.24560609349146517, test 0.24894004878790482\n",
      "RMSE, train 0.24545739679706072, test 0.24916658906832986\n",
      "RMSE, train 0.2454109968589876, test 0.24927630515202231\n",
      "RMSE, train 0.24533923359433557, test 0.24892443910889003\n",
      "RMSE, train 0.24527651394248767, test 0.24889064560765806\n",
      "RMSE, train 0.2452413882989033, test 0.24892763819383537\n",
      "RMSE, train 0.24522763190122673, test 0.24872509396594503\n",
      "RMSE, train 0.24520519635226823, test 0.24863938598529153\n",
      "RMSE, train 0.24519072191477329, test 0.2487997881744219\n",
      "RMSE, train 0.2451825444675555, test 0.24868552607038746\n",
      "RMSE, train 0.24516114950053505, test 0.24865322501763054\n",
      "RMSE, train 0.24515078895410913, test 0.2488133078036101\n",
      "RMSE, train 0.2451632150355924, test 0.2489126495693041\n",
      "RMSE, train 0.24513406564349075, test 0.24865659993627798\n",
      "RMSE, train 0.2451207825395965, test 0.24865224568740182\n",
      "RMSE, train 0.24513832709085662, test 0.2489593012177426\n",
      "RMSE, train 0.24511552976954515, test 0.2488035395093586\n",
      "RMSE, train 0.24511259095051233, test 0.24865342495234116\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 1.346474123909869, test 0.9495423627555917\n",
      "RMSE, train 0.7461627192561402, test 0.5755128606196938\n",
      "RMSE, train 0.49197081807215653, test 0.42063998082362186\n",
      "RMSE, train 0.38260258119469803, test 0.35501520704785616\n",
      "RMSE, train 0.3318772702540517, test 0.32087833673582167\n",
      "RMSE, train 0.30607440406164244, test 0.30295561295036877\n",
      "RMSE, train 0.2912732734608009, test 0.29208640098024946\n",
      "RMSE, train 0.2812995419507604, test 0.2835421379006237\n",
      "RMSE, train 0.27372827701638097, test 0.2774285419818458\n",
      "RMSE, train 0.2676632280707894, test 0.27266306026813086\n",
      "RMSE, train 0.2627639035807062, test 0.2677673776762201\n",
      "RMSE, train 0.2586834942212019, test 0.26457214095723736\n",
      "RMSE, train 0.2553107568100429, test 0.26118674669243874\n",
      "RMSE, train 0.2524832782456693, test 0.2584958955508853\n",
      "RMSE, train 0.2501466535532956, test 0.2567092919841819\n",
      "RMSE, train 0.24813462944175096, test 0.2543385505949685\n",
      "RMSE, train 0.24650655954140718, test 0.2535027579976878\n",
      "RMSE, train 0.24518680278495822, test 0.2520565078892839\n",
      "RMSE, train 0.2441142964857576, test 0.2504770684679714\n",
      "RMSE, train 0.2432551536993061, test 0.24989175400055877\n",
      "RMSE, train 0.2425105523301347, test 0.2494942673029156\n",
      "RMSE, train 0.24197805883371243, test 0.2489529548708452\n",
      "RMSE, train 0.24155258821665973, test 0.2480621635913849\n",
      "RMSE, train 0.24120820567613224, test 0.24778975806105027\n",
      "RMSE, train 0.24092241283088522, test 0.24707481415446744\n",
      "RMSE, train 0.24071530396360988, test 0.24743082886988962\n",
      "RMSE, train 0.24056163370074712, test 0.2471585314755046\n",
      "RMSE, train 0.24040920173774386, test 0.24749691442612115\n",
      "RMSE, train 0.2403285169280698, test 0.2478241857585557\n",
      "RMSE, train 0.2402387375321089, test 0.24725847438387916\n",
      "RMSE, train 0.24017799809374618, test 0.24674465787520103\n",
      "RMSE, train 0.24014993175663757, test 0.24716152770256777\n",
      "RMSE, train 0.2400976983421052, test 0.2469233780279072\n",
      "RMSE, train 0.24005930008775986, test 0.2472352244711797\n",
      "RMSE, train 0.2400563443121354, test 0.24658320133292347\n",
      "RMSE, train 0.2400198597544512, test 0.24658551812171936\n",
      "RMSE, train 0.24001057195422895, test 0.24681480256242488\n",
      "RMSE, train 0.24000791233083058, test 0.2473705972826809\n",
      "RMSE, train 0.23995661134142512, test 0.24649713195245201\n",
      "RMSE, train 0.2399620524035441, test 0.2468453525403224\n",
      "RMSE, train 0.23998938430718778, test 0.24683132781348097\n",
      "RMSE, train 0.2399476035226621, test 0.2468765525642885\n",
      "RMSE, train 0.23994134085862626, test 0.24672239130243248\n",
      "RMSE, train 0.23998996545247434, test 0.24675542389580962\n",
      "RMSE, train 0.23998484837367395, test 0.24735121647699163\n",
      "RMSE, train 0.23997656252619398, test 0.2466818857083627\n",
      "RMSE, train 0.23998065226013884, test 0.24647131931344304\n",
      "RMSE, train 0.23997479804160884, test 0.24683237267196725\n",
      "RMSE, train 0.23994665516064306, test 0.24698683428108145\n",
      "RMSE, train 0.23995780370160602, test 0.24681777103778418\n",
      "RMSE, train 0.23996395878326732, test 0.24658150478787377\n",
      "RMSE, train 0.2399599173277483, test 0.24720936125024742\n",
      "RMSE, train 0.2399547765941898, test 0.24673556228843305\n",
      "RMSE, train 0.2399707880923566, test 0.24703134692043338\n",
      "RMSE, train 0.23995187090116765, test 0.2467502397955011\n",
      "RMSE, train 0.2399611163366536, test 0.24659570996914434\n",
      "RMSE, train 0.2399869720230188, test 0.24713414292269892\n",
      "Early stopping at epoch 57 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.830486862647413, test 0.522807628226777\n",
      "RMSE, train 0.42911459121740225, test 0.38011544818679494\n",
      "RMSE, train 0.35109736966063276, test 0.34140707459300756\n",
      "RMSE, train 0.3201182456781166, test 0.3182858405634761\n",
      "RMSE, train 0.3004613806201954, test 0.3025292553938925\n",
      "RMSE, train 0.2871584611182863, test 0.2916261302307248\n",
      "RMSE, train 0.27778536412451005, test 0.28353733957434696\n",
      "RMSE, train 0.27071842622726855, test 0.27690428774803877\n",
      "RMSE, train 0.2651981368209376, test 0.2719564003249009\n",
      "RMSE, train 0.26058777888314894, test 0.26743850639710826\n",
      "RMSE, train 0.25666845785547987, test 0.2635206279034416\n",
      "RMSE, train 0.25325226746123247, test 0.2606769635652502\n",
      "RMSE, train 0.25039606334434616, test 0.25752909124518436\n",
      "RMSE, train 0.2479371524820424, test 0.2556213974021375\n",
      "RMSE, train 0.24588481148686073, test 0.2532937865083416\n",
      "RMSE, train 0.24419404189996044, test 0.2518835059988002\n",
      "RMSE, train 0.2427722148672499, test 0.2503788936883211\n",
      "RMSE, train 0.24164001572162214, test 0.2494566993167003\n",
      "RMSE, train 0.24069568815857473, test 0.24852050701156259\n",
      "RMSE, train 0.23996126143769783, test 0.24784153187647462\n",
      "RMSE, train 0.23932163131357442, test 0.24708214635029435\n",
      "RMSE, train 0.23888314718549902, test 0.24691218044608831\n",
      "RMSE, train 0.23848101985876005, test 0.24632791383191943\n",
      "RMSE, train 0.2381586002731564, test 0.24611916424085697\n",
      "RMSE, train 0.23786138220116346, test 0.24605644323552647\n",
      "RMSE, train 0.23770870147931455, test 0.24558217326800028\n",
      "RMSE, train 0.23756404074304033, test 0.2454714550015827\n",
      "RMSE, train 0.23744563069758992, test 0.24545010489722094\n",
      "RMSE, train 0.2372512531400931, test 0.24574989515046278\n",
      "RMSE, train 0.2372336776343861, test 0.24519821318487325\n",
      "RMSE, train 0.2371756314403481, test 0.2454176894389093\n",
      "RMSE, train 0.23714212023399092, test 0.24509942283233008\n",
      "RMSE, train 0.23708097076024673, test 0.24519373973210654\n",
      "RMSE, train 0.23705687430320363, test 0.24512939900159836\n",
      "RMSE, train 0.23696909656729362, test 0.24521993535260359\n",
      "RMSE, train 0.2369739737625074, test 0.24532093542317548\n",
      "RMSE, train 0.23697619862628705, test 0.24509115517139435\n",
      "RMSE, train 0.23699410225857387, test 0.2454514430525402\n",
      "RMSE, train 0.23693915565658097, test 0.24494562965507308\n",
      "RMSE, train 0.2369378570354346, test 0.2450756817124784\n",
      "RMSE, train 0.23691673129044397, test 0.24528172689800462\n",
      "RMSE, train 0.2369425519924573, test 0.24494576314464211\n",
      "RMSE, train 0.23692631190924934, test 0.24516606843098998\n",
      "RMSE, train 0.23696483603932642, test 0.2449487017778059\n",
      "RMSE, train 0.2368967445059256, test 0.24507742173348865\n",
      "RMSE, train 0.23693034289912743, test 0.24523571397488317\n",
      "RMSE, train 0.23690129733747906, test 0.2449837027428051\n",
      "RMSE, train 0.23690419143649064, test 0.24496439347664514\n",
      "RMSE, train 0.23688583060948534, test 0.24515067071964344\n",
      "Early stopping at epoch 49 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.906458417444707, test 0.812733133988721\n",
      "RMSE, train 0.734941908087346, test 0.6656529347279242\n",
      "RMSE, train 0.6121150518164915, test 0.5631687808781862\n",
      "RMSE, train 0.5254594478472125, test 0.49027950236839907\n",
      "RMSE, train 0.4629956809783553, test 0.4384776015899011\n",
      "RMSE, train 0.4182087383628671, test 0.4017903158175094\n",
      "RMSE, train 0.38575091740534456, test 0.3743958209774324\n",
      "RMSE, train 0.36236991056429796, test 0.35480720416775774\n",
      "RMSE, train 0.34426431406557173, test 0.3402516370905297\n",
      "RMSE, train 0.33081669264629254, test 0.32876918917255743\n",
      "RMSE, train 0.32032746927151234, test 0.31989695584135397\n",
      "RMSE, train 0.3118671327504717, test 0.3128575451139893\n",
      "RMSE, train 0.30518038242990414, test 0.3068766106984445\n",
      "RMSE, train 0.2997446311779791, test 0.30239257336195025\n",
      "RMSE, train 0.29520265251592875, test 0.29781318083405495\n",
      "RMSE, train 0.2913092497517081, test 0.29478796465056284\n",
      "RMSE, train 0.2883188644330746, test 0.29204916142459425\n",
      "RMSE, train 0.28588258142305095, test 0.2896194262430072\n",
      "RMSE, train 0.2836772542698451, test 0.2878260909180556\n",
      "RMSE, train 0.2821774936254767, test 0.2868715138839824\n",
      "RMSE, train 0.28076398246038975, test 0.2851324662832277\n",
      "RMSE, train 0.27960245256070737, test 0.2842394486069679\n",
      "RMSE, train 0.2789333935396863, test 0.2835649214684963\n",
      "RMSE, train 0.27809222078271423, test 0.2827371091448835\n",
      "RMSE, train 0.2776270652583482, test 0.28278438840061426\n",
      "RMSE, train 0.277136174194953, test 0.2819936150418861\n",
      "RMSE, train 0.2769906969501562, test 0.28159732225217987\n",
      "RMSE, train 0.27652916328449917, test 0.28137849803481785\n",
      "RMSE, train 0.2764009361628094, test 0.2809534410813025\n",
      "RMSE, train 0.27623513922062837, test 0.2811094183208687\n",
      "RMSE, train 0.27607147437814533, test 0.28097145086420433\n",
      "RMSE, train 0.27581691777654205, test 0.28091988393238615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27574468451128026, test 0.2810112577197807\n",
      "RMSE, train 0.2758015583802932, test 0.280651275866798\n",
      "RMSE, train 0.2756750885892278, test 0.28073408800576416\n",
      "RMSE, train 0.27587480693730915, test 0.28048746793397833\n",
      "RMSE, train 0.2759426123501169, test 0.2803922826424241\n",
      "RMSE, train 0.27557666008898374, test 0.2806117430861507\n",
      "RMSE, train 0.27555411940436475, test 0.28063633958143847\n",
      "RMSE, train 0.2755159936958928, test 0.28032923276935307\n",
      "RMSE, train 0.2754754162432062, test 0.28093815954136\n",
      "RMSE, train 0.275655668577857, test 0.2805651941203645\n",
      "RMSE, train 0.2754640824329879, test 0.2804691070424659\n",
      "RMSE, train 0.2756062005859575, test 0.2806242193494524\n",
      "RMSE, train 0.2755868146622103, test 0.28029616735875607\n",
      "RMSE, train 0.27555382469251005, test 0.28055884768920286\n",
      "RMSE, train 0.2757389062045706, test 0.28049151240182774\n",
      "RMSE, train 0.27553541016864364, test 0.28107403178832363\n",
      "RMSE, train 0.2753971956004764, test 0.2802528411682163\n",
      "RMSE, train 0.2754585428045726, test 0.28032581840774845\n",
      "RMSE, train 0.27548689234490487, test 0.28039820678532124\n",
      "RMSE, train 0.2755207687551419, test 0.28077494725584984\n",
      "RMSE, train 0.2755713533277345, test 0.280473436361977\n",
      "RMSE, train 0.27541418360598985, test 0.2805067542940378\n",
      "RMSE, train 0.2755076048615711, test 0.28045107956443516\n",
      "RMSE, train 0.2756248668712728, test 0.2803719524028046\n",
      "RMSE, train 0.2755445273743216, test 0.2803610782804234\n",
      "RMSE, train 0.27550053713368433, test 0.2806805138077055\n",
      "RMSE, train 0.27540879493705067, test 0.2804923749395779\n",
      "Early stopping at epoch 59 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9123567973551728, test 0.7482943157537267\n",
      "RMSE, train 0.6432026406173749, test 0.5532730090508767\n",
      "RMSE, train 0.4968932148052438, test 0.4468677970794363\n",
      "RMSE, train 0.41454934051485876, test 0.38712705986215434\n",
      "RMSE, train 0.36705561389837565, test 0.3530023026903835\n",
      "RMSE, train 0.3385358093966283, test 0.33141756932669825\n",
      "RMSE, train 0.32015369331355586, test 0.3177652060985565\n",
      "RMSE, train 0.30750695422224933, test 0.3079128213431857\n",
      "RMSE, train 0.29805877848190043, test 0.3000644970377651\n",
      "RMSE, train 0.29071295949642967, test 0.2940230131696124\n",
      "RMSE, train 0.2846943870721377, test 0.2885981221264655\n",
      "RMSE, train 0.27970747736537405, test 0.28433730282367914\n",
      "RMSE, train 0.2755463333474681, test 0.28089255996800344\n",
      "RMSE, train 0.2720636745806232, test 0.2774675035968833\n",
      "RMSE, train 0.26919654178779756, test 0.27501973318397455\n",
      "RMSE, train 0.2668290780063702, test 0.27403822021746854\n",
      "RMSE, train 0.26492049605188883, test 0.2715129890573134\n",
      "RMSE, train 0.26334602298891596, test 0.2699491717946639\n",
      "RMSE, train 0.262064790578701, test 0.26916512477835386\n",
      "RMSE, train 0.26109237771798677, test 0.26865008733141316\n",
      "RMSE, train 0.2602643975695687, test 0.2674209374353426\n",
      "RMSE, train 0.2596184577241607, test 0.2671635283516088\n",
      "RMSE, train 0.2590870049702747, test 0.2666911767163408\n",
      "RMSE, train 0.2586732846872689, test 0.2659322940701738\n",
      "RMSE, train 0.2583563098257967, test 0.26597302687277485\n",
      "RMSE, train 0.2580918339269044, test 0.2658545808234346\n",
      "RMSE, train 0.2578712502335754, test 0.2652833214320174\n",
      "RMSE, train 0.25774633810926445, test 0.2653077957006769\n",
      "RMSE, train 0.2575925361415196, test 0.2654984656277053\n",
      "RMSE, train 0.25749591039702496, test 0.26524628425410035\n",
      "RMSE, train 0.25743690433790867, test 0.26553261416767715\n",
      "RMSE, train 0.257358118891716, test 0.2648394519309385\n",
      "RMSE, train 0.25731975234410154, test 0.26534978881341603\n",
      "RMSE, train 0.2572750639621452, test 0.2649690653752843\n",
      "RMSE, train 0.25724357236260254, test 0.2648775838657257\n",
      "RMSE, train 0.25721493159575315, test 0.2651343736626686\n",
      "RMSE, train 0.25718437836843755, test 0.26473321553763995\n",
      "RMSE, train 0.2572045120757257, test 0.26492295612435823\n",
      "RMSE, train 0.25717194064315657, test 0.26502883365941704\n",
      "RMSE, train 0.2571698203348793, test 0.26512692677318506\n",
      "RMSE, train 0.25714750982186185, test 0.26478450328385067\n",
      "RMSE, train 0.25714118715225315, test 0.26505171787848164\n",
      "RMSE, train 0.2571268955020092, test 0.26525188709070924\n",
      "RMSE, train 0.25715948784966103, test 0.264916951093105\n",
      "RMSE, train 0.25717619676226455, test 0.26495141488149626\n",
      "RMSE, train 0.2571514068096208, test 0.26485330454253275\n",
      "RMSE, train 0.25717114216142706, test 0.26494830190588575\n",
      "Early stopping at epoch 47 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8154938253540891, test 0.5910387371928947\n",
      "RMSE, train 0.4928349396678444, test 0.4280547870015635\n",
      "RMSE, train 0.39643219467296736, test 0.3823355876126336\n",
      "RMSE, train 0.35997720958218155, test 0.3583683111135242\n",
      "RMSE, train 0.3392654153343618, test 0.3395132425340634\n",
      "RMSE, train 0.3236403360502737, test 0.32567508475294393\n",
      "RMSE, train 0.3108636234973219, test 0.3143648516784594\n",
      "RMSE, train 0.3001809391655435, test 0.3046234509030592\n",
      "RMSE, train 0.29118542160812294, test 0.2971959442478939\n",
      "RMSE, train 0.2837440061455951, test 0.2908074369708311\n",
      "RMSE, train 0.27754297537503503, test 0.2857346128202179\n",
      "RMSE, train 0.272472890177985, test 0.2811529290618248\n",
      "RMSE, train 0.26830384793587364, test 0.2774129087485156\n",
      "RMSE, train 0.2649236914310206, test 0.2765113857475299\n",
      "RMSE, train 0.262204692723349, test 0.27218664329028824\n",
      "RMSE, train 0.2600158127356595, test 0.2699155312718697\n",
      "RMSE, train 0.25825448036901744, test 0.26921211689421276\n",
      "RMSE, train 0.2569110975766692, test 0.26653184546428976\n",
      "RMSE, train 0.25579919005941043, test 0.2667004163693456\n",
      "RMSE, train 0.25493422950531697, test 0.2658333321219509\n",
      "RMSE, train 0.2542798497189819, test 0.2647833348188585\n",
      "RMSE, train 0.2537234490670954, test 0.2649068165461994\n",
      "RMSE, train 0.2533040969785206, test 0.2633575672663531\n",
      "RMSE, train 0.25291497931061335, test 0.2638718870658319\n",
      "RMSE, train 0.2526803778002211, test 0.26279866217988207\n",
      "RMSE, train 0.25246436327625055, test 0.2637380740596253\n",
      "RMSE, train 0.25231606093834813, test 0.2624716391262499\n",
      "RMSE, train 0.2521828060478609, test 0.2630347148017976\n",
      "RMSE, train 0.25207055400782696, test 0.2632955775677579\n",
      "RMSE, train 0.2519674542539193, test 0.2627223113786827\n",
      "RMSE, train 0.2519243327356574, test 0.26292950175340896\n",
      "RMSE, train 0.2518812979697615, test 0.26317490261156584\n",
      "RMSE, train 0.251853861994245, test 0.26315864602338923\n",
      "RMSE, train 0.2517813363083751, test 0.2629895848267287\n",
      "RMSE, train 0.25179661074188714, test 0.2625228562980022\n",
      "RMSE, train 0.2517444633673036, test 0.263077271216124\n",
      "RMSE, train 0.25175100409220064, test 0.2621696767876449\n",
      "RMSE, train 0.2517443039142604, test 0.2621206301219255\n",
      "RMSE, train 0.25170846230343796, test 0.2623482070212225\n",
      "RMSE, train 0.25169189274311066, test 0.26343299130212916\n",
      "RMSE, train 0.2517095358949376, test 0.2622130442302204\n",
      "RMSE, train 0.25174148879821395, test 0.26193600155196145\n",
      "RMSE, train 0.2516921286132726, test 0.2627134747007518\n",
      "RMSE, train 0.25169999989506187, test 0.2631622425560812\n",
      "RMSE, train 0.25170400052059294, test 0.2630005067991979\n",
      "RMSE, train 0.2516967345232635, test 0.26265810068371226\n",
      "RMSE, train 0.25171736611889545, test 0.2626431512022481\n",
      "RMSE, train 0.25165623645884405, test 0.2631193467424911\n",
      "RMSE, train 0.2516970997609888, test 0.2617602323733487\n",
      "RMSE, train 0.2516886274421017, test 0.26253185587600597\n",
      "RMSE, train 0.2516822868033429, test 0.26245124609146303\n",
      "RMSE, train 0.2517013406810171, test 0.2633178030113572\n",
      "RMSE, train 0.25168664392411283, test 0.26268084260445196\n",
      "RMSE, train 0.2516740433464707, test 0.2636572102319847\n",
      "RMSE, train 0.25169391664643187, test 0.26301980177754336\n",
      "RMSE, train 0.2516875153057932, test 0.26291272709670577\n",
      "RMSE, train 0.25169721291778774, test 0.26299245235989394\n",
      "RMSE, train 0.251699817683238, test 0.26338480441894346\n",
      "RMSE, train 0.25167666549071, test 0.2618675726710014\n",
      "Early stopping at epoch 59 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.7177568621069916, test 0.513260433740086\n",
      "RMSE, train 0.4481432344714265, test 0.4123063329193327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.38281451828396224, test 0.3714092628823386\n",
      "RMSE, train 0.3471996540811184, test 0.3439159310526318\n",
      "RMSE, train 0.32283681872077385, test 0.3246759742498398\n",
      "RMSE, train 0.3056095457382279, test 0.31092223243580924\n",
      "RMSE, train 0.29339514628574853, test 0.3009028004275428\n",
      "RMSE, train 0.28441571137011856, test 0.2934318310684628\n",
      "RMSE, train 0.277643753351227, test 0.2872335304816564\n",
      "RMSE, train 0.27227734647831825, test 0.28287120163440704\n",
      "RMSE, train 0.2679566073048147, test 0.278420323630174\n",
      "RMSE, train 0.2643769720815263, test 0.27550767891936834\n",
      "RMSE, train 0.2613374383221418, test 0.27217314408885107\n",
      "RMSE, train 0.2587841550375252, test 0.27034449759456847\n",
      "RMSE, train 0.25669287611050107, test 0.2683458551764488\n",
      "RMSE, train 0.2549023055082383, test 0.2666339877578947\n",
      "RMSE, train 0.2534103496778365, test 0.2655375381310781\n",
      "RMSE, train 0.2521901218637302, test 0.26440037555164764\n",
      "RMSE, train 0.25120713828869584, test 0.26305531826284195\n",
      "RMSE, train 0.2503436306978493, test 0.2624537209669749\n",
      "RMSE, train 0.2497365480725656, test 0.26242100497086845\n",
      "RMSE, train 0.2491883868477094, test 0.26169913245571985\n",
      "RMSE, train 0.24871037787986253, test 0.2615570063392321\n",
      "RMSE, train 0.24835804763508615, test 0.2610851907067829\n",
      "RMSE, train 0.24808656149154726, test 0.2609007062183486\n",
      "RMSE, train 0.24781754564724842, test 0.2607178429762522\n",
      "RMSE, train 0.24764148670065436, test 0.2603648831446966\n",
      "RMSE, train 0.2475039363309058, test 0.2603598177433014\n",
      "RMSE, train 0.247372103227438, test 0.26043439639939203\n",
      "RMSE, train 0.2472734525598927, test 0.26012338019079634\n",
      "RMSE, train 0.2472133159717781, test 0.2598240782817205\n",
      "RMSE, train 0.24713871597922393, test 0.26032031310929193\n",
      "RMSE, train 0.24711576329087312, test 0.26039774898025725\n",
      "RMSE, train 0.24707676301587303, test 0.260159636537234\n",
      "RMSE, train 0.24701391108273818, test 0.26019448969099257\n",
      "RMSE, train 0.24701698779095857, test 0.2600543083416091\n",
      "RMSE, train 0.24698879664156315, test 0.2601327170928319\n",
      "RMSE, train 0.24695339746712996, test 0.2599690336320135\n",
      "RMSE, train 0.2469383225527735, test 0.2595298954182201\n",
      "RMSE, train 0.24691981354331713, test 0.259926083849536\n",
      "RMSE, train 0.24693214431445232, test 0.2599520209762785\n",
      "RMSE, train 0.24688570044754007, test 0.2601688797275225\n",
      "RMSE, train 0.24690285690550534, test 0.2598306374417411\n",
      "RMSE, train 0.24691039998576325, test 0.25977386236190797\n",
      "RMSE, train 0.246908234095959, test 0.25981801317797765\n",
      "RMSE, train 0.24687412959546093, test 0.2598076679640346\n",
      "RMSE, train 0.24684994444853534, test 0.25989438626501293\n",
      "RMSE, train 0.24690123577162904, test 0.2600679819782575\n",
      "RMSE, train 0.24687926756403838, test 0.25998408877187307\n",
      "Early stopping at epoch 49 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.9853176535778931, test 0.9211859787353361\n",
      "RMSE, train 0.8316537637290862, test 0.7828547804042546\n",
      "RMSE, train 0.714686308557072, test 0.6777885152836038\n",
      "RMSE, train 0.6257603719356882, test 0.5970012172304019\n",
      "RMSE, train 0.5564283931167902, test 0.5346131222416656\n",
      "RMSE, train 0.5029544181812072, test 0.48661348404306354\n",
      "RMSE, train 0.4617053707537849, test 0.44972696810057666\n",
      "RMSE, train 0.42931363598641675, test 0.4213253587785393\n",
      "RMSE, train 0.40460424383869964, test 0.3994257055749797\n",
      "RMSE, train 0.3847331454235068, test 0.38243255049291286\n",
      "RMSE, train 0.36922458987364265, test 0.36912170775008923\n",
      "RMSE, train 0.3567976501285301, test 0.35848665568563676\n",
      "RMSE, train 0.3468453364587938, test 0.3499010145062148\n",
      "RMSE, train 0.3384759681149042, test 0.3429142179513218\n",
      "RMSE, train 0.33169110166705906, test 0.337168557174278\n",
      "RMSE, train 0.3258650600910187, test 0.33246921710293703\n",
      "RMSE, train 0.32124642200749776, test 0.3286020915315609\n",
      "RMSE, train 0.3173033463197116, test 0.3254810767342346\n",
      "RMSE, train 0.3140227686805072, test 0.3230060573780175\n",
      "RMSE, train 0.31133112887007103, test 0.3209314430602873\n",
      "RMSE, train 0.30935495079000885, test 0.3192779644571169\n",
      "RMSE, train 0.3075939986335619, test 0.3179590395002654\n",
      "RMSE, train 0.30626260228728314, test 0.3169103939123828\n",
      "RMSE, train 0.3049339282993582, test 0.31613616931318034\n",
      "RMSE, train 0.3040754108309454, test 0.31551729368441034\n",
      "RMSE, train 0.30336035409154405, test 0.31497004281992863\n",
      "RMSE, train 0.30290549385081295, test 0.3146008677554853\n",
      "RMSE, train 0.302421290855536, test 0.3142770453534945\n",
      "RMSE, train 0.3020145888724945, test 0.3140323914662756\n",
      "RMSE, train 0.3017918941152708, test 0.3138498778295035\n",
      "RMSE, train 0.3016396340866252, test 0.3137266054900006\n",
      "RMSE, train 0.30140652811760427, test 0.3135968708630764\n",
      "RMSE, train 0.30119150884285534, test 0.3134882161111543\n",
      "RMSE, train 0.3011928528620153, test 0.313363653842849\n",
      "RMSE, train 0.30125630444740026, test 0.31333161288439626\n",
      "RMSE, train 0.30095739954112505, test 0.31333860468984853\n",
      "RMSE, train 0.3011105872672461, test 0.3132752597030967\n",
      "RMSE, train 0.3008090896317895, test 0.3132135753679757\n",
      "RMSE, train 0.3007562849442941, test 0.313199052003899\n",
      "RMSE, train 0.3008134889354916, test 0.3132139882355025\n",
      "RMSE, train 0.30097392813500684, test 0.3132107871951479\n",
      "RMSE, train 0.3010401604082299, test 0.3131864841538246\n",
      "RMSE, train 0.3007552308966303, test 0.31311556726995143\n",
      "RMSE, train 0.3008190206545781, test 0.3131303702942049\n",
      "RMSE, train 0.3006348855119463, test 0.31309099901806225\n",
      "RMSE, train 0.3009121846453193, test 0.3131670431055204\n",
      "RMSE, train 0.3009549582281439, test 0.31314917736583286\n",
      "RMSE, train 0.3008132814486627, test 0.3130879983155414\n",
      "RMSE, train 0.3006638986557212, test 0.3131192922592163\n",
      "RMSE, train 0.30084873961790265, test 0.3130497122653807\n",
      "RMSE, train 0.3006778875670981, test 0.3130513405559039\n",
      "RMSE, train 0.30063267751690226, test 0.3131220960857892\n",
      "RMSE, train 0.30081780021668647, test 0.3131010989950161\n",
      "RMSE, train 0.30072576313992294, test 0.3131035524185258\n",
      "RMSE, train 0.30069026281752037, test 0.3131119557703384\n",
      "RMSE, train 0.3006568175073358, test 0.31308430463376674\n",
      "RMSE, train 0.30075065587581223, test 0.3131047791302806\n",
      "RMSE, train 0.30063128635323716, test 0.31312172822277956\n",
      "RMSE, train 0.30073217632280874, test 0.31313661764366457\n",
      "RMSE, train 0.30073943460920327, test 0.3130971948907833\n",
      "Early stopping at epoch 60 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.8975241926282344, test 0.7824798598885536\n",
      "RMSE, train 0.6812845313488834, test 0.6155314032609264\n",
      "RMSE, train 0.5580771359981913, test 0.5203548514594635\n",
      "RMSE, train 0.4858451627872207, test 0.4642853131517768\n",
      "RMSE, train 0.441579169170423, test 0.42961743970712024\n",
      "RMSE, train 0.4124443611562854, test 0.4059615520139535\n",
      "RMSE, train 0.3914288246270382, test 0.38829183112829924\n",
      "RMSE, train 0.37486198431614676, test 0.3743853500733773\n",
      "RMSE, train 0.36103851566411027, test 0.3622844712808728\n",
      "RMSE, train 0.34902331541584, test 0.3517107243339221\n",
      "RMSE, train 0.3386379156750862, test 0.342637589511772\n",
      "RMSE, train 0.3295270474721687, test 0.3349653724581003\n",
      "RMSE, train 0.321612024773853, test 0.32833442899088067\n",
      "RMSE, train 0.3148204449451331, test 0.3225326534981529\n",
      "RMSE, train 0.3090085923445947, test 0.31776205853869516\n",
      "RMSE, train 0.3040764151573783, test 0.31374885033195216\n",
      "RMSE, train 0.2999404446795733, test 0.31064143249144155\n",
      "RMSE, train 0.2964895912493118, test 0.3077908819541335\n",
      "RMSE, train 0.2936618705139016, test 0.30565478559583426\n",
      "RMSE, train 0.2913367877704929, test 0.30406670381004614\n",
      "RMSE, train 0.2893999062779576, test 0.3028426201393207\n",
      "RMSE, train 0.2879042725897197, test 0.30171501465762657\n",
      "RMSE, train 0.28668178896410296, test 0.30082639896621305\n",
      "RMSE, train 0.2857010607993362, test 0.3001870649556319\n",
      "RMSE, train 0.2849943624677682, test 0.29980634975557524\n",
      "RMSE, train 0.28439101418762497, test 0.29951643633345765\n",
      "RMSE, train 0.28392641351680564, test 0.2992413779720664\n",
      "RMSE, train 0.283577540908197, test 0.2992416039730112\n",
      "RMSE, train 0.28335728959152195, test 0.299000955807666\n",
      "RMSE, train 0.28312213406568826, test 0.29894892902423936\n",
      "RMSE, train 0.2829380350733044, test 0.298868147811542\n",
      "RMSE, train 0.2828198485452719, test 0.2986924344052871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.28273081523601457, test 0.2986240005120635\n",
      "RMSE, train 0.28264604896457507, test 0.2987646519516905\n",
      "RMSE, train 0.2826353676165595, test 0.298717658345898\n",
      "RMSE, train 0.28252714401995294, test 0.29853897898768383\n",
      "RMSE, train 0.2825251678098934, test 0.2985460637137294\n",
      "RMSE, train 0.28247409475722696, test 0.2985482905060053\n",
      "RMSE, train 0.2824538474281629, test 0.2984955742334326\n",
      "RMSE, train 0.28243147833931326, test 0.29844981199130416\n",
      "RMSE, train 0.2824456754958991, test 0.2985798556668063\n",
      "RMSE, train 0.28240742056508256, test 0.2984819443275531\n",
      "RMSE, train 0.2824202204367729, test 0.29839924940218526\n",
      "RMSE, train 0.2823945199600374, test 0.29847516554097336\n",
      "RMSE, train 0.2823768106449132, test 0.29818649714191753\n",
      "RMSE, train 0.28237427187838937, test 0.2984224388686319\n",
      "RMSE, train 0.28238678298363784, test 0.2985547298255066\n",
      "RMSE, train 0.28236524316698614, test 0.2986053054531415\n",
      "RMSE, train 0.28239820216490763, test 0.2983872684029241\n",
      "RMSE, train 0.2823990292922415, test 0.29837984638288617\n",
      "RMSE, train 0.282359526389175, test 0.2984150554984808\n",
      "RMSE, train 0.28235428949648683, test 0.29855682142078876\n",
      "RMSE, train 0.28236907701751196, test 0.29838433985908824\n",
      "RMSE, train 0.28235877260114206, test 0.2984974845312536\n",
      "RMSE, train 0.2823632626295692, test 0.29851385826865834\n",
      "Early stopping at epoch 55 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7383156383455282, test 0.5925630986690521\n",
      "RMSE, train 0.5208722381096966, test 0.47294162412484486\n",
      "RMSE, train 0.44794604712419434, test 0.43027034567462075\n",
      "RMSE, train 0.41617798315225585, test 0.40789909793270956\n",
      "RMSE, train 0.39516063327737894, test 0.3906381424930361\n",
      "RMSE, train 0.37779430012818616, test 0.3760730746719572\n",
      "RMSE, train 0.36265306339431, test 0.36326624320613016\n",
      "RMSE, train 0.34943225899475283, test 0.35190176135963863\n",
      "RMSE, train 0.3379120791376119, test 0.34205326239267986\n",
      "RMSE, train 0.3278962126318014, test 0.33383533623483447\n",
      "RMSE, train 0.31931512045731764, test 0.3270120229985979\n",
      "RMSE, train 0.3119595383376767, test 0.32103296319643654\n",
      "RMSE, train 0.3058385430079586, test 0.31638844973511165\n",
      "RMSE, train 0.3006155579237925, test 0.31210406720638273\n",
      "RMSE, train 0.29618868938674825, test 0.30920757055282594\n",
      "RMSE, train 0.2925934226043783, test 0.30659876697593264\n",
      "RMSE, train 0.28956199238563807, test 0.30428410735395217\n",
      "RMSE, train 0.287129213988299, test 0.30269046425819396\n",
      "RMSE, train 0.2851143802272663, test 0.3012133725815349\n",
      "RMSE, train 0.28347301663896146, test 0.3001934490270085\n",
      "RMSE, train 0.28217104515136093, test 0.2991904866364267\n",
      "RMSE, train 0.2810744845642234, test 0.2987639324532615\n",
      "RMSE, train 0.28019468160973726, test 0.2980082184076309\n",
      "RMSE, train 0.27948374520093605, test 0.2979391697380278\n",
      "RMSE, train 0.2789480668515208, test 0.29764356166124345\n",
      "RMSE, train 0.2785057239535684, test 0.2972624808549881\n",
      "RMSE, train 0.2781642093009383, test 0.29708561731709376\n",
      "RMSE, train 0.2779192364601433, test 0.2972475477390819\n",
      "RMSE, train 0.2776193603511769, test 0.29778991755512024\n",
      "RMSE, train 0.27743825890786566, test 0.297559764318996\n",
      "RMSE, train 0.2772932361881688, test 0.29707950005928674\n",
      "RMSE, train 0.2772098523024921, test 0.29722693214813867\n",
      "RMSE, train 0.2770878109488526, test 0.2970283400681284\n",
      "RMSE, train 0.2770211131906895, test 0.2971779078245163\n",
      "RMSE, train 0.27694638254186216, test 0.2970068302419451\n",
      "RMSE, train 0.27690319130523505, test 0.2969560924503538\n",
      "RMSE, train 0.27686769629745794, test 0.2973151428831948\n",
      "RMSE, train 0.27684257442578475, test 0.2970706476105584\n",
      "RMSE, train 0.27682040848661305, test 0.2969317288862334\n",
      "RMSE, train 0.2768144916813329, test 0.29687180121739704\n",
      "RMSE, train 0.27677309448828274, test 0.2970301162865427\n",
      "RMSE, train 0.27677033821527525, test 0.2977053400543001\n",
      "RMSE, train 0.27672342482120843, test 0.29706561499171785\n",
      "RMSE, train 0.27675284397087974, test 0.2972973351677259\n",
      "RMSE, train 0.276750150917354, test 0.29710507326655916\n",
      "RMSE, train 0.27674945309316373, test 0.2974188701974021\n",
      "RMSE, train 0.2767219378781126, test 0.2976611899005042\n",
      "RMSE, train 0.27670225424747263, test 0.29738886372910606\n",
      "RMSE, train 0.2767177096435002, test 0.2970862261123127\n",
      "RMSE, train 0.2767146241391765, test 0.29723101374175814\n",
      "Early stopping at epoch 50 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7120692862714191, test 0.5601777006418277\n",
      "RMSE, train 0.5190450708814128, test 0.48807746936113405\n",
      "RMSE, train 0.46636196692413256, test 0.45091754771195924\n",
      "RMSE, train 0.4290205774091857, test 0.41740906964509916\n",
      "RMSE, train 0.3983523215274573, test 0.3943601934573589\n",
      "RMSE, train 0.3734754497574126, test 0.37319374008056444\n",
      "RMSE, train 0.3534873540156356, test 0.3579070847003888\n",
      "RMSE, train 0.33745495738270126, test 0.34690292752706087\n",
      "RMSE, train 0.32483124788676465, test 0.3349016538033119\n",
      "RMSE, train 0.3147257405835149, test 0.32774714208566225\n",
      "RMSE, train 0.3067288827673297, test 0.3212545517927561\n",
      "RMSE, train 0.3004091414985627, test 0.31625752724134004\n",
      "RMSE, train 0.2952945110303962, test 0.3121408644394997\n",
      "RMSE, train 0.2912142638383996, test 0.3089054265083411\n",
      "RMSE, train 0.28787414353584573, test 0.30566216145570463\n",
      "RMSE, train 0.2850756651237375, test 0.3047020332171367\n",
      "RMSE, train 0.282759718759409, test 0.3017694808733769\n",
      "RMSE, train 0.28085265645171253, test 0.3021064165693063\n",
      "RMSE, train 0.2792102280435532, test 0.30000327947812205\n",
      "RMSE, train 0.2778761975490416, test 0.2985373318959505\n",
      "RMSE, train 0.27668188052756765, test 0.29829099545112026\n",
      "RMSE, train 0.2757311028390659, test 0.2979242528478305\n",
      "RMSE, train 0.27489109165571934, test 0.2973937480113445\n",
      "RMSE, train 0.27424890773132954, test 0.2956339432260929\n",
      "RMSE, train 0.27361545351992517, test 0.2958323407249573\n",
      "RMSE, train 0.27309516160473274, test 0.2954746694901051\n",
      "RMSE, train 0.2726739285705246, test 0.2953797819522711\n",
      "RMSE, train 0.2723304313198428, test 0.295377753674984\n",
      "RMSE, train 0.2720088929030754, test 0.29459061741064757\n",
      "RMSE, train 0.2717286670505072, test 0.294442932957258\n",
      "RMSE, train 0.2715855853115658, test 0.29487706873661435\n",
      "RMSE, train 0.27136358618736267, test 0.29563617878235304\n",
      "RMSE, train 0.27115936605172736, test 0.2939172415779187\n",
      "RMSE, train 0.2711123801837458, test 0.29488953470419615\n",
      "RMSE, train 0.2709971341388619, test 0.29474273534157336\n",
      "RMSE, train 0.27089061469675224, test 0.29535430879929125\n",
      "RMSE, train 0.27082540159841934, test 0.2950925758251777\n",
      "RMSE, train 0.27075233029613616, test 0.2947061285376549\n",
      "RMSE, train 0.2706743924417228, test 0.29594268688024616\n",
      "RMSE, train 0.2706697065139485, test 0.2957033837834994\n",
      "RMSE, train 0.27058421293523083, test 0.29506548092915463\n",
      "RMSE, train 0.2705476826689325, test 0.2955750374075694\n",
      "RMSE, train 0.2705275025044646, test 0.2946624301182918\n",
      "Early stopping at epoch 43 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.Baseline, data_dir = 'data_synthetic')\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/baseline/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960e763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
