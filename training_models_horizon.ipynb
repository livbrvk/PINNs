{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6186b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_models\n",
    "import data_pipeline2 as dp \n",
    "import numpy as np\n",
    "from training_models import train_model\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7dffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size' : 30,\n",
    "    'lr' : 1e-4,\n",
    "    'batch_size' : 32,\n",
    "    'hidden_size' : 8,\n",
    "    'output_size' : 3,\n",
    "    'layer_amt' : 3\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2d2bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.6984525911303848, test 0.2987962857850136\n",
      "RMSE, train 0.2632341519027595, test 0.26520082799177014\n",
      "RMSE, train 0.2562129700872974, test 0.2630294018815602\n",
      "RMSE, train 0.2544940562823073, test 0.26009887216552613\n",
      "RMSE, train 0.2531308759695928, test 0.25831216231228843\n",
      "RMSE, train 0.25271064627606404, test 0.2575947868247186\n",
      "RMSE, train 0.25224445903077425, test 0.2573459828572889\n",
      "RMSE, train 0.25204412823196926, test 0.2583405361060173\n",
      "RMSE, train 0.25173226835228235, test 0.2571198321999081\n",
      "RMSE, train 0.2517068536856429, test 0.25822844873032264\n",
      "RMSE, train 0.2514714247329904, test 0.2563496635806176\n",
      "RMSE, train 0.2514542855410708, test 0.2561549478240551\n",
      "RMSE, train 0.25125251923919667, test 0.25786130635007737\n",
      "RMSE, train 0.2512303413344702, test 0.2563174446864474\n",
      "RMSE, train 0.25129627356887335, test 0.25736758209043936\n",
      "RMSE, train 0.25101331942401856, test 0.25716051405235646\n",
      "RMSE, train 0.25114791803503694, test 0.2568271517032577\n",
      "RMSE, train 0.25095146208294766, test 0.2561264444863604\n",
      "RMSE, train 0.2510359324514866, test 0.25596971719736056\n",
      "RMSE, train 0.2509688816287301, test 0.25812386793474995\n",
      "RMSE, train 0.25089702423912263, test 0.25615884736180305\n",
      "RMSE, train 0.2508478068669323, test 0.2570520936241073\n",
      "RMSE, train 0.2508056248600775, test 0.2562923383328222\n",
      "RMSE, train 0.2508441253672004, test 0.2560478891696661\n",
      "RMSE, train 0.25079164531803416, test 0.2562598987452446\n",
      "RMSE, train 0.25065450742840767, test 0.25563757223708017\n",
      "RMSE, train 0.25064473515266017, test 0.25558607935184435\n",
      "RMSE, train 0.2507515987565395, test 0.25585020742108744\n",
      "RMSE, train 0.2507838910600178, test 0.2555094973574723\n",
      "RMSE, train 0.25046994252932875, test 0.2561181919468987\n",
      "RMSE, train 0.25061170120719867, test 0.2558764617048925\n",
      "RMSE, train 0.250565474330201, test 0.2560899014314336\n",
      "RMSE, train 0.2505236880728614, test 0.25648453254853526\n",
      "RMSE, train 0.25052785293269064, test 0.25536318069263814\n",
      "RMSE, train 0.2505596993792905, test 0.25644693379440614\n",
      "RMSE, train 0.25047639900222124, test 0.255460930327254\n",
      "RMSE, train 0.25037619104910747, test 0.2555551503694827\n",
      "RMSE, train 0.25060372911540885, test 0.2558434705340093\n",
      "RMSE, train 0.25041002964254894, test 0.255729392531418\n",
      "RMSE, train 0.25028548584036203, test 0.2562111425664156\n",
      "RMSE, train 0.2503907961748805, test 0.2561099172960366\n",
      "RMSE, train 0.2504005729563151, test 0.2566350202166265\n",
      "RMSE, train 0.25039558831175324, test 0.2553758001736095\n",
      "RMSE, train 0.2502524032747086, test 0.2577525132125424\n",
      "Early stopping at epoch 44 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.7507505047055874, test 0.321377798422309\n",
      "RMSE, train 0.2565143131292783, test 0.2510776489603618\n",
      "RMSE, train 0.2397921102702135, test 0.24523593386835305\n",
      "RMSE, train 0.23811179826315115, test 0.24151039517615452\n",
      "RMSE, train 0.23658079142693567, test 0.24201952764564308\n",
      "RMSE, train 0.23606279929760496, test 0.2402972931211645\n",
      "RMSE, train 0.23556452437571668, test 0.24241204830733212\n",
      "RMSE, train 0.2353025679193769, test 0.23922991407804253\n",
      "RMSE, train 0.23486210417892286, test 0.24024503561090832\n",
      "RMSE, train 0.2349264969830571, test 0.23882303842581992\n",
      "RMSE, train 0.23479551220169434, test 0.23906600894021593\n",
      "RMSE, train 0.23440479482656065, test 0.23885576383880347\n",
      "RMSE, train 0.23429481015514267, test 0.23955711500703797\n",
      "RMSE, train 0.23421526677635035, test 0.2407905876267055\n",
      "RMSE, train 0.23390257697899333, test 0.23993898700337765\n",
      "RMSE, train 0.23397866383134594, test 0.23901887361175758\n",
      "RMSE, train 0.23378421305886166, test 0.23952938899521\n",
      "RMSE, train 0.2338139723971305, test 0.23912096897925228\n",
      "RMSE, train 0.23373947797818223, test 0.23967351228737635\n",
      "RMSE, train 0.23345208511902735, test 0.23940457502179893\n",
      "Early stopping at epoch 20 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.6660043215001824, test 0.2661764552457291\n",
      "RMSE, train 0.23848958356357586, test 0.23716817541342033\n",
      "RMSE, train 0.2313267624041419, test 0.23631441063786807\n",
      "RMSE, train 0.23083344383089782, test 0.23538919015411744\n",
      "RMSE, train 0.23026408812702337, test 0.2362003607446687\n",
      "RMSE, train 0.23015669018411433, test 0.2356833069209467\n",
      "RMSE, train 0.22993262081957067, test 0.23507899967463394\n",
      "RMSE, train 0.22952747057432304, test 0.23509062839704647\n",
      "RMSE, train 0.22959657455049853, test 0.2346217914631492\n",
      "RMSE, train 0.22908012598339936, test 0.23437431225912614\n",
      "RMSE, train 0.22926542655364282, test 0.23435890563485914\n",
      "RMSE, train 0.22906759220844647, test 0.2345450734883024\n",
      "RMSE, train 0.229021018613249, test 0.234833328478169\n",
      "RMSE, train 0.22924357862360695, test 0.23434211588219592\n",
      "RMSE, train 0.22869414154654627, test 0.23407044745328134\n",
      "RMSE, train 0.22838598726464232, test 0.23500834398886614\n",
      "RMSE, train 0.22858438775864745, test 0.23373811927280927\n",
      "RMSE, train 0.22835120423706864, test 0.23439793746199525\n",
      "RMSE, train 0.22827576499567356, test 0.23394052030747398\n",
      "RMSE, train 0.22815728435384186, test 0.23369073044312627\n",
      "RMSE, train 0.2283288146069309, test 0.23741338369354867\n",
      "RMSE, train 0.22804857487045627, test 0.23446179736863104\n",
      "RMSE, train 0.22795451049611512, test 0.2336173918947839\n",
      "RMSE, train 0.22837099194653762, test 0.23460370158417182\n",
      "RMSE, train 0.22857778675075788, test 0.23369925920116275\n",
      "RMSE, train 0.22804340845676882, test 0.23354387335609972\n",
      "RMSE, train 0.22785266075751928, test 0.23393486237578226\n",
      "RMSE, train 0.2277889900656143, test 0.2336962038095583\n",
      "RMSE, train 0.22791668211918142, test 0.23356969863699192\n",
      "RMSE, train 0.2281118316818148, test 0.23333132476137394\n",
      "RMSE, train 0.2280057500452121, test 0.23358120828082687\n",
      "RMSE, train 0.22786698704843583, test 0.23390206557355428\n",
      "RMSE, train 0.22785480498377955, test 0.23361721791719137\n",
      "RMSE, train 0.22823839968264992, test 0.23337644913740324\n",
      "RMSE, train 0.2278307594025313, test 0.23373854075346076\n",
      "RMSE, train 0.22768993076802826, test 0.23361985646841818\n",
      "RMSE, train 0.2277492683357013, test 0.23330816626548767\n",
      "RMSE, train 0.22782220063941566, test 0.233374737595257\n",
      "RMSE, train 0.2278794267856236, test 0.23441917213954425\n",
      "RMSE, train 0.22748108927819774, test 0.23417218356278904\n",
      "RMSE, train 0.22762318829229392, test 0.23331769660376667\n",
      "RMSE, train 0.22754402725554224, test 0.23351060220024042\n",
      "RMSE, train 0.22772657667904267, test 0.2332434437254019\n",
      "RMSE, train 0.22778684342466693, test 0.23319463392621592\n",
      "RMSE, train 0.22769035595947745, test 0.23355826879279656\n",
      "RMSE, train 0.22722956923438287, test 0.23362489489086888\n",
      "RMSE, train 0.22756400366009935, test 0.23339002494487845\n",
      "RMSE, train 0.22753476874152226, test 0.23370964517980292\n",
      "RMSE, train 0.22793882553066527, test 0.2333132024004794\n",
      "RMSE, train 0.2278932153638492, test 0.2335514746475638\n",
      "RMSE, train 0.2277060959543755, test 0.23363019826642253\n",
      "RMSE, train 0.2275136805165297, test 0.23327320121359407\n",
      "RMSE, train 0.2282117198048624, test 0.23312705186636826\n",
      "RMSE, train 0.2271576910448481, test 0.2334914078053675\n",
      "RMSE, train 0.2273256832570918, test 0.23329008632061773\n",
      "RMSE, train 0.22748998563681075, test 0.23315463241255074\n",
      "RMSE, train 0.2270884993774042, test 0.234580581517596\n",
      "RMSE, train 0.22773444781234778, test 0.2331573320062537\n",
      "RMSE, train 0.22779695861248064, test 0.23320939300353066\n",
      "RMSE, train 0.22773599769197292, test 0.23337796709516592\n",
      "RMSE, train 0.22727372330516132, test 0.23582598390547851\n",
      "RMSE, train 0.22734681240467627, test 0.23393115911044574\n",
      "RMSE, train 0.22744949797450353, test 0.23316794764577298\n",
      "Early stopping at epoch 63 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.5326877635212388, test 0.2683621674922167\n",
      "RMSE, train 0.24713455846528734, test 0.2594285610259748\n",
      "RMSE, train 0.24113250125492958, test 0.2512185083446549\n",
      "RMSE, train 0.23699606914153248, test 0.247203321287445\n",
      "RMSE, train 0.2340020065624845, test 0.24721654687149852\n",
      "RMSE, train 0.23224681733189448, test 0.24109468083171284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2303696283826111, test 0.23825262983640036\n",
      "RMSE, train 0.22907143047075, test 0.23817939201698585\n",
      "RMSE, train 0.22837071696869798, test 0.23516959901533874\n",
      "RMSE, train 0.22791435788241093, test 0.23448068414833032\n",
      "RMSE, train 0.22770932457256432, test 0.23535379986552632\n",
      "RMSE, train 0.2270938165859277, test 0.2348055388121044\n",
      "RMSE, train 0.22680549844565995, test 0.23393925104071112\n",
      "RMSE, train 0.2268866562686843, test 0.23425224730197122\n",
      "RMSE, train 0.22690050837390463, test 0.2332733510902115\n",
      "RMSE, train 0.22667605934891324, test 0.23273330306013426\n",
      "RMSE, train 0.22632341999071595, test 0.23327726059976747\n",
      "RMSE, train 0.22702412175676986, test 0.2329979347539883\n",
      "RMSE, train 0.22639532332132994, test 0.23274255120286755\n",
      "RMSE, train 0.22663350269945254, test 0.233475320552494\n",
      "RMSE, train 0.22643634486667866, test 0.23508268236821772\n",
      "RMSE, train 0.22637894847441403, test 0.23324574997612074\n",
      "RMSE, train 0.2261016517166306, test 0.23317229769685688\n",
      "RMSE, train 0.22672854667987347, test 0.23315109831153177\n",
      "RMSE, train 0.22589176053932572, test 0.23213747421316072\n",
      "RMSE, train 0.22631026546610852, test 0.23261388391256332\n",
      "RMSE, train 0.2260008502155898, test 0.23355718336853326\n",
      "RMSE, train 0.22585913346889194, test 0.2321945955502052\n",
      "RMSE, train 0.22588851695840284, test 0.23361112761731243\n",
      "RMSE, train 0.22604270853760133, test 0.23243641057143025\n",
      "RMSE, train 0.22574728807358868, test 0.23311497030012748\n",
      "RMSE, train 0.225714055923545, test 0.23206396780762018\n",
      "RMSE, train 0.22564740566123356, test 0.23343601026663593\n",
      "RMSE, train 0.2259230026730774, test 0.2326850635456104\n",
      "RMSE, train 0.22597307327752467, test 0.23198634590588363\n",
      "RMSE, train 0.22559503312967272, test 0.2345697527714804\n",
      "RMSE, train 0.22575140856473144, test 0.23277538437761514\n",
      "RMSE, train 0.22505358946209592, test 0.23226547204688483\n",
      "RMSE, train 0.2251377215604509, test 0.23437553132865943\n",
      "RMSE, train 0.22541615943066545, test 0.23262636056717703\n",
      "RMSE, train 0.22521531809485898, test 0.23279184176056994\n",
      "RMSE, train 0.22547891659568772, test 0.23250297931771652\n",
      "RMSE, train 0.225285077685388, test 0.2327700046931996\n",
      "RMSE, train 0.22535885313885878, test 0.23429004687304592\n",
      "RMSE, train 0.22568349204157304, test 0.23332208964754553\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.000075469634706, test 0.7794186665006906\n",
      "RMSE, train 0.4474417689827181, test 0.2720160859921747\n",
      "RMSE, train 0.26670632613522394, test 0.2659076385754199\n",
      "RMSE, train 0.26271237800979325, test 0.2641813868949236\n",
      "RMSE, train 0.2612682789443962, test 0.2628322025714827\n",
      "RMSE, train 0.2604788448811779, test 0.26245599123072033\n",
      "RMSE, train 0.2598745094071473, test 0.26235989259540543\n",
      "RMSE, train 0.259328346053559, test 0.26112458898016244\n",
      "RMSE, train 0.25933065354042956, test 0.2608938474546779\n",
      "RMSE, train 0.2587862720773105, test 0.26059056596815094\n",
      "RMSE, train 0.2586369798068077, test 0.2613900643119142\n",
      "RMSE, train 0.25843771664245474, test 0.2602273797200731\n",
      "RMSE, train 0.2582767072674488, test 0.2601773245644963\n",
      "RMSE, train 0.25802138022657845, test 0.260072205184905\n",
      "RMSE, train 0.2577628615432449, test 0.26025255467773467\n",
      "RMSE, train 0.2577850028962618, test 0.2598574069166972\n",
      "RMSE, train 0.2576907614936992, test 0.2600097535562909\n",
      "RMSE, train 0.2575569867997641, test 0.25997402069489817\n",
      "RMSE, train 0.25755948370562926, test 0.25955318610283956\n",
      "RMSE, train 0.2571768794779576, test 0.2597534730414714\n",
      "RMSE, train 0.25750318899630537, test 0.25972734342429266\n",
      "RMSE, train 0.2573900935390303, test 0.2589934406694302\n",
      "RMSE, train 0.2572487211005101, test 0.25927685416680724\n",
      "RMSE, train 0.25728168837245435, test 0.259221320556215\n",
      "RMSE, train 0.2571893570223643, test 0.25880646607107366\n",
      "RMSE, train 0.257087055999305, test 0.2589008010739137\n",
      "RMSE, train 0.2570509639448456, test 0.2589060035495719\n",
      "RMSE, train 0.2571367319042404, test 0.25881232739972676\n",
      "RMSE, train 0.25700010142980084, test 0.2586625209770912\n",
      "RMSE, train 0.25684301005375965, test 0.2592113536497778\n",
      "RMSE, train 0.2568110704512125, test 0.2600296653252988\n",
      "RMSE, train 0.2570275550167407, test 0.2586124594792847\n",
      "RMSE, train 0.25694189040410903, test 0.2588295112710354\n",
      "RMSE, train 0.2568960736445602, test 0.25899469421422183\n",
      "RMSE, train 0.25684456453628596, test 0.25857178060230146\n",
      "RMSE, train 0.25672228143159903, test 0.25849014249714936\n",
      "RMSE, train 0.2568094999559464, test 0.25877596807381337\n",
      "RMSE, train 0.2567462435352706, test 0.2586824960452466\n",
      "RMSE, train 0.25672714587961953, test 0.2592652713464311\n",
      "RMSE, train 0.25665725043584264, test 0.25992521385023415\n",
      "RMSE, train 0.2568562562096744, test 0.2585924463577507\n",
      "RMSE, train 0.2565412989577218, test 0.25878935079436655\n",
      "RMSE, train 0.2566285688700455, test 0.25896929586229245\n",
      "RMSE, train 0.256670905277133, test 0.258748077779762\n",
      "RMSE, train 0.25677846444229924, test 0.2584738994309725\n",
      "RMSE, train 0.2566516404791224, test 0.2590776600620963\n",
      "RMSE, train 0.25650468977889224, test 0.2584298698862722\n",
      "RMSE, train 0.25663864286616445, test 0.25847201566558237\n",
      "RMSE, train 0.25648896842293684, test 0.2592526899635299\n",
      "RMSE, train 0.25645178586484924, test 0.25884301363190343\n",
      "RMSE, train 0.25658806012342533, test 0.2586550467516765\n",
      "RMSE, train 0.25652171473108953, test 0.2587951750548418\n",
      "RMSE, train 0.25642513971956027, test 0.25979335014977734\n",
      "RMSE, train 0.2562984246760607, test 0.25848460394488876\n",
      "RMSE, train 0.2565146158599565, test 0.25887290468393276\n",
      "RMSE, train 0.2563779143346173, test 0.25939878944523076\n",
      "RMSE, train 0.256299052072028, test 0.2586334699934179\n",
      "Early stopping at epoch 57 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.7319693145734713, test 0.32053768792647425\n",
      "RMSE, train 0.27407301414357726, test 0.25639093743037367\n",
      "RMSE, train 0.25146029066017345, test 0.24898017500921832\n",
      "RMSE, train 0.24741860185095593, test 0.24728829097949853\n",
      "RMSE, train 0.24557759897583278, test 0.24575072489047456\n",
      "RMSE, train 0.24483603453032735, test 0.2453508178813983\n",
      "RMSE, train 0.24446961115891777, test 0.24571512285935676\n",
      "RMSE, train 0.2441414334649636, test 0.2448808971350476\n",
      "RMSE, train 0.24380650836204695, test 0.24503046299441386\n",
      "RMSE, train 0.24366305220471926, test 0.24479564588706373\n",
      "RMSE, train 0.24359331928070418, test 0.24451784549628275\n",
      "RMSE, train 0.2440603664067905, test 0.24410239083029456\n",
      "RMSE, train 0.24363807357909265, test 0.24421359573380422\n",
      "RMSE, train 0.24328133662439083, test 0.24456215586702704\n",
      "RMSE, train 0.24360915228786054, test 0.24434381521354287\n",
      "RMSE, train 0.2431107463915486, test 0.24404176425630764\n",
      "RMSE, train 0.24312703440750927, test 0.24430160047644275\n",
      "RMSE, train 0.24302184377019562, test 0.2438099499855001\n",
      "RMSE, train 0.24304833644924084, test 0.24402936983664156\n",
      "RMSE, train 0.24334242356525473, test 0.24426993323584734\n",
      "RMSE, train 0.24343708112897458, test 0.24404845816099038\n",
      "RMSE, train 0.2427110382902228, test 0.24397874358346908\n",
      "RMSE, train 0.24305624333171805, test 0.24429948375386706\n",
      "RMSE, train 0.2426675314099089, test 0.2442326414383064\n",
      "RMSE, train 0.24270141743554557, test 0.2442761610372592\n",
      "RMSE, train 0.24306992543014613, test 0.24395231580582716\n",
      "RMSE, train 0.24315072008031458, test 0.24525772514989821\n",
      "RMSE, train 0.2426234861327843, test 0.24435770966238896\n",
      "Early stopping at epoch 28 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.7369974090642659, test 0.34865959720419987\n",
      "RMSE, train 0.25842281077097706, test 0.2517784602407898\n",
      "RMSE, train 0.24380909232727063, test 0.2501886204949447\n",
      "RMSE, train 0.2423282638354499, test 0.2471107012326164\n",
      "RMSE, train 0.24076188264783951, test 0.2464962720072695\n",
      "RMSE, train 0.2397434937408547, test 0.24465539592451283\n",
      "RMSE, train 0.23906676953329759, test 0.24472476967743464\n",
      "RMSE, train 0.2389384213680795, test 0.24378449722592319\n",
      "RMSE, train 0.23845095414676437, test 0.24375269854707377\n",
      "RMSE, train 0.23839084773216893, test 0.2428608065071915\n",
      "RMSE, train 0.23832227115992108, test 0.24299981079197355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23829162505522272, test 0.24209427228197455\n",
      "RMSE, train 0.23754213078349246, test 0.24181210289576224\n",
      "RMSE, train 0.23756833462154164, test 0.24331148713827133\n",
      "RMSE, train 0.23735221916878665, test 0.24206691401611483\n",
      "RMSE, train 0.23748842714463964, test 0.24307834257238678\n",
      "RMSE, train 0.2371936016645047, test 0.24130411579140595\n",
      "RMSE, train 0.23715923515540063, test 0.24090995905654772\n",
      "RMSE, train 0.2373769445779017, test 0.2408952968461173\n",
      "RMSE, train 0.2371704884701305, test 0.24128400215080806\n",
      "RMSE, train 0.23711964661714038, test 0.2412161549686321\n",
      "RMSE, train 0.23741862056107302, test 0.24147056881338358\n",
      "RMSE, train 0.23682557642135224, test 0.24097171079899585\n",
      "RMSE, train 0.23681724834416168, test 0.2410261668264866\n",
      "RMSE, train 0.2369689838169447, test 0.2409271623140999\n",
      "RMSE, train 0.23699989252620274, test 0.2409725794568658\n",
      "RMSE, train 0.23728733788972847, test 0.24145527470058628\n",
      "RMSE, train 0.23672801512648597, test 0.24133548286876508\n",
      "RMSE, train 0.23688285887111507, test 0.24107889451884798\n",
      "Early stopping at epoch 29 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.5807621892004258, test 0.27919325247557475\n",
      "RMSE, train 0.25448061254394666, test 0.2683503781304215\n",
      "RMSE, train 0.24712823437012205, test 0.2595362445772296\n",
      "RMSE, train 0.24236692941786317, test 0.2535107268227471\n",
      "RMSE, train 0.23905477559872537, test 0.24885899430573588\n",
      "RMSE, train 0.23666467034875036, test 0.24569129951373495\n",
      "RMSE, train 0.23580031392043843, test 0.24504540205904932\n",
      "RMSE, train 0.23563883094740964, test 0.24460549140819396\n",
      "RMSE, train 0.23470186392952003, test 0.24330858457269092\n",
      "RMSE, train 0.2349309332686998, test 0.24289128673498075\n",
      "RMSE, train 0.2344286626883416, test 0.2429014734848581\n",
      "RMSE, train 0.23494140485023812, test 0.24281377021712486\n",
      "RMSE, train 0.23438003617350223, test 0.24216706749766764\n",
      "RMSE, train 0.23385070665104174, test 0.24345495596979605\n",
      "RMSE, train 0.2332952399271333, test 0.24172682337688678\n",
      "RMSE, train 0.23384523528347972, test 0.24166603649806495\n",
      "RMSE, train 0.2334226311564737, test 0.2411730360954699\n",
      "RMSE, train 0.23364967031263198, test 0.2411021219961571\n",
      "RMSE, train 0.23344371278376336, test 0.24488507933688886\n",
      "RMSE, train 0.23352765479560003, test 0.2407907015747494\n",
      "RMSE, train 0.23311538272935778, test 0.24126394093036652\n",
      "RMSE, train 0.23317633591100465, test 0.24098972961156054\n",
      "RMSE, train 0.23305128075747153, test 0.24065327177746126\n",
      "RMSE, train 0.2327026815169598, test 0.24085640922339277\n",
      "RMSE, train 0.2328313871999533, test 0.24157733372365586\n",
      "RMSE, train 0.2332628043254605, test 0.24033923808372382\n",
      "RMSE, train 0.23282959984392293, test 0.2402736364741518\n",
      "RMSE, train 0.23244469498072393, test 0.2400024708623838\n",
      "RMSE, train 0.23240181178874667, test 0.24170593104579233\n",
      "RMSE, train 0.23266380362230873, test 0.2401821653198714\n",
      "RMSE, train 0.23251368770316644, test 0.2405979244245423\n",
      "RMSE, train 0.2326822743949214, test 0.24137504293461037\n",
      "RMSE, train 0.2325338868100952, test 0.23964548637770644\n",
      "RMSE, train 0.23300018746287432, test 0.2396279647193774\n",
      "RMSE, train 0.23219340518663448, test 0.23964544174948124\n",
      "RMSE, train 0.2322923484233306, test 0.239603003016626\n",
      "RMSE, train 0.23222754035864598, test 0.2395942242759647\n",
      "RMSE, train 0.23199175873857839, test 0.23976586954762238\n",
      "RMSE, train 0.2323457679203495, test 0.2395013841715726\n",
      "RMSE, train 0.23207456602152518, test 0.240058333283723\n",
      "RMSE, train 0.23189489543437958, test 0.239790033285666\n",
      "RMSE, train 0.23219317848131535, test 0.23952709048083334\n",
      "RMSE, train 0.23238400176786853, test 0.23948307801978758\n",
      "RMSE, train 0.23181324472200024, test 0.23914372379129584\n",
      "RMSE, train 0.23191670271907283, test 0.23926922934825975\n",
      "RMSE, train 0.2322624901578304, test 0.23924987108418436\n",
      "RMSE, train 0.23221675403106476, test 0.23908359143469068\n",
      "RMSE, train 0.23225669754090694, test 0.2392221481511087\n",
      "RMSE, train 0.23193770448488243, test 0.23909515315535093\n",
      "RMSE, train 0.23175825335285774, test 0.24012735057057757\n",
      "RMSE, train 0.23192560559817224, test 0.23974192360735902\n",
      "RMSE, train 0.2317321095570084, test 0.2394867932254618\n",
      "RMSE, train 0.23163589926249822, test 0.23882160809907046\n",
      "RMSE, train 0.2319767585156308, test 0.2404459322793315\n",
      "RMSE, train 0.23174148736052524, test 0.23924510685181377\n",
      "RMSE, train 0.2317006365922086, test 0.24007654807182274\n",
      "RMSE, train 0.2315277284088665, test 0.23922824663947326\n",
      "RMSE, train 0.23144472057049897, test 0.2386803695499295\n",
      "RMSE, train 0.23173644328102797, test 0.23999051840016336\n",
      "RMSE, train 0.2316540718479378, test 0.23854883030207472\n",
      "RMSE, train 0.23181172017654755, test 0.23862972095458193\n",
      "RMSE, train 0.23151681557625606, test 0.23902018247830747\n",
      "RMSE, train 0.23162437856998885, test 0.23928831186559466\n",
      "RMSE, train 0.23122367987860096, test 0.23991699554402418\n",
      "RMSE, train 0.231404862878958, test 0.23866932861732715\n",
      "RMSE, train 0.23129624756813633, test 0.23840194624481778\n",
      "RMSE, train 0.23129186203616756, test 0.23877061361616309\n",
      "RMSE, train 0.23148206490249099, test 0.23848325488242236\n",
      "RMSE, train 0.2313332077489214, test 0.23870650867019036\n",
      "RMSE, train 0.23140264333460325, test 0.23905969606806535\n",
      "RMSE, train 0.23133226265461346, test 0.23837895412938764\n",
      "RMSE, train 0.23143155645114577, test 0.239310712751114\n",
      "RMSE, train 0.2310725040096234, test 0.23858435918586424\n",
      "RMSE, train 0.23141735817663245, test 0.23940341106869958\n",
      "RMSE, train 0.23163207791618146, test 0.23881720518222962\n",
      "RMSE, train 0.23090132100002106, test 0.23854706014948662\n",
      "RMSE, train 0.23095699343238307, test 0.2393223802850704\n",
      "RMSE, train 0.2317506410636937, test 0.24174242903186818\n",
      "RMSE, train 0.23105350156795132, test 0.2409728465959279\n",
      "RMSE, train 0.2309953295113405, test 0.23845781543941208\n",
      "RMSE, train 0.2309092580543462, test 0.238580482024135\n",
      "Early stopping at epoch 81 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.90390423328177, test 0.6680696750596419\n",
      "RMSE, train 0.4585407853188101, test 0.30039494554117574\n",
      "RMSE, train 0.28832341121001676, test 0.28265374760001394\n",
      "RMSE, train 0.28229285407164867, test 0.2800344103094885\n",
      "RMSE, train 0.28010739841737037, test 0.27958013161511747\n",
      "RMSE, train 0.2789685248959163, test 0.27814880165003114\n",
      "RMSE, train 0.27884547116835257, test 0.27806358001494813\n",
      "RMSE, train 0.2778740190277415, test 0.2778763584792614\n",
      "RMSE, train 0.277424274489653, test 0.2779745829559989\n",
      "RMSE, train 0.27747890082272614, test 0.27724526298500723\n",
      "RMSE, train 0.276918780920673, test 0.27721340828022717\n",
      "RMSE, train 0.2770277359330457, test 0.2771914387911053\n",
      "RMSE, train 0.2774761300995823, test 0.27667010310342754\n",
      "RMSE, train 0.27684489434415643, test 0.27732768389633145\n",
      "RMSE, train 0.27680737225046337, test 0.2766813938900576\n",
      "RMSE, train 0.27653560184003895, test 0.27668210838810875\n",
      "RMSE, train 0.27659721413919747, test 0.2766920277627848\n",
      "RMSE, train 0.27664465269397115, test 0.27613465260651154\n",
      "RMSE, train 0.27632822983028477, test 0.2765922817890927\n",
      "RMSE, train 0.27641936433155184, test 0.2766135893130707\n",
      "RMSE, train 0.27596881690104147, test 0.2763122815196797\n",
      "RMSE, train 0.2761257963239654, test 0.27659300348516236\n",
      "RMSE, train 0.275874700335678, test 0.2763602663526091\n",
      "RMSE, train 0.27638225923946574, test 0.27678883833400275\n",
      "RMSE, train 0.275916303808162, test 0.2766104389802884\n",
      "RMSE, train 0.2759820379563107, test 0.27615207686262616\n",
      "RMSE, train 0.27604607646622936, test 0.27663302787784805\n",
      "RMSE, train 0.27618407624319563, test 0.2761253316776227\n",
      "RMSE, train 0.275783066445392, test 0.27636457032571404\n",
      "RMSE, train 0.275747782173605, test 0.27607939960592887\n",
      "RMSE, train 0.2761059875700099, test 0.27593866419994223\n",
      "RMSE, train 0.27589669303337405, test 0.2757086320701292\n",
      "RMSE, train 0.275863500681421, test 0.2766684514738746\n",
      "RMSE, train 0.2757260106842626, test 0.27618880140579355\n",
      "RMSE, train 0.275557197014655, test 0.2756865124328662\n",
      "RMSE, train 0.275773878848134, test 0.2756823771080728\n",
      "RMSE, train 0.2757269338173561, test 0.275760839046058\n",
      "RMSE, train 0.275512639725627, test 0.2762341864280782\n",
      "RMSE, train 0.2760524606593877, test 0.27633384589926674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2755051373912037, test 0.27639732408826634\n",
      "RMSE, train 0.2761276553053994, test 0.2766736989556733\n",
      "RMSE, train 0.27546392612097675, test 0.27628614968162474\n",
      "RMSE, train 0.2757911055140998, test 0.2761192972756038\n",
      "RMSE, train 0.2755785298125803, test 0.276111968556198\n",
      "RMSE, train 0.27580858075852727, test 0.2765873265215906\n",
      "RMSE, train 0.2760508908035834, test 0.27584459998850097\n",
      "Early stopping at epoch 46 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.7102092211223712, test 0.3211976848218752\n",
      "RMSE, train 0.2786905181509168, test 0.2712054468367411\n",
      "RMSE, train 0.2646421914773888, test 0.2686119350402252\n",
      "RMSE, train 0.2627479396523184, test 0.2672204305296359\n",
      "RMSE, train 0.26182556414933217, test 0.2662522274514903\n",
      "RMSE, train 0.26073875115302464, test 0.264984237499859\n",
      "RMSE, train 0.2603174094941206, test 0.2633389825406282\n",
      "RMSE, train 0.2596876023618026, test 0.26309628473675767\n",
      "RMSE, train 0.2591878278714836, test 0.2624818883512331\n",
      "RMSE, train 0.25898858580556394, test 0.26262106869531715\n",
      "RMSE, train 0.25871933082359866, test 0.2615757944791213\n",
      "RMSE, train 0.25836229221519647, test 0.2609335962197055\n",
      "RMSE, train 0.2582774698702646, test 0.26101253401973973\n",
      "RMSE, train 0.25801826532605854, test 0.26106949241265004\n",
      "RMSE, train 0.25759209418815665, test 0.2616729568528092\n",
      "RMSE, train 0.2577919311141259, test 0.2617555006690647\n",
      "RMSE, train 0.257497228555492, test 0.26082792748575623\n",
      "RMSE, train 0.25744173402113013, test 0.26035561321870143\n",
      "RMSE, train 0.257438776899928, test 0.2608317898667377\n",
      "RMSE, train 0.257311223830134, test 0.2604503814940867\n",
      "RMSE, train 0.25717089415355854, test 0.2600758124952731\n",
      "RMSE, train 0.25725471647555154, test 0.26010156079478886\n",
      "RMSE, train 0.2570923287777384, test 0.2610813129855239\n",
      "RMSE, train 0.2570403074161515, test 0.26024243844592054\n",
      "RMSE, train 0.2570257258864472, test 0.25988169584585274\n",
      "RMSE, train 0.25693609744247103, test 0.26040118543998053\n",
      "RMSE, train 0.2569560871920262, test 0.25991621095201245\n",
      "RMSE, train 0.2567484247678151, test 0.2610200011211893\n",
      "RMSE, train 0.256762184250127, test 0.26053138245706975\n",
      "RMSE, train 0.2567137260140254, test 0.2615305886320446\n",
      "RMSE, train 0.25655896186575516, test 0.2603896975517273\n",
      "RMSE, train 0.2566578715818197, test 0.2605060554716898\n",
      "RMSE, train 0.25667893725216007, test 0.2598766968302105\n",
      "RMSE, train 0.2566089946341616, test 0.2594740836516671\n",
      "RMSE, train 0.2565540382341974, test 0.26139234511748605\n",
      "RMSE, train 0.2564606884071275, test 0.25979522557362267\n",
      "RMSE, train 0.2565402599118824, test 0.26056033074855806\n",
      "RMSE, train 0.25636943750826924, test 0.25986340058886487\n",
      "RMSE, train 0.25632865399501886, test 0.2599822074174881\n",
      "RMSE, train 0.2564423660215805, test 0.25991127840850664\n",
      "RMSE, train 0.2564044806259959, test 0.2600390148551568\n",
      "RMSE, train 0.2563248136557338, test 0.259919833359511\n",
      "RMSE, train 0.25634345530894154, test 0.2596913066895112\n",
      "RMSE, train 0.25629524094094136, test 0.2594529779708904\n",
      "RMSE, train 0.25623662412293147, test 0.25982007118670836\n",
      "RMSE, train 0.25635895085562566, test 0.25992228570191755\n",
      "RMSE, train 0.2563090538902647, test 0.26007361386133276\n",
      "RMSE, train 0.2561836926515695, test 0.25986702481041785\n",
      "RMSE, train 0.2561739366778396, test 0.26008456984291906\n",
      "RMSE, train 0.25620260600578, test 0.26033382156620855\n",
      "RMSE, train 0.2562121819317214, test 0.25976405960062277\n",
      "RMSE, train 0.2562270978200714, test 0.26050041032874066\n",
      "RMSE, train 0.2561497364960405, test 0.25938052522099536\n",
      "RMSE, train 0.2561203418833435, test 0.2599124237247135\n",
      "RMSE, train 0.2560680759497256, test 0.2604998348199803\n",
      "RMSE, train 0.25616222169179065, test 0.25960791285919105\n",
      "RMSE, train 0.25606065099532943, test 0.25956355398115905\n",
      "RMSE, train 0.25595221820340797, test 0.2598891270549401\n",
      "RMSE, train 0.25607768460443825, test 0.25954428626143417\n",
      "RMSE, train 0.2559821564395716, test 0.2614947324861651\n",
      "RMSE, train 0.25580691448126125, test 0.26042738828970036\n",
      "RMSE, train 0.2559822914675036, test 0.26047970924688424\n",
      "RMSE, train 0.2558812430551604, test 0.2600679922363032\n",
      "Early stopping at epoch 63 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.7776328781995538, test 0.2934642118324927\n",
      "RMSE, train 0.2665378541556174, test 0.2757259519822007\n",
      "RMSE, train 0.2608876254726953, test 0.272403597968434\n",
      "RMSE, train 0.2592852555482644, test 0.27175150032437173\n",
      "RMSE, train 0.2581408542200856, test 0.2695520298743467\n",
      "RMSE, train 0.25753722871098284, test 0.26704076957812\n",
      "RMSE, train 0.25674434935030915, test 0.26566832690337383\n",
      "RMSE, train 0.2561817135444671, test 0.26517408190790664\n",
      "RMSE, train 0.2554531660549042, test 0.2659445790522689\n",
      "RMSE, train 0.2553520659527704, test 0.26502802216131754\n",
      "RMSE, train 0.2547523469868797, test 0.263144293577846\n",
      "RMSE, train 0.25424184207491274, test 0.2624186343009319\n",
      "RMSE, train 0.25355635640198876, test 0.26239711305963886\n",
      "RMSE, train 0.25336600277121823, test 0.265377919403238\n",
      "RMSE, train 0.25333356197438966, test 0.26131809208918055\n",
      "RMSE, train 0.2529437897284202, test 0.26169938211320737\n",
      "RMSE, train 0.2526883483100098, test 0.2629829630118991\n",
      "RMSE, train 0.25243518224211553, test 0.2611331844001735\n",
      "RMSE, train 0.2525746078969652, test 0.26105011712520493\n",
      "RMSE, train 0.2522890521672809, test 0.26110899475736354\n",
      "RMSE, train 0.252213257093467, test 0.25972067387005604\n",
      "RMSE, train 0.25207551241321946, test 0.2595040601327879\n",
      "RMSE, train 0.2518836067897589, test 0.2599513000304546\n",
      "RMSE, train 0.25190303927379337, test 0.2588557514849059\n",
      "RMSE, train 0.2514193410162434, test 0.2599528444196106\n",
      "RMSE, train 0.2518196861205347, test 0.25812907810878316\n",
      "RMSE, train 0.25149405969833044, test 0.2589004842923322\n",
      "RMSE, train 0.2514988401478716, test 0.25989682746863146\n",
      "RMSE, train 0.2514691870375599, test 0.25838717859272564\n",
      "RMSE, train 0.251310746715876, test 0.2594267632299607\n",
      "RMSE, train 0.2510862984431431, test 0.25849851412237235\n",
      "RMSE, train 0.2512130245499547, test 0.2600299002380546\n",
      "RMSE, train 0.2512978602852255, test 0.2586772671533287\n",
      "RMSE, train 0.2510627419458109, test 0.25754679178972856\n",
      "RMSE, train 0.25086469226621194, test 0.258671226988145\n",
      "RMSE, train 0.25089457510832713, test 0.2589611326335767\n",
      "RMSE, train 0.250766840500281, test 0.25837926211160256\n",
      "RMSE, train 0.25088426086533766, test 0.2594439930735378\n",
      "RMSE, train 0.2506694958248748, test 0.25855338149661317\n",
      "RMSE, train 0.25081080283485185, test 0.25943220037659376\n",
      "RMSE, train 0.2505482145555885, test 0.2594873031618398\n",
      "RMSE, train 0.25044226648093876, test 0.2598333740179692\n",
      "RMSE, train 0.25066668015691734, test 0.2587964403519937\n",
      "RMSE, train 0.25050321802697373, test 0.2577939291886233\n",
      "Early stopping at epoch 44 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.6125961165461276, test 0.3294952365880211\n",
      "RMSE, train 0.28842089959241524, test 0.30828069367756444\n",
      "RMSE, train 0.27508070248395505, test 0.2928452263586223\n",
      "RMSE, train 0.2662805303216282, test 0.281062707460175\n",
      "RMSE, train 0.25986754659074124, test 0.27513647886614007\n",
      "RMSE, train 0.2555011043682544, test 0.26647083026667434\n",
      "RMSE, train 0.2526581146462698, test 0.2638625893741846\n",
      "RMSE, train 0.2508853835740475, test 0.2615878803189844\n",
      "RMSE, train 0.2503678642514378, test 0.26034504144142073\n",
      "RMSE, train 0.24966968913948295, test 0.2585681015625596\n",
      "RMSE, train 0.24908677386966618, test 0.2591270631334434\n",
      "RMSE, train 0.2489901477790842, test 0.2569832391260813\n",
      "RMSE, train 0.24868049888373023, test 0.2571960633310179\n",
      "RMSE, train 0.24832034952035456, test 0.2584823512782653\n",
      "RMSE, train 0.24811435848323984, test 0.25735969515517354\n",
      "RMSE, train 0.2477047292496821, test 0.25619002245366573\n",
      "RMSE, train 0.24814060059460727, test 0.2582289983984083\n",
      "RMSE, train 0.24757448410747027, test 0.2568088307355841\n",
      "RMSE, train 0.2475948411256376, test 0.25520096191515523\n",
      "RMSE, train 0.24745648062665654, test 0.2558030843889962\n",
      "RMSE, train 0.24752016598829116, test 0.25727278064005077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.24720660873660535, test 0.2581482028278212\n",
      "RMSE, train 0.2471647256928863, test 0.2547909552231431\n",
      "RMSE, train 0.24707520995853524, test 0.2546630618162453\n",
      "RMSE, train 0.24690316858315708, test 0.2570762683947881\n",
      "RMSE, train 0.2470964514133003, test 0.25650494592264295\n",
      "RMSE, train 0.2468519090966444, test 0.2553574981478353\n",
      "RMSE, train 0.2471459274829337, test 0.2544885695291062\n",
      "RMSE, train 0.24681205426653227, test 0.2558279012640317\n",
      "RMSE, train 0.2469378389004204, test 0.2573917416545252\n",
      "RMSE, train 0.2465464896851718, test 0.2545015022624284\n",
      "RMSE, train 0.24660712932095383, test 0.25417042011395097\n",
      "RMSE, train 0.24662226485558833, test 0.2564095926160614\n",
      "RMSE, train 0.24639042715231577, test 0.2561027342453599\n",
      "RMSE, train 0.24658734985448497, test 0.2559077166952193\n",
      "RMSE, train 0.24639599649894117, test 0.2539088631359239\n",
      "RMSE, train 0.2462451800779261, test 0.2540066805668175\n",
      "RMSE, train 0.24630723739362725, test 0.2540956628508866\n",
      "RMSE, train 0.2463376581706483, test 0.2541882664275666\n",
      "RMSE, train 0.2463193732417292, test 0.25584764157732326\n",
      "RMSE, train 0.24615895755664266, test 0.25396974361501634\n",
      "RMSE, train 0.24600571997915255, test 0.25481820401425165\n",
      "RMSE, train 0.24610178689989778, test 0.2538448801885049\n",
      "RMSE, train 0.24592051946680354, test 0.25364786696930725\n",
      "RMSE, train 0.24564959137051395, test 0.25351561854283017\n",
      "RMSE, train 0.24567976765184088, test 0.2565578257975479\n",
      "RMSE, train 0.2456662619128974, test 0.2532632354026039\n",
      "RMSE, train 0.24591680311343886, test 0.254985988062496\n",
      "RMSE, train 0.24575622319573104, test 0.25611518680428463\n",
      "RMSE, train 0.24547161525021297, test 0.25483696659406024\n",
      "RMSE, train 0.2457136537578672, test 0.2537654935537527\n",
      "RMSE, train 0.2453885685200944, test 0.2551510521831612\n",
      "RMSE, train 0.2459194998661376, test 0.25338359029653174\n",
      "RMSE, train 0.24531759171172826, test 0.25449687816823524\n",
      "RMSE, train 0.24537237127772485, test 0.25334999275704223\n",
      "RMSE, train 0.24539690079035784, test 0.25602521770633757\n",
      "RMSE, train 0.24543930388836546, test 0.254123800744613\n",
      "Early stopping at epoch 57 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9421926565419615, test 0.7042653286563498\n",
      "RMSE, train 0.41776590984241635, test 0.3286793902516365\n",
      "RMSE, train 0.3176050630270266, test 0.3293518413390432\n",
      "RMSE, train 0.31666621838519776, test 0.32685654224561794\n",
      "RMSE, train 0.3156743311609318, test 0.32579976453312803\n",
      "RMSE, train 0.31537620534953986, test 0.3266840313694307\n",
      "RMSE, train 0.31441607814858424, test 0.32512070677642313\n",
      "RMSE, train 0.314125521980989, test 0.3279540083770241\n",
      "RMSE, train 0.31380017348494144, test 0.32409901371491806\n",
      "RMSE, train 0.31325409059820614, test 0.3244603233678\n",
      "RMSE, train 0.31392801690984656, test 0.32574215518044575\n",
      "RMSE, train 0.3131799761019241, test 0.3241054116349135\n",
      "RMSE, train 0.3134511943281606, test 0.32427192599113497\n",
      "RMSE, train 0.31312857350752504, test 0.3244623653590679\n",
      "RMSE, train 0.31290767674612324, test 0.32422084401228596\n",
      "RMSE, train 0.31276535728138777, test 0.3246175777167082\n",
      "RMSE, train 0.31264460158244195, test 0.3239568616928799\n",
      "RMSE, train 0.31277281032927934, test 0.3244775903544256\n",
      "RMSE, train 0.31267608845026146, test 0.3243508115410805\n",
      "RMSE, train 0.3122445206626568, test 0.32313373911061455\n",
      "RMSE, train 0.3124020066688523, test 0.3243983354685562\n",
      "RMSE, train 0.3124143813690069, test 0.32328045048883985\n",
      "RMSE, train 0.3125180300804005, test 0.3227123157786472\n",
      "RMSE, train 0.3119244766553503, test 0.32310441735067535\n",
      "RMSE, train 0.31278338693975105, test 0.32333233752953155\n",
      "RMSE, train 0.3123839936484958, test 0.3229938419535756\n",
      "RMSE, train 0.31227266866397235, test 0.32310920408261673\n",
      "RMSE, train 0.31191961752952835, test 0.32212825066276957\n",
      "RMSE, train 0.3121495224973735, test 0.32423082938683884\n",
      "RMSE, train 0.3118772423604994, test 0.3230081123432943\n",
      "RMSE, train 0.31189976772191996, test 0.323166695024286\n",
      "RMSE, train 0.31181891746250895, test 0.32357420918664764\n",
      "RMSE, train 0.3118969675697273, test 0.3245054225304297\n",
      "RMSE, train 0.31228219209673097, test 0.3226081603871925\n",
      "RMSE, train 0.3119329941623351, test 0.3238547420395272\n",
      "RMSE, train 0.3119581114492645, test 0.32292966957070995\n",
      "RMSE, train 0.31171846844272155, test 0.3238304772281221\n",
      "RMSE, train 0.3114184087917436, test 0.32350446277164985\n",
      "Early stopping at epoch 38 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.7721367730955372, test 0.4066910965180178\n",
      "RMSE, train 0.31702017070800736, test 0.3206241275739232\n",
      "RMSE, train 0.3011679597232374, test 0.31757424197612555\n",
      "RMSE, train 0.29841647011482664, test 0.3180400239765097\n",
      "RMSE, train 0.2973304510350452, test 0.31486906001874065\n",
      "RMSE, train 0.2965125079713595, test 0.31181533873901457\n",
      "RMSE, train 0.2960988936001944, test 0.31247339787286355\n",
      "RMSE, train 0.2960243307622024, test 0.3120142616536639\n",
      "RMSE, train 0.2953460370879537, test 0.3126027158914356\n",
      "RMSE, train 0.2950864532469634, test 0.3138584623096186\n",
      "RMSE, train 0.2947691024819832, test 0.311645757441127\n",
      "RMSE, train 0.2946106399756109, test 0.3119434766266324\n",
      "RMSE, train 0.2943257270172038, test 0.31163731545483303\n",
      "RMSE, train 0.2942920533163398, test 0.31095602520562093\n",
      "RMSE, train 0.2940969495061, test 0.31011502895880183\n",
      "RMSE, train 0.2938666803753964, test 0.3131328323565492\n",
      "RMSE, train 0.2940592813585371, test 0.3108122765744498\n",
      "RMSE, train 0.29365062917428164, test 0.31012871902470196\n",
      "RMSE, train 0.2935790392515905, test 0.30974668387426146\n",
      "RMSE, train 0.2935152392784309, test 0.31258431842567724\n",
      "RMSE, train 0.29365083511768436, test 0.309385407545151\n",
      "RMSE, train 0.29343918527188323, test 0.30941843152593035\n",
      "RMSE, train 0.2931934437075538, test 0.30914652210856797\n",
      "RMSE, train 0.29327267871108825, test 0.3102879771672258\n",
      "RMSE, train 0.2933300312090615, test 0.3094114555951652\n",
      "RMSE, train 0.2931523295161168, test 0.3109011629579264\n",
      "RMSE, train 0.293039581634004, test 0.30881535521614445\n",
      "RMSE, train 0.29308729445052256, test 0.31046141096211355\n",
      "RMSE, train 0.29294990427424555, test 0.31090720449018916\n",
      "RMSE, train 0.2930013305202728, test 0.3075946194179561\n",
      "RMSE, train 0.2929622258640191, test 0.31069433771142174\n",
      "RMSE, train 0.2927283348156465, test 0.30800369874053046\n",
      "RMSE, train 0.2925497320869044, test 0.3063654880458062\n",
      "RMSE, train 0.2927095353636774, test 0.31158184718101395\n",
      "RMSE, train 0.2926722701154482, test 0.30964649270433897\n",
      "RMSE, train 0.2927463274165119, test 0.30919291338789356\n",
      "RMSE, train 0.29249421039370677, test 0.3093610840653061\n",
      "RMSE, train 0.2924847099679468, test 0.30721181426026406\n",
      "RMSE, train 0.2926682929921845, test 0.3094802727119638\n",
      "RMSE, train 0.29238906796737635, test 0.30732501434897064\n",
      "RMSE, train 0.2925422729364692, test 0.3091605628302338\n",
      "RMSE, train 0.2924021754263495, test 0.3074140034684347\n",
      "RMSE, train 0.2924587032319184, test 0.3092893810447203\n",
      "Early stopping at epoch 43 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.6880657791808212, test 0.33177020614152974\n",
      "RMSE, train 0.306458097898054, test 0.3241639509073739\n",
      "RMSE, train 0.3003143671360265, test 0.321346188994866\n",
      "RMSE, train 0.2980552167408257, test 0.3170651322755131\n",
      "RMSE, train 0.29575985843523667, test 0.3183345672430344\n",
      "RMSE, train 0.29437998369017576, test 0.3154713619970581\n",
      "RMSE, train 0.29350269254907574, test 0.3129223225439347\n",
      "RMSE, train 0.2925610013500812, test 0.31593327774006186\n",
      "RMSE, train 0.2917248721006647, test 0.311906231187501\n",
      "RMSE, train 0.2909172185278562, test 0.3192172145959243\n",
      "RMSE, train 0.29041085036520153, test 0.3086991286972194\n",
      "RMSE, train 0.29031225562874324, test 0.30877380586654235\n",
      "RMSE, train 0.2895577083432476, test 0.3056203575750578\n",
      "RMSE, train 0.28976754713228364, test 0.3093974465884051\n",
      "RMSE, train 0.2889880281729256, test 0.31002582103303333\n",
      "RMSE, train 0.28892994362356544, test 0.30888410939753635\n",
      "RMSE, train 0.2886157557545252, test 0.3065504424490975\n",
      "RMSE, train 0.28830438174502016, test 0.3096333056037287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2883402733154365, test 0.30602105207813596\n",
      "RMSE, train 0.28810724711616365, test 0.30736353081985585\n",
      "RMSE, train 0.28826513573208784, test 0.3048221701123182\n",
      "RMSE, train 0.2880827451828257, test 0.3068322271687313\n",
      "RMSE, train 0.28774655866934395, test 0.3157406896352768\n",
      "RMSE, train 0.2877593480422208, test 0.30739154688362935\n",
      "RMSE, train 0.287475439155753, test 0.3149360416872988\n",
      "RMSE, train 0.2873752878142649, test 0.3057178133031697\n",
      "RMSE, train 0.2873095205128901, test 0.30499930014309373\n",
      "RMSE, train 0.28737469564353485, test 0.303437633566486\n",
      "RMSE, train 0.2872964667417374, test 0.30440337022820724\n",
      "RMSE, train 0.2869530188499324, test 0.3033952517706214\n",
      "RMSE, train 0.2872057468973259, test 0.305125133866824\n",
      "RMSE, train 0.286954540785871, test 0.31561176073782654\n",
      "RMSE, train 0.28683152442660864, test 0.30478200685341383\n",
      "RMSE, train 0.28701396746618446, test 0.30495998364629096\n",
      "RMSE, train 0.2867390799409137, test 0.30230292981689416\n",
      "RMSE, train 0.28686728595696265, test 0.3106434469662824\n",
      "RMSE, train 0.2868713027578635, test 0.3023550142217608\n",
      "RMSE, train 0.28700714963632074, test 0.3061083223923896\n",
      "RMSE, train 0.2865115381830379, test 0.30479498583714937\n",
      "RMSE, train 0.28681212638874237, test 0.30507986073933757\n",
      "RMSE, train 0.286611554830063, test 0.30865882771107755\n",
      "RMSE, train 0.2864781120823002, test 0.3044720584327735\n",
      "RMSE, train 0.286605999670091, test 0.309267877085695\n",
      "RMSE, train 0.2866231833104566, test 0.30320551181302485\n",
      "RMSE, train 0.2862693555918555, test 0.30470750502590993\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.7378306490070415, test 0.5152665677997801\n",
      "RMSE, train 0.41913192154904905, test 0.3788946731223\n",
      "RMSE, train 0.32345364050000824, test 0.3494236970941226\n",
      "RMSE, train 0.30572071269837353, test 0.33396314564678403\n",
      "RMSE, train 0.29419231563404885, test 0.315199272831281\n",
      "RMSE, train 0.28725798291498117, test 0.3089083934823672\n",
      "RMSE, train 0.2836549359190496, test 0.30262378553549446\n",
      "RMSE, train 0.2816036360242939, test 0.3023575714892811\n",
      "RMSE, train 0.28033797414797657, test 0.2976555668645435\n",
      "RMSE, train 0.2798379551006777, test 0.2971482844816314\n",
      "RMSE, train 0.2789681248587739, test 0.2985967255300946\n",
      "RMSE, train 0.27862206446835297, test 0.2973768645690547\n",
      "RMSE, train 0.27825649548572995, test 0.296776719391346\n",
      "RMSE, train 0.27798614512395986, test 0.2953909448451466\n",
      "RMSE, train 0.2774554229569885, test 0.2935499699579345\n",
      "RMSE, train 0.27733133986311137, test 0.2943752906388707\n",
      "RMSE, train 0.2770495627607618, test 0.29387271106243135\n",
      "RMSE, train 0.2767398958056764, test 0.2968006586035093\n",
      "RMSE, train 0.27685686976038865, test 0.2939019148548444\n",
      "RMSE, train 0.27658160978732405, test 0.29372915625572205\n",
      "RMSE, train 0.2756647930713998, test 0.2924482701553239\n",
      "RMSE, train 0.27607447852824896, test 0.29279757191737493\n",
      "RMSE, train 0.2756826064054857, test 0.29183439860741295\n",
      "RMSE, train 0.27564904300591375, test 0.2939225344194306\n",
      "RMSE, train 0.2755588843534899, test 0.2943590324785974\n",
      "RMSE, train 0.27538396076693367, test 0.2917340697513686\n",
      "RMSE, train 0.27553665298576946, test 0.29317550940646064\n",
      "RMSE, train 0.27504814864008253, test 0.2920426976349619\n",
      "RMSE, train 0.27504818729875546, test 0.29275597963068223\n",
      "RMSE, train 0.2750769567216503, test 0.291094917886787\n",
      "RMSE, train 0.275043400069774, test 0.2921164030830065\n",
      "RMSE, train 0.27481445244380404, test 0.29095285774932966\n",
      "RMSE, train 0.2748782600795805, test 0.2919821646478441\n",
      "RMSE, train 0.27447672786738353, test 0.29144833700524436\n",
      "RMSE, train 0.27457030517152053, test 0.29435893777343963\n",
      "RMSE, train 0.2747116654388346, test 0.2917768562833468\n",
      "RMSE, train 0.27431520166985107, test 0.2912350363201565\n",
      "RMSE, train 0.2743220198347241, test 0.29426051560375427\n",
      "RMSE, train 0.2741366904781192, test 0.29463502102428013\n",
      "RMSE, train 0.2741485735516985, test 0.29311091552178065\n",
      "RMSE, train 0.2739430386422458, test 0.2946228853530354\n",
      "RMSE, train 0.27389602318928247, test 0.2909207961625523\n",
      "RMSE, train 0.27409717199616035, test 0.292402264310254\n",
      "RMSE, train 0.27391982325566105, test 0.2915940350956387\n",
      "RMSE, train 0.27377510271625055, test 0.29391992770963243\n",
      "RMSE, train 0.2737301079973056, test 0.2970965647035175\n",
      "RMSE, train 0.2740597750017585, test 0.29475587291849986\n",
      "RMSE, train 0.27375504139539686, test 0.29540771543979644\n",
      "RMSE, train 0.273581579970221, test 0.2962477920783891\n",
      "RMSE, train 0.2737994598089203, test 0.29964390595753987\n",
      "RMSE, train 0.2735929684537762, test 0.2914617343081368\n",
      "RMSE, train 0.2735232158571562, test 0.291774256941345\n",
      "Early stopping at epoch 52 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.030307112229774, test 0.8848896219272806\n",
      "RMSE, train 0.7273603190273994, test 0.5300177371863163\n",
      "RMSE, train 0.47739649930181016, test 0.46647816023441274\n",
      "RMSE, train 0.4399962358194925, test 0.4627478098628497\n",
      "RMSE, train 0.43201078179413066, test 0.46025208872978135\n",
      "RMSE, train 0.42777390246140634, test 0.4582498206032647\n",
      "RMSE, train 0.4252334341297523, test 0.45548712469712654\n",
      "RMSE, train 0.4239298050590133, test 0.4573210452241127\n",
      "RMSE, train 0.4226141296199598, test 0.4579916683712391\n",
      "RMSE, train 0.42290955260942503, test 0.45225883945070133\n",
      "RMSE, train 0.4218196780363913, test 0.4531115299523479\n",
      "RMSE, train 0.4210155365446669, test 0.4544014926209594\n",
      "RMSE, train 0.4209104392376972, test 0.45268311464425287\n",
      "RMSE, train 0.4212639859005408, test 0.4518593569295575\n",
      "RMSE, train 0.42038000992574437, test 0.4542391322778933\n",
      "RMSE, train 0.4205206068264535, test 0.4517609251267982\n",
      "RMSE, train 0.4205550254119929, test 0.4506866605293871\n",
      "RMSE, train 0.42039193406081726, test 0.451094954754367\n",
      "RMSE, train 0.4200617593045923, test 0.45553970487430845\n",
      "RMSE, train 0.4203791570801898, test 0.4513347832241444\n",
      "RMSE, train 0.42126984504440884, test 0.4519642066172879\n",
      "RMSE, train 0.4200215438030168, test 0.45138800806469387\n",
      "RMSE, train 0.4205574285065924, test 0.45137106122994664\n",
      "RMSE, train 0.42025708299685804, test 0.450859463275081\n",
      "RMSE, train 0.4194387991372997, test 0.44950635339876616\n",
      "RMSE, train 0.41929689639937906, test 0.45145869796926325\n",
      "RMSE, train 0.4205482362389273, test 0.44976976860051204\n",
      "RMSE, train 0.41998296447808703, test 0.45341443308074064\n",
      "RMSE, train 0.4194627857077093, test 0.45105890192166725\n",
      "RMSE, train 0.41977548741332477, test 0.45231757200125494\n",
      "RMSE, train 0.4192304485147332, test 0.45122457649370634\n",
      "RMSE, train 0.41991243090635405, test 0.4513572899982183\n",
      "RMSE, train 0.418860348765818, test 0.4514089828789836\n",
      "RMSE, train 0.4198254161038434, test 0.45202939016650423\n",
      "RMSE, train 0.4190085541211014, test 0.44917296956885944\n",
      "RMSE, train 0.41994232609685883, test 0.4504668056362807\n",
      "RMSE, train 0.4200263718885431, test 0.45069458854920935\n",
      "RMSE, train 0.4198643209225974, test 0.45116454558541075\n",
      "RMSE, train 0.4192905636609038, test 0.45171634898041235\n",
      "RMSE, train 0.4190362444498137, test 0.4543983144591553\n",
      "RMSE, train 0.41910020150881816, test 0.4493857232308147\n",
      "RMSE, train 0.4197216605936111, test 0.4517853326267666\n",
      "RMSE, train 0.41878039836154884, test 0.45093855818714756\n",
      "RMSE, train 0.41934057060984353, test 0.45304899233760254\n",
      "RMSE, train 0.4188601423082258, test 0.4519470851830762\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.8000910479311991, test 0.47993377487485606\n",
      "RMSE, train 0.41746121705180467, test 0.4446452342284222\n",
      "RMSE, train 0.40602806778718725, test 0.44207315271099407\n",
      "RMSE, train 0.40466721732207017, test 0.4406326310709119\n",
      "RMSE, train 0.40395956633217406, test 0.44050336396321654\n",
      "RMSE, train 0.403463954538709, test 0.43908418575301766\n",
      "RMSE, train 0.4028406017506965, test 0.43969915589938563\n",
      "RMSE, train 0.4027105796743523, test 0.44192702835425735\n",
      "RMSE, train 0.40243067795580084, test 0.4391517322510481\n",
      "RMSE, train 0.40196615969291843, test 0.440826953543971\n",
      "RMSE, train 0.4019699961774879, test 0.43915387413774926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.401767562849052, test 0.4412633744068444\n",
      "RMSE, train 0.4014088689829364, test 0.4398636308809121\n",
      "RMSE, train 0.40146247327628765, test 0.4395568963761131\n",
      "RMSE, train 0.40125728255570536, test 0.43678963572407764\n",
      "RMSE, train 0.40118251959181794, test 0.4366226855975886\n",
      "RMSE, train 0.4010976709877, test 0.4374077948741615\n",
      "RMSE, train 0.40089245166892956, test 0.4350769656399886\n",
      "RMSE, train 0.400698204458964, test 0.4394052669716378\n",
      "RMSE, train 0.40071459031767315, test 0.4378998544998467\n",
      "RMSE, train 0.40062200838718753, test 0.43796476908028126\n",
      "RMSE, train 0.4007946453386485, test 0.4412638229938845\n",
      "RMSE, train 0.40052588141024714, test 0.4357329720320801\n",
      "RMSE, train 0.4004354520578577, test 0.4354233459259073\n",
      "RMSE, train 0.40052714311715326, test 0.43491720252980787\n",
      "RMSE, train 0.40028871174412545, test 0.43950646293039125\n",
      "RMSE, train 0.4004551581097673, test 0.43291393558805186\n",
      "RMSE, train 0.4000939741881207, test 0.43560852358738583\n",
      "RMSE, train 0.4002642822687072, test 0.43714264780282974\n",
      "RMSE, train 0.40025922509305406, test 0.43618006833518547\n",
      "RMSE, train 0.4002142474431582, test 0.43453723456089693\n",
      "RMSE, train 0.4000526201168094, test 0.43643669846157235\n",
      "RMSE, train 0.4000626078458748, test 0.43626735188687843\n",
      "RMSE, train 0.4000957111141296, test 0.437437425677975\n",
      "RMSE, train 0.4001027617340136, test 0.43577447564651567\n",
      "RMSE, train 0.40010924069116816, test 0.43793116494392353\n",
      "RMSE, train 0.4000420126725327, test 0.43733936579277116\n",
      "Early stopping at epoch 37 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.9030661868920544, test 0.5380062305265003\n",
      "RMSE, train 0.43309424271320074, test 0.45998378925853306\n",
      "RMSE, train 0.41339303906555125, test 0.4564807171622912\n",
      "RMSE, train 0.410590004768333, test 0.45212905920214125\n",
      "RMSE, train 0.40872816705318155, test 0.44783399750789005\n",
      "RMSE, train 0.4071621306822949, test 0.45355649060673187\n",
      "RMSE, train 0.4057815769772645, test 0.45452629658910965\n",
      "RMSE, train 0.4047311495417212, test 0.4471578962273068\n",
      "RMSE, train 0.4039465599866569, test 0.4424765282207065\n",
      "RMSE, train 0.40306064606998165, test 0.4418280806806352\n",
      "RMSE, train 0.4024092362656426, test 0.4437648961941401\n",
      "RMSE, train 0.4018605338595305, test 0.4397634244627423\n",
      "RMSE, train 0.40158227813051073, test 0.44091081122557324\n",
      "RMSE, train 0.40106026691728525, test 0.4394542713960012\n",
      "RMSE, train 0.4008152108549108, test 0.4452230837610033\n",
      "RMSE, train 0.40031807337488445, test 0.44050482859214146\n",
      "RMSE, train 0.4001800170484579, test 0.44119114577770235\n",
      "RMSE, train 0.3996043828218131, test 0.438882591161463\n",
      "RMSE, train 0.39965198889896875, test 0.4391726238860024\n",
      "RMSE, train 0.39920283520639427, test 0.4452123416794671\n",
      "RMSE, train 0.3992684672704604, test 0.4402324610286289\n",
      "RMSE, train 0.39878662251879904, test 0.4406861404577891\n",
      "RMSE, train 0.39899955846550006, test 0.44227414578199387\n",
      "RMSE, train 0.39890821932782383, test 0.44137441400024624\n",
      "RMSE, train 0.3985962092153467, test 0.44070970200830034\n",
      "RMSE, train 0.39878709461650436, test 0.44117961393462285\n",
      "RMSE, train 0.3984337363924299, test 0.4413495103518168\n",
      "RMSE, train 0.39827121472904947, test 0.43516426401005853\n",
      "RMSE, train 0.3983522958430961, test 0.4371044605970383\n",
      "RMSE, train 0.3981233121892513, test 0.4392145201563835\n",
      "RMSE, train 0.3983207457872093, test 0.43573047982321844\n",
      "RMSE, train 0.3978613682512967, test 0.4378978545467059\n",
      "RMSE, train 0.39798114033079535, test 0.4360421154234144\n",
      "RMSE, train 0.3975663105593216, test 0.4449605897068977\n",
      "RMSE, train 0.39795938833061895, test 0.44335090551111433\n",
      "RMSE, train 0.39765874093594256, test 0.4332383915781975\n",
      "RMSE, train 0.39756960612583675, test 0.4400888244311015\n",
      "RMSE, train 0.3979838699343391, test 0.436188429262903\n",
      "RMSE, train 0.39749971232966913, test 0.4388315714067883\n",
      "RMSE, train 0.3974689013472786, test 0.43820916877852545\n",
      "RMSE, train 0.3973892309835979, test 0.4379960826701588\n",
      "RMSE, train 0.3970188132996829, test 0.4331075855427318\n",
      "RMSE, train 0.39720382298420703, test 0.43720340232054394\n",
      "RMSE, train 0.3969497673836037, test 0.43846286055114536\n",
      "RMSE, train 0.39702454924262115, test 0.4368990808725357\n",
      "RMSE, train 0.3967374837141474, test 0.4352332962883843\n",
      "RMSE, train 0.3963755229011057, test 0.4338221377796597\n",
      "RMSE, train 0.3968247433476692, test 0.44386058747768403\n",
      "RMSE, train 0.3969494519689976, test 0.43299092451731364\n",
      "RMSE, train 0.39665152453829977, test 0.4368451457884577\n",
      "RMSE, train 0.39674796927168043, test 0.4370883403552903\n",
      "RMSE, train 0.39641662942110045, test 0.4389554349912537\n",
      "RMSE, train 0.39661265246951677, test 0.43781703727112875\n",
      "RMSE, train 0.3964423797522594, test 0.4344362548655934\n",
      "RMSE, train 0.39658238045931504, test 0.4393456005387836\n",
      "RMSE, train 0.3964184964442189, test 0.4359256277481715\n",
      "RMSE, train 0.39640207235221914, test 0.4391440429621273\n",
      "RMSE, train 0.3961987986236891, test 0.43651353385713365\n",
      "RMSE, train 0.39627107094240316, test 0.43749124623007246\n",
      "Early stopping at epoch 59 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.8308721821627513, test 0.51147282964144\n",
      "RMSE, train 0.4559151104120451, test 0.5023574460393343\n",
      "RMSE, train 0.44038426871426006, test 0.47832521070272493\n",
      "RMSE, train 0.4297214663381517, test 0.46807521839554495\n",
      "RMSE, train 0.41954445885349284, test 0.4628388965741182\n",
      "RMSE, train 0.41074602155020673, test 0.44818613143303454\n",
      "RMSE, train 0.40318339074326454, test 0.43714824252021617\n",
      "RMSE, train 0.39604709401865984, test 0.4337338969493524\n",
      "RMSE, train 0.39066214009980177, test 0.4284964389143846\n",
      "RMSE, train 0.38646134938406423, test 0.4244893233363445\n",
      "RMSE, train 0.38402849537932615, test 0.42311693250368804\n",
      "RMSE, train 0.38240676816564484, test 0.41423342396051455\n",
      "RMSE, train 0.38122878550926104, test 0.41954444578060734\n",
      "RMSE, train 0.380199603666769, test 0.41331683003749603\n",
      "RMSE, train 0.3796200288976093, test 0.4185265220510654\n",
      "RMSE, train 0.37907048326415066, test 0.4219968920716873\n",
      "RMSE, train 0.37853050909681113, test 0.41284383776096195\n",
      "RMSE, train 0.37831807182956706, test 0.416724172158119\n",
      "RMSE, train 0.3772695323109998, test 0.4113665899405113\n",
      "RMSE, train 0.37687504523639737, test 0.4129434718917578\n",
      "RMSE, train 0.37730537303882966, test 0.4213737986790828\n",
      "RMSE, train 0.3760598376161213, test 0.4068549464528377\n",
      "RMSE, train 0.3759627052092478, test 0.40774456698160905\n",
      "RMSE, train 0.37524324065985337, test 0.4125006540845602\n",
      "RMSE, train 0.3746331506336218, test 0.4120074892655397\n",
      "RMSE, train 0.37430808129154636, test 0.41007518768310547\n",
      "RMSE, train 0.37417159408238077, test 0.40878622754453087\n",
      "RMSE, train 0.3733094061646506, test 0.4185681604804137\n",
      "RMSE, train 0.3731436167736291, test 0.41803992883517194\n",
      "RMSE, train 0.3727052760922649, test 0.4136313083462226\n",
      "RMSE, train 0.37232268237250615, test 0.4115047273345483\n",
      "RMSE, train 0.3717946689169726, test 0.4223206889552948\n",
      "Early stopping at epoch 32 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "output_sizes = [1,5,10,20,40]\n",
    "input_sizes = [5,10,20,40]\n",
    "\n",
    "\n",
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.CNN, data_dir = 'data_synthetic', only_one = True)\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/cnn/'+'output_size' + str(output) + 'input_size' + str(inputs) + '_singlevar.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ab3b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.079905639170658, test 1.0075218759236797\n",
      "RMSE, train 0.9731022292092855, test 0.9005647246395388\n",
      "RMSE, train 0.8241849191221795, test 0.7517638790511316\n",
      "RMSE, train 0.6834451843627357, test 0.6625366874279515\n",
      "RMSE, train 0.620226880366152, test 0.6219887132606199\n",
      "RMSE, train 0.582224846092373, test 0.5862668686576428\n",
      "RMSE, train 0.550610122267201, test 0.5605628925465769\n",
      "RMSE, train 0.5224069107485854, test 0.5326091271013983\n",
      "RMSE, train 0.49709368932977493, test 0.5102052556410912\n",
      "RMSE, train 0.4741190805324453, test 0.48815450072288513\n",
      "RMSE, train 0.45296294539577875, test 0.46586502343416214\n",
      "RMSE, train 0.4332182867666007, test 0.4469918362315624\n",
      "RMSE, train 0.4152973963337925, test 0.4307775496234817\n",
      "RMSE, train 0.3988027822358806, test 0.41240444995703235\n",
      "RMSE, train 0.38335264153160126, test 0.3968433872345955\n",
      "RMSE, train 0.3693574534162231, test 0.381529594861692\n",
      "RMSE, train 0.356524477333655, test 0.36962750566101843\n",
      "RMSE, train 0.3449557596456863, test 0.35720533937696486\n",
      "RMSE, train 0.3344066308244415, test 0.34784640612140777\n",
      "RMSE, train 0.3250230826113535, test 0.336923788271604\n",
      "RMSE, train 0.3165402472195889, test 0.32738718666857286\n",
      "RMSE, train 0.308877820745405, test 0.31862367881882575\n",
      "RMSE, train 0.3021180590415896, test 0.31145059930220725\n",
      "RMSE, train 0.29604694621247263, test 0.3053815405695669\n",
      "RMSE, train 0.2906563540280101, test 0.29970675382402634\n",
      "RMSE, train 0.2857986379105583, test 0.2964410922460018\n",
      "RMSE, train 0.2815108242418926, test 0.2902496239591029\n",
      "RMSE, train 0.27781643796520744, test 0.28619994211100763\n",
      "RMSE, train 0.27455115162218985, test 0.2834904225122544\n",
      "RMSE, train 0.27168566955938167, test 0.2800344149431875\n",
      "RMSE, train 0.26928189019911847, test 0.2771691511715612\n",
      "RMSE, train 0.2670458555074313, test 0.27491996641601285\n",
      "RMSE, train 0.2651567060073374, test 0.2739979880711725\n",
      "RMSE, train 0.26356210139959224, test 0.2718121804777653\n",
      "RMSE, train 0.2620206121281673, test 0.269600095647958\n",
      "RMSE, train 0.26085497652412404, test 0.2684254004589973\n",
      "RMSE, train 0.2597851686974759, test 0.2697619735713928\n",
      "RMSE, train 0.2588710284132967, test 0.26639744369012697\n",
      "RMSE, train 0.2580236963957195, test 0.26565827008697296\n",
      "RMSE, train 0.2573627681865287, test 0.2647032699277324\n",
      "RMSE, train 0.2565778238853447, test 0.26305526218587355\n",
      "RMSE, train 0.2561022011717789, test 0.26307039960257467\n",
      "RMSE, train 0.25570831050279114, test 0.2627289647296552\n",
      "RMSE, train 0.25527132773705624, test 0.26148777298869624\n",
      "RMSE, train 0.25478228842729167, test 0.2612129433621322\n",
      "RMSE, train 0.25445255582688353, test 0.26169066119097895\n",
      "RMSE, train 0.25409673490071955, test 0.2609854346561816\n",
      "RMSE, train 0.25383351946418936, test 0.26043923235227984\n",
      "RMSE, train 0.2536015829343805, test 0.2606128714978695\n",
      "RMSE, train 0.25330981666686037, test 0.26100890482625655\n",
      "RMSE, train 0.25305743728996266, test 0.25998824804780946\n",
      "RMSE, train 0.2528149942930037, test 0.25900284050693434\n",
      "RMSE, train 0.25273292062605324, test 0.2597769853328505\n",
      "RMSE, train 0.25253142920053995, test 0.25868513687483724\n",
      "RMSE, train 0.25230344367239316, test 0.25886001425885385\n",
      "RMSE, train 0.2521436111228504, test 0.25883062604454254\n",
      "RMSE, train 0.2520647547815157, test 0.258674213001805\n",
      "RMSE, train 0.2519243273722089, test 0.25879872398030374\n",
      "RMSE, train 0.2518563649871133, test 0.25871323679964386\n",
      "RMSE, train 0.2517712037318309, test 0.2578482499886905\n",
      "RMSE, train 0.2515504147430418, test 0.2584858197238176\n",
      "RMSE, train 0.25163070231735, test 0.2575319125767677\n",
      "RMSE, train 0.2515959539285055, test 0.2573802686266361\n",
      "RMSE, train 0.2514572521237281, test 0.25761661125767615\n",
      "RMSE, train 0.25131433024236804, test 0.2574475109577179\n",
      "RMSE, train 0.25124116520224354, test 0.25805939752007684\n",
      "RMSE, train 0.251274464202846, test 0.25796660552582434\n",
      "RMSE, train 0.25111015223467303, test 0.2574572941708949\n",
      "RMSE, train 0.25111785595831665, test 0.257591231996494\n",
      "RMSE, train 0.2510247707602535, test 0.2571699040070657\n",
      "RMSE, train 0.25096770456951595, test 0.2578408168929239\n",
      "RMSE, train 0.25102997778844927, test 0.25754842937232986\n",
      "RMSE, train 0.2509546879929281, test 0.2574714978616084\n",
      "RMSE, train 0.2508172921895274, test 0.25739491094023953\n",
      "RMSE, train 0.2507350941302748, test 0.2570549357201784\n",
      "RMSE, train 0.25087421397741133, test 0.2579911872143707\n",
      "RMSE, train 0.250785952220439, test 0.2568368938180708\n",
      "RMSE, train 0.25076336769954016, test 0.2570763569205038\n",
      "RMSE, train 0.2506381105852457, test 0.25752834783446404\n",
      "RMSE, train 0.2506338698207861, test 0.25683259459272506\n",
      "RMSE, train 0.2505619002601846, test 0.25615356496024516\n",
      "RMSE, train 0.25054065093928174, test 0.25736744064957867\n",
      "RMSE, train 0.25062139609114453, test 0.25710619817818364\n",
      "RMSE, train 0.25051802196521533, test 0.2571038919831476\n",
      "RMSE, train 0.25055712757433357, test 0.25679561603934536\n",
      "RMSE, train 0.2505006894115874, test 0.2565555851305685\n",
      "RMSE, train 0.25049170903243095, test 0.2563128445537821\n",
      "RMSE, train 0.2506572686047422, test 0.2570281474580688\n",
      "RMSE, train 0.25042676715099293, test 0.25670585793352896\n",
      "RMSE, train 0.2504884478720752, test 0.2587525810926191\n",
      "RMSE, train 0.25049070413169183, test 0.2568173240269384\n",
      "Early stopping at epoch 91 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.8792020545194024, test 0.6955746870395566\n",
      "RMSE, train 0.48025057856973846, test 0.3070495076908553\n",
      "RMSE, train 0.2605922558318507, test 0.2522052570808032\n",
      "RMSE, train 0.2433516414391126, test 0.24588469686833295\n",
      "RMSE, train 0.2402405954203625, test 0.2445570176297968\n",
      "RMSE, train 0.23855139642410916, test 0.24327897101887003\n",
      "RMSE, train 0.23762714665247361, test 0.2408540859079558\n",
      "RMSE, train 0.23726581653904336, test 0.24202356271999925\n",
      "RMSE, train 0.23624377711280156, test 0.24115836435605673\n",
      "RMSE, train 0.23583217122052846, test 0.24128106655168138\n",
      "RMSE, train 0.23535538653311458, test 0.23921648419100391\n",
      "RMSE, train 0.23523610275284, test 0.23898211466379402\n",
      "RMSE, train 0.23515922936652353, test 0.2408076016124615\n",
      "RMSE, train 0.23456889668456937, test 0.2392777283329609\n",
      "RMSE, train 0.23444864040745897, test 0.2392921203916723\n",
      "RMSE, train 0.2342543609379998, test 0.23894740561069536\n",
      "RMSE, train 0.23409879791290172, test 0.2390594788449855\n",
      "RMSE, train 0.23402757262471716, test 0.23862679863025335\n",
      "RMSE, train 0.23414916047441814, test 0.2387855713032494\n",
      "RMSE, train 0.23377375509816142, test 0.23767413863958406\n",
      "RMSE, train 0.23371730179258204, test 0.23878816336639658\n",
      "RMSE, train 0.23345950273005103, test 0.23779638000756256\n",
      "RMSE, train 0.23345147113990689, test 0.23698815107653456\n",
      "RMSE, train 0.23337680464874394, test 0.23806381022388284\n",
      "RMSE, train 0.23356502285973746, test 0.23762195791341056\n",
      "RMSE, train 0.2331520897988607, test 0.2370544707725856\n",
      "RMSE, train 0.23319977773768216, test 0.2377652270981103\n",
      "RMSE, train 0.23349829165921038, test 0.23730831069887176\n",
      "RMSE, train 0.23309815231605097, test 0.23903218441265672\n",
      "RMSE, train 0.23326557951598514, test 0.23890612292880856\n",
      "RMSE, train 0.23331965880114058, test 0.23824633633302264\n",
      "RMSE, train 0.2333730951645355, test 0.2378305452298527\n",
      "RMSE, train 0.233031887576165, test 0.23850559966623291\n",
      "Early stopping at epoch 33 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9105651845047469, test 0.7010860024837026\n",
      "RMSE, train 0.5113097162389043, test 0.3694413237665829\n",
      "RMSE, train 0.2850779599345315, test 0.2517675862631254\n",
      "RMSE, train 0.2421776470281422, test 0.2443759503463904\n",
      "RMSE, train 0.23832117686711396, test 0.24120494422682545\n",
      "RMSE, train 0.23572209351924436, test 0.23924306636316733\n",
      "RMSE, train 0.23435799054690262, test 0.2380599847488236\n",
      "RMSE, train 0.23307160259500495, test 0.23702755472377726\n",
      "RMSE, train 0.23212223058379788, test 0.23668795190097994\n",
      "RMSE, train 0.23152438304952974, test 0.2359849360951206\n",
      "RMSE, train 0.23108724005885725, test 0.23602997034526707\n",
      "RMSE, train 0.23113921594454537, test 0.23528832739643885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23126288087192629, test 0.23530116559643494\n",
      "RMSE, train 0.23063772640375693, test 0.2346882088142529\n",
      "RMSE, train 0.22982870537970365, test 0.23481931302108264\n",
      "RMSE, train 0.22949078482097146, test 0.23545934887308823\n",
      "RMSE, train 0.22982085164167734, test 0.23431764784873577\n",
      "RMSE, train 0.22943263507283318, test 0.23429933347200094\n",
      "RMSE, train 0.22895739581793356, test 0.23395365110614844\n",
      "RMSE, train 0.229405703733979, test 0.23392190941070257\n",
      "RMSE, train 0.22899207965270288, test 0.23371766141632147\n",
      "RMSE, train 0.22851595840156713, test 0.23383976460287445\n",
      "RMSE, train 0.22849449014930584, test 0.23351205800447547\n",
      "RMSE, train 0.22863735228395665, test 0.23352369934059025\n",
      "RMSE, train 0.22845010575391592, test 0.23345842552289628\n",
      "RMSE, train 0.22834376790630284, test 0.23393466317078523\n",
      "RMSE, train 0.22825558588448872, test 0.23365624706473268\n",
      "RMSE, train 0.22814235826735813, test 0.23364866002087006\n",
      "RMSE, train 0.22826880909232442, test 0.23326973773931203\n",
      "RMSE, train 0.2279935272485971, test 0.23385905507102348\n",
      "RMSE, train 0.22774990018941701, test 0.23375353099484192\n",
      "RMSE, train 0.22783949419951388, test 0.2332705561921262\n",
      "RMSE, train 0.22796850661034268, test 0.2331778067245818\n",
      "RMSE, train 0.22808781185193355, test 0.23315463894814775\n",
      "RMSE, train 0.22772275229125644, test 0.2337779610564834\n",
      "RMSE, train 0.22756287179140647, test 0.2333878532313464\n",
      "RMSE, train 0.22756883088967947, test 0.23318372157059217\n",
      "RMSE, train 0.22782539963912862, test 0.23320707384692996\n",
      "RMSE, train 0.22754828412649727, test 0.23426551031961776\n",
      "RMSE, train 0.2276801336516958, test 0.23329208320692965\n",
      "RMSE, train 0.2276793515154802, test 0.23349481984450107\n",
      "RMSE, train 0.22745239269186948, test 0.2331656874402573\n",
      "RMSE, train 0.22773638734621787, test 0.2331872617074272\n",
      "RMSE, train 0.2274634695129354, test 0.23317107963457442\n",
      "Early stopping at epoch 44 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.8456536860056311, test 0.5533561268273521\n",
      "RMSE, train 0.439007860094949, test 0.3896808427046327\n",
      "RMSE, train 0.2981076507978052, test 0.27629369263555487\n",
      "RMSE, train 0.25280969076054194, test 0.2552615951965837\n",
      "RMSE, train 0.24000471451615377, test 0.24574755701948614\n",
      "RMSE, train 0.23394275289517882, test 0.23984630719995967\n",
      "RMSE, train 0.23152671238687555, test 0.23753833639271119\n",
      "RMSE, train 0.23074143259010338, test 0.23753258826978066\n",
      "RMSE, train 0.22924376336017485, test 0.2355072834328109\n",
      "RMSE, train 0.22861217280631987, test 0.2346928037849127\n",
      "RMSE, train 0.22832965459630142, test 0.2344763617889554\n",
      "RMSE, train 0.22769897808109663, test 0.23471560015105733\n",
      "RMSE, train 0.2274069163708243, test 0.23433747106030875\n",
      "RMSE, train 0.22695313221586064, test 0.2338023472066019\n",
      "RMSE, train 0.22655247397240705, test 0.2337322882285305\n",
      "RMSE, train 0.22639918049935226, test 0.23315893544578084\n",
      "RMSE, train 0.22628720623923373, test 0.23343474615146131\n",
      "RMSE, train 0.22596058939408004, test 0.23344344127119757\n",
      "RMSE, train 0.22583332286174088, test 0.23335555970084434\n",
      "RMSE, train 0.22566663059528233, test 0.2330412785066109\n",
      "RMSE, train 0.2254466987381687, test 0.2325977085559976\n",
      "RMSE, train 0.22573715348801351, test 0.23232685774564743\n",
      "RMSE, train 0.22579739223232131, test 0.23279428087613163\n",
      "RMSE, train 0.22522625771655672, test 0.23198587958719216\n",
      "RMSE, train 0.22576696914676267, test 0.23387046304403566\n",
      "RMSE, train 0.22526670567389034, test 0.23256789111331397\n",
      "RMSE, train 0.2249953312030271, test 0.23194473828462994\n",
      "RMSE, train 0.22487235430245753, test 0.23286733060490852\n",
      "RMSE, train 0.22500125941129176, test 0.2319943015920181\n",
      "RMSE, train 0.224733134620514, test 0.23205658077609306\n",
      "RMSE, train 0.22535058064719657, test 0.23211436514176575\n",
      "RMSE, train 0.22442903246970622, test 0.2317617512216755\n",
      "RMSE, train 0.22462747098437927, test 0.23182107902625027\n",
      "RMSE, train 0.22464104032317322, test 0.23251314410099796\n",
      "RMSE, train 0.2245037235444087, test 0.23200026629310028\n",
      "RMSE, train 0.22473045025989946, test 0.23159170523285866\n",
      "RMSE, train 0.22440493378903814, test 0.23292248155556472\n",
      "RMSE, train 0.2243872660974614, test 0.2323506875511478\n",
      "RMSE, train 0.22439440140647365, test 0.23312759121843413\n",
      "RMSE, train 0.22458470280244414, test 0.2321711861181493\n",
      "RMSE, train 0.22435131669044495, test 0.23291027838108586\n",
      "RMSE, train 0.22457944546650588, test 0.23238731007657798\n",
      "RMSE, train 0.22477437902535347, test 0.23320370138275856\n",
      "RMSE, train 0.22448601730185647, test 0.23282244114899167\n",
      "RMSE, train 0.22438303260288261, test 0.2331457815918268\n",
      "RMSE, train 0.22417996480598654, test 0.23251562996530065\n",
      "Early stopping at epoch 46 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.8454454862062009, test 0.6826088492535363\n",
      "RMSE, train 0.5373918433643637, test 0.45870606022432814\n",
      "RMSE, train 0.3923701473601883, test 0.35946955217802823\n",
      "RMSE, train 0.3152578386568254, test 0.2983902814713391\n",
      "RMSE, train 0.28127050234545625, test 0.2770755570535817\n",
      "RMSE, train 0.27050410362801725, test 0.26967938262815316\n",
      "RMSE, train 0.2662659305328083, test 0.2667705078016628\n",
      "RMSE, train 0.2640212044390219, test 0.26546721505232096\n",
      "RMSE, train 0.2626177101065555, test 0.26374000003022596\n",
      "RMSE, train 0.26159183520282947, test 0.2626956728371707\n",
      "RMSE, train 0.2607373230219368, test 0.26187680809458425\n",
      "RMSE, train 0.2600427116417596, test 0.2616098507746192\n",
      "RMSE, train 0.2595416540880838, test 0.26091116426651145\n",
      "RMSE, train 0.25908641125105564, test 0.2603236242266726\n",
      "RMSE, train 0.2586703925663906, test 0.25993221148479084\n",
      "RMSE, train 0.25834804888994944, test 0.25967747219337906\n",
      "RMSE, train 0.25814636569890764, test 0.25922803075845574\n",
      "RMSE, train 0.2579354287065085, test 0.2589865650766152\n",
      "RMSE, train 0.2578826456390802, test 0.25898296552256117\n",
      "RMSE, train 0.2578096517301615, test 0.25888010268369\n",
      "RMSE, train 0.25750835235380837, test 0.2586649456792626\n",
      "RMSE, train 0.2574058065581466, test 0.25875819012645845\n",
      "RMSE, train 0.2574097740223571, test 0.25862953054510857\n",
      "RMSE, train 0.257277618252462, test 0.25864797535021444\n",
      "RMSE, train 0.2573056386693591, test 0.25835316868360375\n",
      "RMSE, train 0.25714698606621356, test 0.25875820970732316\n",
      "RMSE, train 0.25711231922069866, test 0.25835575637492264\n",
      "RMSE, train 0.2570511684753001, test 0.2584094848514588\n",
      "RMSE, train 0.2569296553941263, test 0.258768866993179\n",
      "RMSE, train 0.25702899045521216, test 0.25820914058645894\n",
      "RMSE, train 0.2569356750576727, test 0.2582936876199462\n",
      "RMSE, train 0.25688534567973786, test 0.2581297230622\n",
      "RMSE, train 0.2568519602439577, test 0.2581428077595293\n",
      "RMSE, train 0.2568963014430577, test 0.2584746297725961\n",
      "RMSE, train 0.2568081180384803, test 0.25807371082877323\n",
      "RMSE, train 0.2568426392521829, test 0.2581078385518602\n",
      "RMSE, train 0.25674845509591604, test 0.2581850728712791\n",
      "RMSE, train 0.25678363206586047, test 0.2584574258278224\n",
      "RMSE, train 0.256760609636624, test 0.25807720909187615\n",
      "RMSE, train 0.2566192289513926, test 0.2583262114362283\n",
      "RMSE, train 0.2567343596939839, test 0.2580801054589019\n",
      "RMSE, train 0.2565145295924477, test 0.2582687150594617\n",
      "RMSE, train 0.25660872198040446, test 0.2580207571510441\n",
      "RMSE, train 0.25651852957784166, test 0.2581283314661546\n",
      "RMSE, train 0.2566293176984595, test 0.25822697561388175\n",
      "RMSE, train 0.25645671141964776, test 0.25826541722313434\n",
      "RMSE, train 0.25654877716254804, test 0.2579885989058116\n",
      "RMSE, train 0.25642680373763843, test 0.2585944193453828\n",
      "RMSE, train 0.2565731642497403, test 0.25822446661547194\n",
      "RMSE, train 0.2564844050925345, test 0.25818855026044135\n",
      "RMSE, train 0.2564996804801687, test 0.2581056466649386\n",
      "RMSE, train 0.25632743361676413, test 0.2579403936493495\n",
      "RMSE, train 0.2564020928506169, test 0.2584056372731185\n",
      "RMSE, train 0.25641737241418133, test 0.25811515588405703\n",
      "RMSE, train 0.25633653402028067, test 0.2580934362716911\n",
      "RMSE, train 0.2563943713903427, test 0.2582113119688901\n",
      "RMSE, train 0.256445832475419, test 0.2580889605047289\n",
      "RMSE, train 0.25637013848210055, test 0.2580532339239909\n",
      "RMSE, train 0.2563716204867007, test 0.2582758979733325\n",
      "RMSE, train 0.25636604138379615, test 0.25825256626468057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2561732731429079, test 0.25800901183412095\n",
      "RMSE, train 0.25635046620042096, test 0.25815660974457244\n",
      "Early stopping at epoch 62 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9785679636661672, test 0.9192985086622885\n",
      "RMSE, train 0.8474866945512038, test 0.5835542443950298\n",
      "RMSE, train 0.34390155817112644, test 0.2683087078444028\n",
      "RMSE, train 0.2627921182862368, test 0.26303306171449564\n",
      "RMSE, train 0.25935382716172983, test 0.2593085429299686\n",
      "RMSE, train 0.25667428237593864, test 0.2573710443862414\n",
      "RMSE, train 0.2553377490613825, test 0.2555935783153873\n",
      "RMSE, train 0.2532042539101248, test 0.25384077985407943\n",
      "RMSE, train 0.2520337153749525, test 0.25237281317428006\n",
      "RMSE, train 0.2507828342736014, test 0.2516535539495743\n",
      "RMSE, train 0.249923220520054, test 0.25057044044389565\n",
      "RMSE, train 0.24915971810167487, test 0.2495559736833734\n",
      "RMSE, train 0.24884298352971057, test 0.24899559954212883\n",
      "RMSE, train 0.2477790460852552, test 0.24824971333146095\n",
      "RMSE, train 0.24736028891210712, test 0.24792259571663403\n",
      "RMSE, train 0.2467558836210365, test 0.24747414975348164\n",
      "RMSE, train 0.24612144145283324, test 0.24773168330222872\n",
      "RMSE, train 0.24584830287566856, test 0.24666124380241006\n",
      "RMSE, train 0.24569067519065763, test 0.24654210548279648\n",
      "RMSE, train 0.2452802588193377, test 0.2467789393612894\n",
      "RMSE, train 0.24507155606507763, test 0.24603556658504372\n",
      "RMSE, train 0.2448146313213366, test 0.2458127847541187\n",
      "RMSE, train 0.24457868028524493, test 0.24590535783919237\n",
      "RMSE, train 0.24434526644893423, test 0.24560501255978973\n",
      "RMSE, train 0.24417760557194879, test 0.24515836092375093\n",
      "RMSE, train 0.24437308513120679, test 0.24502271817902388\n",
      "RMSE, train 0.24406956307097408, test 0.24488465923626543\n",
      "RMSE, train 0.24374573568482538, test 0.2450157021945816\n",
      "RMSE, train 0.24419944520947362, test 0.24496501753643407\n",
      "RMSE, train 0.24339916985020166, test 0.24449189285100517\n",
      "RMSE, train 0.24358041983190154, test 0.24483299192230581\n",
      "RMSE, train 0.2433235278922664, test 0.24423472116054115\n",
      "RMSE, train 0.243676896892057, test 0.24439750700178792\n",
      "RMSE, train 0.24366443675042185, test 0.24429960624646332\n",
      "RMSE, train 0.24345538400359884, test 0.24449473417411416\n",
      "RMSE, train 0.24308396332458523, test 0.24448574264928447\n",
      "RMSE, train 0.24309371142409558, test 0.24456599253719136\n",
      "RMSE, train 0.24294777057510764, test 0.24429371479456707\n",
      "RMSE, train 0.2432679874006628, test 0.24382866458114932\n",
      "RMSE, train 0.24306949515911666, test 0.24377211505326174\n",
      "RMSE, train 0.24285936812785539, test 0.2441226097486787\n",
      "RMSE, train 0.24282759806710827, test 0.24397913215018935\n",
      "RMSE, train 0.24310500496490436, test 0.24457880747267755\n",
      "RMSE, train 0.24285473850024633, test 0.24394833006091038\n",
      "RMSE, train 0.2426755290540043, test 0.2439113032641047\n",
      "RMSE, train 0.24263746166709532, test 0.24380350744320176\n",
      "RMSE, train 0.2429543178805635, test 0.24386521687699578\n",
      "RMSE, train 0.2425506497802567, test 0.24410925256246227\n",
      "RMSE, train 0.24280848583468229, test 0.24362262382598246\n",
      "RMSE, train 0.24285405447845124, test 0.24409350525524656\n",
      "RMSE, train 0.24282703676438036, test 0.24411457347667823\n",
      "RMSE, train 0.24272063175939823, test 0.24392044670500998\n",
      "RMSE, train 0.2427997158239942, test 0.24403885398375785\n",
      "RMSE, train 0.24278645512978891, test 0.24371758747403904\n",
      "RMSE, train 0.24243636874189553, test 0.24398643877041543\n",
      "RMSE, train 0.24233308440643894, test 0.2438150214315471\n",
      "RMSE, train 0.24241513512597596, test 0.24423456109933933\n",
      "RMSE, train 0.24245209539355325, test 0.24429046501547602\n",
      "RMSE, train 0.2424281403607081, test 0.24434353928949873\n",
      "Early stopping at epoch 59 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.863353827420403, test 0.6608562514718089\n",
      "RMSE, train 0.5478095004663748, test 0.46457764665995327\n",
      "RMSE, train 0.3539785805416003, test 0.28416539249675615\n",
      "RMSE, train 0.2584716665166915, test 0.2569665047340095\n",
      "RMSE, train 0.24919367076784438, test 0.252551136006202\n",
      "RMSE, train 0.24660486036461163, test 0.25070215382480193\n",
      "RMSE, train 0.24487121575278653, test 0.24895614738176977\n",
      "RMSE, train 0.243534830189868, test 0.2479126720822283\n",
      "RMSE, train 0.24224158540400545, test 0.24713039098839676\n",
      "RMSE, train 0.24155671608863574, test 0.24558197055011988\n",
      "RMSE, train 0.2406791778269157, test 0.24458094792706625\n",
      "RMSE, train 0.24015657235269713, test 0.24447704652058228\n",
      "RMSE, train 0.23966937940689473, test 0.24436095583119563\n",
      "RMSE, train 0.23930773294829075, test 0.24385451804846525\n",
      "RMSE, train 0.23901054901040458, test 0.24296045802267535\n",
      "RMSE, train 0.23912526582710625, test 0.24310748844540545\n",
      "RMSE, train 0.2385494705119164, test 0.2419521857851318\n",
      "RMSE, train 0.2386003318273164, test 0.24224867099629982\n",
      "RMSE, train 0.23809031427945446, test 0.24295162190017955\n",
      "RMSE, train 0.23806631738778553, test 0.24215098304141844\n",
      "RMSE, train 0.2379932833068511, test 0.2425522339264197\n",
      "RMSE, train 0.2378951730226899, test 0.24137891908841475\n",
      "RMSE, train 0.2377361510931017, test 0.24279592212821757\n",
      "RMSE, train 0.23752292880305537, test 0.24134025563086783\n",
      "RMSE, train 0.2374025686666337, test 0.24110720359853335\n",
      "RMSE, train 0.23732932111601424, test 0.24112715372549637\n",
      "RMSE, train 0.23723346869865014, test 0.24078410305082798\n",
      "RMSE, train 0.23715012095267995, test 0.24069885297545365\n",
      "RMSE, train 0.23710097239427835, test 0.24075979859169042\n",
      "RMSE, train 0.2371595965491401, test 0.24125536817259022\n",
      "RMSE, train 0.23690502483535697, test 0.2408638001818742\n",
      "RMSE, train 0.23720761946928007, test 0.2411069931196315\n",
      "RMSE, train 0.2371898046765712, test 0.24127603894365685\n",
      "RMSE, train 0.23736450571185364, test 0.2403184173495642\n",
      "RMSE, train 0.23711695111395228, test 0.24028313964871423\n",
      "RMSE, train 0.23676896742940728, test 0.24194954854569264\n",
      "RMSE, train 0.2368204947033479, test 0.24048354383558035\n",
      "RMSE, train 0.2372229375383433, test 0.2405232491769961\n",
      "RMSE, train 0.23704233238055555, test 0.24019714484789542\n",
      "RMSE, train 0.23674617012991106, test 0.24060249168957984\n",
      "RMSE, train 0.23690875572576503, test 0.24024052285988415\n",
      "RMSE, train 0.23661912427423826, test 0.24002415487276657\n",
      "RMSE, train 0.2370875574697077, test 0.23995112428175552\n",
      "RMSE, train 0.2367149743054687, test 0.24041817071182386\n",
      "RMSE, train 0.23672152649862835, test 0.23954034337241734\n",
      "RMSE, train 0.23663841220418352, test 0.23995823399829014\n",
      "RMSE, train 0.23631866019795403, test 0.24040940364024468\n",
      "RMSE, train 0.23657360679443626, test 0.2411860720520573\n",
      "RMSE, train 0.23632725617140207, test 0.24048042842852219\n",
      "RMSE, train 0.23659226116531554, test 0.24038675207910792\n",
      "RMSE, train 0.2363892012237204, test 0.2399360158347658\n",
      "RMSE, train 0.23651841891552108, test 0.24018339367051209\n",
      "RMSE, train 0.23626955194410934, test 0.24060352678809846\n",
      "RMSE, train 0.23650530081299134, test 0.24037718107657774\n",
      "RMSE, train 0.2362651122583803, test 0.24017362748937948\n",
      "Early stopping at epoch 55 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.856604455444224, test 0.5970845652951134\n",
      "RMSE, train 0.3810653328749836, test 0.292783781735584\n",
      "RMSE, train 0.26495130227145475, test 0.2802184135323823\n",
      "RMSE, train 0.25649883323018885, test 0.2729190726472874\n",
      "RMSE, train 0.25180836921799155, test 0.2660816718231548\n",
      "RMSE, train 0.24782806183131809, test 0.26015043755372363\n",
      "RMSE, train 0.24468443254896946, test 0.2560860182751309\n",
      "RMSE, train 0.24275211503496963, test 0.252020133264137\n",
      "RMSE, train 0.24007422114497, test 0.2495436328228074\n",
      "RMSE, train 0.23881593013232377, test 0.24675204868268485\n",
      "RMSE, train 0.23721685218636157, test 0.24513736615578333\n",
      "RMSE, train 0.23696362899393209, test 0.24342518036413674\n",
      "RMSE, train 0.23537322233970706, test 0.242653523280163\n",
      "RMSE, train 0.23498169901099938, test 0.241860592079283\n",
      "RMSE, train 0.2342854560259502, test 0.24144925914629542\n",
      "RMSE, train 0.23406685415136202, test 0.24026760195541863\n",
      "RMSE, train 0.23429247547478432, test 0.24030250243165277\n",
      "RMSE, train 0.23347261256577043, test 0.23983124033971268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.23320480148264713, test 0.23954558086515676\n",
      "RMSE, train 0.23290482334665097, test 0.23942749119467205\n",
      "RMSE, train 0.2330625069789898, test 0.23908161364420497\n",
      "RMSE, train 0.23237244316665934, test 0.2389413086753903\n",
      "RMSE, train 0.23226759992630966, test 0.23887859661169727\n",
      "RMSE, train 0.2323513753293196, test 0.23884418712119865\n",
      "RMSE, train 0.2320436519231365, test 0.2384674186357344\n",
      "RMSE, train 0.23236405031532414, test 0.23898281473101993\n",
      "RMSE, train 0.231923091254928, test 0.23821716763154424\n",
      "RMSE, train 0.2319034168218925, test 0.2379665451519417\n",
      "RMSE, train 0.23165061215535354, test 0.2382635964889719\n",
      "RMSE, train 0.23155304820511335, test 0.237837937745181\n",
      "RMSE, train 0.23184132289988488, test 0.2379211958761167\n",
      "RMSE, train 0.23167071779301815, test 0.23799650235609573\n",
      "RMSE, train 0.23168563276237847, test 0.23784490388752233\n",
      "RMSE, train 0.2317303994028376, test 0.23788891853106142\n",
      "RMSE, train 0.23130886287662977, test 0.2379525676369667\n",
      "RMSE, train 0.2315547562097279, test 0.2377937813900938\n",
      "RMSE, train 0.23119472745068206, test 0.2379821217571846\n",
      "RMSE, train 0.23153417885376362, test 0.23769621972483818\n",
      "RMSE, train 0.23168031998834868, test 0.23776415110838534\n",
      "RMSE, train 0.231163613753243, test 0.23774547762039935\n",
      "RMSE, train 0.23107448522648194, test 0.23741393709423567\n",
      "RMSE, train 0.2308928829169215, test 0.23773152983248835\n",
      "RMSE, train 0.2319064404460212, test 0.23785276101394134\n",
      "RMSE, train 0.23095368001892397, test 0.23766189196495094\n",
      "RMSE, train 0.23118967081996222, test 0.2376154799654026\n",
      "RMSE, train 0.23077430415780154, test 0.23730272303024927\n",
      "RMSE, train 0.2308318842484782, test 0.23745040121403607\n",
      "RMSE, train 0.23078151506287545, test 0.23740930719809097\n",
      "RMSE, train 0.23071011866290295, test 0.23751185044194711\n",
      "RMSE, train 0.2307250629973878, test 0.23719515854662115\n",
      "RMSE, train 0.23061363256939466, test 0.23777915733029145\n",
      "RMSE, train 0.2308776184807197, test 0.23713223049134918\n",
      "RMSE, train 0.23067366411968665, test 0.23760554081562793\n",
      "RMSE, train 0.2305207171438667, test 0.23754910387174047\n",
      "RMSE, train 0.23092170003209544, test 0.23779677050282258\n",
      "RMSE, train 0.23037106485486322, test 0.23717851688464484\n",
      "RMSE, train 0.2307006015389939, test 0.2371615603415653\n",
      "RMSE, train 0.2303213516482514, test 0.23697300104781835\n",
      "RMSE, train 0.23034632991097667, test 0.23692165676391486\n",
      "RMSE, train 0.23038416405033074, test 0.23708495542858588\n",
      "RMSE, train 0.23048510808670725, test 0.23727584743138516\n",
      "RMSE, train 0.23039345166356756, test 0.23694850414088278\n",
      "RMSE, train 0.23058681231912015, test 0.23734999636206963\n",
      "RMSE, train 0.23017462839379288, test 0.23695065051016181\n",
      "RMSE, train 0.23030212517909723, test 0.23686476638822845\n",
      "RMSE, train 0.23040650163784004, test 0.23722765075437952\n",
      "RMSE, train 0.23062061886405594, test 0.23678402813396068\n",
      "RMSE, train 0.23040256390580338, test 0.23685491807533032\n",
      "RMSE, train 0.23025454566210582, test 0.23719968210266093\n",
      "RMSE, train 0.2306093266620904, test 0.23718559689293003\n",
      "RMSE, train 0.2302471774204436, test 0.23680360479788345\n",
      "RMSE, train 0.2308184468986644, test 0.2367327329185274\n",
      "RMSE, train 0.23050348242075344, test 0.2366462912071835\n",
      "RMSE, train 0.23028768231058472, test 0.23695915899794512\n",
      "RMSE, train 0.23030311497688877, test 0.23685521414183608\n",
      "RMSE, train 0.23028428499156514, test 0.2373879577475365\n",
      "RMSE, train 0.23022116961135258, test 0.23717308977637627\n",
      "RMSE, train 0.2304111275557784, test 0.23675359093179607\n",
      "RMSE, train 0.23019651778971362, test 0.23756207202119056\n",
      "RMSE, train 0.23004497901005966, test 0.2366587534697369\n",
      "RMSE, train 0.23053452633048035, test 0.23672510322296259\n",
      "RMSE, train 0.22983122494044397, test 0.23738040105260985\n",
      "RMSE, train 0.23027938376647628, test 0.23662782618493744\n",
      "RMSE, train 0.23000570860279218, test 0.23648364059250765\n",
      "RMSE, train 0.22969341311776842, test 0.23662340046480448\n",
      "RMSE, train 0.22999923399360372, test 0.2372554187672307\n",
      "RMSE, train 0.23001681025934687, test 0.23658107913503743\n",
      "RMSE, train 0.2302509108171195, test 0.2365641433632735\n",
      "RMSE, train 0.22996496558553722, test 0.2367046968352915\n",
      "RMSE, train 0.23041273358398662, test 0.23645727283725834\n",
      "RMSE, train 0.22977119090358902, test 0.23658248368236753\n",
      "RMSE, train 0.22989711438676838, test 0.23653107783710114\n",
      "RMSE, train 0.22988302211452522, test 0.23664055666839234\n",
      "RMSE, train 0.23045857737073105, test 0.2365548044744164\n",
      "RMSE, train 0.22959994071124526, test 0.23724547532772777\n",
      "RMSE, train 0.22982048214137699, test 0.23696748355422356\n",
      "RMSE, train 0.22995731411251288, test 0.236602394041991\n",
      "RMSE, train 0.22997531014287384, test 0.23668559256828192\n",
      "RMSE, train 0.2298645314311923, test 0.23689075205663238\n",
      "RMSE, train 0.2296711125372383, test 0.23691725806154387\n",
      "Early stopping at epoch 100 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9150226230710006, test 0.7881091830589003\n",
      "RMSE, train 0.6922112605419041, test 0.5511028933323036\n",
      "RMSE, train 0.4972735815489095, test 0.406799881008722\n",
      "RMSE, train 0.3864782995983096, test 0.3417876083719528\n",
      "RMSE, train 0.3350030700098877, test 0.31930713949062056\n",
      "RMSE, train 0.3158512958748774, test 0.3105206354442289\n",
      "RMSE, train 0.3063402081847437, test 0.30414957666801196\n",
      "RMSE, train 0.3008938532722883, test 0.2996872676126027\n",
      "RMSE, train 0.29693633416467463, test 0.2961655660706051\n",
      "RMSE, train 0.2932539928612138, test 0.2946922760141098\n",
      "RMSE, train 0.29035573020146405, test 0.2912881799926192\n",
      "RMSE, train 0.2879715809398446, test 0.2895691706720045\n",
      "RMSE, train 0.2867115644568747, test 0.287750090204053\n",
      "RMSE, train 0.28515686247159133, test 0.2864897118534072\n",
      "RMSE, train 0.2838929807844241, test 0.28523532680030594\n",
      "RMSE, train 0.28306517531433384, test 0.28460695657689694\n",
      "RMSE, train 0.2822627530641053, test 0.283715457355572\n",
      "RMSE, train 0.28133212186950296, test 0.28344399721945746\n",
      "RMSE, train 0.28091623229244034, test 0.2821904968912319\n",
      "RMSE, train 0.279977871228225, test 0.2823377979003777\n",
      "RMSE, train 0.2795238558757157, test 0.2810666789063963\n",
      "RMSE, train 0.2792103919085146, test 0.2806138585684663\n",
      "RMSE, train 0.2789409609034288, test 0.280385985465373\n",
      "RMSE, train 0.2782867162619248, test 0.2794643357648688\n",
      "RMSE, train 0.2780937158833604, test 0.2794805612351935\n",
      "RMSE, train 0.2776415168407781, test 0.2787923631021532\n",
      "RMSE, train 0.27742003543256233, test 0.2780564498093169\n",
      "RMSE, train 0.27729417477572754, test 0.27773880150358554\n",
      "RMSE, train 0.27680265669487725, test 0.27798178937223\n",
      "RMSE, train 0.2772782993741518, test 0.27758143097162247\n",
      "RMSE, train 0.2766589516204251, test 0.2774448101803408\n",
      "RMSE, train 0.2763188061542994, test 0.27693144333059505\n",
      "RMSE, train 0.276324393320059, test 0.276979871851913\n",
      "RMSE, train 0.27636374884154186, test 0.27654639189526187\n",
      "RMSE, train 0.2761883760594632, test 0.27635358526545056\n",
      "RMSE, train 0.27670591501596054, test 0.2760634682441162\n",
      "RMSE, train 0.2760298373408554, test 0.2762243778018628\n",
      "RMSE, train 0.2760805109254092, test 0.2763109378264112\n",
      "RMSE, train 0.27564037448056966, test 0.27572821850998924\n",
      "RMSE, train 0.2758130870667125, test 0.27570691300650774\n",
      "RMSE, train 0.27548337793978284, test 0.275416122402175\n",
      "RMSE, train 0.2754887501778435, test 0.27568427473306656\n",
      "RMSE, train 0.2758910979860085, test 0.27526569770554365\n",
      "RMSE, train 0.27546159644449547, test 0.2755624363988133\n",
      "RMSE, train 0.27555681875914584, test 0.2757003188006959\n",
      "RMSE, train 0.2756529371138693, test 0.27535013172586087\n",
      "RMSE, train 0.27544901826349666, test 0.27513525660260246\n",
      "RMSE, train 0.27536322410441627, test 0.27534561882079656\n",
      "RMSE, train 0.275824288429677, test 0.2750692651686022\n",
      "RMSE, train 0.27555335964237854, test 0.27521229926812446\n",
      "RMSE, train 0.2753392399311805, test 0.27525181386430386\n",
      "RMSE, train 0.275182729771684, test 0.27525053779452535\n",
      "RMSE, train 0.2755575763323337, test 0.2748871819447663\n",
      "RMSE, train 0.2751514656269107, test 0.27513020561408186\n",
      "RMSE, train 0.27550241634372835, test 0.27489959120245305\n",
      "RMSE, train 0.2758842979765628, test 0.27516586131463616\n",
      "RMSE, train 0.27529505555602635, test 0.2749415607649391\n",
      "RMSE, train 0.27556321212698603, test 0.27478427010572565\n",
      "RMSE, train 0.27515089961369177, test 0.2750945120292195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27510950859051103, test 0.27496574642294547\n",
      "RMSE, train 0.27552628226208786, test 0.2748547203965106\n",
      "RMSE, train 0.2750880178679858, test 0.275472505870512\n",
      "RMSE, train 0.27503210674078504, test 0.2746454747551579\n",
      "RMSE, train 0.2751899730291002, test 0.27531114372156434\n",
      "RMSE, train 0.2752560982403676, test 0.27488298941466766\n",
      "RMSE, train 0.2752924258551322, test 0.2750462301833145\n",
      "RMSE, train 0.2752132812006907, test 0.27460268506054153\n",
      "RMSE, train 0.27531524174962163, test 0.274741129223573\n",
      "RMSE, train 0.27587850402640407, test 0.2748450699372817\n",
      "RMSE, train 0.27529643722309555, test 0.2752029583868334\n",
      "RMSE, train 0.275224051307425, test 0.27491551056756813\n",
      "RMSE, train 0.27524082144060413, test 0.2745482782691212\n",
      "RMSE, train 0.27522335224592487, test 0.27485003309734796\n",
      "RMSE, train 0.2750921320508827, test 0.2751498222351074\n",
      "RMSE, train 0.2750456499720901, test 0.2751743374234539\n",
      "RMSE, train 0.2751834993212184, test 0.2746347377108315\n",
      "RMSE, train 0.27558198055514127, test 0.27490432042691665\n",
      "RMSE, train 0.2751177053375185, test 0.2749512880030325\n",
      "RMSE, train 0.27480800680754597, test 0.2753131194513733\n",
      "RMSE, train 0.274875852348637, test 0.2746109515428543\n",
      "RMSE, train 0.27535611178633596, test 0.27475795768580197\n",
      "RMSE, train 0.27496880337534363, test 0.2749580267374798\n",
      "Early stopping at epoch 82 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.000909095230629, test 0.8439792785955512\n",
      "RMSE, train 0.7636750391714132, test 0.6350145303684732\n",
      "RMSE, train 0.5848244378014987, test 0.4594901934913967\n",
      "RMSE, train 0.3976518771197892, test 0.3162162730227346\n",
      "RMSE, train 0.2957642323114057, test 0.2867506134769191\n",
      "RMSE, train 0.2764318446349946, test 0.2789556359467299\n",
      "RMSE, train 0.2700891189134804, test 0.27416622055613477\n",
      "RMSE, train 0.2665547600565696, test 0.27108576777188675\n",
      "RMSE, train 0.264102195684191, test 0.2682445257902145\n",
      "RMSE, train 0.2623133680559774, test 0.2664897020096364\n",
      "RMSE, train 0.2611229666320888, test 0.2667287554429925\n",
      "RMSE, train 0.26044166534189966, test 0.26517001934673473\n",
      "RMSE, train 0.25991584506131027, test 0.2648421420999195\n",
      "RMSE, train 0.25938487188957804, test 0.26380191710980044\n",
      "RMSE, train 0.2590627224993301, test 0.26424991047900653\n",
      "RMSE, train 0.25868606651221615, test 0.2632574544652649\n",
      "RMSE, train 0.2585608826163215, test 0.2636617493370305\n",
      "RMSE, train 0.2582436477777305, test 0.2625474125794742\n",
      "RMSE, train 0.25808803224639526, test 0.26171189540106315\n",
      "RMSE, train 0.2579691890635055, test 0.2625013177809508\n",
      "RMSE, train 0.25754139197480147, test 0.26327087179474207\n",
      "RMSE, train 0.2577248791315753, test 0.2622103272572808\n",
      "RMSE, train 0.2574980848027896, test 0.26116844882135803\n",
      "RMSE, train 0.2575092326430505, test 0.26173053111719047\n",
      "RMSE, train 0.25725679396950263, test 0.2607795316240062\n",
      "RMSE, train 0.25726173846584977, test 0.2611712933882423\n",
      "RMSE, train 0.25708774532608675, test 0.2618446619614311\n",
      "RMSE, train 0.25703880954889735, test 0.2604014110306035\n",
      "RMSE, train 0.25700225562426693, test 0.2607470487770827\n",
      "RMSE, train 0.25689141200796056, test 0.2609870698141015\n",
      "RMSE, train 0.2568604260398324, test 0.2601786104881245\n",
      "RMSE, train 0.2568692423545631, test 0.2602592075648515\n",
      "RMSE, train 0.25664020120907743, test 0.2601767703242924\n",
      "RMSE, train 0.2567641467425474, test 0.26030246472877006\n",
      "RMSE, train 0.25661825909103303, test 0.2599565980227097\n",
      "RMSE, train 0.2566085564103096, test 0.26148719800555187\n",
      "RMSE, train 0.25642676491709526, test 0.259813454941563\n",
      "RMSE, train 0.2565812071164449, test 0.25975741951361947\n",
      "RMSE, train 0.25651650837842066, test 0.25957181090893955\n",
      "RMSE, train 0.25644094462164396, test 0.2599550949490589\n",
      "RMSE, train 0.2563819341092606, test 0.25942971771178036\n",
      "RMSE, train 0.25650744945317067, test 0.2603215822707052\n",
      "RMSE, train 0.2563455178068195, test 0.2606498067793639\n",
      "RMSE, train 0.25643278642571404, test 0.2598509679669919\n",
      "RMSE, train 0.2564468085133093, test 0.2600932519720948\n",
      "RMSE, train 0.25636608792654775, test 0.25959979153197743\n",
      "RMSE, train 0.2562533818707345, test 0.25955037604207576\n",
      "RMSE, train 0.25633080306832706, test 0.2598099217466686\n",
      "RMSE, train 0.2562669200502383, test 0.2596167372620624\n",
      "RMSE, train 0.256319858038881, test 0.25961919556493346\n",
      "RMSE, train 0.2562467493037762, test 0.2595992646139601\n",
      "Early stopping at epoch 51 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.8877059083615718, test 0.6510510923118766\n",
      "RMSE, train 0.4997249703035761, test 0.4547449056435069\n",
      "RMSE, train 0.42249230171800195, test 0.4350024640833566\n",
      "RMSE, train 0.40481825493643636, test 0.41753986040386587\n",
      "RMSE, train 0.3898176849222504, test 0.402667504384977\n",
      "RMSE, train 0.3762174317855471, test 0.3880371666009273\n",
      "RMSE, train 0.36379308714594005, test 0.37645892429789274\n",
      "RMSE, train 0.35276306129891777, test 0.3642603213633966\n",
      "RMSE, train 0.34272793763956144, test 0.35326683808357345\n",
      "RMSE, train 0.33370683101661536, test 0.34650038538175987\n",
      "RMSE, train 0.3256122761911341, test 0.3376830857281291\n",
      "RMSE, train 0.3183460824960016, test 0.327990302662237\n",
      "RMSE, train 0.3117243288410619, test 0.32002170684687586\n",
      "RMSE, train 0.3059029039914298, test 0.31358402092522436\n",
      "RMSE, train 0.3004927554339037, test 0.3086503536329357\n",
      "RMSE, train 0.29569338211965135, test 0.30306963034726064\n",
      "RMSE, train 0.2914493622700997, test 0.2979496683959567\n",
      "RMSE, train 0.28767578495925317, test 0.2957826099537928\n",
      "RMSE, train 0.28399755493341006, test 0.29131806511944586\n",
      "RMSE, train 0.28092774712050445, test 0.28693121466614785\n",
      "RMSE, train 0.2781677661722551, test 0.28337638644040175\n",
      "RMSE, train 0.27572795194093425, test 0.2835582695696332\n",
      "RMSE, train 0.2734693920598971, test 0.2795801395123158\n",
      "RMSE, train 0.271509500245476, test 0.2791951902962606\n",
      "RMSE, train 0.2696468576521617, test 0.27656333777335806\n",
      "RMSE, train 0.26804307044688364, test 0.2780754722039634\n",
      "RMSE, train 0.26667719930744493, test 0.2735586728934848\n",
      "RMSE, train 0.26532047784849666, test 0.274205999363453\n",
      "RMSE, train 0.26424971886079407, test 0.27296259288394126\n",
      "RMSE, train 0.263226134811148, test 0.2694501617086043\n",
      "RMSE, train 0.2623166816785197, test 0.26876165095819243\n",
      "RMSE, train 0.2614965402759244, test 0.26794770742775104\n",
      "RMSE, train 0.26056793079849316, test 0.26977226281658223\n",
      "RMSE, train 0.25995872014373406, test 0.26773121269471056\n",
      "RMSE, train 0.2592971204642223, test 0.26584331896326957\n",
      "RMSE, train 0.25879078166300407, test 0.2677664879812013\n",
      "RMSE, train 0.25827280381869844, test 0.2649058413888336\n",
      "RMSE, train 0.2577691432840354, test 0.2649604380130768\n",
      "RMSE, train 0.2572959717780753, test 0.2632823948739865\n",
      "RMSE, train 0.25676272106210746, test 0.26316838937068204\n",
      "RMSE, train 0.256432330611709, test 0.2639291003483151\n",
      "RMSE, train 0.2561188622006119, test 0.2634180663922511\n",
      "RMSE, train 0.25586755278065065, test 0.263603928575822\n",
      "RMSE, train 0.25548957956478735, test 0.2629343756568541\n",
      "RMSE, train 0.25516801033453024, test 0.2644547083235662\n",
      "RMSE, train 0.25498194583261496, test 0.2608722816776792\n",
      "RMSE, train 0.25468253320909934, test 0.26332682002028196\n",
      "RMSE, train 0.254605155104078, test 0.26250155967309935\n",
      "RMSE, train 0.2543362171593803, test 0.26161508337346784\n",
      "RMSE, train 0.25399302935119167, test 0.2626768660928131\n",
      "RMSE, train 0.2538175505540029, test 0.2607814744798415\n",
      "RMSE, train 0.2537489842974284, test 0.261614444742509\n",
      "RMSE, train 0.25360950430011536, test 0.2601155281545372\n",
      "RMSE, train 0.25330761886899245, test 0.26060864206300965\n",
      "RMSE, train 0.2531273943526595, test 0.2614049674994355\n",
      "RMSE, train 0.2531312173190673, test 0.26023654065547736\n",
      "RMSE, train 0.253003976103169, test 0.2604602885629059\n",
      "RMSE, train 0.252749315007786, test 0.2607185269167664\n",
      "RMSE, train 0.2526938912913938, test 0.2607388487512912\n",
      "RMSE, train 0.2525867623832461, test 0.2598184492746624\n",
      "RMSE, train 0.25247927106950313, test 0.2591071905346092\n",
      "RMSE, train 0.25236407964753466, test 0.259706692753035\n",
      "RMSE, train 0.2522595536314586, test 0.2603382670551265\n",
      "RMSE, train 0.2521677534910328, test 0.26068247745343304\n",
      "RMSE, train 0.2520702137808094, test 0.2600739245567847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.25191319185923033, test 0.26052826752356434\n",
      "RMSE, train 0.2518997305979109, test 0.2586433698824786\n",
      "RMSE, train 0.25180330358011305, test 0.25904482855982736\n",
      "RMSE, train 0.2516530399198222, test 0.2599327087128928\n",
      "RMSE, train 0.25153073608340704, test 0.26042266463467834\n",
      "RMSE, train 0.2516053712053951, test 0.2599067544444985\n",
      "RMSE, train 0.251487932364235, test 0.2589439984855302\n",
      "RMSE, train 0.2515077744798543, test 0.25996762657657674\n",
      "RMSE, train 0.2513535607422414, test 0.2582272637054461\n",
      "RMSE, train 0.2513504637396924, test 0.259075742385803\n",
      "RMSE, train 0.2511107705767379, test 0.25930488690597203\n",
      "RMSE, train 0.2510383444349595, test 0.25991183697083675\n",
      "RMSE, train 0.2512118848617034, test 0.2592147170403682\n",
      "RMSE, train 0.25098394552421144, test 0.25918977085603484\n",
      "RMSE, train 0.2509293313985983, test 0.2580217298701269\n",
      "RMSE, train 0.2509846149906182, test 0.2589718017282836\n",
      "RMSE, train 0.2509737401332021, test 0.25851397339357146\n",
      "RMSE, train 0.25092005061461786, test 0.25857257596943356\n",
      "RMSE, train 0.250793819770952, test 0.2594249541059547\n",
      "RMSE, train 0.25068014009851514, test 0.2589254073046763\n",
      "RMSE, train 0.25076940253109675, test 0.258633471205147\n",
      "RMSE, train 0.2507062024299072, test 0.2600704810214699\n",
      "RMSE, train 0.25056724388970925, test 0.2576869254538772\n",
      "RMSE, train 0.2505591057341195, test 0.2586388617343859\n",
      "RMSE, train 0.2504632376100985, test 0.2589149920765413\n",
      "RMSE, train 0.25051067754492634, test 0.25833310091167416\n",
      "RMSE, train 0.2503583215912094, test 0.2574267819387103\n",
      "RMSE, train 0.2504312026861537, test 0.25858620376488484\n",
      "RMSE, train 0.25037465328058317, test 0.2602717618056394\n",
      "RMSE, train 0.25036295774004386, test 0.2580642711815484\n",
      "RMSE, train 0.25035186955546584, test 0.2597334103983477\n",
      "RMSE, train 0.25029191698862296, test 0.26021977725925793\n",
      "RMSE, train 0.25021805659337426, test 0.2584994191286761\n",
      "RMSE, train 0.2502037389830356, test 0.25848854654425873\n",
      "RMSE, train 0.2501101521733363, test 0.25899840071113833\n",
      "RMSE, train 0.2501242221771602, test 0.2580839027778818\n",
      "RMSE, train 0.2501946553220396, test 0.25800232144944163\n",
      "Early stopping at epoch 102 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.8354338461702521, test 0.64224204638352\n",
      "RMSE, train 0.6242729152242342, test 0.5193267585709691\n",
      "RMSE, train 0.4147431521742332, test 0.3103241777668397\n",
      "RMSE, train 0.28105641135738957, test 0.295441306506594\n",
      "RMSE, train 0.2720830591790604, test 0.29257941727216047\n",
      "RMSE, train 0.2688815362111788, test 0.28878603611762327\n",
      "RMSE, train 0.2663408022637319, test 0.2835206415814658\n",
      "RMSE, train 0.2634033119362412, test 0.2802283151540905\n",
      "RMSE, train 0.26108657297762955, test 0.27760121746299166\n",
      "RMSE, train 0.2587553413603643, test 0.27514083140219253\n",
      "RMSE, train 0.25689942871380334, test 0.2718133527475099\n",
      "RMSE, train 0.2552274429625032, test 0.2692915349422644\n",
      "RMSE, train 0.25357555195388165, test 0.26771541265770793\n",
      "RMSE, train 0.2523397969815767, test 0.2655118221106629\n",
      "RMSE, train 0.25130335629136874, test 0.26291666777494055\n",
      "RMSE, train 0.25027595808484937, test 0.26121215817208093\n",
      "RMSE, train 0.24956059517959753, test 0.2606970168805371\n",
      "RMSE, train 0.24875217939567085, test 0.2588289960597952\n",
      "RMSE, train 0.24812689732120494, test 0.25829334937346476\n",
      "RMSE, train 0.2475977020545138, test 0.25764300068840384\n",
      "RMSE, train 0.24718854916893473, test 0.25693196648110944\n",
      "RMSE, train 0.24684000912715087, test 0.2560117724351585\n",
      "RMSE, train 0.24655284939540756, test 0.2555738541608055\n",
      "RMSE, train 0.2463309336641822, test 0.2551643728899459\n",
      "RMSE, train 0.2461997534176617, test 0.2554545945798357\n",
      "RMSE, train 0.2459156826853451, test 0.2548469918159147\n",
      "RMSE, train 0.24575886517913656, test 0.2541126358943681\n",
      "RMSE, train 0.24556945503284835, test 0.25382835247243446\n",
      "RMSE, train 0.24529344197174516, test 0.25441269933556515\n",
      "RMSE, train 0.24531051535347495, test 0.25382265999602777\n",
      "RMSE, train 0.24517540631796977, test 0.2546002665379395\n",
      "RMSE, train 0.24500036975274783, test 0.2539550221990794\n",
      "RMSE, train 0.24521334442977955, test 0.2536636497825384\n",
      "RMSE, train 0.24479605635684548, test 0.2546437407533328\n",
      "RMSE, train 0.24486689886661492, test 0.2535944387006263\n",
      "RMSE, train 0.24482336107904862, test 0.25338798101680976\n",
      "RMSE, train 0.24475341337272014, test 0.25361770081023377\n",
      "RMSE, train 0.24460761139940734, test 0.25337884287970763\n",
      "RMSE, train 0.24462650891280535, test 0.25387762067839503\n",
      "RMSE, train 0.2444179453369644, test 0.25374215360110003\n",
      "RMSE, train 0.24446240964938293, test 0.2524486449547112\n",
      "RMSE, train 0.2445423532503121, test 0.2529041970459123\n",
      "RMSE, train 0.244452657987072, test 0.25250239949673414\n",
      "RMSE, train 0.24426554638252715, test 0.2533222306519747\n",
      "RMSE, train 0.24413145724872146, test 0.2522034392071267\n",
      "RMSE, train 0.24419931098442488, test 0.252933567079405\n",
      "RMSE, train 0.24421715826699228, test 0.25256167848904926\n",
      "RMSE, train 0.2441730254113373, test 0.2522729228561123\n",
      "RMSE, train 0.24420415124658382, test 0.25289727312823135\n",
      "RMSE, train 0.2441518400993311, test 0.25393343282242614\n",
      "RMSE, train 0.24411833577911662, test 0.2522140128227572\n",
      "RMSE, train 0.24391730474025913, test 0.2522213599489381\n",
      "RMSE, train 0.24405194478429326, test 0.25275340722873807\n",
      "RMSE, train 0.24390836756187256, test 0.2524516358971596\n",
      "RMSE, train 0.24392939469955785, test 0.25223474064841866\n",
      "Early stopping at epoch 55 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.1661118237800847, test 1.02080935133355\n",
      "RMSE, train 0.9102490691707544, test 0.7411158686237675\n",
      "RMSE, train 0.6010609693451904, test 0.45351423629160437\n",
      "RMSE, train 0.38281843270741256, test 0.35224681600396124\n",
      "RMSE, train 0.33369066713941903, test 0.3438781364155667\n",
      "RMSE, train 0.3266209141718536, test 0.33973413932004143\n",
      "RMSE, train 0.32316786875392356, test 0.3349021457667862\n",
      "RMSE, train 0.32137550290243816, test 0.3332950494119099\n",
      "RMSE, train 0.31838812477773054, test 0.3306747478033815\n",
      "RMSE, train 0.3167413516144607, test 0.3285986744532628\n",
      "RMSE, train 0.3155662442409395, test 0.3279501883579152\n",
      "RMSE, train 0.31435613324439604, test 0.32807986424969776\n",
      "RMSE, train 0.31414427741355627, test 0.3273227084428072\n",
      "RMSE, train 0.3142366073619826, test 0.32740163962755886\n",
      "RMSE, train 0.3135297426341146, test 0.32683057471045424\n",
      "RMSE, train 0.3139023887468319, test 0.32517809034990414\n",
      "RMSE, train 0.3129610440050595, test 0.32674299406685997\n",
      "RMSE, train 0.31305298108550716, test 0.32559155034167425\n",
      "RMSE, train 0.3126008909252474, test 0.3250543312834842\n",
      "RMSE, train 0.3126810821410358, test 0.3267964973513569\n",
      "RMSE, train 0.31246056281078877, test 0.32581574389977114\n",
      "RMSE, train 0.3121928289240482, test 0.3247226926365069\n",
      "RMSE, train 0.31231080485844664, test 0.32456702805523363\n",
      "RMSE, train 0.31333083279576956, test 0.3235226046027882\n",
      "RMSE, train 0.31188947129548245, test 0.3239753242315991\n",
      "RMSE, train 0.31154813747325494, test 0.3255754489717739\n",
      "RMSE, train 0.31202154439389057, test 0.3247646114655903\n",
      "RMSE, train 0.31216891814420944, test 0.3242504158988595\n",
      "RMSE, train 0.3117218286383386, test 0.32500353508761953\n",
      "RMSE, train 0.3115502153087026, test 0.32483701274863314\n",
      "RMSE, train 0.3117233387849949, test 0.324838873265045\n",
      "RMSE, train 0.3117787860382616, test 0.3229865983926824\n",
      "RMSE, train 0.31165823929644876, test 0.32297178344534977\n",
      "RMSE, train 0.31140888357344276, test 0.32271821557411123\n",
      "RMSE, train 0.3113178559994905, test 0.3241764224533524\n",
      "RMSE, train 0.31132615859212437, test 0.32463851677519934\n",
      "RMSE, train 0.31118998187949193, test 0.32365216926804613\n",
      "RMSE, train 0.3112096970572191, test 0.3222427440008947\n",
      "RMSE, train 0.3115488718342937, test 0.32351004438740866\n",
      "RMSE, train 0.3115072792521749, test 0.3227524110781295\n",
      "RMSE, train 0.31204384967911997, test 0.323704322400902\n",
      "RMSE, train 0.31120944396472966, test 0.3239217029352273\n",
      "RMSE, train 0.31114144485305856, test 0.3239399261240448\n",
      "RMSE, train 0.31094290187870494, test 0.32332437206059694\n",
      "RMSE, train 0.3113042778925958, test 0.3240301430092326\n",
      "RMSE, train 0.3114375143204379, test 0.32397895958274603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.31103059568306457, test 0.32256291686956373\n",
      "RMSE, train 0.31072764673264197, test 0.3237359595618078\n",
      "Early stopping at epoch 48 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9644869328079737, test 0.8169990832652521\n",
      "RMSE, train 0.6942929741780319, test 0.5544104026545078\n",
      "RMSE, train 0.48252278646546093, test 0.470367874300808\n",
      "RMSE, train 0.42775198229225225, test 0.4334237728643855\n",
      "RMSE, train 0.39494844863500295, test 0.4014869421173673\n",
      "RMSE, train 0.3696604063024435, test 0.38053404040839695\n",
      "RMSE, train 0.3499543748695754, test 0.359635052330997\n",
      "RMSE, train 0.33534605172984805, test 0.34667007214979295\n",
      "RMSE, train 0.3248756867353157, test 0.33706926246848673\n",
      "RMSE, train 0.31742730147034065, test 0.3324020324497048\n",
      "RMSE, train 0.311878898552715, test 0.3254866583631673\n",
      "RMSE, train 0.3083764364767502, test 0.32322917523187233\n",
      "RMSE, train 0.3056111152663894, test 0.3205073145004587\n",
      "RMSE, train 0.30361447332953123, test 0.31877844261193494\n",
      "RMSE, train 0.3021506690190512, test 0.3174775251007955\n",
      "RMSE, train 0.30074951064359445, test 0.3156166551036572\n",
      "RMSE, train 0.2996387445271817, test 0.3154466349050539\n",
      "RMSE, train 0.29878990205146805, test 0.3152100755534041\n",
      "RMSE, train 0.2981987759270476, test 0.312694743822474\n",
      "RMSE, train 0.29766407147918583, test 0.315483495593071\n",
      "RMSE, train 0.29714006140427207, test 0.3139165615269897\n",
      "RMSE, train 0.2966551417192536, test 0.31274652617787\n",
      "RMSE, train 0.2962567990169664, test 0.3120647485649914\n",
      "RMSE, train 0.29581189777017175, test 0.3130221051087073\n",
      "RMSE, train 0.29556808109507965, test 0.3144978399670452\n",
      "RMSE, train 0.29540315059936634, test 0.31082928467781173\n",
      "RMSE, train 0.29497223263898775, test 0.31313412561329135\n",
      "RMSE, train 0.2947067975864282, test 0.3135945315754742\n",
      "RMSE, train 0.2947137956194279, test 0.3117699836372235\n",
      "RMSE, train 0.29450670319020483, test 0.31045666815490897\n",
      "RMSE, train 0.29429270794840673, test 0.3110495787968329\n",
      "RMSE, train 0.2942182706009112, test 0.3108795948258234\n",
      "RMSE, train 0.29412409395914973, test 0.31125838015604457\n",
      "RMSE, train 0.2939032619743871, test 0.31125647308082754\n",
      "RMSE, train 0.2938688820720788, test 0.3111826784293586\n",
      "RMSE, train 0.29371063070446923, test 0.3113339645873516\n",
      "RMSE, train 0.2937111351722559, test 0.30969084498532323\n",
      "RMSE, train 0.29353065277562546, test 0.3084975348426661\n",
      "RMSE, train 0.2934597006961369, test 0.3094944818577635\n",
      "RMSE, train 0.29350189423614553, test 0.3100061649029408\n",
      "RMSE, train 0.2933995183306692, test 0.3102170989054059\n",
      "RMSE, train 0.2933835380881891, test 0.3109390760233643\n",
      "RMSE, train 0.29317906627540097, test 0.31219215732102\n",
      "RMSE, train 0.29327686364875244, test 0.31295668504653723\n",
      "RMSE, train 0.2932202468204391, test 0.3099118959192836\n",
      "RMSE, train 0.29311696318032493, test 0.31080761893626746\n",
      "RMSE, train 0.29310380343364495, test 0.309949884105713\n",
      "RMSE, train 0.29309960685236036, test 0.30897500960651886\n",
      "Early stopping at epoch 48 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9957267714226331, test 0.794988589090051\n",
      "RMSE, train 0.6083208805662436, test 0.40387584970703405\n",
      "RMSE, train 0.33549663243979005, test 0.33874554295563003\n",
      "RMSE, train 0.30829135409939035, test 0.335479867111132\n",
      "RMSE, train 0.3038800351870315, test 0.3263184546483952\n",
      "RMSE, train 0.3010088327095231, test 0.32551167204578235\n",
      "RMSE, train 0.29923144911997673, test 0.3260873093188388\n",
      "RMSE, train 0.29759532910486297, test 0.319892063628412\n",
      "RMSE, train 0.29641491850736307, test 0.3226427074196269\n",
      "RMSE, train 0.29558265095935016, test 0.3212806842859509\n",
      "RMSE, train 0.29462886061917576, test 0.31676298506485606\n",
      "RMSE, train 0.2940679320671779, test 0.31746691928326504\n",
      "RMSE, train 0.2935027716384931, test 0.3196884045033779\n",
      "RMSE, train 0.2929196978372803, test 0.31655273492475156\n",
      "RMSE, train 0.29223878058713293, test 0.31806669839956225\n",
      "RMSE, train 0.2916349063576542, test 0.31620613261333946\n",
      "RMSE, train 0.2913224849664117, test 0.3139392102806314\n",
      "RMSE, train 0.290809826319263, test 0.3127691757331774\n",
      "RMSE, train 0.29048383103201336, test 0.3184783681503777\n",
      "RMSE, train 0.29015378220418286, test 0.31215684000149513\n",
      "RMSE, train 0.2898220213532731, test 0.3125567583783159\n",
      "RMSE, train 0.28952349963069246, test 0.3129428502136064\n",
      "RMSE, train 0.28927952440504223, test 0.3087168005701986\n",
      "RMSE, train 0.2890970880727587, test 0.3125341909313665\n",
      "RMSE, train 0.2887454503116302, test 0.3159650562747011\n",
      "RMSE, train 0.2885675275269144, test 0.3096047688311743\n",
      "RMSE, train 0.28839901031267046, test 0.30993817703237814\n",
      "RMSE, train 0.28827531741945306, test 0.3083007044873191\n",
      "RMSE, train 0.28811174639967446, test 0.3108973963168061\n",
      "RMSE, train 0.2878008207700032, test 0.3069765212972766\n",
      "RMSE, train 0.2878459785620277, test 0.3077634049995432\n",
      "RMSE, train 0.28764752932158333, test 0.3112228122151014\n",
      "RMSE, train 0.2874695339954664, test 0.31047440949574256\n",
      "RMSE, train 0.2874325770805114, test 0.3103806544276117\n",
      "RMSE, train 0.2873849750025255, test 0.305796077131357\n",
      "RMSE, train 0.28733779387349473, test 0.30652895005582603\n",
      "RMSE, train 0.28717177345322314, test 0.30898235014920095\n",
      "RMSE, train 0.28713774958939564, test 0.30769144143294364\n",
      "RMSE, train 0.28705165841375563, test 0.3070045486815925\n",
      "RMSE, train 0.28696541251026253, test 0.3058506685842588\n",
      "RMSE, train 0.28711143897010144, test 0.3061512681899719\n",
      "RMSE, train 0.2866844738039438, test 0.3090862202123531\n",
      "RMSE, train 0.28684380960223793, test 0.30644680501766575\n",
      "RMSE, train 0.2867466544382929, test 0.3091958094279743\n",
      "RMSE, train 0.2867134787549316, test 0.30721094929477544\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.1841671625076922, test 1.0668162769741483\n",
      "RMSE, train 0.917660182537737, test 0.659238933192359\n",
      "RMSE, train 0.49977004046067397, test 0.4103439134028223\n",
      "RMSE, train 0.3602108377009389, test 0.38030797160334057\n",
      "RMSE, train 0.32991085669422404, test 0.3538851237959332\n",
      "RMSE, train 0.3103056878172805, test 0.33658823106024\n",
      "RMSE, train 0.2990371534686204, test 0.32462233967251247\n",
      "RMSE, train 0.2933936776176617, test 0.3187703029976951\n",
      "RMSE, train 0.28988701265777217, test 0.31476815425687366\n",
      "RMSE, train 0.2876752710165682, test 0.312108353111479\n",
      "RMSE, train 0.2858330598979626, test 0.3102180351813634\n",
      "RMSE, train 0.28411397988584164, test 0.30624195006158617\n",
      "RMSE, train 0.28275503742325336, test 0.3068672150373459\n",
      "RMSE, train 0.28177137321458673, test 0.3034241878324085\n",
      "RMSE, train 0.2808631106889794, test 0.30204532659716077\n",
      "RMSE, train 0.2799497402180237, test 0.3010947465068764\n",
      "RMSE, train 0.27921079348200417, test 0.3004726617700524\n",
      "RMSE, train 0.2785329946048176, test 0.2991009435719914\n",
      "RMSE, train 0.2780489584586691, test 0.2980379142695003\n",
      "RMSE, train 0.2774953527069799, test 0.2984309155080054\n",
      "RMSE, train 0.2770706173785613, test 0.29739297959539623\n",
      "RMSE, train 0.27667414682171737, test 0.29579620709021887\n",
      "RMSE, train 0.2762673395382105, test 0.2952206580175294\n",
      "RMSE, train 0.2760109719280605, test 0.29614330695735086\n",
      "RMSE, train 0.2757818899908156, test 0.2958831528822581\n",
      "RMSE, train 0.27556351084272174, test 0.2961921284596125\n",
      "RMSE, train 0.27536380692633655, test 0.2949271218644248\n",
      "RMSE, train 0.2751423521946383, test 0.29470059159729217\n",
      "RMSE, train 0.2748969491480817, test 0.29445357388920257\n",
      "RMSE, train 0.27476698252550674, test 0.29572575986385347\n",
      "RMSE, train 0.27468042244326396, test 0.2937909318341149\n",
      "RMSE, train 0.27440794089412435, test 0.2935473798049821\n",
      "RMSE, train 0.27427723322997516, test 0.2937961315943135\n",
      "RMSE, train 0.274237287092723, test 0.29513739893833796\n",
      "RMSE, train 0.2741315637155363, test 0.29351079679197734\n",
      "RMSE, train 0.2739462388975601, test 0.29441623704300984\n",
      "RMSE, train 0.27369473910717307, test 0.2930622104141447\n",
      "RMSE, train 0.2736440438104447, test 0.29261823677354387\n",
      "RMSE, train 0.2734729582368524, test 0.29364646590418286\n",
      "RMSE, train 0.27342488618713184, test 0.2929153804977735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.27339453479109427, test 0.2931923983825578\n",
      "RMSE, train 0.27317339936999296, test 0.2950329340166516\n",
      "RMSE, train 0.27303713644450567, test 0.2923826641506619\n",
      "RMSE, train 0.27307226942636253, test 0.2935121553639571\n",
      "RMSE, train 0.2728409471135898, test 0.29286915908257166\n",
      "RMSE, train 0.2727511222110283, test 0.2944419079356723\n",
      "RMSE, train 0.27275156012844204, test 0.29404479447338316\n",
      "RMSE, train 0.27251095202251907, test 0.29280212339427736\n",
      "RMSE, train 0.27252275334053605, test 0.2925519206457668\n",
      "RMSE, train 0.2723421181710261, test 0.29181886861721673\n",
      "RMSE, train 0.272208684698912, test 0.2908540699217055\n",
      "RMSE, train 0.2721883232060147, test 0.2925754095117251\n",
      "RMSE, train 0.27201261791096865, test 0.2927607382337252\n",
      "RMSE, train 0.27180902555464415, test 0.2920410279598501\n",
      "RMSE, train 0.27190428176980136, test 0.29200565897756153\n",
      "RMSE, train 0.2716800269452388, test 0.29204162773158815\n",
      "RMSE, train 0.2716399205903801, test 0.29155389269193016\n",
      "RMSE, train 0.2715162449689567, test 0.291816992395454\n",
      "RMSE, train 0.27147816967048416, test 0.29171500934494865\n",
      "RMSE, train 0.27139615315713006, test 0.29230285609761875\n",
      "RMSE, train 0.2710962412010306, test 0.2940479396118058\n",
      "Early stopping at epoch 61 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.0090207747550348, test 0.9629624407700818\n",
      "RMSE, train 0.9633795225532831, test 0.9091700643602044\n",
      "RMSE, train 0.8757298736671364, test 0.7959077836889209\n",
      "RMSE, train 0.7422790400556364, test 0.7008413079411092\n",
      "RMSE, train 0.651149813951082, test 0.6449288328488668\n",
      "RMSE, train 0.5682849274870819, test 0.5406005045380256\n",
      "RMSE, train 0.47038315014326193, test 0.49083144541340645\n",
      "RMSE, train 0.4441953754658221, test 0.4804908630221781\n",
      "RMSE, train 0.43507953141166994, test 0.4715439627567927\n",
      "RMSE, train 0.430183356031229, test 0.4672580794854598\n",
      "RMSE, train 0.42721958709812397, test 0.46294343260803605\n",
      "RMSE, train 0.4257537834801709, test 0.45995052414711074\n",
      "RMSE, train 0.42415477291733245, test 0.4596344500479072\n",
      "RMSE, train 0.42345372490894534, test 0.45735582498588945\n",
      "RMSE, train 0.4230564032979583, test 0.45740084831762795\n",
      "RMSE, train 0.4227053517598686, test 0.4572614925076263\n",
      "RMSE, train 0.42159047850332515, test 0.4558696603835231\n",
      "RMSE, train 0.42129880222685473, test 0.4564011578608041\n",
      "RMSE, train 0.4211601647741929, test 0.45532723960250315\n",
      "RMSE, train 0.422207196359238, test 0.45393682444336436\n",
      "RMSE, train 0.42098550050357736, test 0.4556422250138389\n",
      "RMSE, train 0.42026346011091853, test 0.4542998903327518\n",
      "RMSE, train 0.4202975568095163, test 0.45409933545372705\n",
      "RMSE, train 0.41986093941556796, test 0.45416652433799976\n",
      "RMSE, train 0.41952827824211353, test 0.45313993006041553\n",
      "RMSE, train 0.4196910173939609, test 0.4532392943146253\n",
      "RMSE, train 0.42097159935967554, test 0.4527075683528727\n",
      "RMSE, train 0.4201652194876543, test 0.45299792289733887\n",
      "RMSE, train 0.4200637633832568, test 0.4535147084130181\n",
      "RMSE, train 0.41930897052975913, test 0.45277849772963863\n",
      "RMSE, train 0.41943148222995563, test 0.4528680383557021\n",
      "RMSE, train 0.4191243882794252, test 0.452817271905716\n",
      "RMSE, train 0.4196111971198201, test 0.45293894139203156\n",
      "RMSE, train 0.41942514264204683, test 0.4540631455002409\n",
      "RMSE, train 0.41893640448382546, test 0.45252289796116374\n",
      "RMSE, train 0.419023951629409, test 0.452477251640474\n",
      "RMSE, train 0.41939280147511687, test 0.4527376325744571\n",
      "RMSE, train 0.4190841074896325, test 0.45171641129435913\n",
      "RMSE, train 0.41847512579561735, test 0.4525126214280273\n",
      "RMSE, train 0.41924554204299574, test 0.45281432042218217\n",
      "RMSE, train 0.41927802679299725, test 0.4526883446507984\n",
      "RMSE, train 0.4183704165199858, test 0.4536433650387658\n",
      "RMSE, train 0.4184768998899786, test 0.45185215003562695\n",
      "RMSE, train 0.41946846862439713, test 0.4521696495287346\n",
      "RMSE, train 0.4186557380523542, test 0.4525186148556796\n",
      "RMSE, train 0.41837504819436294, test 0.4518755885085674\n",
      "RMSE, train 0.4186130942080015, test 0.4526280363400777\n",
      "RMSE, train 0.41842280331917087, test 0.45116405189037323\n",
      "RMSE, train 0.41876523648468383, test 0.4511355066841299\n",
      "RMSE, train 0.4186715878600888, test 0.45143020604595996\n",
      "RMSE, train 0.4183430460379584, test 0.45343627261393\n",
      "RMSE, train 0.4193456068197789, test 0.45275588815260415\n",
      "RMSE, train 0.4187565207991448, test 0.4527113652891583\n",
      "RMSE, train 0.42005570844945234, test 0.45148792983305575\n",
      "RMSE, train 0.41880719800887306, test 0.4519179534129422\n",
      "RMSE, train 0.41954623337625585, test 0.45232999987072414\n",
      "RMSE, train 0.4195457556282687, test 0.4517358117031329\n",
      "RMSE, train 0.4183337315370518, test 0.45166078104515267\n",
      "RMSE, train 0.4184672602231462, test 0.45177990273393764\n",
      "Early stopping at epoch 59 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.9291193403980949, test 0.77409443911165\n",
      "RMSE, train 0.7159719083345297, test 0.6230578143149614\n",
      "RMSE, train 0.6025454973181089, test 0.5512217835833629\n",
      "RMSE, train 0.5384547501952961, test 0.5068449269359311\n",
      "RMSE, train 0.49477013083870963, test 0.483569447727253\n",
      "RMSE, train 0.4626694451453108, test 0.46862252879266936\n",
      "RMSE, train 0.44110808498931653, test 0.4635778159524004\n",
      "RMSE, train 0.42817265619382716, test 0.46076492747912806\n",
      "RMSE, train 0.4213279184668955, test 0.4598387965622048\n",
      "RMSE, train 0.41701845896213946, test 0.45714985579252243\n",
      "RMSE, train 0.4141438268501349, test 0.4561292372333507\n",
      "RMSE, train 0.4120434634387493, test 0.45405374374240637\n",
      "RMSE, train 0.41072725617524347, test 0.45150308155765134\n",
      "RMSE, train 0.40952369943261147, test 0.45211749772230786\n",
      "RMSE, train 0.4086047231097414, test 0.4502683603204787\n",
      "RMSE, train 0.4077120772515885, test 0.44755371458207566\n",
      "RMSE, train 0.4070034114399342, test 0.44757243680457276\n",
      "RMSE, train 0.40630868020834343, test 0.44692427028591436\n",
      "RMSE, train 0.4055280066424548, test 0.4458974458587666\n",
      "RMSE, train 0.4051229647840514, test 0.4458510611827175\n",
      "RMSE, train 0.4044433853993512, test 0.4447319114891191\n",
      "RMSE, train 0.4042868592748136, test 0.4443289133099218\n",
      "RMSE, train 0.40393567070214437, test 0.44189499504864216\n",
      "RMSE, train 0.4036448463195502, test 0.44359910193209845\n",
      "RMSE, train 0.4035414212355108, test 0.4420807803981006\n",
      "RMSE, train 0.4032351192877148, test 0.4420193725576003\n",
      "RMSE, train 0.4030079392321182, test 0.4416923248209059\n",
      "RMSE, train 0.40290615662480844, test 0.44095276373748976\n",
      "RMSE, train 0.40277226468679883, test 0.44161584849158925\n",
      "RMSE, train 0.40243979407982394, test 0.44203037209808826\n",
      "RMSE, train 0.40238786221604156, test 0.4405109866832693\n",
      "RMSE, train 0.4023939351165535, test 0.44205282131830853\n",
      "RMSE, train 0.40222166734512405, test 0.44024194823578\n",
      "RMSE, train 0.4021353040153932, test 0.44066264185433585\n",
      "RMSE, train 0.4021019833632792, test 0.4405883053938548\n",
      "RMSE, train 0.4020335600532667, test 0.44008122322460014\n",
      "RMSE, train 0.401912935454436, test 0.4398549860343337\n",
      "RMSE, train 0.401819925303712, test 0.44116339708367985\n",
      "RMSE, train 0.4016382387566446, test 0.4399160050476591\n",
      "RMSE, train 0.4016119782446009, test 0.4405061996852358\n",
      "RMSE, train 0.4015829781766492, test 0.4389047163228194\n",
      "RMSE, train 0.40154899280480666, test 0.4397135123920937\n",
      "RMSE, train 0.4013470939238264, test 0.440488931722939\n",
      "RMSE, train 0.40137707396890177, test 0.43864776690800983\n",
      "RMSE, train 0.40129787975338976, test 0.44010474408666295\n",
      "RMSE, train 0.40126293916443384, test 0.4394246415855984\n",
      "RMSE, train 0.4012383595108986, test 0.44027369655668736\n",
      "RMSE, train 0.4011403134450166, test 0.4385306453332305\n",
      "RMSE, train 0.40098182322702025, test 0.43887988897040486\n",
      "RMSE, train 0.4010323691322948, test 0.4385692165233195\n",
      "RMSE, train 0.4010256661309136, test 0.4384263039877017\n",
      "RMSE, train 0.40107682588124516, test 0.4386266757113238\n",
      "RMSE, train 0.40084279200645406, test 0.44025631605957943\n",
      "RMSE, train 0.4010235107306278, test 0.43877928238362074\n",
      "RMSE, train 0.4007987938445024, test 0.44076769969736534\n",
      "RMSE, train 0.40088929819187735, test 0.4383114723799129\n",
      "RMSE, train 0.40094311422470846, test 0.4398134265405436\n",
      "RMSE, train 0.4009100826400699, test 0.4395385483900706\n",
      "RMSE, train 0.4006649537595234, test 0.43891067802906036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.4007165101591987, test 0.43856618848318857\n",
      "RMSE, train 0.4006053087009926, test 0.4390570435983439\n",
      "RMSE, train 0.4005250021664783, test 0.4387647745509942\n",
      "RMSE, train 0.4005729596346918, test 0.43943133965755504\n",
      "RMSE, train 0.40068130405864333, test 0.4387185702410837\n",
      "RMSE, train 0.4005630427237713, test 0.4391026571393013\n",
      "RMSE, train 0.4005440534139522, test 0.43821409639591974\n",
      "RMSE, train 0.40057980762136103, test 0.43825941532850266\n",
      "RMSE, train 0.4005255975356006, test 0.4404775265914698\n",
      "RMSE, train 0.40059212335582933, test 0.4399796443370481\n",
      "RMSE, train 0.40043885565616866, test 0.4382732260661821\n",
      "RMSE, train 0.40032875613130703, test 0.4390915430461367\n",
      "RMSE, train 0.40032458674125, test 0.4378415768345197\n",
      "RMSE, train 0.4002918082505766, test 0.4392007696442306\n",
      "RMSE, train 0.400361116034816, test 0.43802877453466255\n",
      "RMSE, train 0.40030260907128606, test 0.4385072626173496\n",
      "RMSE, train 0.40048777214204423, test 0.4376146161618332\n",
      "RMSE, train 0.4002444814852994, test 0.43917286085585755\n",
      "RMSE, train 0.4004070773494966, test 0.4375668531283736\n",
      "RMSE, train 0.4002205573323399, test 0.4398362558955948\n",
      "RMSE, train 0.4003237544963456, test 0.4381837947294116\n",
      "RMSE, train 0.40019779814162637, test 0.43967218153799575\n",
      "RMSE, train 0.4003354692549417, test 0.43832137746115524\n",
      "RMSE, train 0.40018672695515134, test 0.43912259458253783\n",
      "RMSE, train 0.4001682737108433, test 0.43840994002918404\n",
      "RMSE, train 0.40004255884148254, test 0.43784155634542304\n",
      "RMSE, train 0.40018092050696863, test 0.438385923858732\n",
      "RMSE, train 0.4001836586705964, test 0.43747559702023864\n",
      "RMSE, train 0.400207115318438, test 0.440407145768404\n",
      "RMSE, train 0.4000104077988201, test 0.43939390949284035\n",
      "RMSE, train 0.4003016651805603, test 0.43890336916471523\n",
      "RMSE, train 0.40018171380565626, test 0.4397417788083355\n",
      "RMSE, train 0.4000572721765499, test 0.4404105016340812\n",
      "RMSE, train 0.4003321662394687, test 0.4384498870931566\n",
      "RMSE, train 0.4000718039319371, test 0.4386425473106404\n",
      "RMSE, train 0.3999597803887093, test 0.4398115129830937\n",
      "RMSE, train 0.40004730533168775, test 0.4388153301551938\n",
      "RMSE, train 0.3999710904453138, test 0.4391354958837231\n",
      "Early stopping at epoch 97 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.1904507609551165, test 1.0600126107533774\n",
      "RMSE, train 0.9955219600721189, test 0.856152159637875\n",
      "RMSE, train 0.7695647124652913, test 0.6197645240359836\n",
      "RMSE, train 0.5362241087817761, test 0.46901269753774005\n",
      "RMSE, train 0.434603668166942, test 0.46612448659208083\n",
      "RMSE, train 0.419761996063582, test 0.4596747203005685\n",
      "RMSE, train 0.41504001055123674, test 0.46115325159496734\n",
      "RMSE, train 0.41221835261406603, test 0.4572032105591562\n",
      "RMSE, train 0.4102504918115801, test 0.4563351492087046\n",
      "RMSE, train 0.40881992274056866, test 0.45347058011425867\n",
      "RMSE, train 0.4074959289433179, test 0.45472034530507194\n",
      "RMSE, train 0.40672659163044467, test 0.45236487239599227\n",
      "RMSE, train 0.40574551580569174, test 0.4537428870797157\n",
      "RMSE, train 0.40509598621862597, test 0.4535034904877345\n",
      "RMSE, train 0.40453475669548516, test 0.45045736564530264\n",
      "RMSE, train 0.4037154100815241, test 0.4522064495417807\n",
      "RMSE, train 0.4033074687031723, test 0.4482181128528383\n",
      "RMSE, train 0.4027457543299847, test 0.4481274770365821\n",
      "RMSE, train 0.40222548779772943, test 0.4453881185915735\n",
      "RMSE, train 0.4018120228681924, test 0.4471359595656395\n",
      "RMSE, train 0.40151197003386413, test 0.44843815879689325\n",
      "RMSE, train 0.4010519885791923, test 0.4472687375214365\n",
      "RMSE, train 0.4008132937462182, test 0.44754202365875245\n",
      "RMSE, train 0.40033779082433235, test 0.4453223930464851\n",
      "RMSE, train 0.39998746568944576, test 0.4445812627673149\n",
      "RMSE, train 0.39963660961534136, test 0.44505481951766546\n",
      "RMSE, train 0.3996090161993176, test 0.4456411671307352\n",
      "RMSE, train 0.3992180998996904, test 0.4450958862900734\n",
      "RMSE, train 0.3990336867435923, test 0.44517270310057533\n",
      "RMSE, train 0.39906030162325445, test 0.4461624859107865\n",
      "RMSE, train 0.39861065848175725, test 0.44504003375768664\n",
      "RMSE, train 0.3982329728066761, test 0.443168049885167\n",
      "RMSE, train 0.398142229594953, test 0.44549852394395406\n",
      "RMSE, train 0.39816037021235956, test 0.4454072685705291\n",
      "RMSE, train 0.39796586929145206, test 0.44238010727696947\n",
      "RMSE, train 0.39794077742292555, test 0.44330161892705494\n",
      "RMSE, train 0.39789702042415137, test 0.44162603418032326\n",
      "RMSE, train 0.3975436949745985, test 0.4434635470310847\n",
      "RMSE, train 0.3974977470633155, test 0.4436634749174118\n",
      "RMSE, train 0.3974255378837534, test 0.44370227654774985\n",
      "RMSE, train 0.3973213694085972, test 0.44272120661205716\n",
      "RMSE, train 0.3973307987509391, test 0.44214675658278996\n",
      "RMSE, train 0.3970861780354276, test 0.4408862714966138\n",
      "RMSE, train 0.3971287439855925, test 0.44206250955661136\n",
      "RMSE, train 0.396804840175932, test 0.4457274905509419\n",
      "RMSE, train 0.3968403466306928, test 0.4438618982831637\n",
      "RMSE, train 0.39672401475135205, test 0.44208593120177586\n",
      "RMSE, train 0.3966847438455592, test 0.4428491519557105\n",
      "RMSE, train 0.39683515287313176, test 0.44224962211317487\n",
      "RMSE, train 0.396630192220693, test 0.44294111960464055\n",
      "RMSE, train 0.396473155550237, test 0.44111137257681954\n",
      "RMSE, train 0.3962570977098537, test 0.44349338230159546\n",
      "RMSE, train 0.39655298918405313, test 0.44001308100091086\n",
      "RMSE, train 0.3965870841654806, test 0.443403434753418\n",
      "RMSE, train 0.39632728985056404, test 0.4403553576933013\n",
      "RMSE, train 0.3960923799928629, test 0.4426513892081049\n",
      "RMSE, train 0.39611198373560635, test 0.44455012761884266\n",
      "RMSE, train 0.3960628180571322, test 0.4408122440179189\n",
      "RMSE, train 0.3959766531167326, test 0.4436525488893191\n",
      "RMSE, train 0.39568528733806146, test 0.4430623441934586\n",
      "RMSE, train 0.3959834359164508, test 0.44209475451045566\n",
      "RMSE, train 0.39588829688225796, test 0.4424786976642079\n",
      "RMSE, train 0.3958195938334632, test 0.4402969098753399\n",
      "Early stopping at epoch 63 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.9982310449965647, test 0.8968242108821869\n",
      "RMSE, train 0.8641481204567668, test 0.8085992844440998\n",
      "RMSE, train 0.7773280360988367, test 0.7161592894639724\n",
      "RMSE, train 0.7107124475768051, test 0.6751323239161418\n",
      "RMSE, train 0.6148289650492951, test 0.5354768819151781\n",
      "RMSE, train 0.48155130859104645, test 0.4564624283558283\n",
      "RMSE, train 0.41625793904901665, test 0.4433186170764459\n",
      "RMSE, train 0.40092332600804503, test 0.4417115281789731\n",
      "RMSE, train 0.3963137765261243, test 0.44435958296824724\n",
      "RMSE, train 0.39322767822170557, test 0.4407164725737694\n",
      "RMSE, train 0.39099110885758265, test 0.4464211951081569\n",
      "RMSE, train 0.38904354380112943, test 0.4288366242096974\n",
      "RMSE, train 0.38698616558888993, test 0.4291861179547432\n",
      "RMSE, train 0.3858282684908478, test 0.42949614826685345\n",
      "RMSE, train 0.3845883672389657, test 0.42555321256319684\n",
      "RMSE, train 0.3831514559245184, test 0.42031182769017345\n",
      "RMSE, train 0.3821873233140072, test 0.4271246301822173\n",
      "RMSE, train 0.38125476677469744, test 0.4200383900449826\n",
      "RMSE, train 0.380661825014052, test 0.4203904830874541\n",
      "RMSE, train 0.37993665930823745, test 0.419867768119543\n",
      "RMSE, train 0.3793586137417321, test 0.42318899356401884\n",
      "RMSE, train 0.37880469334088385, test 0.4161466645697753\n",
      "RMSE, train 0.37841566895770135, test 0.41847001360012936\n",
      "RMSE, train 0.37789531172807345, test 0.41165316138321006\n",
      "RMSE, train 0.3774770475993647, test 0.4173706265596243\n",
      "RMSE, train 0.37725029444768793, test 0.4252616035250517\n",
      "RMSE, train 0.37699009427029023, test 0.41572943759652287\n",
      "RMSE, train 0.37668586506093404, test 0.4227934793019906\n",
      "RMSE, train 0.3761991520537023, test 0.4123841022642759\n",
      "RMSE, train 0.37611219175508087, test 0.41355759440324247\n",
      "RMSE, train 0.37587325052123205, test 0.41475739501989806\n",
      "RMSE, train 0.3755860712808612, test 0.41681972719155824\n",
      "RMSE, train 0.3755136035220274, test 0.4128441075101877\n",
      "RMSE, train 0.3753803847734802, test 0.4111773996398999\n",
      "RMSE, train 0.37497599344015864, test 0.408533380074331\n",
      "RMSE, train 0.3750595426726564, test 0.4128033908513876\n",
      "RMSE, train 0.3747370660397865, test 0.40928514015216094\n",
      "RMSE, train 0.37464795913837406, test 0.4186403919488956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.3745249137050266, test 0.4089011314014594\n",
      "RMSE, train 0.3740609826699967, test 0.4144121748514665\n",
      "RMSE, train 0.3741019390453802, test 0.41007254215387196\n",
      "RMSE, train 0.37388612747749433, test 0.41117809063349015\n",
      "RMSE, train 0.37403086477722336, test 0.41133043069679004\n",
      "RMSE, train 0.37388266381630647, test 0.4114988226539049\n",
      "RMSE, train 0.37381657893041215, test 0.4103356510018691\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.MLP, data_dir = 'data_synthetic', only_one = True)\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/mlp/'+'output_size' + str(output) + 'input_size' + str(inputs) + '_singlevar.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf63eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.0388226437827814, test 0.9823458959018031\n",
      "RMSE, train 0.9881572818214243, test 0.9547313744983366\n",
      "RMSE, train 0.9541317095516227, test 0.8923820386971196\n",
      "RMSE, train 0.7904460393039605, test 0.6088620823237204\n",
      "RMSE, train 0.48244342732099676, test 0.38954358764233127\n",
      "RMSE, train 0.3611674599290601, test 0.32880157100096824\n",
      "RMSE, train 0.3170258354233659, test 0.3066683774513583\n",
      "RMSE, train 0.2938137413425879, test 0.2861885917523215\n",
      "RMSE, train 0.2795271896444291, test 0.2771848593988726\n",
      "RMSE, train 0.2733554068967523, test 0.26875790484970613\n",
      "RMSE, train 0.2711200496630942, test 0.2716198663317388\n",
      "RMSE, train 0.2660335302794639, test 0.26900798857452407\n",
      "RMSE, train 0.26338563030475215, test 0.270724700283139\n",
      "RMSE, train 0.2620842077809831, test 0.2690396920567559\n",
      "RMSE, train 0.2606278508018128, test 0.2661669358250595\n",
      "RMSE, train 0.2613460391524281, test 0.26726988132201857\n",
      "RMSE, train 0.2604763441877403, test 0.26809164022486054\n",
      "RMSE, train 0.2589090561766634, test 0.26589035771546826\n",
      "RMSE, train 0.2575907087019781, test 0.2639468505738243\n",
      "RMSE, train 0.25904043208763533, test 0.26528169214725494\n",
      "RMSE, train 0.2575687932019884, test 0.26305243475062234\n",
      "RMSE, train 0.25790047030086105, test 0.26265085380404224\n",
      "RMSE, train 0.2569232190786143, test 0.25899412314737996\n",
      "RMSE, train 0.2568047221882541, test 0.2600414810041266\n",
      "RMSE, train 0.2565359948534268, test 0.26408519896288074\n",
      "RMSE, train 0.2558968398616955, test 0.26224634772346866\n",
      "RMSE, train 0.25692050091244956, test 0.2615698789877276\n",
      "RMSE, train 0.2546185503452427, test 0.26133582644885583\n",
      "RMSE, train 0.25562071155300253, test 0.26238937712004107\n",
      "RMSE, train 0.25509810076636286, test 0.26080673668653737\n",
      "RMSE, train 0.2554664389329701, test 0.2604396522285477\n",
      "RMSE, train 0.25484440967499505, test 0.2591425914677881\n",
      "RMSE, train 0.2555380616587377, test 0.26199893569273336\n",
      "Early stopping at epoch 33 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.0076262727681442, test 0.9682446013797413\n",
      "RMSE, train 0.9748346409213687, test 0.9246297005779487\n",
      "RMSE, train 0.8845197662771472, test 0.7664323059980535\n",
      "RMSE, train 0.6655844749226744, test 0.5353146623974004\n",
      "RMSE, train 0.48072248350391505, test 0.41390927554654683\n",
      "RMSE, train 0.39114276238298606, test 0.3539470588126458\n",
      "RMSE, train 0.33932922240572905, test 0.32140860146234845\n",
      "RMSE, train 0.3069767168900262, test 0.2920911946326248\n",
      "RMSE, train 0.2862361302290127, test 0.2786014583115735\n",
      "RMSE, train 0.2725608315364069, test 0.2723071354726129\n",
      "RMSE, train 0.26214776189643363, test 0.2573004205180101\n",
      "RMSE, train 0.25703788283262174, test 0.25925810555042317\n",
      "RMSE, train 0.2531958304134458, test 0.25452224454603906\n",
      "RMSE, train 0.25176625181487217, test 0.25375852838528057\n",
      "RMSE, train 0.247488302649998, test 0.2518022597944441\n",
      "RMSE, train 0.24700339907697338, test 0.2486604681192351\n",
      "RMSE, train 0.24392865418724202, test 0.24904578025183402\n",
      "RMSE, train 0.24395421927093494, test 0.24841089177230172\n",
      "RMSE, train 0.24197657060948943, test 0.24304812894133496\n",
      "RMSE, train 0.24060264338365933, test 0.24629555734967398\n",
      "RMSE, train 0.24100756014768893, test 0.2458657132199973\n",
      "RMSE, train 0.2400209349297319, test 0.24201843111721938\n",
      "RMSE, train 0.23996101126738406, test 0.24439419535073367\n",
      "RMSE, train 0.23953524427978615, test 0.24709962123681692\n",
      "RMSE, train 0.23978445653309707, test 0.2423414688957624\n",
      "RMSE, train 0.23842683413371382, test 0.2457640608233854\n",
      "RMSE, train 0.23899518647174603, test 0.24169040896183203\n",
      "RMSE, train 0.23793031460782776, test 0.24301272335131308\n",
      "RMSE, train 0.23857521870539256, test 0.24168891589011043\n",
      "RMSE, train 0.23739861567252077, test 0.24227704600361752\n",
      "RMSE, train 0.2368768379544681, test 0.24266762760552493\n",
      "RMSE, train 0.23746174085236754, test 0.24333576002150528\n",
      "RMSE, train 0.23648652282019375, test 0.23869196824298416\n",
      "RMSE, train 0.23705131166920004, test 0.24096428799974032\n",
      "RMSE, train 0.2373329805971881, test 0.24128381396867027\n",
      "RMSE, train 0.2370904096466327, test 0.24130899600746217\n",
      "RMSE, train 0.23615661451992717, test 0.2440819558033273\n",
      "RMSE, train 0.23653196997427747, test 0.24273208516442085\n",
      "RMSE, train 0.23662487993597503, test 0.24173106277777143\n",
      "RMSE, train 0.23576984400691292, test 0.24033111303059523\n",
      "RMSE, train 0.2354406767679371, test 0.24236741403410259\n",
      "RMSE, train 0.23606093016713253, test 0.24163903511506468\n",
      "RMSE, train 0.235336899832796, test 0.24108829189184283\n",
      "Early stopping at epoch 43 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.0667637301914727, test 0.9849309638926858\n",
      "RMSE, train 0.9962759187607877, test 0.9584747678355167\n",
      "RMSE, train 0.9640022719592682, test 0.9126016215274209\n",
      "RMSE, train 0.8770064644849123, test 0.7864204394189935\n",
      "RMSE, train 0.7039552916214664, test 0.5881748779823905\n",
      "RMSE, train 0.5249102054628482, test 0.4399926487291068\n",
      "RMSE, train 0.4147446963197387, test 0.37573415001756266\n",
      "RMSE, train 0.35688665378957923, test 0.32908064937382414\n",
      "RMSE, train 0.31371495759944673, test 0.29400102585031274\n",
      "RMSE, train 0.2865123942907431, test 0.2766746592364813\n",
      "RMSE, train 0.26935497190016927, test 0.26497878957735865\n",
      "RMSE, train 0.2604220060905668, test 0.26030371442698597\n",
      "RMSE, train 0.2531022951960055, test 0.2529397829059969\n",
      "RMSE, train 0.2506653712724826, test 0.2526196327648665\n",
      "RMSE, train 0.2474936523448938, test 0.24825875689847426\n",
      "RMSE, train 0.24424079762720097, test 0.24928984764898032\n",
      "RMSE, train 0.24419104312655768, test 0.24875462787193164\n",
      "RMSE, train 0.24066633241834925, test 0.24842744196454683\n",
      "RMSE, train 0.24178072522634636, test 0.24709357791825345\n",
      "RMSE, train 0.2395539686941643, test 0.24465830035899816\n",
      "RMSE, train 0.23842999192951583, test 0.24544343639884078\n",
      "RMSE, train 0.23714814230259548, test 0.24505558237433434\n",
      "RMSE, train 0.2369091783695892, test 0.2421389488143879\n",
      "RMSE, train 0.23614394623460547, test 0.243313515264737\n",
      "RMSE, train 0.23595946884231528, test 0.2445546810825666\n",
      "RMSE, train 0.23652842752079464, test 0.2412767352111507\n",
      "RMSE, train 0.2358387323743753, test 0.24131634726858975\n",
      "RMSE, train 0.23558023718120194, test 0.2397376075387001\n",
      "RMSE, train 0.2344695366680749, test 0.2412273004128222\n",
      "RMSE, train 0.23509071293924408, test 0.2410796523878449\n",
      "RMSE, train 0.23451476166052604, test 0.24209124542642058\n",
      "RMSE, train 0.23459890967747296, test 0.23958103803166172\n",
      "RMSE, train 0.23325429470744977, test 0.24036248498841337\n",
      "RMSE, train 0.23295738560749268, test 0.2427889982467158\n",
      "RMSE, train 0.2346461723163438, test 0.23943777035987168\n",
      "RMSE, train 0.23250918751205207, test 0.23929821203152338\n",
      "RMSE, train 0.2320765053063059, test 0.23882866572392614\n",
      "RMSE, train 0.23287851083825137, test 0.23918653998458594\n",
      "RMSE, train 0.23168700901684222, test 0.24003003132447862\n",
      "RMSE, train 0.23280911150771672, test 0.23802440325941956\n",
      "RMSE, train 0.23280534071962972, test 0.23860196148355803\n",
      "RMSE, train 0.23190037304086725, test 0.23851570369381653\n",
      "RMSE, train 0.23188661887193285, test 0.23914284703501484\n",
      "RMSE, train 0.23189306684902736, test 0.2400973822202599\n",
      "RMSE, train 0.2315502707510869, test 0.23900921028434186\n",
      "RMSE, train 0.23183701880006138, test 0.23960950781117407\n",
      "RMSE, train 0.23186283893803797, test 0.23803215382391946\n",
      "RMSE, train 0.231078285461804, test 0.23663389120708433\n",
      "RMSE, train 0.2309671323150714, test 0.23730192111249557\n",
      "RMSE, train 0.23207097247973688, test 0.23848461242098556\n",
      "RMSE, train 0.23082086669483673, test 0.2377931059975373\n",
      "RMSE, train 0.23101054705472898, test 0.23917677240413532\n",
      "RMSE, train 0.23055140955298187, test 0.23736429724254107\n",
      "RMSE, train 0.23050192387691185, test 0.23701717397361471\n",
      "RMSE, train 0.23090986082993592, test 0.2366497606823319\n",
      "RMSE, train 0.23065398914664031, test 0.23689657423579902\n",
      "RMSE, train 0.23078451895002108, test 0.2379031028402479\n",
      "RMSE, train 0.23065611208552744, test 0.23668565738357997\n",
      "Early stopping at epoch 58 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.9959887865050596, test 0.9622469234700296\n",
      "RMSE, train 0.9735958924014699, test 0.9155282816466164\n",
      "RMSE, train 0.8799173638473547, test 0.7580414805926529\n",
      "RMSE, train 0.6614907802147058, test 0.5334225815593028\n",
      "RMSE, train 0.4774739962417926, test 0.420566390542423\n",
      "RMSE, train 0.39410119711783737, test 0.37208165155321943\n",
      "RMSE, train 0.34785817531526514, test 0.32989102791921765\n",
      "RMSE, train 0.31448967747728124, test 0.31008488129751355\n",
      "RMSE, train 0.2980104435528662, test 0.29659147940429986\n",
      "RMSE, train 0.2797787774505365, test 0.281834194327102\n",
      "RMSE, train 0.27213111857668026, test 0.27855420054173935\n",
      "RMSE, train 0.26927253189618944, test 0.27216214759677065\n",
      "RMSE, train 0.26005889932338266, test 0.26987525996039896\n",
      "RMSE, train 0.25768423848618754, test 0.26143258934219676\n",
      "RMSE, train 0.25404342678253294, test 0.25761251107734795\n",
      "RMSE, train 0.2538298152582742, test 0.2576495497396179\n",
      "RMSE, train 0.25195236402721566, test 0.25770748742655214\n",
      "RMSE, train 0.24837188511588978, test 0.2537989866207628\n",
      "RMSE, train 0.24948972155982385, test 0.2525494311954461\n",
      "RMSE, train 0.2460230440168079, test 0.2544695426728211\n",
      "RMSE, train 0.24445331311809135, test 0.24883492290973663\n",
      "RMSE, train 0.24276865506655845, test 0.2505484441039609\n",
      "RMSE, train 0.24232194567352605, test 0.2538584746858653\n",
      "RMSE, train 0.24136691001690658, test 0.2507768090010858\n",
      "RMSE, train 0.24065071431506505, test 0.2452896358627899\n",
      "RMSE, train 0.24060312937722855, test 0.24789799859418588\n",
      "RMSE, train 0.23998214037719945, test 0.24470396354502322\n",
      "RMSE, train 0.2381037301372799, test 0.246283142005696\n",
      "RMSE, train 0.23896928549453011, test 0.24513443055398323\n",
      "RMSE, train 0.23706974380767432, test 0.24614846837871215\n",
      "RMSE, train 0.2372229604099417, test 0.24308556573940257\n",
      "RMSE, train 0.23650670700610965, test 0.24430540445096352\n",
      "RMSE, train 0.2359110562748727, test 0.2443831612666448\n",
      "RMSE, train 0.23580472546502912, test 0.2425119592716881\n",
      "RMSE, train 0.23598012450842412, test 0.24054987538678974\n",
      "RMSE, train 0.23403478554296608, test 0.24451047810269336\n",
      "RMSE, train 0.23455908794960714, test 0.2437307871147698\n",
      "RMSE, train 0.23356721623131654, test 0.24467524404034896\n",
      "RMSE, train 0.2337600317270204, test 0.24361836939465767\n",
      "RMSE, train 0.23383794484886747, test 0.2424003059665362\n",
      "RMSE, train 0.23336979841062164, test 0.24585966875447945\n",
      "RMSE, train 0.2325349417392849, test 0.2394622292588739\n",
      "RMSE, train 0.23416417860259303, test 0.24226034578739428\n",
      "RMSE, train 0.23270679791602428, test 0.23969949321711764\n",
      "RMSE, train 0.23277038725221924, test 0.23902829349333166\n",
      "RMSE, train 0.23261878376288744, test 0.23946704627836451\n",
      "RMSE, train 0.23221693152388412, test 0.23844321291236317\n",
      "RMSE, train 0.2312758580241397, test 0.23750041965760438\n",
      "RMSE, train 0.23028360701972944, test 0.24216474373550975\n",
      "RMSE, train 0.23085310905816162, test 0.241147995141207\n",
      "RMSE, train 0.23091818756803978, test 0.24173635375850341\n",
      "RMSE, train 0.23167245648356782, test 0.2383247470008392\n",
      "RMSE, train 0.23120227626798262, test 0.23834751195767345\n",
      "RMSE, train 0.2303442780577482, test 0.23899984199042415\n",
      "RMSE, train 0.23067374970221577, test 0.23913322856613234\n",
      "RMSE, train 0.2308608074283543, test 0.2404229123802746\n",
      "RMSE, train 0.2304565115233879, test 0.24159095779645676\n",
      "RMSE, train 0.22992647759314083, test 0.24078048772963823\n",
      "Early stopping at epoch 58 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.0057015989816958, test 0.9753418579574459\n",
      "RMSE, train 0.9919024013703869, test 0.9616194086626542\n",
      "RMSE, train 0.955019815013774, test 0.8840619017762587\n",
      "RMSE, train 0.7734983881875392, test 0.5824310501252324\n",
      "RMSE, train 0.47641430416655156, test 0.3857478951373376\n",
      "RMSE, train 0.3675729011996619, test 0.33800258124170224\n",
      "RMSE, train 0.3297451673406026, test 0.3106635762147667\n",
      "RMSE, train 0.3077845519048072, test 0.2932433207665593\n",
      "RMSE, train 0.2921465914996882, test 0.28821755625492285\n",
      "RMSE, train 0.2867425462351211, test 0.27689101269915084\n",
      "RMSE, train 0.2786945648972065, test 0.27731751693674356\n",
      "RMSE, train 0.273910264514627, test 0.2731756311187074\n",
      "RMSE, train 0.2722012149170041, test 0.2711093508261294\n",
      "RMSE, train 0.2688093721085498, test 0.2683066276233058\n",
      "RMSE, train 0.269593890365814, test 0.2680169507737987\n",
      "RMSE, train 0.2682174351216564, test 0.26584471700605283\n",
      "RMSE, train 0.26618111052460247, test 0.2682692250929588\n",
      "RMSE, train 0.2656047745427537, test 0.2655764695657186\n",
      "RMSE, train 0.2648644452133486, test 0.26635962693898146\n",
      "RMSE, train 0.26513382413935277, test 0.26345671183806807\n",
      "RMSE, train 0.2645717368971917, test 0.2629903916361903\n",
      "RMSE, train 0.2636976267751907, test 0.26614507256953185\n",
      "RMSE, train 0.2627218565603177, test 0.26361076533794403\n",
      "RMSE, train 0.2624186935323861, test 0.2635087554981886\n",
      "RMSE, train 0.2625855254460006, test 0.2607431996706103\n",
      "RMSE, train 0.2617723609681331, test 0.2653511994141192\n",
      "RMSE, train 0.26213502244002396, test 0.26299547016128033\n",
      "RMSE, train 0.2610674903037087, test 0.26411251428206106\n",
      "RMSE, train 0.26185454088713855, test 0.26408244447767243\n",
      "RMSE, train 0.26118450482646305, test 0.2613928350042706\n",
      "RMSE, train 0.2611037959765282, test 0.2601704781582533\n",
      "RMSE, train 0.26027684971209497, test 0.2605527623379526\n",
      "RMSE, train 0.26068922320020294, test 0.2629765900821725\n",
      "RMSE, train 0.2597752055303464, test 0.2609556173859549\n",
      "RMSE, train 0.26019681808388523, test 0.2601774578744715\n",
      "RMSE, train 0.2592744047212745, test 0.26092597620546326\n",
      "RMSE, train 0.2601644512446177, test 0.2606771210870467\n",
      "RMSE, train 0.25976659694025594, test 0.26002209257981007\n",
      "RMSE, train 0.25962142086017037, test 0.2599321042210603\n",
      "RMSE, train 0.2594047085862727, test 0.2604731053483388\n",
      "RMSE, train 0.2595204110858181, test 0.25969335769326235\n",
      "RMSE, train 0.2590325171909025, test 0.25914348914357255\n",
      "RMSE, train 0.25816264210809625, test 0.2606411949415837\n",
      "RMSE, train 0.25872167429676457, test 0.26078248713627333\n",
      "RMSE, train 0.25838686704575536, test 0.2603816652347234\n",
      "RMSE, train 0.25832924901718096, test 0.2595951171083884\n",
      "RMSE, train 0.25879498245194554, test 0.26119138805334235\n",
      "RMSE, train 0.2591274465704637, test 0.2605899116717094\n",
      "RMSE, train 0.25878522713338176, test 0.26068763594982053\n",
      "RMSE, train 0.2590288716638761, test 0.25961244771303227\n",
      "RMSE, train 0.2580764060088944, test 0.25976089104886885\n",
      "RMSE, train 0.2582897921092808, test 0.2598965284376105\n",
      "Early stopping at epoch 52 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.998655072667382, test 0.9661718574115785\n",
      "RMSE, train 0.9654792564466965, test 0.907587189037921\n",
      "RMSE, train 0.8423042363248581, test 0.6809079611705522\n",
      "RMSE, train 0.5166175619445064, test 0.38325036203457136\n",
      "RMSE, train 0.3588417988609184, test 0.3248662709937257\n",
      "RMSE, train 0.31524950564523374, test 0.2994026392698288\n",
      "RMSE, train 0.2926058989972615, test 0.2781211644158525\n",
      "RMSE, train 0.27699279911385094, test 0.27094264366364074\n",
      "RMSE, train 0.26993445875046174, test 0.26395345984374063\n",
      "RMSE, train 0.26463316106968676, test 0.26275804626234506\n",
      "RMSE, train 0.2606253082101995, test 0.2565990118152004\n",
      "RMSE, train 0.25711481828889077, test 0.25416472573149\n",
      "RMSE, train 0.2565302781853055, test 0.255863660283513\n",
      "RMSE, train 0.25303424865561575, test 0.25391421530206326\n",
      "RMSE, train 0.25219838068751266, test 0.2507803289819572\n",
      "RMSE, train 0.25133145700616777, test 0.2512610057779288\n",
      "RMSE, train 0.25075211563755656, test 0.2498656749977904\n",
      "RMSE, train 0.24893857487900692, test 0.2509793467440848\n",
      "RMSE, train 0.2494473332646957, test 0.249423058608831\n",
      "RMSE, train 0.24941828528280593, test 0.2514114335684453\n",
      "RMSE, train 0.24853934997246285, test 0.2494640751915463\n",
      "RMSE, train 0.2489282628136479, test 0.24905518177202193\n",
      "RMSE, train 0.24753028970242533, test 0.24853163989166083\n",
      "RMSE, train 0.2480780733210489, test 0.24720000185198704\n",
      "RMSE, train 0.2478997644714334, test 0.24716151183692076\n",
      "RMSE, train 0.2472355140234567, test 0.24695847259234574\n",
      "RMSE, train 0.24612039149053827, test 0.2477048224438045\n",
      "RMSE, train 0.2468070664158291, test 0.24804301244222512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2452538075956924, test 0.2489417515442533\n",
      "RMSE, train 0.24529999545352024, test 0.2463036336131015\n",
      "RMSE, train 0.24599263250581488, test 0.24765922722675032\n",
      "RMSE, train 0.24527513634505843, test 0.2461777719653259\n",
      "RMSE, train 0.2457182565319144, test 0.24785520894042515\n",
      "RMSE, train 0.24561906125673577, test 0.24749246220720017\n",
      "RMSE, train 0.24494215588985888, test 0.24634827338790488\n",
      "RMSE, train 0.2448013639924201, test 0.24657471389588664\n",
      "RMSE, train 0.24581330680588553, test 0.24580954760313034\n",
      "RMSE, train 0.2448828821801696, test 0.24836570327564822\n",
      "RMSE, train 0.24503835847924563, test 0.24627463380664083\n",
      "RMSE, train 0.24441132286548123, test 0.24621442591739914\n",
      "RMSE, train 0.24490463281096506, test 0.24628506979699863\n",
      "RMSE, train 0.243504206011118, test 0.24673098073167316\n",
      "RMSE, train 0.24332567792355028, test 0.245616754864232\n",
      "RMSE, train 0.2444928703783465, test 0.24568105400618862\n",
      "RMSE, train 0.24438204516248763, test 0.24549659000614943\n",
      "RMSE, train 0.24451498110001244, test 0.24570814545376826\n",
      "RMSE, train 0.24449508038372542, test 0.24601608047545967\n",
      "RMSE, train 0.24370474994859911, test 0.2460802832649926\n",
      "RMSE, train 0.24397271360493888, test 0.24503946298007237\n",
      "RMSE, train 0.2437051094852942, test 0.24584871012780626\n",
      "RMSE, train 0.2441747936397052, test 0.24661115215996565\n",
      "RMSE, train 0.24337604215507172, test 0.24496206022420172\n",
      "RMSE, train 0.2432890722589675, test 0.2458390730543662\n",
      "RMSE, train 0.2447472935434708, test 0.24529015689583147\n",
      "RMSE, train 0.24359996590670968, test 0.24539657915800306\n",
      "RMSE, train 0.2439417070439778, test 0.245099187654964\n",
      "RMSE, train 0.2440543588989776, test 0.2455597932182126\n",
      "RMSE, train 0.24368952362497975, test 0.24630105811155448\n",
      "RMSE, train 0.24357733630752268, test 0.24619420712529602\n",
      "RMSE, train 0.24381521253361682, test 0.2447717247878091\n",
      "RMSE, train 0.24434181425935966, test 0.24489192885615058\n",
      "RMSE, train 0.2436939698359198, test 0.24670027796242197\n",
      "RMSE, train 0.2440303527742378, test 0.24551078361474862\n",
      "RMSE, train 0.24352765868394827, test 0.24489827397263655\n",
      "RMSE, train 0.24389454046618347, test 0.24506201797117622\n",
      "RMSE, train 0.24315473112500896, test 0.24508967136932633\n",
      "RMSE, train 0.24391692171781515, test 0.24456044463282925\n",
      "RMSE, train 0.24283872279223084, test 0.24492563016838947\n",
      "RMSE, train 0.242978316277635, test 0.24496134945144088\n",
      "RMSE, train 0.24325989579304683, test 0.2440498238902981\n",
      "RMSE, train 0.24402786815954633, test 0.24529132347995952\n",
      "RMSE, train 0.243071785258237, test 0.24513363711914773\n",
      "RMSE, train 0.2432954108173197, test 0.24598941611031355\n",
      "RMSE, train 0.24393210533913995, test 0.2449398855284109\n",
      "RMSE, train 0.24288769087885037, test 0.24496521068326496\n",
      "RMSE, train 0.24296436508086103, test 0.24439814825684336\n",
      "RMSE, train 0.24337138897500749, test 0.24465372539677863\n",
      "RMSE, train 0.24307358001689772, test 0.24456628670884392\n",
      "RMSE, train 0.24304680955742508, test 0.2459185755480144\n",
      "RMSE, train 0.24295329277919345, test 0.2456656538455163\n",
      "Early stopping at epoch 80 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.005513099608598, test 0.9480906586561885\n",
      "RMSE, train 0.9258014090959802, test 0.8205828956727471\n",
      "RMSE, train 0.7151821725768461, test 0.5616547946951219\n",
      "RMSE, train 0.4961950566319339, test 0.4198069987552507\n",
      "RMSE, train 0.4020198857927115, test 0.3693708379619888\n",
      "RMSE, train 0.355330533516433, test 0.3259893087670207\n",
      "RMSE, train 0.3182378417461266, test 0.29952085337468554\n",
      "RMSE, train 0.2956807940938634, test 0.2861683193062033\n",
      "RMSE, train 0.28252980354889284, test 0.2791424519382417\n",
      "RMSE, train 0.2727796174829302, test 0.27131011203995775\n",
      "RMSE, train 0.26631174226796706, test 0.2622086176914828\n",
      "RMSE, train 0.26103162241202815, test 0.25989500326769693\n",
      "RMSE, train 0.2570497915960345, test 0.2549383911703314\n",
      "RMSE, train 0.2536509651731302, test 0.25433014100417495\n",
      "RMSE, train 0.2505699419832437, test 0.25395539842013803\n",
      "RMSE, train 0.25086077179329586, test 0.253320069052279\n",
      "RMSE, train 0.24910266192585295, test 0.2522199217762266\n",
      "RMSE, train 0.2482263539189347, test 0.2514731770248285\n",
      "RMSE, train 0.24730518964283607, test 0.2488591613780175\n",
      "RMSE, train 0.24680111730929813, test 0.2483857087790966\n",
      "RMSE, train 0.24466787418249125, test 0.24821234507752316\n",
      "RMSE, train 0.24424222791831218, test 0.24863220106012054\n",
      "RMSE, train 0.2448494617131281, test 0.24712138529866934\n",
      "RMSE, train 0.24455932949817777, test 0.24612352637840168\n",
      "RMSE, train 0.2426884700594904, test 0.2470692760044975\n",
      "RMSE, train 0.24331368944224188, test 0.2465929808760328\n",
      "RMSE, train 0.24291156532652758, test 0.24407648840653046\n",
      "RMSE, train 0.24246069751598737, test 0.24557699582406453\n",
      "RMSE, train 0.24208225464054703, test 0.24662990309298038\n",
      "RMSE, train 0.24245841335302346, test 0.24443220120987721\n",
      "RMSE, train 0.2420840213371518, test 0.2461198031503175\n",
      "RMSE, train 0.239953585715725, test 0.24299263189147627\n",
      "RMSE, train 0.24048534636274144, test 0.24700212578422256\n",
      "RMSE, train 0.2414904348308744, test 0.24457945628091693\n",
      "RMSE, train 0.24107076786052686, test 0.2468004800113184\n",
      "RMSE, train 0.2411520321222432, test 0.24484366830438375\n",
      "RMSE, train 0.24124209952899833, test 0.24613531020336918\n",
      "RMSE, train 0.24065420659733752, test 0.24372140477810586\n",
      "RMSE, train 0.24096118937974922, test 0.2430592552492661\n",
      "RMSE, train 0.2408145174611368, test 0.2450114025601319\n",
      "RMSE, train 0.24038189037627905, test 0.24315420205571822\n",
      "RMSE, train 0.23944191978777676, test 0.24395822886643664\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9947338271111906, test 0.9639546540048387\n",
      "RMSE, train 0.9762015857877242, test 0.9217782604573953\n",
      "RMSE, train 0.8825804683719113, test 0.760172115130858\n",
      "RMSE, train 0.636068960200895, test 0.5018443821957617\n",
      "RMSE, train 0.4369255071893006, test 0.39567351025162323\n",
      "RMSE, train 0.3629387277554183, test 0.34448631228220583\n",
      "RMSE, train 0.32429744310513103, test 0.315895930835695\n",
      "RMSE, train 0.2968869838490171, test 0.2928368814966895\n",
      "RMSE, train 0.28195851789855725, test 0.28089686084275295\n",
      "RMSE, train 0.2724233040344744, test 0.27461457704052783\n",
      "RMSE, train 0.26583643900663173, test 0.26487648456987706\n",
      "RMSE, train 0.26053577444736997, test 0.26069437057682965\n",
      "RMSE, train 0.2572611523906001, test 0.26032240094259534\n",
      "RMSE, train 0.2527661657092915, test 0.2551652560330401\n",
      "RMSE, train 0.25104967712408754, test 0.25554152721106405\n",
      "RMSE, train 0.24940704574357617, test 0.25320928852365476\n",
      "RMSE, train 0.24833656300979606, test 0.2527486707526024\n",
      "RMSE, train 0.24755021847766304, test 0.25159239227121527\n",
      "RMSE, train 0.2460677909202564, test 0.24988126724657386\n",
      "RMSE, train 0.24437650695698185, test 0.25077479445573053\n",
      "RMSE, train 0.24341432537091098, test 0.2493742365728725\n",
      "RMSE, train 0.24215225033771728, test 0.24977622820873452\n",
      "RMSE, train 0.2422150161235723, test 0.24792207852758544\n",
      "RMSE, train 0.24240906829866046, test 0.24869869348376689\n",
      "RMSE, train 0.2427850545800694, test 0.24681722568442124\n",
      "RMSE, train 0.24003243577509462, test 0.24639558205098816\n",
      "RMSE, train 0.23982370291406194, test 0.24718450747355067\n",
      "RMSE, train 0.23999592248341273, test 0.2434270138090307\n",
      "RMSE, train 0.24035237201268633, test 0.24598056431671586\n",
      "RMSE, train 0.23828668755759236, test 0.24452896559178228\n",
      "RMSE, train 0.2394017664793068, test 0.24544718048789285\n",
      "RMSE, train 0.23702561075646603, test 0.24333692522663058\n",
      "RMSE, train 0.23768212817481793, test 0.2443972871911646\n",
      "RMSE, train 0.23722505073967073, test 0.24375709966577666\n",
      "RMSE, train 0.23698996907341452, test 0.2462971555163162\n",
      "RMSE, train 0.2368605310110999, test 0.2450154319857106\n",
      "RMSE, train 0.2375797126032321, test 0.2435980269102135\n",
      "RMSE, train 0.23658592020751212, test 0.24202715041059436\n",
      "RMSE, train 0.23653086109091426, test 0.2420318289989173\n",
      "RMSE, train 0.23729401018042437, test 0.2416392673898225\n",
      "RMSE, train 0.23681381117087996, test 0.24241782679702295\n",
      "RMSE, train 0.23549863894659034, test 0.241396324652614\n",
      "RMSE, train 0.2356397108445832, test 0.24315544722056148\n",
      "RMSE, train 0.236127310284484, test 0.2425533232062754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2362867275521633, test 0.24297908166743287\n",
      "RMSE, train 0.23536244433710218, test 0.2440561582945814\n",
      "RMSE, train 0.23581089722425255, test 0.24192574266532454\n",
      "RMSE, train 0.23507441008295, test 0.242335766403362\n",
      "RMSE, train 0.23518751042469208, test 0.24241330865958724\n",
      "RMSE, train 0.23522951089592609, test 0.24269280334313711\n",
      "RMSE, train 0.23458167353148565, test 0.2409626180776442\n",
      "RMSE, train 0.23472536346148745, test 0.24227674711834302\n",
      "RMSE, train 0.23472319661769425, test 0.24189803395608458\n",
      "RMSE, train 0.23539091604773166, test 0.24205295606092972\n",
      "RMSE, train 0.23443878205233507, test 0.24177028464548517\n",
      "RMSE, train 0.23477625737563323, test 0.2421798843024957\n",
      "RMSE, train 0.23492797535176965, test 0.24280082517200047\n",
      "RMSE, train 0.23438696940327042, test 0.24035124917222997\n",
      "RMSE, train 0.23462802627121615, test 0.24271810927776374\n",
      "RMSE, train 0.23361742838962155, test 0.2423577228128308\n",
      "RMSE, train 0.23402262653946002, test 0.24237671088088641\n",
      "RMSE, train 0.2338655595747358, test 0.23811952137585843\n",
      "RMSE, train 0.2338622457240788, test 0.2407826983717957\n",
      "RMSE, train 0.23388189882550087, test 0.2416477653414312\n",
      "RMSE, train 0.2338009382846303, test 0.24112298166511034\n",
      "RMSE, train 0.23316746332607527, test 0.2434076794771233\n",
      "RMSE, train 0.23374245587217196, test 0.241811736891366\n",
      "RMSE, train 0.23276633007820777, test 0.24144532757275033\n",
      "RMSE, train 0.23339828653921416, test 0.24089336131859307\n",
      "RMSE, train 0.23308321301686444, test 0.24174625577047618\n",
      "RMSE, train 0.23332531229208034, test 0.24051463634076745\n",
      "RMSE, train 0.23366536445970348, test 0.24108536165169994\n",
      "Early stopping at epoch 72 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.0199223798045443, test 0.976395196833853\n",
      "RMSE, train 0.9862467299315555, test 0.9425562286781053\n",
      "RMSE, train 0.9202934871774074, test 0.8275909295021477\n",
      "RMSE, train 0.7320671141270764, test 0.594697649953729\n",
      "RMSE, train 0.5276670714855687, test 0.45039775980226066\n",
      "RMSE, train 0.4326445999101174, test 0.3926662149823318\n",
      "RMSE, train 0.381663157458394, test 0.3523322712566893\n",
      "RMSE, train 0.3453393332537048, test 0.32296621483766424\n",
      "RMSE, train 0.3245636678554795, test 0.3128224282951678\n",
      "RMSE, train 0.3140004093119921, test 0.3029399303308988\n",
      "RMSE, train 0.3013748557052829, test 0.29687644288701526\n",
      "RMSE, train 0.29670758139003406, test 0.2888790146779206\n",
      "RMSE, train 0.2930666306633348, test 0.28455626749891344\n",
      "RMSE, train 0.29126825897900527, test 0.28545655928930996\n",
      "RMSE, train 0.2892555728677876, test 0.28672505119594477\n",
      "RMSE, train 0.28878647258335893, test 0.28352989799390405\n",
      "RMSE, train 0.2871785180504657, test 0.2847787162004891\n",
      "RMSE, train 0.28676427922342435, test 0.28341187561972664\n",
      "RMSE, train 0.2847968938275556, test 0.28249355809668364\n",
      "RMSE, train 0.2846906716542796, test 0.28002079216352965\n",
      "RMSE, train 0.28374494365916764, test 0.28030488235970674\n",
      "RMSE, train 0.28370407731695607, test 0.2796424551535461\n",
      "RMSE, train 0.2828556789039088, test 0.28234446099248983\n",
      "RMSE, train 0.282351863978446, test 0.2822778423206281\n",
      "RMSE, train 0.2826056844008363, test 0.27922457507101156\n",
      "RMSE, train 0.28270494639257754, test 0.2809736285421808\n",
      "RMSE, train 0.28300889803112045, test 0.28202223196878273\n",
      "RMSE, train 0.2813458250419906, test 0.28063324832562675\n",
      "RMSE, train 0.28186022939760824, test 0.27857014581055967\n",
      "RMSE, train 0.27959817218448013, test 0.2810330555095511\n",
      "RMSE, train 0.2803803986046186, test 0.2802106696417776\n",
      "RMSE, train 0.28010910884900525, test 0.27908343948045017\n",
      "RMSE, train 0.28060119208102385, test 0.2795816108710685\n",
      "RMSE, train 0.2789102417593899, test 0.2779529520263106\n",
      "RMSE, train 0.28061097767973736, test 0.2790965456199848\n",
      "RMSE, train 0.2802390241456672, test 0.27866126142315945\n",
      "RMSE, train 0.27970521113535096, test 0.27800670430316765\n",
      "RMSE, train 0.27835109876083935, test 0.2796316692384623\n",
      "RMSE, train 0.2799559251120514, test 0.279818081249625\n",
      "RMSE, train 0.2788155942631901, test 0.275848034074751\n",
      "RMSE, train 0.27885322152706216, test 0.2772110614736201\n",
      "RMSE, train 0.27901756181574067, test 0.2792241597958541\n",
      "RMSE, train 0.27978874308880697, test 0.27959338663998295\n",
      "RMSE, train 0.2792246944986838, test 0.27824784878451947\n",
      "RMSE, train 0.2789936276876237, test 0.27781904387777134\n",
      "RMSE, train 0.27891433879363636, test 0.27765347871739987\n",
      "RMSE, train 0.28012117671141445, test 0.27706795160548164\n",
      "RMSE, train 0.2792767524288213, test 0.2773950877836195\n",
      "RMSE, train 0.2781005750048505, test 0.2786616472116971\n",
      "RMSE, train 0.2779106422643031, test 0.2796351601511745\n",
      "Early stopping at epoch 50 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.005639832870216, test 0.9683269329693006\n",
      "RMSE, train 0.9797019097329198, test 0.9203086744184079\n",
      "RMSE, train 0.8523920289143888, test 0.6933918457964192\n",
      "RMSE, train 0.5462711572077623, test 0.41268737976965697\n",
      "RMSE, train 0.3803869398852569, test 0.3483468076457148\n",
      "RMSE, train 0.3393762349892574, test 0.32280268047166905\n",
      "RMSE, train 0.3144868651519662, test 0.30562280222125676\n",
      "RMSE, train 0.2966705573971864, test 0.2889438705599826\n",
      "RMSE, train 0.285398365158564, test 0.2834629443676575\n",
      "RMSE, train 0.2781340506584275, test 0.28406646912512573\n",
      "RMSE, train 0.2745911096343316, test 0.2753684146248776\n",
      "RMSE, train 0.2712679751328096, test 0.2713523435851802\n",
      "RMSE, train 0.26879808811308725, test 0.2702389285616253\n",
      "RMSE, train 0.2697180815183433, test 0.2713888840830844\n",
      "RMSE, train 0.2669921910623583, test 0.27110008908354716\n",
      "RMSE, train 0.2654594988295227, test 0.26836834647085356\n",
      "RMSE, train 0.2636161105679605, test 0.26980508876883463\n",
      "RMSE, train 0.2647242489925362, test 0.2698344172342964\n",
      "RMSE, train 0.26366146397628604, test 0.266727732575458\n",
      "RMSE, train 0.26214203107192513, test 0.26572027983872787\n",
      "RMSE, train 0.26265798846058025, test 0.266533803615881\n",
      "RMSE, train 0.2633397129310924, test 0.2640651981467786\n",
      "RMSE, train 0.2622922382410418, test 0.26382899634216145\n",
      "RMSE, train 0.26234312395064946, test 0.265852473611417\n",
      "RMSE, train 0.26220064298615586, test 0.2673906764258509\n",
      "RMSE, train 0.2608591866562827, test 0.2636618356341901\n",
      "RMSE, train 0.26134776221212563, test 0.2638636318237885\n",
      "RMSE, train 0.26226029829804304, test 0.26428853364094446\n",
      "RMSE, train 0.2602171658552123, test 0.26558328854001084\n",
      "RMSE, train 0.26097242056437614, test 0.26401721802742584\n",
      "RMSE, train 0.2600281406549891, test 0.2632497134416\n",
      "RMSE, train 0.2595771219098897, test 0.2650385551478552\n",
      "RMSE, train 0.26013173561566955, test 0.26391459217538005\n",
      "RMSE, train 0.2595725016166197, test 0.2636970766212629\n",
      "RMSE, train 0.2589431573852359, test 0.2616434049995049\n",
      "RMSE, train 0.2591437440199457, test 0.26452481552310614\n",
      "RMSE, train 0.25855357073358165, test 0.26419767154299695\n",
      "RMSE, train 0.25936378622447354, test 0.26259524809277573\n",
      "RMSE, train 0.25903610402674687, test 0.2626856354267701\n",
      "RMSE, train 0.25844999428071286, test 0.26366904650045475\n",
      "RMSE, train 0.25882389780822074, test 0.2621353900950888\n",
      "RMSE, train 0.25856992977250154, test 0.2619059411079987\n",
      "RMSE, train 0.25930907833538236, test 0.260838661763979\n",
      "RMSE, train 0.2589357002240837, test 0.2629821186480315\n",
      "RMSE, train 0.2594650478246612, test 0.26243068206569425\n",
      "RMSE, train 0.25835184325837784, test 0.2616256620572961\n",
      "RMSE, train 0.2581657600567346, test 0.2611720823723337\n",
      "RMSE, train 0.25778207295196576, test 0.26258015127285667\n",
      "RMSE, train 0.25814915189001464, test 0.26126270229401793\n",
      "RMSE, train 0.2585327397486207, test 0.2622726719016614\n",
      "RMSE, train 0.25869509416401004, test 0.2611379610455554\n",
      "RMSE, train 0.2576609900391279, test 0.26146185767391456\n",
      "RMSE, train 0.25835351122349437, test 0.26213283389806746\n",
      "Early stopping at epoch 53 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9967321561056403, test 0.9564122601386604\n",
      "RMSE, train 0.9607828123820736, test 0.8895096029710332\n",
      "RMSE, train 0.82401109817584, test 0.6724839519470109\n",
      "RMSE, train 0.5731019034246693, test 0.46810484916792006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.4340101676604673, test 0.3973317997991492\n",
      "RMSE, train 0.3775796605933942, test 0.35850274781568336\n",
      "RMSE, train 0.346042976919311, test 0.3315661665769892\n",
      "RMSE, train 0.32042250869119115, test 0.31054802854126745\n",
      "RMSE, train 0.30416598642086234, test 0.2932760986166263\n",
      "RMSE, train 0.28980025137887405, test 0.2903888403275691\n",
      "RMSE, train 0.28234475266372144, test 0.28249662765942585\n",
      "RMSE, train 0.2785091054345995, test 0.27980867875825377\n",
      "RMSE, train 0.2747436159628656, test 0.27364822149003315\n",
      "RMSE, train 0.2705174674668387, test 0.27493707965546793\n",
      "RMSE, train 0.26871248028938544, test 0.27127069644971724\n",
      "RMSE, train 0.26636915852737536, test 0.27164216530979224\n",
      "RMSE, train 0.2657774779695032, test 0.2698300951117769\n",
      "RMSE, train 0.2645221062238441, test 0.26795412641052807\n",
      "RMSE, train 0.2636133100286193, test 0.26806776198225285\n",
      "RMSE, train 0.26348813476182953, test 0.26641334921395016\n",
      "RMSE, train 0.2616823855202829, test 0.2686120626439742\n",
      "RMSE, train 0.2601429719828704, test 0.26748469389906715\n",
      "RMSE, train 0.2615148007468792, test 0.2687806904042533\n",
      "RMSE, train 0.2601191688145223, test 0.26504445855223807\n",
      "RMSE, train 0.26014751747183734, test 0.2625855966172087\n",
      "RMSE, train 0.2589618020561511, test 0.26203743450411965\n",
      "RMSE, train 0.25929557425157906, test 0.26389592947489626\n",
      "RMSE, train 0.25926835243611057, test 0.26357397320893927\n",
      "RMSE, train 0.25807667931232753, test 0.26362385607640676\n",
      "RMSE, train 0.2569347290414064, test 0.2627616043484539\n",
      "RMSE, train 0.2575285369070923, test 0.2640265439628461\n",
      "RMSE, train 0.2574807891764181, test 0.26449424944339545\n",
      "RMSE, train 0.256944722107574, test 0.2618205572623725\n",
      "RMSE, train 0.25657160499972614, test 0.26454710974058976\n",
      "RMSE, train 0.2561684803778281, test 0.261462379486189\n",
      "RMSE, train 0.25638253221731017, test 0.2616162419045737\n",
      "RMSE, train 0.25621448395431307, test 0.26092663099732966\n",
      "RMSE, train 0.2559315049895524, test 0.2607737336683711\n",
      "RMSE, train 0.2557034279666674, test 0.2614608508867955\n",
      "RMSE, train 0.2551028904058206, test 0.26325334348809826\n",
      "RMSE, train 0.25533453035982734, test 0.2608015874930478\n",
      "RMSE, train 0.25475570805070114, test 0.2615670092882366\n",
      "RMSE, train 0.2554117390393142, test 0.2628636983556485\n",
      "RMSE, train 0.25478647301817153, test 0.2595494736772065\n",
      "RMSE, train 0.25494090455997687, test 0.2606699553514839\n",
      "RMSE, train 0.2540419799998202, test 0.2596589783462909\n",
      "RMSE, train 0.25465039736820977, test 0.25840723582910835\n",
      "RMSE, train 0.25488836308231266, test 0.26272613944810463\n",
      "RMSE, train 0.2547630995779294, test 0.2580850891290455\n",
      "RMSE, train 0.2536522893427199, test 0.2608840736227298\n",
      "RMSE, train 0.25371472393851646, test 0.2576077139568985\n",
      "RMSE, train 0.2540408996155176, test 0.2591521167153612\n",
      "RMSE, train 0.2545287135504019, test 0.2596901333250037\n",
      "RMSE, train 0.2538754672246396, test 0.2611007855162708\n",
      "RMSE, train 0.2532730084497298, test 0.2593813382020784\n",
      "RMSE, train 0.2532468402733183, test 0.260121500683487\n",
      "RMSE, train 0.25260762320706126, test 0.2592609098198217\n",
      "RMSE, train 0.25332092896371144, test 0.26098876466991705\n",
      "RMSE, train 0.2531203738509807, test 0.2595282361731617\n",
      "RMSE, train 0.2526639835416202, test 0.2615970784644468\n",
      "RMSE, train 0.25294393448017105, test 0.2600365673456717\n",
      "Early stopping at epoch 61 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.0253148531973963, test 0.9725252874195576\n",
      "RMSE, train 0.9954637903908287, test 0.9475926806529363\n",
      "RMSE, train 0.9478498299164001, test 0.8682539459938804\n",
      "RMSE, train 0.8090773138283479, test 0.6895548840984702\n",
      "RMSE, train 0.6064564756145983, test 0.5180994067341089\n",
      "RMSE, train 0.47272031456984653, test 0.43940986366942525\n",
      "RMSE, train 0.41044622095245303, test 0.39640081363419694\n",
      "RMSE, train 0.3711383395423793, test 0.3650896375377973\n",
      "RMSE, train 0.34497695540388423, test 0.3408739428656797\n",
      "RMSE, train 0.3251265354755551, test 0.3233097762179871\n",
      "RMSE, train 0.3116052136427224, test 0.31109638325870037\n",
      "RMSE, train 0.29926671528003435, test 0.2943379123074313\n",
      "RMSE, train 0.2943193775535834, test 0.29347191634587944\n",
      "RMSE, train 0.2868058570858204, test 0.2888541380719592\n",
      "RMSE, train 0.28154369883916597, test 0.28557620585585636\n",
      "RMSE, train 0.27908783310064766, test 0.2794554211044063\n",
      "RMSE, train 0.2768587531766506, test 0.27980587041626376\n",
      "RMSE, train 0.2746557050732651, test 0.2772806087353577\n",
      "RMSE, train 0.2724562803415036, test 0.2772990285108487\n",
      "RMSE, train 0.26998714827979453, test 0.27176299582545954\n",
      "RMSE, train 0.269072855192453, test 0.27277770956667763\n",
      "RMSE, train 0.2647458963246659, test 0.27209928647304576\n",
      "RMSE, train 0.2648877649934906, test 0.26790397249472636\n",
      "RMSE, train 0.2632785055673484, test 0.2713741958141327\n",
      "RMSE, train 0.2622328548118322, test 0.26693590202679235\n",
      "RMSE, train 0.2622930005456161, test 0.2665026356310894\n",
      "RMSE, train 0.2600692371753129, test 0.26698996413809556\n",
      "RMSE, train 0.2592438804079788, test 0.2644017635223766\n",
      "RMSE, train 0.25922738962025954, test 0.2637659376487136\n",
      "RMSE, train 0.25796916539018805, test 0.2624811234418303\n",
      "RMSE, train 0.257291395555843, test 0.260317020273457\n",
      "RMSE, train 0.25747501927268024, test 0.2616343131909768\n",
      "RMSE, train 0.25606880024677575, test 0.2615604786357532\n",
      "RMSE, train 0.25523238220825945, test 0.25928390367577475\n",
      "RMSE, train 0.2559363798172486, test 0.260685568364958\n",
      "RMSE, train 0.2538702402339138, test 0.26197199694191414\n",
      "RMSE, train 0.2534518801052161, test 0.2578680644898365\n",
      "RMSE, train 0.2539211589316226, test 0.25861744101469714\n",
      "RMSE, train 0.25439568804671064, test 0.2587295677512884\n",
      "RMSE, train 0.25337016360476766, test 0.2582177276102205\n",
      "RMSE, train 0.2527793095343643, test 0.2598743746057153\n",
      "RMSE, train 0.2520613136014553, test 0.2588350405761351\n",
      "RMSE, train 0.252955241843757, test 0.2577266540999214\n",
      "RMSE, train 0.251969616032309, test 0.25905791639039916\n",
      "RMSE, train 0.25167535928388435, test 0.2591562873373429\n",
      "RMSE, train 0.25156593110148956, test 0.25757485240076977\n",
      "RMSE, train 0.25115473103718927, test 0.25926336653841037\n",
      "RMSE, train 0.25148721424994447, test 0.25777394805724424\n",
      "RMSE, train 0.25224672882544874, test 0.25594163678276044\n",
      "RMSE, train 0.251667258094507, test 0.2566267106837283\n",
      "RMSE, train 0.2512138814599526, test 0.2567627156774203\n",
      "RMSE, train 0.25057105780249894, test 0.25763447970772785\n",
      "RMSE, train 0.24976227052434527, test 0.2576971733942628\n",
      "RMSE, train 0.2492243577773222, test 0.25656295474618673\n",
      "RMSE, train 0.2498788075954324, test 0.25928391981869936\n",
      "RMSE, train 0.24862064613085805, test 0.25513202231377363\n",
      "RMSE, train 0.24950980045127147, test 0.25668746791779995\n",
      "RMSE, train 0.2495597471304313, test 0.2565328512961666\n",
      "RMSE, train 0.2492665850341019, test 0.25635761247637373\n",
      "RMSE, train 0.24833192474989577, test 0.2558734101864199\n",
      "RMSE, train 0.24937743121626402, test 0.25583819129193824\n",
      "RMSE, train 0.24870018305426295, test 0.25533786478141945\n",
      "RMSE, train 0.24858102892911194, test 0.25517282153790194\n",
      "RMSE, train 0.2484639436006546, test 0.25446953577920794\n",
      "RMSE, train 0.24841883225422917, test 0.25292459813257057\n",
      "RMSE, train 0.24826815333029237, test 0.2568329417457183\n",
      "RMSE, train 0.24820832951427108, test 0.2559236161566029\n",
      "RMSE, train 0.2483961135337148, test 0.25784588636209566\n",
      "RMSE, train 0.2475415174708222, test 0.2544617336243391\n",
      "RMSE, train 0.24820714218146872, test 0.2572359121404588\n",
      "RMSE, train 0.24842488658473347, test 0.2547809694272776\n",
      "RMSE, train 0.2473638646605641, test 0.25519826635718346\n",
      "RMSE, train 0.2469700826802338, test 0.2558967676013708\n",
      "RMSE, train 0.24786180615274592, test 0.2540474943816662\n",
      "RMSE, train 0.24809394812568872, test 0.2557081618967156\n",
      "Early stopping at epoch 75 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.0187530840923584, test 0.9785016482429845\n",
      "RMSE, train 1.0010565133006484, test 0.9626080707779953\n",
      "RMSE, train 0.9736787664474745, test 0.9088670720479318\n",
      "RMSE, train 0.8663201330144421, test 0.7392581360680717\n",
      "RMSE, train 0.6292862445765331, test 0.4881902262568474\n",
      "RMSE, train 0.4474593614570975, test 0.4087915319417204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.39253265889511646, test 0.37579462490975857\n",
      "RMSE, train 0.36805898954276167, test 0.3655666767486504\n",
      "RMSE, train 0.3503586377518369, test 0.35206191215131966\n",
      "RMSE, train 0.3414267088917606, test 0.34229086485824417\n",
      "RMSE, train 0.3343492610164977, test 0.3419149511360696\n",
      "RMSE, train 0.33120068433757444, test 0.34146897667752846\n",
      "RMSE, train 0.3282207933646142, test 0.33606928972793476\n",
      "RMSE, train 0.3292922360055587, test 0.3334485036986215\n",
      "RMSE, train 0.32532421906919, test 0.33732753047453506\n",
      "RMSE, train 0.3249691287319385, test 0.33198597242257427\n",
      "RMSE, train 0.32376022107720637, test 0.33292574901133776\n",
      "RMSE, train 0.32123644361049264, test 0.3309185983213995\n",
      "RMSE, train 0.32186882152406737, test 0.33006604867322104\n",
      "RMSE, train 0.32068252177150164, test 0.32938836408512934\n",
      "RMSE, train 0.3218217122983309, test 0.3265373025621687\n",
      "RMSE, train 0.3196830101846869, test 0.33325361433838097\n",
      "RMSE, train 0.3194731843367641, test 0.3266345154760139\n",
      "RMSE, train 0.3195569629827616, test 0.3300596985167691\n",
      "RMSE, train 0.31931957212928075, test 0.3277902463451028\n",
      "RMSE, train 0.3193016008419149, test 0.32727246891175\n",
      "RMSE, train 0.3172260148203191, test 0.3264925293624401\n",
      "RMSE, train 0.3162821115751412, test 0.32499268983623814\n",
      "RMSE, train 0.3176575519939913, test 0.3255284706662808\n",
      "RMSE, train 0.31706300202537985, test 0.3289552742083158\n",
      "RMSE, train 0.316210496951552, test 0.32627859791474684\n",
      "RMSE, train 0.3160105814471484, test 0.32552318767245325\n",
      "RMSE, train 0.317126499346918, test 0.3255648547783494\n",
      "RMSE, train 0.3157753703835743, test 0.3263795387798122\n",
      "RMSE, train 0.316143098739757, test 0.32474339181291206\n",
      "RMSE, train 0.31568389394054747, test 0.32425087437565836\n",
      "RMSE, train 0.3151042134641043, test 0.32753241314951864\n",
      "RMSE, train 0.3158309930582452, test 0.3230545297265053\n",
      "RMSE, train 0.3161080166665038, test 0.3241568932841931\n",
      "RMSE, train 0.31541050629678113, test 0.32416983055216925\n",
      "RMSE, train 0.31547864654744634, test 0.3245722344145179\n",
      "RMSE, train 0.3158703290559108, test 0.32588924414345194\n",
      "RMSE, train 0.3161510960533728, test 0.3243169777893594\n",
      "RMSE, train 0.3143381132928894, test 0.3245615340503199\n",
      "RMSE, train 0.3144031913062326, test 0.3255587656583105\n",
      "RMSE, train 0.3152008721186964, test 0.3253661368840507\n",
      "RMSE, train 0.3143805498521053, test 0.324857696890831\n",
      "RMSE, train 0.3139799407040112, test 0.324170839839748\n",
      "Early stopping at epoch 48 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.1494824382489037, test 1.0452356808776155\n",
      "RMSE, train 1.0246079664994783, test 0.9652471216993594\n",
      "RMSE, train 0.9888229168984922, test 0.9442177472311423\n",
      "RMSE, train 0.9443280720924583, test 0.8713514922408883\n",
      "RMSE, train 0.8260499718745193, test 0.7180489000924136\n",
      "RMSE, train 0.64413873243225, test 0.5505933370612083\n",
      "RMSE, train 0.5069449829948323, test 0.45663271721349946\n",
      "RMSE, train 0.4371071456526427, test 0.4275355322645345\n",
      "RMSE, train 0.40995386379850285, test 0.41266929570141186\n",
      "RMSE, train 0.39296688009136993, test 0.3924056518515316\n",
      "RMSE, train 0.3772428842938, test 0.38037986697953774\n",
      "RMSE, train 0.362725827258264, test 0.3683417041640763\n",
      "RMSE, train 0.3496739140340031, test 0.3588777444231401\n",
      "RMSE, train 0.3398295260397843, test 0.3500855865828488\n",
      "RMSE, train 0.32972893750320104, test 0.3418516825645342\n",
      "RMSE, train 0.32574240388891623, test 0.3361610772959683\n",
      "RMSE, train 0.3198223893818834, test 0.3329071392980191\n",
      "RMSE, train 0.3166555507868662, test 0.32604377504882465\n",
      "RMSE, train 0.3136302914320086, test 0.3268012435884651\n",
      "RMSE, train 0.31066840140341107, test 0.32544387152435583\n",
      "RMSE, train 0.3074456890334997, test 0.32595162394396754\n",
      "RMSE, train 0.30602194188421616, test 0.32109264913228674\n",
      "RMSE, train 0.3061252684069321, test 0.3230934577797531\n",
      "RMSE, train 0.30325416801288524, test 0.3163796523842243\n",
      "RMSE, train 0.3030252561240453, test 0.31607918003830343\n",
      "RMSE, train 0.3017675161796033, test 0.3154232443199245\n",
      "RMSE, train 0.30016733736067075, test 0.3149366898274203\n",
      "RMSE, train 0.3002333406175199, test 0.31650708328693283\n",
      "RMSE, train 0.29937729775705146, test 0.3147385951575883\n",
      "RMSE, train 0.2985061751887403, test 0.3106095810002143\n",
      "RMSE, train 0.29922847847366546, test 0.3157101106753043\n",
      "RMSE, train 0.29808460623694105, test 0.31339280088560295\n",
      "RMSE, train 0.29625757895577115, test 0.3104667376487627\n",
      "RMSE, train 0.29718475591708726, test 0.31434413530957805\n",
      "RMSE, train 0.2969018337003586, test 0.3128946910210706\n",
      "RMSE, train 0.2968780740327097, test 0.3120808513886338\n",
      "RMSE, train 0.29699427141670154, test 0.3121345348040992\n",
      "RMSE, train 0.29672233593303526, test 0.31183751952757527\n",
      "RMSE, train 0.2957513682176714, test 0.3134294483092947\n",
      "RMSE, train 0.2968503008909824, test 0.3093888063769822\n",
      "RMSE, train 0.2953898275580107, test 0.3100243605878375\n",
      "RMSE, train 0.2950301244186714, test 0.3119436129244096\n",
      "RMSE, train 0.294788617356743, test 0.3155498403474825\n",
      "RMSE, train 0.29502237564779715, test 0.31291075296905063\n",
      "RMSE, train 0.29528313328933825, test 0.31048656576270356\n",
      "RMSE, train 0.29546241813042773, test 0.3107284688894902\n",
      "RMSE, train 0.2947490796647264, test 0.310545867052647\n",
      "RMSE, train 0.2949222988311218, test 0.3121560378632414\n",
      "RMSE, train 0.2954806784009185, test 0.3136135108700586\n",
      "RMSE, train 0.2950234016061096, test 0.3132828288122055\n",
      "Early stopping at epoch 50 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.0724171799322206, test 1.0053418840019448\n",
      "RMSE, train 0.9974264505356905, test 0.9935858874645048\n",
      "RMSE, train 0.9601692795187164, test 0.9007230348957395\n",
      "RMSE, train 0.8861227387345602, test 0.8151016837184869\n",
      "RMSE, train 0.7321648215454718, test 0.6449240405582687\n",
      "RMSE, train 0.5524103393747235, test 0.5011666175520536\n",
      "RMSE, train 0.4527146590081643, test 0.44038008341511475\n",
      "RMSE, train 0.41341048369356687, test 0.42347122092270156\n",
      "RMSE, train 0.38827499503053, test 0.40370829649341916\n",
      "RMSE, train 0.37074759308770827, test 0.38665049675020197\n",
      "RMSE, train 0.3541977069298615, test 0.36773798621973947\n",
      "RMSE, train 0.3417366573547241, test 0.35429042679013556\n",
      "RMSE, train 0.33149882549344784, test 0.34778314988011294\n",
      "RMSE, train 0.3247657556290298, test 0.3432065964613146\n",
      "RMSE, train 0.3179873428760968, test 0.33414291337277124\n",
      "RMSE, train 0.3125856745979282, test 0.33361042428363874\n",
      "RMSE, train 0.3103828157636729, test 0.3306252496335113\n",
      "RMSE, train 0.3081862856047737, test 0.3223786271602205\n",
      "RMSE, train 0.30410494547416933, test 0.3218213003671285\n",
      "RMSE, train 0.3030432533481625, test 0.32256773041868675\n",
      "RMSE, train 0.3014483878526155, test 0.3195046526425093\n",
      "RMSE, train 0.299924820466874, test 0.3239374632395587\n",
      "RMSE, train 0.299273429124344, test 0.3276348380209173\n",
      "RMSE, train 0.2974109275359439, test 0.3181213082619084\n",
      "RMSE, train 0.29724457435256796, test 0.3124517959551614\n",
      "RMSE, train 0.29630644003597406, test 0.31472717645098863\n",
      "RMSE, train 0.29592563388891285, test 0.314806788002403\n",
      "RMSE, train 0.29533109429896304, test 0.3134744171125507\n",
      "RMSE, train 0.29429178909706105, test 0.31384156543074304\n",
      "RMSE, train 0.29425443307166993, test 0.3125898496980227\n",
      "RMSE, train 0.2932961900627811, test 0.3133880786814736\n",
      "RMSE, train 0.2931577312691478, test 0.32279812146737735\n",
      "RMSE, train 0.29391285957604857, test 0.31242211437919765\n",
      "RMSE, train 0.29314954019640516, test 0.3130390340986761\n",
      "RMSE, train 0.29245862145321955, test 0.31920410909699004\n",
      "RMSE, train 0.29276770006449376, test 0.30825228490007733\n",
      "RMSE, train 0.2925025581464065, test 0.3116356566982362\n",
      "RMSE, train 0.29126182559550234, test 0.3107492580865193\n",
      "RMSE, train 0.29296004434167067, test 0.30687369283252547\n",
      "RMSE, train 0.2918587148260334, test 0.3126296769212751\n",
      "RMSE, train 0.2907196535704538, test 0.31009307691773164\n",
      "RMSE, train 0.29148523235193624, test 0.31116795814731746\n",
      "RMSE, train 0.2910738835496178, test 0.3122135449237036\n",
      "RMSE, train 0.29044503500937285, test 0.3101869815761603\n",
      "RMSE, train 0.2902598894619319, test 0.30942523088848706\n",
      "RMSE, train 0.290100042086599, test 0.3065023885189908\n",
      "RMSE, train 0.29011571752416265, test 0.3072678108871417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2905785921881431, test 0.3125668602082336\n",
      "RMSE, train 0.2897744207795612, test 0.3061078423182073\n",
      "RMSE, train 0.28911151636099874, test 0.30897889597323336\n",
      "RMSE, train 0.28940617625829446, test 0.3090211291915005\n",
      "RMSE, train 0.2897806880097491, test 0.3093023346465768\n",
      "RMSE, train 0.2897971098680677, test 0.309857901728269\n",
      "RMSE, train 0.28955262407412724, test 0.3099084212942031\n",
      "RMSE, train 0.28881621725344037, test 0.3139727367359458\n",
      "RMSE, train 0.28998090643568447, test 0.31749366093607784\n",
      "RMSE, train 0.2895984075910405, test 0.30849373969927574\n",
      "RMSE, train 0.28932333588954107, test 0.3113629153920609\n",
      "RMSE, train 0.28921771447689687, test 0.3101396824694374\n",
      "Early stopping at epoch 59 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9932499591391685, test 0.9502973814805349\n",
      "RMSE, train 0.9755115018218675, test 0.9225238773557874\n",
      "RMSE, train 0.909890901447949, test 0.8120033148262236\n",
      "RMSE, train 0.7377125572644154, test 0.6149508870310254\n",
      "RMSE, train 0.5318547666394164, test 0.4781175659762488\n",
      "RMSE, train 0.4349655114977829, test 0.42838206158743963\n",
      "RMSE, train 0.3922968505608104, test 0.3985951537887255\n",
      "RMSE, train 0.3666752579639543, test 0.3708943785892593\n",
      "RMSE, train 0.34821891977459274, test 0.3550069769223531\n",
      "RMSE, train 0.33349396330568026, test 0.3440643050604396\n",
      "RMSE, train 0.32260112038680483, test 0.3398829627368185\n",
      "RMSE, train 0.3187135957442525, test 0.3251736064751943\n",
      "RMSE, train 0.31199593544809645, test 0.32294875284036\n",
      "RMSE, train 0.30749973877661957, test 0.31702727178732554\n",
      "RMSE, train 0.30275826734513284, test 0.3133868412839042\n",
      "RMSE, train 0.2987418296041514, test 0.3174840827782949\n",
      "RMSE, train 0.29726778304159157, test 0.31013912426100837\n",
      "RMSE, train 0.29571335740648513, test 0.3115537128514714\n",
      "RMSE, train 0.293912875584033, test 0.3061780000726382\n",
      "RMSE, train 0.2928420645448397, test 0.3089484633670913\n",
      "RMSE, train 0.2916839201696157, test 0.30101134727398554\n",
      "RMSE, train 0.2891955051541007, test 0.30401068843073314\n",
      "RMSE, train 0.2896367171703966, test 0.30384962012370426\n",
      "RMSE, train 0.28830580618182283, test 0.3015517324209213\n",
      "RMSE, train 0.2871505699830878, test 0.30217385258939533\n",
      "RMSE, train 0.2874044370297794, test 0.30231018778350616\n",
      "RMSE, train 0.2870019583327751, test 0.3019199974007077\n",
      "RMSE, train 0.28556422395204917, test 0.3032413526541657\n",
      "RMSE, train 0.2857760514692476, test 0.3006345402863291\n",
      "RMSE, train 0.2837775864932094, test 0.3024431076314714\n",
      "RMSE, train 0.2834117250903597, test 0.3022908788588312\n",
      "RMSE, train 0.28337862505263717, test 0.2982362381286091\n",
      "RMSE, train 0.2826353603738016, test 0.2978305112984445\n",
      "RMSE, train 0.2833243407047984, test 0.30006827869349056\n",
      "RMSE, train 0.2825827105347358, test 0.29536916000975505\n",
      "RMSE, train 0.2824666653722123, test 0.29873281593124074\n",
      "RMSE, train 0.28257288605055075, test 0.2958589310447375\n",
      "RMSE, train 0.2808898247356685, test 0.2973098499907388\n",
      "RMSE, train 0.28092347228061154, test 0.29767849130762947\n",
      "RMSE, train 0.28234510009259867, test 0.29264861742655435\n",
      "RMSE, train 0.28008154006499164, test 0.29466769347588223\n",
      "RMSE, train 0.28050402818985704, test 0.29580656107929015\n",
      "RMSE, train 0.27982779084190207, test 0.29638864530457393\n",
      "RMSE, train 0.2796486593843149, test 0.2926650976141294\n",
      "RMSE, train 0.2794256407134938, test 0.2964799920717875\n",
      "RMSE, train 0.28049549817878283, test 0.29374110168880885\n",
      "RMSE, train 0.2802907802425626, test 0.2935959595772955\n",
      "RMSE, train 0.2789238129825284, test 0.29649697922998003\n",
      "RMSE, train 0.27932099560200363, test 0.29454618626170687\n",
      "RMSE, train 0.2786850566169965, test 0.2955189065800773\n",
      "Early stopping at epoch 50 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.026492177274233, test 0.9817188535675858\n",
      "RMSE, train 0.9994741807939954, test 0.9643032556832439\n",
      "RMSE, train 0.9778875664131566, test 0.9311750181997666\n",
      "RMSE, train 0.9163360911942927, test 0.8334093256430193\n",
      "RMSE, train 0.7528596639924644, test 0.6428803762402198\n",
      "RMSE, train 0.58368549104279, test 0.5466086105866865\n",
      "RMSE, train 0.5185692491406042, test 0.5284976534771196\n",
      "RMSE, train 0.49520258805862555, test 0.5096899958873036\n",
      "RMSE, train 0.47866427136954004, test 0.49686117605729535\n",
      "RMSE, train 0.46161988741902676, test 0.48758851051932633\n",
      "RMSE, train 0.45515471919095896, test 0.4785022657326978\n",
      "RMSE, train 0.4486799625210774, test 0.47307418979177573\n",
      "RMSE, train 0.44301880294944374, test 0.4695177964790903\n",
      "RMSE, train 0.43727696699734714, test 0.4623870693071924\n",
      "RMSE, train 0.43506720796919685, test 0.4659384093200318\n",
      "RMSE, train 0.43154620942101796, test 0.46341524837595044\n",
      "RMSE, train 0.42961468545760967, test 0.4609320103520095\n",
      "RMSE, train 0.43074174436642665, test 0.4600884917408529\n",
      "RMSE, train 0.43229599981990013, test 0.45867339965671\n",
      "RMSE, train 0.42751169474317274, test 0.4610903254061034\n",
      "RMSE, train 0.4278617761027259, test 0.4559999207655589\n",
      "RMSE, train 0.4271230473203589, test 0.4593780194268082\n",
      "RMSE, train 0.4276288466159172, test 0.45623347569595685\n",
      "RMSE, train 0.4264095518874656, test 0.4591699259148704\n",
      "RMSE, train 0.42605503446315496, test 0.45528179979083516\n",
      "RMSE, train 0.42776398335226007, test 0.45774407624596297\n",
      "RMSE, train 0.42400801775653674, test 0.4550434245605661\n",
      "RMSE, train 0.42449593183318096, test 0.45393552638665596\n",
      "RMSE, train 0.42293694025146933, test 0.45344388575264905\n",
      "RMSE, train 0.423678903423778, test 0.4539359631863507\n",
      "RMSE, train 0.42343589215377725, test 0.4557672883525039\n",
      "RMSE, train 0.42428173817020176, test 0.4547437206663267\n",
      "RMSE, train 0.4228929938853224, test 0.4552542901400364\n",
      "RMSE, train 0.42375823655017725, test 0.45262291621078143\n",
      "RMSE, train 0.42292562986935844, test 0.4575809854449648\n",
      "RMSE, train 0.4231617860587127, test 0.45387798532693074\n",
      "RMSE, train 0.4223131481330377, test 0.4554319676726755\n",
      "RMSE, train 0.422297453348386, test 0.454739790522691\n",
      "RMSE, train 0.4226731198924095, test 0.453927399985718\n",
      "RMSE, train 0.4225313686071223, test 0.4545465674665239\n",
      "RMSE, train 0.4219729967761448, test 0.45642496765864016\n",
      "RMSE, train 0.42186642749676784, test 0.4549036623552592\n",
      "RMSE, train 0.4226014978801126, test 0.4549130273587776\n",
      "RMSE, train 0.42103676304840515, test 0.45262209438916406\n",
      "RMSE, train 0.4211168072771618, test 0.4533357203307778\n",
      "RMSE, train 0.42194505174323227, test 0.4568084412150913\n",
      "RMSE, train 0.4209842572220963, test 0.45088436055665065\n",
      "RMSE, train 0.4208973888808766, test 0.45261876992505007\n",
      "RMSE, train 0.42102078503239126, test 0.45160304250741246\n",
      "RMSE, train 0.4210995783287039, test 0.44999318923613035\n",
      "RMSE, train 0.4204012932652075, test 0.45475586887561914\n",
      "RMSE, train 0.4222688892432705, test 0.45301796842103054\n",
      "RMSE, train 0.42167234431706313, test 0.45207727497274225\n",
      "RMSE, train 0.42104210072449777, test 0.45313965642091\n",
      "RMSE, train 0.42101940461650744, test 0.4530463060646346\n",
      "RMSE, train 0.42166778131918686, test 0.45463119371972904\n",
      "RMSE, train 0.42000188678503036, test 0.4517811904049883\n",
      "RMSE, train 0.42108255100133657, test 0.44867927362822524\n",
      "RMSE, train 0.42188866549424264, test 0.45479738336018843\n",
      "RMSE, train 0.42083289946058267, test 0.4521922538376818\n",
      "RMSE, train 0.4204550785511222, test 0.45223696830898824\n",
      "RMSE, train 0.42240521665161573, test 0.4502643459674084\n",
      "RMSE, train 0.4211682661238393, test 0.4506442452018911\n",
      "RMSE, train 0.42125902450609326, test 0.4515140815214677\n",
      "RMSE, train 0.4211521676233753, test 0.45066730873753325\n",
      "RMSE, train 0.4211092951609628, test 0.45292790279243933\n",
      "RMSE, train 0.4204398821720576, test 0.45333356207067316\n",
      "RMSE, train 0.41991580924369887, test 0.45180842325542914\n",
      "Early stopping at epoch 68 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.9984294977603536, test 0.9614840640376011\n",
      "RMSE, train 0.9886124277807246, test 0.9473964407419165\n",
      "RMSE, train 0.9603329902947552, test 0.8994680372998118\n",
      "RMSE, train 0.871996216927514, test 0.771377577756842\n",
      "RMSE, train 0.698945030532401, test 0.6069108055283626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.5576414486600293, test 0.5441760765388608\n",
      "RMSE, train 0.5073913712468412, test 0.5255473122621576\n",
      "RMSE, train 0.48533812041083974, test 0.5055487679007152\n",
      "RMSE, train 0.46865629306947343, test 0.502618914625297\n",
      "RMSE, train 0.46036374625383003, test 0.4884087033569813\n",
      "RMSE, train 0.4454917506963918, test 0.4795006870602568\n",
      "RMSE, train 0.43736266547983343, test 0.4742652070708573\n",
      "RMSE, train 0.4367613231368137, test 0.47012344701215625\n",
      "RMSE, train 0.428998470983722, test 0.4653387451544404\n",
      "RMSE, train 0.4227869123446219, test 0.46072064402202767\n",
      "RMSE, train 0.4248155148492919, test 0.46395006915554404\n",
      "RMSE, train 0.4208748175414524, test 0.45700779526184004\n",
      "RMSE, train 0.4173444096713957, test 0.4567528668170174\n",
      "RMSE, train 0.41491644735438654, test 0.4518853227297465\n",
      "RMSE, train 0.41618641251415917, test 0.4521833524728815\n",
      "RMSE, train 0.41420672803816166, test 0.45018718065693974\n",
      "RMSE, train 0.4126307066868652, test 0.4547413250741859\n",
      "RMSE, train 0.413303813511374, test 0.4475602046586573\n",
      "RMSE, train 0.4104348872647141, test 0.4514479065934817\n",
      "RMSE, train 0.4118742673761315, test 0.4503169435386856\n",
      "RMSE, train 0.41123325727654225, test 0.44476756220683455\n",
      "RMSE, train 0.4097198506422115, test 0.4478446656527619\n",
      "RMSE, train 0.4101732466181721, test 0.44073972944170237\n",
      "RMSE, train 0.4092719066850465, test 0.4506175859520833\n",
      "RMSE, train 0.40931011879383916, test 0.4477721389072637\n",
      "RMSE, train 0.40829071703583303, test 0.44300311322634417\n",
      "RMSE, train 0.4084341690847368, test 0.44436787255108356\n",
      "RMSE, train 0.406864510905562, test 0.4485211349092424\n",
      "RMSE, train 0.40695502044576587, test 0.4481687972632547\n",
      "RMSE, train 0.4069323009914822, test 0.4449670778897901\n",
      "RMSE, train 0.40751366896761787, test 0.4432964588825901\n",
      "RMSE, train 0.4075238568463711, test 0.4451034824984769\n",
      "RMSE, train 0.40506820154912543, test 0.44353021184603375\n",
      "Early stopping at epoch 38 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.0623813558299586, test 0.9815926194190979\n",
      "RMSE, train 0.9982189070182348, test 0.9439208951261309\n",
      "RMSE, train 0.9706589346626056, test 0.912318002515369\n",
      "RMSE, train 0.9252558158575043, test 0.8543816414144304\n",
      "RMSE, train 0.8317068438484984, test 0.7496099630991618\n",
      "RMSE, train 0.6845698052178817, test 0.6198647035492791\n",
      "RMSE, train 0.5656425433981451, test 0.5565229839748806\n",
      "RMSE, train 0.5204220533049653, test 0.5424254829684894\n",
      "RMSE, train 0.49871411148428596, test 0.5309412389993667\n",
      "RMSE, train 0.4827276390357159, test 0.5207664201656977\n",
      "RMSE, train 0.4740126947909995, test 0.513504492243131\n",
      "RMSE, train 0.4608006719951681, test 0.5016657723320855\n",
      "RMSE, train 0.45645245524108247, test 0.49087623440557054\n",
      "RMSE, train 0.4472269676926965, test 0.49071839153766633\n",
      "RMSE, train 0.44330011364424005, test 0.4801139425900247\n",
      "RMSE, train 0.4365515230559917, test 0.4795602381229401\n",
      "RMSE, train 0.4342077282882444, test 0.47573176092571684\n",
      "RMSE, train 0.42701626354150696, test 0.4697690902484788\n",
      "RMSE, train 0.42434488975937473, test 0.4674587763018078\n",
      "RMSE, train 0.42357405590400543, test 0.4628730810350842\n",
      "RMSE, train 0.42062903679606084, test 0.46433828920125964\n",
      "RMSE, train 0.41711304320720327, test 0.4632762468523449\n",
      "RMSE, train 0.4152499597589925, test 0.4609949635134803\n",
      "RMSE, train 0.4156904686895021, test 0.45478590627511345\n",
      "RMSE, train 0.4125415308054567, test 0.45532826764716045\n",
      "RMSE, train 0.411847177220162, test 0.45926523506641387\n",
      "RMSE, train 0.41191041413343177, test 0.45501815097199544\n",
      "RMSE, train 0.4105768894972506, test 0.45289460337824294\n",
      "RMSE, train 0.4088763005408958, test 0.4485835244258245\n",
      "RMSE, train 0.4080727840208943, test 0.4544532749387953\n",
      "RMSE, train 0.40693205422307605, test 0.45453536825047597\n",
      "RMSE, train 0.40752633875913696, test 0.4523952179484897\n",
      "RMSE, train 0.40705107256890627, test 0.4514480036165979\n",
      "RMSE, train 0.40537557732866136, test 0.4598973744445377\n",
      "RMSE, train 0.4057540135643874, test 0.4488299795322948\n",
      "RMSE, train 0.4058012931816019, test 0.4475952577259805\n",
      "RMSE, train 0.4054551962813277, test 0.4488554863466157\n",
      "RMSE, train 0.4061398870861434, test 0.44681080910894605\n",
      "RMSE, train 0.4039121163742883, test 0.4470985018544727\n",
      "RMSE, train 0.4046990336835224, test 0.44755682001511254\n",
      "RMSE, train 0.4047923012563803, test 0.4508267765243848\n",
      "RMSE, train 0.402752920382749, test 0.4471286118030548\n",
      "RMSE, train 0.40315625400877386, test 0.446061999268002\n",
      "RMSE, train 0.4045425644621374, test 0.4425742788447274\n",
      "RMSE, train 0.40313947931775507, test 0.4456851296954685\n",
      "RMSE, train 0.40190898805776376, test 0.44993786381350626\n",
      "RMSE, train 0.4024150059068942, test 0.4508527679575814\n",
      "RMSE, train 0.4027624570054185, test 0.4472013788090812\n",
      "RMSE, train 0.40259220605751256, test 0.446808660030365\n",
      "RMSE, train 0.4013462573932509, test 0.4436895890368356\n",
      "RMSE, train 0.401111319219327, test 0.44174927605523\n",
      "RMSE, train 0.4003212651152495, test 0.44877293672826557\n",
      "RMSE, train 0.4011404248421404, test 0.44544005427095623\n",
      "RMSE, train 0.401988542224519, test 0.44545309576723313\n",
      "RMSE, train 0.401123669430252, test 0.4460050223602189\n",
      "RMSE, train 0.40104498511376085, test 0.44581515143315\n",
      "RMSE, train 0.40111746657087477, test 0.4418860604365667\n",
      "RMSE, train 0.40057140412035014, test 0.4423527754015393\n",
      "RMSE, train 0.40145420799197534, test 0.44561443196402656\n",
      "RMSE, train 0.40055890453632953, test 0.4444326354397668\n",
      "RMSE, train 0.4006929861888731, test 0.4420920709768931\n",
      "Early stopping at epoch 61 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.1139747935849187, test 1.0054756043813167\n",
      "RMSE, train 1.012941052052091, test 0.9450536232728225\n",
      "RMSE, train 0.9819129524386931, test 0.9291788859245105\n",
      "RMSE, train 0.9636945823828379, test 0.9062470411643003\n",
      "RMSE, train 0.9313930851462474, test 0.8737198053262173\n",
      "RMSE, train 0.8787675988265659, test 0.8211495203849597\n",
      "RMSE, train 0.8022508299053643, test 0.7325357236923316\n",
      "RMSE, train 0.6952203722014977, test 0.6585932458058382\n",
      "RMSE, train 0.6107162832285384, test 0.5905560606565231\n",
      "RMSE, train 0.5584789940686984, test 0.5899533411631217\n",
      "RMSE, train 0.5231306456331152, test 0.5820093901875691\n",
      "RMSE, train 0.5035133496437488, test 0.5205309345172002\n",
      "RMSE, train 0.483409328995464, test 0.5045793117621006\n",
      "RMSE, train 0.46603921747467597, test 0.493854297659336\n",
      "RMSE, train 0.45211718995066075, test 0.47642484345497227\n",
      "RMSE, train 0.4429837986130581, test 0.4690233286565695\n",
      "RMSE, train 0.4353112464196214, test 0.46049362134474975\n",
      "RMSE, train 0.4269207747554482, test 0.4621203583784593\n",
      "RMSE, train 0.42384799994597927, test 0.45579135647186864\n",
      "RMSE, train 0.4185048809211202, test 0.4555360762736736\n",
      "RMSE, train 0.41544335834519514, test 0.4434389334458571\n",
      "RMSE, train 0.4118139396575381, test 0.44750286715152937\n",
      "RMSE, train 0.41026984183030707, test 0.48073278806912595\n",
      "RMSE, train 0.4070773156261147, test 0.44160769478632855\n",
      "RMSE, train 0.4052598392851999, test 0.4348963623723158\n",
      "RMSE, train 0.4032720398865756, test 0.4375235142234044\n",
      "RMSE, train 0.40056951292950044, test 0.4375823967349835\n",
      "RMSE, train 0.39826662578501065, test 0.45183998804826003\n",
      "RMSE, train 0.3972547062182352, test 0.4312379249395468\n",
      "RMSE, train 0.39546751627855214, test 0.43352744671014637\n",
      "RMSE, train 0.3973041770985565, test 0.44073009147093845\n",
      "RMSE, train 0.3955661147554344, test 0.4433860455950101\n",
      "RMSE, train 0.39258126756669576, test 0.4303207989686575\n",
      "RMSE, train 0.3912718533262657, test 0.4253974071679971\n",
      "RMSE, train 0.3905869971647441, test 0.42866513419609803\n",
      "RMSE, train 0.39168713675852507, test 0.43163196150309\n",
      "RMSE, train 0.3884959689274755, test 0.44306315080477643\n",
      "RMSE, train 0.38973071419190025, test 0.4303736388683319\n",
      "RMSE, train 0.3888641636226779, test 0.4228420700782385\n",
      "RMSE, train 0.38663174458010546, test 0.42720498087314457\n",
      "RMSE, train 0.386270416767055, test 0.42845317816887146\n",
      "RMSE, train 0.386070581518601, test 0.4284471972630574\n",
      "RMSE, train 0.3836716885135924, test 0.43107345681159925\n",
      "RMSE, train 0.38466135298723003, test 0.4334707193267651\n",
      "RMSE, train 0.38359231977633595, test 0.42721320402163726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.38465833543245664, test 0.42480742167203855\n",
      "RMSE, train 0.3821151776477184, test 0.4246773184874119\n",
      "RMSE, train 0.381994571037753, test 0.4336686266156343\n",
      "RMSE, train 0.38256756469282405, test 0.4237963803685628\n",
      "Early stopping at epoch 49 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.LSTM, data_dir = 'data_synthetic', only_one = True)\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/lstm/'+'output_size' + str(output) + 'input_size' + str(inputs) + '_singlevar.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22ea43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9776900614438792, test 0.91857482540992\n",
      "RMSE, train 0.8190069675681149, test 0.6232421198679555\n",
      "RMSE, train 0.46824737320186594, test 0.36045048361824406\n",
      "RMSE, train 0.3466632783177342, test 0.3302622273444168\n",
      "RMSE, train 0.32229958306777146, test 0.3130274416217881\n",
      "RMSE, train 0.3033917153717972, test 0.29943741112947464\n",
      "RMSE, train 0.289402319920864, test 0.28697393594249604\n",
      "RMSE, train 0.2781087525866248, test 0.28040460767524855\n",
      "RMSE, train 0.2712918455922321, test 0.2742835094010638\n",
      "RMSE, train 0.2671470672422247, test 0.26894865257124745\n",
      "RMSE, train 0.2628527589348465, test 0.26720739654715986\n",
      "RMSE, train 0.2604059797855234, test 0.26672471206515064\n",
      "RMSE, train 0.25894323067938385, test 0.26413388970878815\n",
      "RMSE, train 0.25902723956838425, test 0.2636939956536216\n",
      "RMSE, train 0.2582979301807909, test 0.2616949483391739\n",
      "RMSE, train 0.25612979099566757, test 0.26045154263415643\n",
      "RMSE, train 0.2567454385074231, test 0.26030323930805727\n",
      "RMSE, train 0.25549200769116287, test 0.2603329458544331\n",
      "RMSE, train 0.2555285764953836, test 0.26245185961165735\n",
      "RMSE, train 0.25519507257599133, test 0.26043498492048633\n",
      "RMSE, train 0.25455175088387233, test 0.2605660924868238\n",
      "RMSE, train 0.2543611510145099, test 0.25963705742070753\n",
      "RMSE, train 0.25506578904131183, test 0.25832174369885075\n",
      "RMSE, train 0.25357798104111856, test 0.2576028417435385\n",
      "RMSE, train 0.2538358611846159, test 0.25857005184215887\n",
      "RMSE, train 0.2539892673875268, test 0.26101722592307675\n",
      "RMSE, train 0.25337073417461436, test 0.2590029555703363\n",
      "RMSE, train 0.25280622616704745, test 0.258510974025534\n",
      "RMSE, train 0.2535686697295532, test 0.25933611465077244\n",
      "RMSE, train 0.2526454017773683, test 0.25925906879767296\n",
      "RMSE, train 0.25309669594519696, test 0.25906487037577935\n",
      "RMSE, train 0.25402576354122447, test 0.2587081890913748\n",
      "RMSE, train 0.2525188027487206, test 0.2587642223844605\n",
      "RMSE, train 0.2519512704680324, test 0.2587223096239951\n",
      "Early stopping at epoch 34 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9892201409166158, test 0.9164682040529802\n",
      "RMSE, train 0.8070385005430654, test 0.615988360825649\n",
      "RMSE, train 0.48145092535115447, test 0.37119764151159396\n",
      "RMSE, train 0.34393694945554504, test 0.3243496813311065\n",
      "RMSE, train 0.31379678843897363, test 0.3055176610542723\n",
      "RMSE, train 0.2954928875572768, test 0.2901767878985602\n",
      "RMSE, train 0.28186437863147695, test 0.2804623297915971\n",
      "RMSE, train 0.2721175002273519, test 0.2729400504719127\n",
      "RMSE, train 0.2631797527796344, test 0.2662121563657256\n",
      "RMSE, train 0.2601672090469343, test 0.2609034941092996\n",
      "RMSE, train 0.2547141452006966, test 0.26305866635535374\n",
      "RMSE, train 0.25245330534000626, test 0.25534635104916314\n",
      "RMSE, train 0.25014265189286666, test 0.2579403401406343\n",
      "RMSE, train 0.24766771733640178, test 0.25367198810597097\n",
      "RMSE, train 0.2462986291721765, test 0.24948550071105485\n",
      "RMSE, train 0.2450730379836762, test 0.24836999769053184\n",
      "RMSE, train 0.2422787463254774, test 0.2460301870649511\n",
      "RMSE, train 0.24210084633909257, test 0.24560414082255244\n",
      "RMSE, train 0.2416623516634167, test 0.2476787314680982\n",
      "RMSE, train 0.241090975400166, test 0.24619440481928753\n",
      "RMSE, train 0.2396953967117105, test 0.24611454179956893\n",
      "RMSE, train 0.24046770162005657, test 0.24688321567517668\n",
      "RMSE, train 0.239650792679806, test 0.24550656512502797\n",
      "RMSE, train 0.23945983719487904, test 0.24293263804567747\n",
      "RMSE, train 0.2388503897316784, test 0.24440820281170617\n",
      "RMSE, train 0.23885846122918342, test 0.24536608818395078\n",
      "RMSE, train 0.23767244426707024, test 0.24311761465693307\n",
      "RMSE, train 0.23816852055882154, test 0.2448494360466634\n",
      "RMSE, train 0.23760723229120617, test 0.24431497160314528\n",
      "RMSE, train 0.2369583002348178, test 0.2440700330886959\n",
      "RMSE, train 0.23776240794644182, test 0.2423677550982838\n",
      "RMSE, train 0.23643028647883943, test 0.24350873510207027\n",
      "RMSE, train 0.23683494278173214, test 0.2406159795759138\n",
      "RMSE, train 0.23687700824698937, test 0.24143572952136522\n",
      "RMSE, train 0.237153929284951, test 0.2427955452691425\n",
      "RMSE, train 0.23646477691316412, test 0.2424412410367619\n",
      "RMSE, train 0.23647477841268666, test 0.24285483508070638\n",
      "RMSE, train 0.23689665714738822, test 0.24139575118368323\n",
      "RMSE, train 0.23596120609143967, test 0.24420585372477524\n",
      "RMSE, train 0.23647273089058005, test 0.241616401297987\n",
      "RMSE, train 0.23589264654256553, test 0.24113653298498186\n",
      "RMSE, train 0.23642571820964214, test 0.24620934052408233\n",
      "RMSE, train 0.23630257457615392, test 0.24092835508102228\n",
      "Early stopping at epoch 43 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.0784942323465083, test 0.9529147752021488\n",
      "RMSE, train 0.9361749450280976, test 0.8568378561421445\n",
      "RMSE, train 0.781453987809895, test 0.6348731826271927\n",
      "RMSE, train 0.5119102397071782, test 0.3976766835702093\n",
      "RMSE, train 0.365084890331795, test 0.3400096591365965\n",
      "RMSE, train 0.3307880703955571, test 0.318568544952493\n",
      "RMSE, train 0.30931082660201265, test 0.3052083513977235\n",
      "RMSE, train 0.2929632373964354, test 0.2910495176911354\n",
      "RMSE, train 0.2783027312108703, test 0.2808203486758366\n",
      "RMSE, train 0.2692530002039887, test 0.27128449683649497\n",
      "RMSE, train 0.2609041415011959, test 0.2646405505375904\n",
      "RMSE, train 0.2571138372299259, test 0.2623040832971272\n",
      "RMSE, train 0.25274873445473756, test 0.2564437776934682\n",
      "RMSE, train 0.2487342314584169, test 0.25571680859776963\n",
      "RMSE, train 0.24735339927965644, test 0.2537155535660292\n",
      "RMSE, train 0.24470690558396424, test 0.253679464522161\n",
      "RMSE, train 0.24458780633742366, test 0.24759451221478612\n",
      "RMSE, train 0.24363088081958198, test 0.24978183824242206\n",
      "RMSE, train 0.24016991758873976, test 0.24625006389983914\n",
      "RMSE, train 0.24048032835602506, test 0.2459421295738011\n",
      "RMSE, train 0.2399589304985014, test 0.2435847157449053\n",
      "RMSE, train 0.2396719460802546, test 0.24327218813592927\n",
      "RMSE, train 0.23936972347721616, test 0.24563676942335932\n",
      "RMSE, train 0.2378256152560716, test 0.24248564537418515\n",
      "RMSE, train 0.23743729868423202, test 0.24098008361301923\n",
      "RMSE, train 0.237180686946998, test 0.2456409957978809\n",
      "RMSE, train 0.2368746831663636, test 0.2419144177253832\n",
      "RMSE, train 0.23614601889398815, test 0.24270419122879966\n",
      "RMSE, train 0.2362930740057024, test 0.2411154104037243\n",
      "RMSE, train 0.23541270860476787, test 0.24105291499903328\n",
      "RMSE, train 0.23572097583683824, test 0.23980324009531423\n",
      "RMSE, train 0.23464930001924286, test 0.23998179142935233\n",
      "RMSE, train 0.2354649059744532, test 0.23731074913551933\n",
      "RMSE, train 0.234637706105643, test 0.24036524771598347\n",
      "RMSE, train 0.23452649265527725, test 0.2399315444523828\n",
      "RMSE, train 0.23426337098516126, test 0.2400387787635912\n",
      "RMSE, train 0.23366975144091953, test 0.23926915744679017\n",
      "RMSE, train 0.2336453727917122, test 0.23858429759479405\n",
      "RMSE, train 0.23316399686372102, test 0.2385564132740623\n",
      "RMSE, train 0.2326405181654735, test 0.23998822049613586\n",
      "RMSE, train 0.23216622648462812, test 0.23849390296821008\n",
      "RMSE, train 0.23281053590304307, test 0.23984948957436963\n",
      "RMSE, train 0.23289261218200105, test 0.2392490351278531\n",
      "Early stopping at epoch 43 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9728501791174485, test 0.8968609562691521\n",
      "RMSE, train 0.8329276434703772, test 0.6870535048199635\n",
      "RMSE, train 0.5619825511672901, test 0.44263628212844625\n",
      "RMSE, train 0.39544050598201436, test 0.3625556997516576\n",
      "RMSE, train 0.3460087982097503, test 0.32945004894452934\n",
      "RMSE, train 0.32262578649281887, test 0.3169303967380056\n",
      "RMSE, train 0.3028513110267234, test 0.297437971859586\n",
      "RMSE, train 0.29249120302729503, test 0.2892068636183645\n",
      "RMSE, train 0.2820366369582588, test 0.2801324931137702\n",
      "RMSE, train 0.27634071828997503, test 0.27592508421809064\n",
      "RMSE, train 0.2686635124939438, test 0.27086459991394307\n",
      "RMSE, train 0.26328517224524073, test 0.2687494500594981\n",
      "RMSE, train 0.2602671083053996, test 0.266445827396477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2568483489403292, test 0.2606584144865765\n",
      "RMSE, train 0.25379417589498876, test 0.2595629759278952\n",
      "RMSE, train 0.25288362655264096, test 0.2612605325731577\n",
      "RMSE, train 0.24950105608007503, test 0.2549448160856378\n",
      "RMSE, train 0.24732445194641559, test 0.2572601807175898\n",
      "RMSE, train 0.24493547717469405, test 0.25336505764839695\n",
      "RMSE, train 0.2451939224165493, test 0.25270215969751864\n",
      "RMSE, train 0.24389782736437987, test 0.2518731343979929\n",
      "RMSE, train 0.24330019575670397, test 0.2499125757638146\n",
      "RMSE, train 0.24141673478775774, test 0.25213011770563964\n",
      "RMSE, train 0.2410772848065258, test 0.24835624333982373\n",
      "RMSE, train 0.24027151678442102, test 0.24911503917446323\n",
      "RMSE, train 0.2398423639288381, test 0.24789492143135444\n",
      "RMSE, train 0.23940883562644513, test 0.24903534498869204\n",
      "RMSE, train 0.23739767615152146, test 0.25009214374072414\n",
      "RMSE, train 0.23815612980389084, test 0.24562191335009595\n",
      "RMSE, train 0.23836633351438086, test 0.24656789837514653\n",
      "RMSE, train 0.23825592652567815, test 0.24540044294268476\n",
      "RMSE, train 0.23695445202984503, test 0.24434204392281234\n",
      "RMSE, train 0.23647902527188344, test 0.24747244896841983\n",
      "RMSE, train 0.23558444707589957, test 0.24692735521524561\n",
      "RMSE, train 0.2356299283360809, test 0.24394280996684933\n",
      "RMSE, train 0.23516761203938852, test 0.24399604889399865\n",
      "RMSE, train 0.23499710393762815, test 0.2435393944820937\n",
      "RMSE, train 0.23375648336578383, test 0.24322620983801635\n",
      "RMSE, train 0.234247331865363, test 0.24169414819163434\n",
      "RMSE, train 0.23420738562194715, test 0.2446067562582446\n",
      "RMSE, train 0.2340649122590097, test 0.2427141979775008\n",
      "RMSE, train 0.2343555397236262, test 0.2439771266836746\n",
      "RMSE, train 0.23408632556549974, test 0.24397452672322592\n",
      "RMSE, train 0.23332400399489164, test 0.24242443912753872\n",
      "RMSE, train 0.23356504336461817, test 0.2410549343216653\n",
      "RMSE, train 0.2318680877119374, test 0.24248840455331055\n",
      "RMSE, train 0.2326711460699045, test 0.2412944685886888\n",
      "RMSE, train 0.23271044121437254, test 0.2418734929433056\n",
      "RMSE, train 0.23159176539763063, test 0.24129164730216943\n",
      "RMSE, train 0.2320825918655407, test 0.24270977313612022\n",
      "RMSE, train 0.23151406409276698, test 0.24115293487614275\n",
      "RMSE, train 0.23108454902160708, test 0.23978404832236908\n",
      "RMSE, train 0.23208016699495634, test 0.24176970241116544\n",
      "RMSE, train 0.2315368196951461, test 0.23966405438441857\n",
      "RMSE, train 0.23124005817997142, test 0.24143204808819527\n",
      "RMSE, train 0.2297350594280443, test 0.23884820572885812\n",
      "RMSE, train 0.2310636450218699, test 0.2385756087069418\n",
      "RMSE, train 0.22997493023021692, test 0.23972502847512564\n",
      "RMSE, train 0.23023810950696896, test 0.23974656824972115\n",
      "RMSE, train 0.23032326375741094, test 0.2405010358083482\n",
      "RMSE, train 0.22983032160912037, test 0.2406232557898643\n",
      "RMSE, train 0.2287233795143824, test 0.23956052170080297\n",
      "RMSE, train 0.22990279817211315, test 0.23839184619924603\n",
      "RMSE, train 0.22989175098821485, test 0.2402937983473142\n",
      "RMSE, train 0.2290392915111453, test 0.24000167072403664\n",
      "RMSE, train 0.22828904228164928, test 0.2378897485779781\n",
      "RMSE, train 0.22883343147136145, test 0.23975644582042507\n",
      "RMSE, train 0.22920926363342986, test 0.23909553184228785\n",
      "RMSE, train 0.2284218894766737, test 0.23839233479663438\n",
      "RMSE, train 0.228932454844221, test 0.23963208730314292\n",
      "RMSE, train 0.22895003414239407, test 0.23670459838182317\n",
      "RMSE, train 0.22848394516686552, test 0.23790247124784134\n",
      "RMSE, train 0.22874865126140362, test 0.23950702441381475\n",
      "RMSE, train 0.22834474346233724, test 0.23775950833862902\n",
      "RMSE, train 0.22834707963722703, test 0.23734651871171653\n",
      "RMSE, train 0.22830958445700938, test 0.23762650787830353\n",
      "RMSE, train 0.2285640691373684, test 0.23815577878963715\n",
      "RMSE, train 0.22787908996346457, test 0.2390515445640274\n",
      "RMSE, train 0.22765203545799118, test 0.2388060979691206\n",
      "RMSE, train 0.22752290533806657, test 0.2387778556668291\n",
      "RMSE, train 0.22672778912119762, test 0.2403058314732477\n",
      "Early stopping at epoch 81 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.0130824474317413, test 0.9395684824009573\n",
      "RMSE, train 0.893587977595387, test 0.7692536460466621\n",
      "RMSE, train 0.5977595848662238, test 0.4186280476899186\n",
      "RMSE, train 0.37015862976230923, test 0.3379232280017916\n",
      "RMSE, train 0.3255426346534683, test 0.3103616958068422\n",
      "RMSE, train 0.3061934556631792, test 0.29683538064483767\n",
      "RMSE, train 0.29308305467448886, test 0.28764016926288605\n",
      "RMSE, train 0.283166503308401, test 0.28042601135151446\n",
      "RMSE, train 0.27637095235648657, test 0.2740948862773328\n",
      "RMSE, train 0.27296474682647853, test 0.27215180613777856\n",
      "RMSE, train 0.2689751587627876, test 0.2693009406697652\n",
      "RMSE, train 0.2672862555350988, test 0.267628549174829\n",
      "RMSE, train 0.2657284938219574, test 0.2671738186897325\n",
      "RMSE, train 0.263893871913634, test 0.26603368645118286\n",
      "RMSE, train 0.26348576072843805, test 0.262085924710124\n",
      "RMSE, train 0.26212434032030646, test 0.26388557957223624\n",
      "RMSE, train 0.261668918353896, test 0.2618915416485022\n",
      "RMSE, train 0.26151102012203586, test 0.26292362390470897\n",
      "RMSE, train 0.2601894395305745, test 0.2625343044680997\n",
      "RMSE, train 0.26090258996813526, test 0.2614845634122525\n",
      "RMSE, train 0.2598956907168031, test 0.2607168195045684\n",
      "RMSE, train 0.2597720928400034, test 0.26099209234980514\n",
      "RMSE, train 0.2592893509013999, test 0.26186029477552936\n",
      "RMSE, train 0.25971739423731643, test 0.25987220524756377\n",
      "RMSE, train 0.25945091773305207, test 0.25974397121135856\n",
      "RMSE, train 0.25899229439035537, test 0.26056231102667565\n",
      "RMSE, train 0.2598683976628367, test 0.26028479352470274\n",
      "RMSE, train 0.25858520719433026, test 0.26032598168889354\n",
      "RMSE, train 0.25862098175791964, test 0.2609383927519656\n",
      "RMSE, train 0.25862271506940165, test 0.25917471465000436\n",
      "RMSE, train 0.25876035173273376, test 0.2593350385831407\n",
      "RMSE, train 0.2580623245918222, test 0.25918401075788766\n",
      "RMSE, train 0.2584763890012137, test 0.2587758427070192\n",
      "RMSE, train 0.2584129810603636, test 0.2596489361618176\n",
      "RMSE, train 0.25802679833084824, test 0.2589470795856034\n",
      "RMSE, train 0.25816402856200454, test 0.25804213212787613\n",
      "RMSE, train 0.2574761554809107, test 0.2588842495167551\n",
      "RMSE, train 0.2584245551918303, test 0.2585472080333174\n",
      "RMSE, train 0.2575847243199185, test 0.25877159156582574\n",
      "RMSE, train 0.2575438031325898, test 0.2589929790413084\n",
      "RMSE, train 0.2578495981532239, test 0.2588854597127142\n",
      "RMSE, train 0.25790254387163347, test 0.259229104011512\n",
      "RMSE, train 0.257702948165036, test 0.25957461711296365\n",
      "RMSE, train 0.2577078590590146, test 0.2579737239755875\n",
      "RMSE, train 0.25745868033939795, test 0.25924278179968685\n",
      "RMSE, train 0.25769665643512724, test 0.2586216773868592\n",
      "RMSE, train 0.2579313921742141, test 0.25920800014960865\n",
      "RMSE, train 0.25735967930766845, test 0.25982591620654116\n",
      "RMSE, train 0.25757025466150335, test 0.2600980770489401\n",
      "RMSE, train 0.2572364267562666, test 0.2592251868533694\n",
      "RMSE, train 0.2576198368483493, test 0.2583164158315698\n",
      "RMSE, train 0.25755970895050034, test 0.25880580346200094\n",
      "RMSE, train 0.25763825746253133, test 0.25920971790867403\n",
      "RMSE, train 0.2573111962016311, test 0.2605376049629913\n",
      "Early stopping at epoch 54 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9890335050126737, test 0.9371937131982738\n",
      "RMSE, train 0.8716279842759952, test 0.7046638095782976\n",
      "RMSE, train 0.53650714706414, test 0.38572385301024226\n",
      "RMSE, train 0.35512147545198763, test 0.32283366029545413\n",
      "RMSE, train 0.3188451170952113, test 0.29893654445975515\n",
      "RMSE, train 0.2959777897701037, test 0.2879540586875657\n",
      "RMSE, train 0.2813361588065043, test 0.2740144819273787\n",
      "RMSE, train 0.27146807780935744, test 0.2670231061845513\n",
      "RMSE, train 0.264687241078162, test 0.25856207753137006\n",
      "RMSE, train 0.26056273226156706, test 0.25613752007484436\n",
      "RMSE, train 0.2560832047573298, test 0.25501020587349343\n",
      "RMSE, train 0.25433904320494205, test 0.2532875491148334\n",
      "RMSE, train 0.2523454896767031, test 0.2518007925758928\n",
      "RMSE, train 0.2507032316393596, test 0.2516211772621688\n",
      "RMSE, train 0.2498439341814311, test 0.2510188843234111\n",
      "RMSE, train 0.24976487331523384, test 0.24916077121081998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2476373060552542, test 0.24804824641195394\n",
      "RMSE, train 0.24788323483499122, test 0.2477032282089783\n",
      "RMSE, train 0.24756996004172593, test 0.24756225615234698\n",
      "RMSE, train 0.246113039645528, test 0.24708325466362097\n",
      "RMSE, train 0.2462009177658676, test 0.24726471014447132\n",
      "RMSE, train 0.2461070360015493, test 0.24653831124305725\n",
      "RMSE, train 0.24682081621602053, test 0.24780102112030578\n",
      "RMSE, train 0.24580112767736773, test 0.24639853689882715\n",
      "RMSE, train 0.24525597094258, test 0.24800187330377305\n",
      "RMSE, train 0.24619453012450668, test 0.24571201874543044\n",
      "RMSE, train 0.24574636981999579, test 0.2455293072734849\n",
      "RMSE, train 0.24491511953394274, test 0.24723416320600752\n",
      "RMSE, train 0.24431165917353195, test 0.24679902587401664\n",
      "RMSE, train 0.2454369357702407, test 0.24529756706649974\n",
      "RMSE, train 0.2452292230195743, test 0.24603098694045664\n",
      "RMSE, train 0.24527186455497565, test 0.24663533952276587\n",
      "RMSE, train 0.24566646516015214, test 0.24577566810836227\n",
      "RMSE, train 0.2445944551039826, test 0.24544590566370447\n",
      "RMSE, train 0.24479136511314015, test 0.24587883055210114\n",
      "RMSE, train 0.2444581155134134, test 0.24514566753375328\n",
      "RMSE, train 0.2440338550859, test 0.24570049168699878\n",
      "RMSE, train 0.2442558833844344, test 0.24507010096715667\n",
      "RMSE, train 0.24516225184414012, test 0.2459695320260727\n",
      "RMSE, train 0.24410907539331222, test 0.2465197103003324\n",
      "RMSE, train 0.24445885907827822, test 0.2461043404320539\n",
      "RMSE, train 0.24381588573359753, test 0.24628594984947624\n",
      "RMSE, train 0.24409568629974177, test 0.24564985122721075\n",
      "RMSE, train 0.24356505208579468, test 0.24546185843015123\n",
      "RMSE, train 0.24432971326957556, test 0.24568950309086654\n",
      "RMSE, train 0.24361929694606252, test 0.24500688329591588\n",
      "RMSE, train 0.24375141890765714, test 0.2457776762923952\n",
      "RMSE, train 0.24491409681860574, test 0.24545127090256094\n",
      "RMSE, train 0.24464757378744192, test 0.24460887631117287\n",
      "RMSE, train 0.24388349784368818, test 0.24449779756240925\n",
      "RMSE, train 0.24422972125947967, test 0.24511547039373446\n",
      "RMSE, train 0.24320780875330622, test 0.24560138109629437\n",
      "RMSE, train 0.24312090318003468, test 0.24667504909685103\n",
      "RMSE, train 0.24355093383592022, test 0.24527929249708935\n",
      "RMSE, train 0.24426350956551793, test 0.24538820363202338\n",
      "RMSE, train 0.24332609455570703, test 0.24568910372711844\n",
      "RMSE, train 0.24387370183879187, test 0.24568847427933904\n",
      "RMSE, train 0.243260423506587, test 0.24570207089438276\n",
      "RMSE, train 0.2442098186343662, test 0.24501373031634396\n",
      "RMSE, train 0.2436588348528324, test 0.24383794036457093\n",
      "RMSE, train 0.2431849445377992, test 0.2442911940989858\n",
      "RMSE, train 0.2436549370908294, test 0.24531547567349368\n",
      "RMSE, train 0.24352743644421257, test 0.24416029188087432\n",
      "RMSE, train 0.2432246278232533, test 0.24601660233180403\n",
      "RMSE, train 0.24369624310965873, test 0.24418989032254382\n",
      "RMSE, train 0.24321657002033772, test 0.24565756207300446\n",
      "RMSE, train 0.24358352944870626, test 0.2442443050065283\n",
      "RMSE, train 0.24358545385362687, test 0.24438926811187955\n",
      "RMSE, train 0.24327191127048545, test 0.2446042061862299\n",
      "RMSE, train 0.2433066754332505, test 0.24453198505660234\n",
      "Early stopping at epoch 70 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9825843688839142, test 0.8947690038808754\n",
      "RMSE, train 0.8183617427588029, test 0.651147838149752\n",
      "RMSE, train 0.5258018101417421, test 0.39789600763469934\n",
      "RMSE, train 0.37720527641134327, test 0.34944162398044554\n",
      "RMSE, train 0.3396180649338724, test 0.32386977917381693\n",
      "RMSE, train 0.3155464484216341, test 0.30452938045242\n",
      "RMSE, train 0.2985569277457682, test 0.29063316793846233\n",
      "RMSE, train 0.28592105066984047, test 0.2822958817705512\n",
      "RMSE, train 0.27689029870469584, test 0.2740862036922148\n",
      "RMSE, train 0.27216744455377, test 0.26917368013943943\n",
      "RMSE, train 0.2654088097005628, test 0.2650192105876548\n",
      "RMSE, train 0.26249678413462796, test 0.2599145147417273\n",
      "RMSE, train 0.2604154535855343, test 0.26061111675309284\n",
      "RMSE, train 0.2572218289107798, test 0.25701255737138645\n",
      "RMSE, train 0.25606984341586075, test 0.2613897177257708\n",
      "RMSE, train 0.25415591309597807, test 0.25867979122059687\n",
      "RMSE, train 0.2533410528354136, test 0.2569427456972854\n",
      "RMSE, train 0.25175434969414295, test 0.2536235490281667\n",
      "RMSE, train 0.24991508191836945, test 0.25507682455437525\n",
      "RMSE, train 0.2518892203313593, test 0.2562976817467383\n",
      "RMSE, train 0.24880414249980112, test 0.25100953464529346\n",
      "RMSE, train 0.2487539904179916, test 0.2528189559733229\n",
      "RMSE, train 0.24788827989615647, test 0.25284855174166815\n",
      "RMSE, train 0.24723944454281419, test 0.2522012278038476\n",
      "RMSE, train 0.2464281859805641, test 0.25098679859989453\n",
      "RMSE, train 0.24694314196478567, test 0.2494853206777147\n",
      "RMSE, train 0.2460244447317518, test 0.2506802576993193\n",
      "RMSE, train 0.24553519336421506, test 0.24721314684887016\n",
      "RMSE, train 0.24484481574857936, test 0.24732451892590948\n",
      "RMSE, train 0.24522044483677755, test 0.24648856278508902\n",
      "RMSE, train 0.2439221683767886, test 0.24882807988407357\n",
      "RMSE, train 0.24364530321105113, test 0.24737163120880723\n",
      "RMSE, train 0.2431967481646143, test 0.24722201417067222\n",
      "RMSE, train 0.2436162717072273, test 0.2465795585885644\n",
      "RMSE, train 0.24367389061806768, test 0.24677017410951002\n",
      "RMSE, train 0.24168438332922318, test 0.2462505456060171\n",
      "RMSE, train 0.24245196329287713, test 0.24723171462704027\n",
      "RMSE, train 0.24173496025644875, test 0.24551059092794145\n",
      "RMSE, train 0.24278988921304673, test 0.2467125216498971\n",
      "RMSE, train 0.24268743543518395, test 0.24475361792636768\n",
      "RMSE, train 0.2416802351576051, test 0.24522128781037672\n",
      "RMSE, train 0.241249690014942, test 0.24537982931360602\n",
      "RMSE, train 0.2416883774897112, test 0.24767644849738904\n",
      "RMSE, train 0.2401890708437932, test 0.24463960880945837\n",
      "RMSE, train 0.24130604057400315, test 0.24341914164168493\n",
      "RMSE, train 0.24087471550651104, test 0.24384252673813275\n",
      "RMSE, train 0.2399462998595113, test 0.24648042568670853\n",
      "RMSE, train 0.2402213570988516, test 0.24422095862350293\n",
      "RMSE, train 0.23959927739725653, test 0.24487594754568168\n",
      "RMSE, train 0.24075099410314704, test 0.2452474688179791\n",
      "RMSE, train 0.24044922034789795, test 0.24289735187111156\n",
      "RMSE, train 0.2407253768968686, test 0.244325795343944\n",
      "RMSE, train 0.24034579060890576, test 0.24418101672615325\n",
      "RMSE, train 0.240528578592022, test 0.24490136353831207\n",
      "RMSE, train 0.24014883447836166, test 0.24265305465087295\n",
      "RMSE, train 0.24016292662662098, test 0.2445453818488334\n",
      "RMSE, train 0.2396814965507044, test 0.24414000686790263\n",
      "RMSE, train 0.2407565077843879, test 0.24401286989450455\n",
      "RMSE, train 0.23929823426963975, test 0.24342315178364515\n",
      "RMSE, train 0.23903870507100827, test 0.2436479918126549\n",
      "RMSE, train 0.23983059930645562, test 0.24394928138437016\n",
      "RMSE, train 0.23952426151057993, test 0.24365416089338915\n",
      "RMSE, train 0.23954682154398338, test 0.24439071571188314\n",
      "RMSE, train 0.23938054349557505, test 0.24263574156377996\n",
      "RMSE, train 0.23894109914570333, test 0.24115082900971174\n",
      "RMSE, train 0.23973746998702258, test 0.2422970323158162\n",
      "RMSE, train 0.24005326597843815, test 0.24234130725796735\n",
      "RMSE, train 0.23857667801946336, test 0.24235558170559152\n",
      "RMSE, train 0.23890691583322804, test 0.2437774828369064\n",
      "RMSE, train 0.23917737327240132, test 0.24248573942376034\n",
      "RMSE, train 0.23943408812377967, test 0.24496122602639453\n",
      "RMSE, train 0.23941420494276455, test 0.24267347090478456\n",
      "RMSE, train 0.23924735876729544, test 0.24181718698569707\n",
      "RMSE, train 0.23847087234063866, test 0.24292189920587198\n",
      "RMSE, train 0.23842127379314051, test 0.24316416700769747\n",
      "Early stopping at epoch 75 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.0645609580362922, test 0.9628170897262265\n",
      "RMSE, train 0.9214688979617541, test 0.8175965673995741\n",
      "RMSE, train 0.7098048196007978, test 0.5592151777912872\n",
      "RMSE, train 0.4764892869153058, test 0.4081827411145875\n",
      "RMSE, train 0.38537338008070343, test 0.3665617412388927\n",
      "RMSE, train 0.34833958034556184, test 0.33925477272332316\n",
      "RMSE, train 0.3202752013005371, test 0.31850884403243207\n",
      "RMSE, train 0.30356368050890037, test 0.30484303937415885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.29150172874950836, test 0.29331911724023146\n",
      "RMSE, train 0.28027094814990144, test 0.2856872220232029\n",
      "RMSE, train 0.27495195682007995, test 0.28266473069335474\n",
      "RMSE, train 0.2699428252092492, test 0.27385883831014535\n",
      "RMSE, train 0.2654756205771255, test 0.2707189259806065\n",
      "RMSE, train 0.2633543418205746, test 0.26484921845522796\n",
      "RMSE, train 0.25991997075401485, test 0.2662722742316699\n",
      "RMSE, train 0.25565400712356007, test 0.26473762140129553\n",
      "RMSE, train 0.2553536369485785, test 0.2632584869861603\n",
      "RMSE, train 0.252835605503003, test 0.2611816885946977\n",
      "RMSE, train 0.25244127569178204, test 0.2591033853364713\n",
      "RMSE, train 0.25158230339183785, test 0.25612115182659845\n",
      "RMSE, train 0.2512239950611131, test 0.25961156400165175\n",
      "RMSE, train 0.24978440683016276, test 0.2570446597205268\n",
      "RMSE, train 0.2483066148272645, test 0.25847482794161997\n",
      "RMSE, train 0.24855596768899768, test 0.25478167989940353\n",
      "RMSE, train 0.24838390558375123, test 0.25532570180266795\n",
      "RMSE, train 0.2470083002975634, test 0.2524029373219519\n",
      "RMSE, train 0.2454860398413791, test 0.2518242515548311\n",
      "RMSE, train 0.24579089768868495, test 0.2533246479702718\n",
      "RMSE, train 0.24517078878025553, test 0.2504546908718167\n",
      "RMSE, train 0.24367801021684352, test 0.2527851882306012\n",
      "RMSE, train 0.2439019468710883, test 0.2510122677894554\n",
      "RMSE, train 0.24350112931652582, test 0.2494704094198015\n",
      "RMSE, train 0.24366766706218346, test 0.2508137058278527\n",
      "RMSE, train 0.24363004235883215, test 0.24962157658254258\n",
      "RMSE, train 0.24351261625371529, test 0.24915645918761842\n",
      "RMSE, train 0.24149299542303482, test 0.24760712457425665\n",
      "RMSE, train 0.2417722268799698, test 0.24935691434927662\n",
      "RMSE, train 0.24250590048894322, test 0.24898653974135718\n",
      "RMSE, train 0.24102639073556092, test 0.24836874647875024\n",
      "RMSE, train 0.24127136037883082, test 0.24828171662308954\n",
      "RMSE, train 0.24090719676615266, test 0.24727237721284231\n",
      "RMSE, train 0.2412103745712919, test 0.24577357032985397\n",
      "RMSE, train 0.24023182967035578, test 0.24879499818339493\n",
      "RMSE, train 0.24098020952313337, test 0.24774152582341974\n",
      "RMSE, train 0.2403431400146636, test 0.2455665443581764\n",
      "RMSE, train 0.23940374279590573, test 0.24655494093894958\n",
      "RMSE, train 0.24035502279810333, test 0.24638152295591856\n",
      "RMSE, train 0.23977104262938417, test 0.24570404301689128\n",
      "RMSE, train 0.2399835300183238, test 0.2450334354482516\n",
      "RMSE, train 0.2392632811715084, test 0.24530531375697165\n",
      "RMSE, train 0.23861594268628614, test 0.24485345832025163\n",
      "RMSE, train 0.23855290445328342, test 0.24576260811752743\n",
      "RMSE, train 0.23735008798630722, test 0.24479601863357756\n",
      "RMSE, train 0.23963535546090609, test 0.24592641944235022\n",
      "RMSE, train 0.2381496638023183, test 0.24584372612563046\n",
      "RMSE, train 0.23760481319028182, test 0.2448489653943765\n",
      "RMSE, train 0.23821848831287515, test 0.24653122024704713\n",
      "RMSE, train 0.23726706449079046, test 0.2441523333992621\n",
      "RMSE, train 0.2379669490245269, test 0.24422771784693303\n",
      "RMSE, train 0.23781381028278534, test 0.2447768131440336\n",
      "RMSE, train 0.23662411875130204, test 0.24338078378426908\n",
      "RMSE, train 0.23716153548734403, test 0.24529898512845089\n",
      "RMSE, train 0.23670886418711584, test 0.24402017650580166\n",
      "RMSE, train 0.23729954884002727, test 0.24328779120637914\n",
      "RMSE, train 0.2371803094020391, test 0.24588806806790708\n",
      "RMSE, train 0.23711790598036317, test 0.24304775585128804\n",
      "RMSE, train 0.23632532797189096, test 0.2447468102580369\n",
      "RMSE, train 0.23609660983012767, test 0.24223633404030945\n",
      "RMSE, train 0.23554736098916723, test 0.24438659613481675\n",
      "RMSE, train 0.23608550269038286, test 0.24310600975848207\n",
      "RMSE, train 0.2361309514870562, test 0.24358855609339897\n",
      "RMSE, train 0.23479863363693862, test 0.24185495981664368\n",
      "RMSE, train 0.23629282008683478, test 0.24371424099110595\n",
      "RMSE, train 0.23587449058926777, test 0.2426606413691935\n",
      "RMSE, train 0.23574970023191938, test 0.2443321341215962\n",
      "RMSE, train 0.23565031784816592, test 0.2450418978026419\n",
      "RMSE, train 0.23561549817000157, test 0.24504717025491926\n",
      "RMSE, train 0.23506747927598673, test 0.2444432486187328\n",
      "RMSE, train 0.23533413284128044, test 0.24363508293725022\n",
      "RMSE, train 0.23531047041666828, test 0.2443619774598064\n",
      "RMSE, train 0.23463393053754908, test 0.24203822588679766\n",
      "RMSE, train 0.23462157716523754, test 0.2419881760471999\n",
      "Early stopping at epoch 82 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.0044226079932914, test 0.9393243365368601\n",
      "RMSE, train 0.8913179405095163, test 0.7786441654977152\n",
      "RMSE, train 0.6180040788613568, test 0.42772092771227077\n",
      "RMSE, train 0.3667769083553109, test 0.326632883652287\n",
      "RMSE, train 0.32286560461540853, test 0.3082217759752678\n",
      "RMSE, train 0.31023512771430095, test 0.3002551081195726\n",
      "RMSE, train 0.300333134768423, test 0.29289270634368314\n",
      "RMSE, train 0.293617351011427, test 0.2887485883498596\n",
      "RMSE, train 0.2882994142445651, test 0.284667119636374\n",
      "RMSE, train 0.28615103642002115, test 0.28108461744199364\n",
      "RMSE, train 0.2830431885278422, test 0.2815243858149496\n",
      "RMSE, train 0.2827850004334834, test 0.27891412402613686\n",
      "RMSE, train 0.28092693686793163, test 0.2788091227412224\n",
      "RMSE, train 0.27945297814844067, test 0.2782273137847246\n",
      "RMSE, train 0.27929437451434036, test 0.27786247154413646\n",
      "RMSE, train 0.27932306736215085, test 0.27758235383336827\n",
      "RMSE, train 0.2790893936637512, test 0.2783466575004287\n",
      "RMSE, train 0.278196347246239, test 0.2775329739107924\n",
      "RMSE, train 0.2775024573264782, test 0.2770252034573232\n",
      "RMSE, train 0.2792127116714135, test 0.27701469775983845\n",
      "RMSE, train 0.277871944379708, test 0.2773214148641643\n",
      "RMSE, train 0.2773100918174283, test 0.2776063302437128\n",
      "RMSE, train 0.2783639306310287, test 0.2786255751625966\n",
      "RMSE, train 0.27832412661230266, test 0.2774705953769765\n",
      "RMSE, train 0.27724907591877396, test 0.27695823738635594\n",
      "RMSE, train 0.2772949130759259, test 0.27643258238242846\n",
      "RMSE, train 0.27698566084188864, test 0.27684034697585186\n",
      "RMSE, train 0.27799780229645327, test 0.2774527841957949\n",
      "RMSE, train 0.2771554192112497, test 0.2776101670401581\n",
      "RMSE, train 0.2769877095206464, test 0.27692307759139495\n",
      "RMSE, train 0.2776079122131028, test 0.2761870201487662\n",
      "RMSE, train 0.27741118283434346, test 0.277384151657254\n",
      "RMSE, train 0.2770462725927268, test 0.27811229102692364\n",
      "RMSE, train 0.27704305194071993, test 0.2775275572124174\n",
      "RMSE, train 0.27722148543362285, test 0.2771339778930454\n",
      "RMSE, train 0.2767558692346427, test 0.27727006236880514\n",
      "RMSE, train 0.27752238265739, test 0.2759816367494858\n",
      "RMSE, train 0.27724514384407645, test 0.27759849273804893\n",
      "RMSE, train 0.2768780856493337, test 0.2764759959053185\n",
      "RMSE, train 0.27722843539369996, test 0.2781962658894264\n",
      "RMSE, train 0.27802091359722714, test 0.27750592224173626\n",
      "RMSE, train 0.27720780624461566, test 0.2759870303384328\n",
      "RMSE, train 0.27730402074877386, test 0.2769589816867295\n",
      "RMSE, train 0.2772058460491994, test 0.27651329187013335\n",
      "RMSE, train 0.27644220009938747, test 0.2762663673798917\n",
      "RMSE, train 0.27724757337988903, test 0.27622945000559596\n",
      "RMSE, train 0.2772893838984661, test 0.2763515117309861\n",
      "Early stopping at epoch 47 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.0485875273712628, test 0.9726116304812225\n",
      "RMSE, train 0.9753913989492283, test 0.9077431199343308\n",
      "RMSE, train 0.8301216067781874, test 0.6643526678499968\n",
      "RMSE, train 0.5260823273481584, test 0.40724124999149985\n",
      "RMSE, train 0.3816729398036965, test 0.3552213277505792\n",
      "RMSE, train 0.34305595306011266, test 0.32624333073263584\n",
      "RMSE, train 0.3169636995612689, test 0.29918826909168905\n",
      "RMSE, train 0.2947042310440363, test 0.28706437867620715\n",
      "RMSE, train 0.2830836798861275, test 0.2766070648379948\n",
      "RMSE, train 0.2768965667536811, test 0.2757521597587544\n",
      "RMSE, train 0.2721950402621757, test 0.27012257219656655\n",
      "RMSE, train 0.268985192677018, test 0.26995316944692443\n",
      "RMSE, train 0.268673386353596, test 0.271027424024499\n",
      "RMSE, train 0.2656583325055501, test 0.2667295330244562\n",
      "RMSE, train 0.26719456564658767, test 0.2698277487055115\n",
      "RMSE, train 0.2655907713050802, test 0.26780046859513157\n",
      "RMSE, train 0.2645038471986281, test 0.26554716177608656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2637335044468284, test 0.26599330260701803\n",
      "RMSE, train 0.2634589150547981, test 0.2656988731544951\n",
      "RMSE, train 0.2637763476106012, test 0.2646003974520642\n",
      "RMSE, train 0.2625213307971155, test 0.26436173358689186\n",
      "RMSE, train 0.26200175679223553, test 0.26297626806342084\n",
      "RMSE, train 0.26252609356889806, test 0.2665601633165194\n",
      "RMSE, train 0.2617123743436139, test 0.26304651382176775\n",
      "RMSE, train 0.26138400958728386, test 0.2647997107194818\n",
      "RMSE, train 0.26028342255551346, test 0.26200120293575785\n",
      "RMSE, train 0.260936735241403, test 0.2609258894039237\n",
      "RMSE, train 0.26021067747518006, test 0.26478095754333164\n",
      "RMSE, train 0.2594596410759442, test 0.2615152881845184\n",
      "RMSE, train 0.25983397621511145, test 0.2637451293675796\n",
      "RMSE, train 0.26034515589918555, test 0.2631277724452641\n",
      "RMSE, train 0.26038313176158634, test 0.26406420689562093\n",
      "RMSE, train 0.25999358726661426, test 0.26366009336450824\n",
      "RMSE, train 0.25978311265160325, test 0.2635275329584661\n",
      "RMSE, train 0.25951478565447905, test 0.2635874943888706\n",
      "RMSE, train 0.2585897164106875, test 0.2623358815908432\n",
      "RMSE, train 0.2588038400543217, test 0.263302054029444\n",
      "Early stopping at epoch 37 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9970098501363678, test 0.9480885256321059\n",
      "RMSE, train 0.9395703056601665, test 0.8573190028514337\n",
      "RMSE, train 0.778777314575531, test 0.6214472178472291\n",
      "RMSE, train 0.5077962259607465, test 0.42434899919076796\n",
      "RMSE, train 0.40582484895605675, test 0.3901407077498392\n",
      "RMSE, train 0.377236633891482, test 0.36796508907178127\n",
      "RMSE, train 0.35812568718007864, test 0.35081809253320784\n",
      "RMSE, train 0.3395085427325403, test 0.3318930262819343\n",
      "RMSE, train 0.3238169429280833, test 0.3212613995195529\n",
      "RMSE, train 0.31053420978143076, test 0.3096947754741809\n",
      "RMSE, train 0.30142998137415256, test 0.30126828713974824\n",
      "RMSE, train 0.2940692689119433, test 0.28888764457965116\n",
      "RMSE, train 0.28734186054478844, test 0.2858826049150677\n",
      "RMSE, train 0.28054191122006944, test 0.28272160149495534\n",
      "RMSE, train 0.2772647424730485, test 0.2807161359612001\n",
      "RMSE, train 0.2738457079726217, test 0.27688269891323297\n",
      "RMSE, train 0.27016326908707083, test 0.2746992350444881\n",
      "RMSE, train 0.2684709408525127, test 0.27561539363697035\n",
      "RMSE, train 0.2679933661703572, test 0.273291285568421\n",
      "RMSE, train 0.2656047118184545, test 0.2704850024449716\n",
      "RMSE, train 0.26587845463589704, test 0.2702213865491228\n",
      "RMSE, train 0.2632556632495247, test 0.2698449787743595\n",
      "RMSE, train 0.2638460419103169, test 0.2697537194151397\n",
      "RMSE, train 0.2632448060663559, test 0.26741330571677707\n",
      "RMSE, train 0.26203807680596153, test 0.2688762289941858\n",
      "RMSE, train 0.26123231281881376, test 0.26881091652113365\n",
      "RMSE, train 0.26008220900668694, test 0.2692167843700549\n",
      "RMSE, train 0.2598363204186807, test 0.2649795717875892\n",
      "RMSE, train 0.26019617813250945, test 0.26572958195428237\n",
      "RMSE, train 0.2597641554648566, test 0.26714959638107805\n",
      "RMSE, train 0.2591988021015052, test 0.2651680068138543\n",
      "RMSE, train 0.2595481817765086, test 0.2632035451744675\n",
      "RMSE, train 0.2580395171026211, test 0.26569885575990065\n",
      "RMSE, train 0.25723165213527166, test 0.2655631590873823\n",
      "RMSE, train 0.2581892631313191, test 0.2655754886362531\n",
      "RMSE, train 0.2580012012557064, test 0.26525127299881857\n",
      "RMSE, train 0.256830524736723, test 0.26323222478321934\n",
      "RMSE, train 0.2578623491953307, test 0.2629934420142699\n",
      "RMSE, train 0.2563336000113744, test 0.262144996348871\n",
      "RMSE, train 0.2576016320475281, test 0.2637997516388193\n",
      "RMSE, train 0.25690528307728167, test 0.26244829861669366\n",
      "RMSE, train 0.2562060671035752, test 0.263254997243575\n",
      "RMSE, train 0.25606907892454367, test 0.2624489473640372\n",
      "RMSE, train 0.25635424897809733, test 0.2637951604406768\n",
      "RMSE, train 0.25612432031888066, test 0.2612522234883877\n",
      "RMSE, train 0.25629911633550856, test 0.26381216929593215\n",
      "RMSE, train 0.256406181212097, test 0.2632428847868508\n",
      "RMSE, train 0.25543791474983296, test 0.262978004479627\n",
      "RMSE, train 0.2558774183850919, test 0.26106378832541477\n",
      "RMSE, train 0.2547841525632437, test 0.26213124312392067\n",
      "RMSE, train 0.25403971400429315, test 0.26008152469582513\n",
      "RMSE, train 0.2559483191624885, test 0.2607031045567005\n",
      "RMSE, train 0.2557246230308785, test 0.2606790266725995\n",
      "RMSE, train 0.25535779443022383, test 0.26121058663643826\n",
      "RMSE, train 0.25551998647005036, test 0.26062948031162997\n",
      "RMSE, train 0.2553197343754394, test 0.26171509196998877\n",
      "RMSE, train 0.2541748129432779, test 0.26268999565631973\n",
      "RMSE, train 0.25454531100499256, test 0.26366064321557314\n",
      "RMSE, train 0.25456854448791577, test 0.26077437892966315\n",
      "RMSE, train 0.25390623147378055, test 0.2611055025540361\n",
      "RMSE, train 0.2540821963628846, test 0.2623565990580331\n",
      "Early stopping at epoch 61 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.0041030719123705, test 0.945683162038525\n",
      "RMSE, train 0.9250311095907231, test 0.8193617432067791\n",
      "RMSE, train 0.7327312273208542, test 0.605456909785668\n",
      "RMSE, train 0.5103599363279463, test 0.43730433098971844\n",
      "RMSE, train 0.3999178499886484, test 0.37917194453378517\n",
      "RMSE, train 0.358230683388132, test 0.3465466789590816\n",
      "RMSE, train 0.33342172254366104, test 0.3332279307457308\n",
      "RMSE, train 0.3165041355021072, test 0.31692766584455967\n",
      "RMSE, train 0.30581521111154797, test 0.30997853151833016\n",
      "RMSE, train 0.2961942757846731, test 0.301072402857244\n",
      "RMSE, train 0.2914102014267083, test 0.30043053704624373\n",
      "RMSE, train 0.28634527135602755, test 0.289094695666184\n",
      "RMSE, train 0.2825887565021262, test 0.2905419875557224\n",
      "RMSE, train 0.28053986514457546, test 0.2819156771680961\n",
      "RMSE, train 0.2780214081508945, test 0.28179623388374847\n",
      "RMSE, train 0.2744056358557157, test 0.28187458341320354\n",
      "RMSE, train 0.27049073866671985, test 0.2823883011005819\n",
      "RMSE, train 0.2689932253249366, test 0.2778883605885009\n",
      "RMSE, train 0.26833358884911346, test 0.2783320884530743\n",
      "RMSE, train 0.2659549565440176, test 0.2762675709867229\n",
      "RMSE, train 0.2644662811336192, test 0.2749706165244182\n",
      "RMSE, train 0.2647724110219214, test 0.27257819365089136\n",
      "RMSE, train 0.2631786342221077, test 0.2713686980617543\n",
      "RMSE, train 0.2633522551770162, test 0.2720780191011727\n",
      "RMSE, train 0.2605647157426133, test 0.2704958990216255\n",
      "RMSE, train 0.26031317131010573, test 0.2675899173288296\n",
      "RMSE, train 0.25943364456973295, test 0.2680314611643553\n",
      "RMSE, train 0.26004262853677224, test 0.2690576027768354\n",
      "RMSE, train 0.258705876316085, test 0.2672144901007414\n",
      "RMSE, train 0.2578145911108063, test 0.2681146482937038\n",
      "RMSE, train 0.25733192622511075, test 0.26652798848226666\n",
      "RMSE, train 0.258328343845076, test 0.266308181375886\n",
      "RMSE, train 0.2561211915442137, test 0.26367748094101745\n",
      "RMSE, train 0.2559427666957631, test 0.26773938567688066\n",
      "RMSE, train 0.2556620878402633, test 0.2657414215306441\n",
      "RMSE, train 0.2548180806140105, test 0.2645668176313241\n",
      "RMSE, train 0.2555974453236117, test 0.26438640896230936\n",
      "RMSE, train 0.2553238385930808, test 0.26400779420509934\n",
      "RMSE, train 0.25553910942240193, test 0.2629515826702118\n",
      "RMSE, train 0.25476447801397306, test 0.2653894736431539\n",
      "RMSE, train 0.2550953475551473, test 0.2620218372903764\n",
      "RMSE, train 0.25377243111907233, test 0.26381096461166936\n",
      "RMSE, train 0.2534525656903332, test 0.2644651527516544\n",
      "RMSE, train 0.25370612716057683, test 0.2632981219018499\n",
      "RMSE, train 0.253474354066632, test 0.2620183676481247\n",
      "RMSE, train 0.2529492055752663, test 0.2641243493805329\n",
      "RMSE, train 0.25227934323401763, test 0.2616972252726555\n",
      "RMSE, train 0.2511098019853987, test 0.2645907749732335\n",
      "RMSE, train 0.2527014310048385, test 0.261416370049119\n",
      "RMSE, train 0.25225979185691383, test 0.26163260110964376\n",
      "RMSE, train 0.25325408897767165, test 0.25998031875739497\n",
      "RMSE, train 0.2509139936342083, test 0.2616044365180035\n",
      "RMSE, train 0.2504805030884466, test 0.26158017789324123\n",
      "RMSE, train 0.2518916513319268, test 0.2603581144164006\n",
      "RMSE, train 0.25199391019314227, test 0.2615448593472441\n",
      "RMSE, train 0.25245957178148354, test 0.26159968227148056\n",
      "RMSE, train 0.2519497594824343, test 0.2609422992294033\n",
      "RMSE, train 0.24991298239264223, test 0.26171553569535416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.25115788769390845, test 0.2620588663655023\n",
      "RMSE, train 0.2507760377431458, test 0.26113632041960955\n",
      "RMSE, train 0.2506296153772961, test 0.2598542630051573\n",
      "RMSE, train 0.25023976978704787, test 0.26093100461487967\n",
      "RMSE, train 0.2504252711254539, test 0.26028565239782137\n",
      "RMSE, train 0.250616158462233, test 0.2604381927133848\n",
      "RMSE, train 0.2503804067582494, test 0.26164580540110666\n",
      "RMSE, train 0.2501294848631428, test 0.2601389998259644\n",
      "RMSE, train 0.2490616503049328, test 0.25787979845578474\n",
      "RMSE, train 0.24990719086443536, test 0.2586627956479788\n",
      "RMSE, train 0.24939029496351275, test 0.258052675674359\n",
      "RMSE, train 0.24962562653753492, test 0.2600605950380365\n",
      "RMSE, train 0.24873043626847893, test 0.2590385389824708\n",
      "RMSE, train 0.24887253502101608, test 0.25933281099423766\n",
      "RMSE, train 0.24960780954646944, test 0.25867335754446685\n",
      "RMSE, train 0.24894917327346225, test 0.2594166750398775\n",
      "RMSE, train 0.24922048249705273, test 0.25837540603242815\n",
      "RMSE, train 0.24886029606892002, test 0.26035056938417256\n",
      "RMSE, train 0.2483879244237235, test 0.2594940443523228\n",
      "Early stopping at epoch 77 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.014192308021267, test 0.9697210200663123\n",
      "RMSE, train 0.9880889768434246, test 0.93116398741092\n",
      "RMSE, train 0.9113339966158981, test 0.8100912640137332\n",
      "RMSE, train 0.683687004518405, test 0.5108410026878119\n",
      "RMSE, train 0.45053543010828023, test 0.41005381516047884\n",
      "RMSE, train 0.4008875635000096, test 0.3976291501894593\n",
      "RMSE, train 0.3853631689495251, test 0.3853318857561265\n",
      "RMSE, train 0.37102327351346776, test 0.3740681146404573\n",
      "RMSE, train 0.36115742047887484, test 0.3657916182918208\n",
      "RMSE, train 0.3505067014681228, test 0.35468564461916685\n",
      "RMSE, train 0.34420158417006724, test 0.351385798172227\n",
      "RMSE, train 0.3369943153169939, test 0.3443339351298554\n",
      "RMSE, train 0.33234688548740476, test 0.33844125430498806\n",
      "RMSE, train 0.32793212316784204, test 0.3387303860591991\n",
      "RMSE, train 0.3253855186480063, test 0.3360112535634211\n",
      "RMSE, train 0.32249168730249594, test 0.332824209438903\n",
      "RMSE, train 0.32118800686660154, test 0.3301435323165996\n",
      "RMSE, train 0.3203474124792095, test 0.33247157612017225\n",
      "RMSE, train 0.3190567105164455, test 0.328917312834944\n",
      "RMSE, train 0.3174766695252691, test 0.3285702845480825\n",
      "RMSE, train 0.31590977872768516, test 0.32581829386098043\n",
      "RMSE, train 0.31672356616957253, test 0.3259983201112066\n",
      "RMSE, train 0.31716343260538604, test 0.3262223260743277\n",
      "RMSE, train 0.31559177022224416, test 0.32764982378908564\n",
      "RMSE, train 0.31486806396825123, test 0.3279717608488032\n",
      "RMSE, train 0.31456040267980695, test 0.32752120348491837\n",
      "RMSE, train 0.3152506638780918, test 0.32889790021415266\n",
      "RMSE, train 0.3144245281620742, test 0.3266832772642374\n",
      "RMSE, train 0.31371482606157497, test 0.3256728697035994\n",
      "RMSE, train 0.3141993400448028, test 0.32591694513601915\n",
      "RMSE, train 0.31365766858353333, test 0.3286787683277258\n",
      "RMSE, train 0.31400970380939947, test 0.32548571271555765\n",
      "RMSE, train 0.31385043933825296, test 0.32546268762754543\n",
      "RMSE, train 0.3138887084257629, test 0.3259609675567065\n",
      "RMSE, train 0.31429258199948373, test 0.32683138376367943\n",
      "RMSE, train 0.3132432751308859, test 0.32381809489535435\n",
      "RMSE, train 0.3123932772829382, test 0.3240094542769449\n",
      "RMSE, train 0.3130769301895742, test 0.3236617552382605\n",
      "RMSE, train 0.3133048628799796, test 0.3241583775462849\n",
      "RMSE, train 0.3136289037910162, test 0.3240667235638414\n",
      "RMSE, train 0.31351803856737476, test 0.32491889423025505\n",
      "RMSE, train 0.3133102422965638, test 0.3236997400277427\n",
      "RMSE, train 0.3122489401392947, test 0.32424310787713956\n",
      "RMSE, train 0.31316289049218166, test 0.3234733965780054\n",
      "RMSE, train 0.3123623470822451, test 0.32414328972143786\n",
      "RMSE, train 0.31248126592901015, test 0.3240770029702357\n",
      "RMSE, train 0.31316944047776185, test 0.32435080382440773\n",
      "RMSE, train 0.3124171478880776, test 0.32431475232754436\n",
      "RMSE, train 0.31245432407767687, test 0.32350726246035527\n",
      "RMSE, train 0.3129202044023148, test 0.3242232421679156\n",
      "RMSE, train 0.31219137828464344, test 0.32437210583261084\n",
      "RMSE, train 0.31251972997337907, test 0.3216862670545067\n",
      "RMSE, train 0.31199149719250746, test 0.32340842738215414\n",
      "RMSE, train 0.3128987440031858, test 0.32385443935969044\n",
      "RMSE, train 0.31249805025285626, test 0.3230569787057383\n",
      "RMSE, train 0.3122792595222365, test 0.3232574264651963\n",
      "RMSE, train 0.3121455128838294, test 0.3235957356435912\n",
      "RMSE, train 0.3123493231264854, test 0.3238790707130517\n",
      "RMSE, train 0.31288442957115586, test 0.3251986981236509\n",
      "RMSE, train 0.31237590306464885, test 0.324566701294056\n",
      "RMSE, train 0.31235752279072804, test 0.3251625948718616\n",
      "RMSE, train 0.3114163697512581, test 0.3256087356380054\n",
      "Early stopping at epoch 62 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.1575268043263611, test 1.0087474724021526\n",
      "RMSE, train 0.9951749292991621, test 0.9226214188501376\n",
      "RMSE, train 0.8844752655168285, test 0.7715544088171162\n",
      "RMSE, train 0.6851327548914427, test 0.5584862861064596\n",
      "RMSE, train 0.5001962462548718, test 0.4355082231650659\n",
      "RMSE, train 0.413039172277055, test 0.39874671604655204\n",
      "RMSE, train 0.3851477483730145, test 0.37968663556860127\n",
      "RMSE, train 0.3608603690304029, test 0.3597973225587005\n",
      "RMSE, train 0.3413988771794088, test 0.34798432244073363\n",
      "RMSE, train 0.3297260824607627, test 0.33464724085199726\n",
      "RMSE, train 0.31888874189201494, test 0.32520365550977376\n",
      "RMSE, train 0.3149373559072413, test 0.3220900741465595\n",
      "RMSE, train 0.3088662879282584, test 0.3187428272645408\n",
      "RMSE, train 0.30837947345702105, test 0.31697829354793655\n",
      "RMSE, train 0.304993811944675, test 0.31438312590669054\n",
      "RMSE, train 0.3024532001114747, test 0.3141451384359544\n",
      "RMSE, train 0.30166594236420946, test 0.3155676496958514\n",
      "RMSE, train 0.30315485887329674, test 0.3158520460128784\n",
      "RMSE, train 0.30175658333796024, test 0.31764710715057654\n",
      "RMSE, train 0.3008003978250807, test 0.31377502893089154\n",
      "RMSE, train 0.3003951687983868, test 0.31322355048918943\n",
      "RMSE, train 0.3000261273752948, test 0.31218168358190346\n",
      "RMSE, train 0.2992115788529272, test 0.3132097978110707\n",
      "RMSE, train 0.297913821238707, test 0.3125575414491356\n",
      "RMSE, train 0.2977748024089454, test 0.3100918254584347\n",
      "RMSE, train 0.29745546040112664, test 0.31305297375272173\n",
      "RMSE, train 0.29586970654103256, test 0.3156324496509832\n",
      "RMSE, train 0.2972987766624032, test 0.31093897814050725\n",
      "RMSE, train 0.2965701735273605, test 0.311027783046075\n",
      "RMSE, train 0.29633891739519186, test 0.309580518154923\n",
      "RMSE, train 0.29625928802875123, test 0.3105781381830163\n",
      "RMSE, train 0.2966134857570109, test 0.30955883416287394\n",
      "RMSE, train 0.29627945155506713, test 0.31032368732154914\n",
      "RMSE, train 0.29662274475723105, test 0.31009718700559863\n",
      "RMSE, train 0.29611556205247014, test 0.31210867896539357\n",
      "RMSE, train 0.296684706157633, test 0.3114452065404402\n",
      "RMSE, train 0.2951015985566672, test 0.31121185613334723\n",
      "RMSE, train 0.2957311149001656, test 0.3152047949373175\n",
      "RMSE, train 0.2959886094045746, test 0.31062736628799265\n",
      "RMSE, train 0.29413815231935325, test 0.3098286270001613\n",
      "RMSE, train 0.2949139356546338, test 0.30722370101224394\n",
      "RMSE, train 0.2948912305615408, test 0.3087461290009525\n",
      "RMSE, train 0.2947815689070342, test 0.308706548235832\n",
      "RMSE, train 0.29460384342568874, test 0.31097234826569164\n",
      "RMSE, train 0.2948609116098806, test 0.30804383385618894\n",
      "RMSE, train 0.29505484404184357, test 0.3102185958569203\n",
      "RMSE, train 0.2941810182659081, test 0.3140774177848746\n",
      "RMSE, train 0.2950919978487652, test 0.31113914461857684\n",
      "RMSE, train 0.2945396283248882, test 0.3107231803443454\n",
      "RMSE, train 0.294656306688962, test 0.31081898606151614\n",
      "RMSE, train 0.2944408998294262, test 0.30921941913595985\n",
      "Early stopping at epoch 51 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9760366403575181, test 0.9185985014276598\n",
      "RMSE, train 0.8826763712736886, test 0.7611362942792836\n",
      "RMSE, train 0.6393795691589845, test 0.5007014864856757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.4539392954026152, test 0.434647246327215\n",
      "RMSE, train 0.4037386267810989, test 0.40792602474249684\n",
      "RMSE, train 0.3789418597402595, test 0.38864334665455863\n",
      "RMSE, train 0.36082081061360954, test 0.36800046713606827\n",
      "RMSE, train 0.34261745996684756, test 0.35916550978294853\n",
      "RMSE, train 0.33382507450790133, test 0.34928434334912345\n",
      "RMSE, train 0.3262800828436491, test 0.35085577597317186\n",
      "RMSE, train 0.3190546218757108, test 0.34513110067080527\n",
      "RMSE, train 0.31494503376248895, test 0.3306526143682524\n",
      "RMSE, train 0.3122842687219735, test 0.33082416769370293\n",
      "RMSE, train 0.3093224578225131, test 0.33010553243090807\n",
      "RMSE, train 0.3066657277403705, test 0.3256845752012382\n",
      "RMSE, train 0.3050697683367763, test 0.3291306116627258\n",
      "RMSE, train 0.30428501699925037, test 0.32301881996173304\n",
      "RMSE, train 0.30144083464513766, test 0.32327480809491815\n",
      "RMSE, train 0.2994482204176468, test 0.3188266387589059\n",
      "RMSE, train 0.29901170542999006, test 0.32162581514386296\n",
      "RMSE, train 0.29863262211908354, test 0.32994846015879253\n",
      "RMSE, train 0.29761988432489495, test 0.3174572702750419\n",
      "RMSE, train 0.2983189075123386, test 0.31623348676897944\n",
      "RMSE, train 0.2965448438554931, test 0.31763039283382083\n",
      "RMSE, train 0.29708748530251394, test 0.3164161333036654\n",
      "RMSE, train 0.29650578660240084, test 0.3176653502346243\n",
      "RMSE, train 0.2958146518100752, test 0.31336739225294985\n",
      "RMSE, train 0.29516252643492896, test 0.3164319887901973\n",
      "RMSE, train 0.2938033249627383, test 0.3115097883980251\n",
      "RMSE, train 0.2940138796092212, test 0.3128612099341976\n",
      "RMSE, train 0.29319057447256214, test 0.31130459948072153\n",
      "RMSE, train 0.2926077347717772, test 0.3112932042878808\n",
      "RMSE, train 0.29263439670098934, test 0.312460328479415\n",
      "RMSE, train 0.29180423246426707, test 0.31384277987538034\n",
      "RMSE, train 0.2939016542921723, test 0.3128496127799877\n",
      "RMSE, train 0.29237515311201506, test 0.3193936319027132\n",
      "RMSE, train 0.2923183941642915, test 0.3123850318992022\n",
      "RMSE, train 0.29123915024013247, test 0.3075290701343018\n",
      "RMSE, train 0.29214078929461096, test 0.3106633975233847\n",
      "RMSE, train 0.2917272729927457, test 0.3126694683021712\n",
      "RMSE, train 0.2918839956547472, test 0.31022649844294614\n",
      "RMSE, train 0.29131122308643864, test 0.31210786263340884\n",
      "RMSE, train 0.29145819895553476, test 0.30686305830417904\n",
      "RMSE, train 0.29053893888860305, test 0.31265861721872124\n",
      "RMSE, train 0.2907292825698569, test 0.31687073496360224\n",
      "RMSE, train 0.2901199632755651, test 0.30838449175460536\n",
      "RMSE, train 0.2899443465782741, test 0.30826023119745904\n",
      "RMSE, train 0.29075078533480114, test 0.3084595537590749\n",
      "RMSE, train 0.29015227617815387, test 0.3169289608892885\n",
      "RMSE, train 0.2899268616406765, test 0.3120462751214944\n",
      "RMSE, train 0.28987403385642024, test 0.3119853765351101\n",
      "RMSE, train 0.28936347370688537, test 0.30908891746720063\n",
      "RMSE, train 0.2902229169202247, test 0.3086779619594222\n",
      "Early stopping at epoch 53 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.044797602207513, test 0.9682287375132242\n",
      "RMSE, train 0.9762838529447982, test 0.9116372591919369\n",
      "RMSE, train 0.8840085020605123, test 0.7813437143961589\n",
      "RMSE, train 0.6904218017733643, test 0.5780173536803987\n",
      "RMSE, train 0.505926271895514, test 0.47254369523790146\n",
      "RMSE, train 0.43290479561549955, test 0.4448477526505788\n",
      "RMSE, train 0.4009309686780618, test 0.4136940578619639\n",
      "RMSE, train 0.38065737264978916, test 0.39105700999498366\n",
      "RMSE, train 0.36393373505767146, test 0.36899087329705554\n",
      "RMSE, train 0.3517857938201601, test 0.36065083957380717\n",
      "RMSE, train 0.33698541263364395, test 0.34613636053270763\n",
      "RMSE, train 0.32772163729462017, test 0.33938170754247243\n",
      "RMSE, train 0.3225233443181791, test 0.33504749370945824\n",
      "RMSE, train 0.31485259042917235, test 0.3331723562545247\n",
      "RMSE, train 0.3114078222821665, test 0.32181977795230016\n",
      "RMSE, train 0.304391318455218, test 0.322364794380135\n",
      "RMSE, train 0.302432233392389, test 0.3210859833492173\n",
      "RMSE, train 0.29781303141075327, test 0.31807664450671935\n",
      "RMSE, train 0.2990752734103293, test 0.31285441401931974\n",
      "RMSE, train 0.296003324966225, test 0.31810654567347635\n",
      "RMSE, train 0.2936041671029641, test 0.31589455579717957\n",
      "RMSE, train 0.2918867812243433, test 0.31268767615159354\n",
      "RMSE, train 0.2920874186522877, test 0.3118103630012936\n",
      "RMSE, train 0.2901636452848378, test 0.3096625225411521\n",
      "RMSE, train 0.29123473052949594, test 0.31139239602618746\n",
      "RMSE, train 0.2905929366131677, test 0.30980330523517396\n",
      "RMSE, train 0.28921688574986315, test 0.3094056490394804\n",
      "RMSE, train 0.2861584436620342, test 0.3089505018459426\n",
      "RMSE, train 0.28602849567595195, test 0.31044913878043495\n",
      "RMSE, train 0.28469082480170976, test 0.30658677054776085\n",
      "RMSE, train 0.286747431036115, test 0.30779730164342456\n",
      "RMSE, train 0.2851765197965334, test 0.3056447328792678\n",
      "RMSE, train 0.28458508451511916, test 0.3068909784158071\n",
      "RMSE, train 0.2839038184469922, test 0.30656859113110435\n",
      "RMSE, train 0.2844864502348347, test 0.3088773642977079\n",
      "RMSE, train 0.2828312029414421, test 0.30372168918450676\n",
      "RMSE, train 0.28405799294980066, test 0.3046969340907203\n",
      "RMSE, train 0.28266636685862373, test 0.3036315412984954\n",
      "RMSE, train 0.2836128524893699, test 0.30108972407049606\n",
      "RMSE, train 0.28235746116811694, test 0.30267535944779717\n",
      "RMSE, train 0.2830065747075325, test 0.30159957541359794\n",
      "RMSE, train 0.2825602957341228, test 0.3030573864777883\n",
      "RMSE, train 0.28159676311472354, test 0.3038218712641133\n",
      "RMSE, train 0.2808576039869509, test 0.30315347413221994\n",
      "RMSE, train 0.27991553626934473, test 0.30410877913236617\n",
      "RMSE, train 0.2799297260707922, test 0.3020686748954985\n",
      "RMSE, train 0.280590464443852, test 0.3007171793116464\n",
      "RMSE, train 0.2798617090578028, test 0.3014940278397666\n",
      "RMSE, train 0.2812693117442478, test 0.3019033503201273\n",
      "RMSE, train 0.27902853952826195, test 0.3045253876182768\n",
      "RMSE, train 0.27893024383770487, test 0.30149333443906573\n",
      "RMSE, train 0.279918929838106, test 0.3030593592259619\n",
      "RMSE, train 0.2799892781799373, test 0.3011689316895273\n",
      "RMSE, train 0.2798572598160759, test 0.30091137256887224\n",
      "RMSE, train 0.27841762953370086, test 0.3006148679388894\n",
      "RMSE, train 0.27893050394530566, test 0.3037668603989813\n",
      "RMSE, train 0.2782221414409879, test 0.3006339649359385\n",
      "RMSE, train 0.2793131159402611, test 0.3011788972549968\n",
      "RMSE, train 0.2795771459805355, test 0.29897148095899156\n",
      "RMSE, train 0.27926859908267815, test 0.2992431996597184\n",
      "RMSE, train 0.2778468195680338, test 0.3014067583613925\n",
      "RMSE, train 0.27746445163481964, test 0.30147676517566047\n",
      "RMSE, train 0.27704291465388475, test 0.2997700492540995\n",
      "RMSE, train 0.27831654857111104, test 0.30028122084008324\n",
      "RMSE, train 0.27842395351019833, test 0.29895956019560493\n",
      "RMSE, train 0.27819528004952837, test 0.3010840516951349\n",
      "RMSE, train 0.2770835584948326, test 0.29953997731208803\n",
      "RMSE, train 0.2758300885397469, test 0.29703623023298054\n",
      "RMSE, train 0.27710064783732524, test 0.3003981325361464\n",
      "RMSE, train 0.27631680133207787, test 0.30090781301259995\n",
      "RMSE, train 0.27789198247730895, test 0.29796583784951103\n",
      "RMSE, train 0.2772399910657875, test 0.29821245181891654\n",
      "RMSE, train 0.275977731333428, test 0.3001621784435378\n",
      "RMSE, train 0.27586575189851364, test 0.29620242764552435\n",
      "RMSE, train 0.2767867654401337, test 0.2986767793695132\n",
      "RMSE, train 0.27685993865654474, test 0.29686524189180796\n",
      "RMSE, train 0.2759150015215347, test 0.2985415945450465\n",
      "RMSE, train 0.2764991716835698, test 0.29883432106839286\n",
      "RMSE, train 0.27520743634983535, test 0.29721575826406477\n",
      "RMSE, train 0.2767720334733914, test 0.300227624260717\n",
      "RMSE, train 0.2759371515353414, test 0.2993078192075094\n",
      "RMSE, train 0.276482120618184, test 0.2973847347829077\n",
      "RMSE, train 0.27567984563401443, test 0.29651589194933575\n",
      "RMSE, train 0.2752769195808555, test 0.2967520142594973\n",
      "Early stopping at epoch 84 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.9741275865029007, test 0.9200912518332703\n",
      "RMSE, train 0.893420588343534, test 0.7958070247462301\n",
      "RMSE, train 0.6897855282631363, test 0.5565548974155176\n",
      "RMSE, train 0.49893298879958015, test 0.49183553803448726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.46215385708657336, test 0.48573370639121893\n",
      "RMSE, train 0.4552834077685853, test 0.48414751149789254\n",
      "RMSE, train 0.4504128528399106, test 0.4792929654470598\n",
      "RMSE, train 0.4463277489748444, test 0.47838130171852883\n",
      "RMSE, train 0.44186016840719067, test 0.47356760787843455\n",
      "RMSE, train 0.4397499098608721, test 0.47329473871775346\n",
      "RMSE, train 0.43658354554170503, test 0.47078656713769895\n",
      "RMSE, train 0.4370747856012475, test 0.4702114589286573\n",
      "RMSE, train 0.433660462535098, test 0.47013441239944614\n",
      "RMSE, train 0.43285877485292756, test 0.4653736435704761\n",
      "RMSE, train 0.4308961798188739, test 0.46580858302838873\n",
      "RMSE, train 0.43150223048362873, test 0.4622981780105167\n",
      "RMSE, train 0.4300771637257271, test 0.4625078891262864\n",
      "RMSE, train 0.4282700745502719, test 0.4619256959419058\n",
      "RMSE, train 0.4282511507677857, test 0.45892475756129836\n",
      "RMSE, train 0.42592536197169195, test 0.4601431550702663\n",
      "RMSE, train 0.4256037965161876, test 0.46452119494929456\n",
      "RMSE, train 0.42447445567123465, test 0.4627966003285514\n",
      "RMSE, train 0.4247562996769884, test 0.45819636727824353\n",
      "RMSE, train 0.4239353216219065, test 0.45799601454325395\n",
      "RMSE, train 0.4240921802436227, test 0.4596902034198395\n",
      "RMSE, train 0.42370982307822314, test 0.457565720033164\n",
      "RMSE, train 0.4234418231438308, test 0.45634490793401544\n",
      "RMSE, train 0.42300582613367904, test 0.46042284851122384\n",
      "RMSE, train 0.42295117949506766, test 0.4575583629234873\n",
      "RMSE, train 0.4220686684610791, test 0.4575308072145539\n",
      "RMSE, train 0.42297909363266306, test 0.45516581562432373\n",
      "RMSE, train 0.4214430124952041, test 0.45834038730221566\n",
      "RMSE, train 0.4219904678593638, test 0.45560486900686015\n",
      "RMSE, train 0.42195544411908736, test 0.45743689753792505\n",
      "RMSE, train 0.42250212659025543, test 0.4548424202384371\n",
      "RMSE, train 0.4225358216132978, test 0.45711854040020644\n",
      "RMSE, train 0.4224287723999443, test 0.4574788772698605\n",
      "RMSE, train 0.42185529352400297, test 0.45506836368580056\n",
      "RMSE, train 0.42169536806843394, test 0.4549385736687015\n",
      "RMSE, train 0.4211368652602571, test 0.45195202785308913\n",
      "RMSE, train 0.4209855740256881, test 0.45513373387582373\n",
      "RMSE, train 0.42141433071099166, test 0.45586272938684985\n",
      "RMSE, train 0.42014760897474357, test 0.45908723003936536\n",
      "RMSE, train 0.42123984365125156, test 0.45674205804714046\n",
      "RMSE, train 0.42166986846544924, test 0.45457234572280536\n",
      "RMSE, train 0.42055237151154096, test 0.4549191390926188\n",
      "RMSE, train 0.4201034433902913, test 0.45548508700096246\n",
      "RMSE, train 0.4203904223398358, test 0.45585013564788934\n",
      "RMSE, train 0.42150484684918504, test 0.4544567646402301\n",
      "RMSE, train 0.42056737311894854, test 0.45417389950969\n",
      "Early stopping at epoch 50 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.0690721580476472, test 0.9772199901441733\n",
      "RMSE, train 0.9896449555050243, test 0.9308506029968461\n",
      "RMSE, train 0.9146943786228546, test 0.8195876013487577\n",
      "RMSE, train 0.7476758465095602, test 0.6367394169792533\n",
      "RMSE, train 0.576769432560964, test 0.5416917409747839\n",
      "RMSE, train 0.5107159712398895, test 0.5241969578589002\n",
      "RMSE, train 0.49443383006887004, test 0.5211681701863805\n",
      "RMSE, train 0.4839199980476288, test 0.5179391006628672\n",
      "RMSE, train 0.4738880050829565, test 0.5116328190391263\n",
      "RMSE, train 0.4646118329179407, test 0.5046919944385687\n",
      "RMSE, train 0.457304525480728, test 0.49809054859603447\n",
      "RMSE, train 0.4522105059539429, test 0.48975903913378716\n",
      "RMSE, train 0.44566433079013923, test 0.48502739425748587\n",
      "RMSE, train 0.44206512038304346, test 0.475447836642464\n",
      "RMSE, train 0.4347689107361466, test 0.47624846392621595\n",
      "RMSE, train 0.4321128849429314, test 0.47255801564703387\n",
      "RMSE, train 0.4265502193810964, test 0.47024068888276815\n",
      "RMSE, train 0.4271626348673093, test 0.46603607417394716\n",
      "RMSE, train 0.4211748702583289, test 0.46265280231212574\n",
      "RMSE, train 0.4202982767889596, test 0.4601548248901963\n",
      "RMSE, train 0.4186691379155775, test 0.45849789554874104\n",
      "RMSE, train 0.4157142316677956, test 0.4570381751594444\n",
      "RMSE, train 0.41421357455729235, test 0.4544159813473622\n",
      "RMSE, train 0.41578215778325545, test 0.4523026680884262\n",
      "RMSE, train 0.41362356992833543, test 0.4504411288847526\n",
      "RMSE, train 0.41203592785380105, test 0.45370852046956617\n",
      "RMSE, train 0.4122199118889944, test 0.45167806403090555\n",
      "RMSE, train 0.41084144896630087, test 0.45039945592482883\n",
      "RMSE, train 0.4098055416511165, test 0.449413419701159\n",
      "RMSE, train 0.40835367579652804, test 0.4479844079663356\n",
      "RMSE, train 0.4092854471745515, test 0.4473944121661286\n",
      "RMSE, train 0.40850802996393404, test 0.4486092096194625\n",
      "RMSE, train 0.40796393280227977, test 0.448350400198251\n",
      "RMSE, train 0.4082621679537826, test 0.4412508592940867\n",
      "RMSE, train 0.40677886693315074, test 0.449477747703592\n",
      "RMSE, train 0.4067851153362279, test 0.4456672677770257\n",
      "RMSE, train 0.4060887779024514, test 0.4444267861545086\n",
      "RMSE, train 0.4068901138097951, test 0.44490124052390456\n",
      "RMSE, train 0.4060650827607723, test 0.44218287772188586\n",
      "RMSE, train 0.4054466242892574, test 0.4433990924929579\n",
      "RMSE, train 0.40519015299099864, test 0.4441759147060414\n",
      "RMSE, train 0.40390539895554983, test 0.44233927968889475\n",
      "RMSE, train 0.4050202076558513, test 0.44621284476791817\n",
      "RMSE, train 0.4045865506573458, test 0.444086038817962\n",
      "Early stopping at epoch 44 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.9823652602270285, test 0.9269584526618322\n",
      "RMSE, train 0.9180628670997054, test 0.8239096224308013\n",
      "RMSE, train 0.752476637655834, test 0.6334293256203334\n",
      "RMSE, train 0.5569245514040687, test 0.5252949065632291\n",
      "RMSE, train 0.4906521332312144, test 0.51419029004044\n",
      "RMSE, train 0.4690296830674709, test 0.5100870377487606\n",
      "RMSE, train 0.4597423287495127, test 0.5014491657416026\n",
      "RMSE, train 0.4541134763599406, test 0.48953265382183925\n",
      "RMSE, train 0.4440677950806374, test 0.48568324695030846\n",
      "RMSE, train 0.44152748167032824, test 0.47630116161372926\n",
      "RMSE, train 0.43756934566639183, test 0.47797869824700884\n",
      "RMSE, train 0.43458187182476576, test 0.4733430862426758\n",
      "RMSE, train 0.43159050568737434, test 0.4686003696587351\n",
      "RMSE, train 0.42887634420491294, test 0.47182586126857334\n",
      "RMSE, train 0.4264085519345944, test 0.46799186600579157\n",
      "RMSE, train 0.4234114143485329, test 0.4704661728607284\n",
      "RMSE, train 0.42237433530089025, test 0.4654558612240685\n",
      "RMSE, train 0.42284813459028775, test 0.4663115746445126\n",
      "RMSE, train 0.42204361611781416, test 0.45920238925351037\n",
      "RMSE, train 0.42051873811975, test 0.46045383661985395\n",
      "RMSE, train 0.41893167862031017, test 0.4623803925183084\n",
      "RMSE, train 0.4185109999221612, test 0.45915444807873834\n",
      "RMSE, train 0.4172135076995166, test 0.46152438289589354\n",
      "RMSE, train 0.4171952395586955, test 0.4625033165017764\n",
      "RMSE, train 0.4166035893953072, test 0.45556718591186735\n",
      "RMSE, train 0.4135301932893352, test 0.45724561462799707\n",
      "RMSE, train 0.41433598338111716, test 0.45761314034461975\n",
      "RMSE, train 0.41314392558969254, test 0.454937086502711\n",
      "RMSE, train 0.4124712453216234, test 0.45700032595131135\n",
      "RMSE, train 0.41173680303392385, test 0.45270252227783203\n",
      "RMSE, train 0.41033951199118984, test 0.4573825056354205\n",
      "RMSE, train 0.411085051988977, test 0.45409524424208536\n",
      "RMSE, train 0.41076081400772313, test 0.45271419717205896\n",
      "RMSE, train 0.4094132790668313, test 0.4540138797627555\n",
      "RMSE, train 0.4083999419871045, test 0.45264027764399845\n",
      "RMSE, train 0.40865359144069435, test 0.4545626829067866\n",
      "RMSE, train 0.4086402232113553, test 0.4534380301833153\n",
      "RMSE, train 0.408634166029907, test 0.45289502176973556\n",
      "RMSE, train 0.40844599874514453, test 0.45155826956033707\n",
      "RMSE, train 0.40622490672570355, test 0.45621872312492795\n",
      "RMSE, train 0.40673728383615654, test 0.44968192097213533\n",
      "RMSE, train 0.40662238536016, test 0.45183346304628585\n",
      "RMSE, train 0.40434431162163254, test 0.4520839879910151\n",
      "RMSE, train 0.4057728381491093, test 0.4522530441482862\n",
      "RMSE, train 0.4057976615959101, test 0.4525522947311401\n",
      "RMSE, train 0.40518379697420526, test 0.44811582929558225\n",
      "RMSE, train 0.40363205820723685, test 0.4501194344626533\n",
      "RMSE, train 0.40439012498065147, test 0.44922082705630195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.40356980215989036, test 0.4488000518745846\n",
      "RMSE, train 0.40278021637802175, test 0.4490840540991889\n",
      "RMSE, train 0.4038227915442536, test 0.44795735908879175\n",
      "RMSE, train 0.4030635620786173, test 0.44584782272577284\n",
      "RMSE, train 0.4031703099407597, test 0.44794338908460407\n",
      "RMSE, train 0.40190900215562786, test 0.4501053652829594\n",
      "RMSE, train 0.4026937020837136, test 0.4467208961645762\n",
      "RMSE, train 0.4021791976015523, test 0.4491695400741365\n",
      "RMSE, train 0.40362511201688867, test 0.4479268088936806\n",
      "RMSE, train 0.4023645281229379, test 0.4465027410950926\n",
      "RMSE, train 0.40130609109234616, test 0.44740937451521556\n",
      "RMSE, train 0.40226006266884407, test 0.44677392327123217\n",
      "RMSE, train 0.40050918916165024, test 0.44676055444611446\n",
      "RMSE, train 0.40115846251702375, test 0.4453736146291097\n",
      "RMSE, train 0.40102442114982967, test 0.4462789644797643\n",
      "RMSE, train 0.4014027189774655, test 0.4498694019185172\n",
      "RMSE, train 0.40150134458214126, test 0.44731697456704245\n",
      "RMSE, train 0.4014613297429046, test 0.44646756533119414\n",
      "RMSE, train 0.4009841470464542, test 0.4484697073698044\n",
      "RMSE, train 0.40131716482401536, test 0.446982251935535\n",
      "RMSE, train 0.4006533022678766, test 0.44676095280382366\n",
      "RMSE, train 0.3998633176489982, test 0.44280294047461616\n",
      "RMSE, train 0.4005274009913447, test 0.4436168352762858\n",
      "RMSE, train 0.4012237461911379, test 0.446078771021631\n",
      "RMSE, train 0.40058848775943334, test 0.4460956990718842\n",
      "RMSE, train 0.39994597447047014, test 0.4482684150338173\n",
      "RMSE, train 0.4009746924002537, test 0.44212232612901264\n",
      "RMSE, train 0.3990662205171071, test 0.4451681014564302\n",
      "RMSE, train 0.4007640147225233, test 0.4411011078291469\n",
      "RMSE, train 0.4003344311547087, test 0.44714166538582906\n",
      "RMSE, train 0.4004755690493031, test 0.4446900415751669\n",
      "RMSE, train 0.39965306604004935, test 0.4434250912732548\n",
      "RMSE, train 0.39951311003647727, test 0.4477031081914902\n",
      "RMSE, train 0.3996213193771974, test 0.4478565734293726\n",
      "RMSE, train 0.3986964626212647, test 0.44281478474537533\n",
      "RMSE, train 0.3997344420444612, test 0.4466716072625584\n",
      "RMSE, train 0.40037317489678004, test 0.44399787303474214\n",
      "RMSE, train 0.3991579901015341, test 0.44828238354788885\n",
      "RMSE, train 0.3991310897702477, test 0.4432268713911374\n",
      "Early stopping at epoch 87 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.0546906531971192, test 0.981387870051922\n",
      "RMSE, train 1.0052270465922133, test 0.9584605411077157\n",
      "RMSE, train 0.9906084296116576, test 0.9317730850516222\n",
      "RMSE, train 0.9709212387276587, test 0.9139634368893428\n",
      "RMSE, train 0.9320320462883447, test 0.855672748042987\n",
      "RMSE, train 0.8553989785853947, test 0.7717933807617579\n",
      "RMSE, train 0.727124235340368, test 0.6656685788662006\n",
      "RMSE, train 0.6037657107705268, test 0.5772444528455918\n",
      "RMSE, train 0.533875116028147, test 0.5516816734885558\n",
      "RMSE, train 0.5057241066686833, test 0.5383318492617363\n",
      "RMSE, train 0.49311237403908253, test 0.5218827724456787\n",
      "RMSE, train 0.4813471726167982, test 0.5023927650390527\n",
      "RMSE, train 0.47348978252054374, test 0.4908548344213229\n",
      "RMSE, train 0.46179472188526227, test 0.49354602549320614\n",
      "RMSE, train 0.4523282291547532, test 0.4804899304723128\n",
      "RMSE, train 0.4468073687078054, test 0.49698614806700975\n",
      "RMSE, train 0.4419166194594166, test 0.4803001452714969\n",
      "RMSE, train 0.4365455151254143, test 0.4717391142860437\n",
      "RMSE, train 0.43237027423775454, test 0.47174609299653614\n",
      "RMSE, train 0.42998570895454963, test 0.46124604783761197\n",
      "RMSE, train 0.42631577925518666, test 0.4559128339856099\n",
      "RMSE, train 0.4237843002207183, test 0.4624675743472882\n",
      "RMSE, train 0.41940722927868923, test 0.45401051158133227\n",
      "RMSE, train 0.4204197673132858, test 0.4528692263441208\n",
      "RMSE, train 0.4129470771068353, test 0.446192560526423\n",
      "RMSE, train 0.4121414912731105, test 0.4593746461547338\n",
      "RMSE, train 0.41180411264346767, test 0.44369865199312186\n",
      "RMSE, train 0.4078332405316867, test 0.4479157508183748\n",
      "RMSE, train 0.4068552299266292, test 0.4469595024218926\n",
      "RMSE, train 0.4075476411161393, test 0.439628181549219\n",
      "RMSE, train 0.4050279976422913, test 0.44197292492175716\n",
      "RMSE, train 0.4032627862190532, test 0.4350907462529647\n",
      "RMSE, train 0.4026362877397151, test 0.45199528623085755\n",
      "RMSE, train 0.4003078468677782, test 0.4423905486861865\n",
      "RMSE, train 0.3998798765590258, test 0.4406451214200411\n",
      "RMSE, train 0.3977520053631791, test 0.4436639585556128\n",
      "RMSE, train 0.39853810386679994, test 0.4318527470414455\n",
      "RMSE, train 0.39718174159155456, test 0.4435730538307092\n",
      "RMSE, train 0.39586987371942334, test 0.4573762023296112\n",
      "RMSE, train 0.39572061510100914, test 0.43623488625654805\n",
      "RMSE, train 0.39534268855491533, test 0.43088752566239774\n",
      "RMSE, train 0.39219833659791503, test 0.4354243950010874\n",
      "RMSE, train 0.391582696469402, test 0.43771671312741744\n",
      "RMSE, train 0.39327630224257615, test 0.43760263232084423\n",
      "RMSE, train 0.3926415152360346, test 0.4296883505124312\n",
      "RMSE, train 0.3889623950017947, test 0.445243008625813\n",
      "RMSE, train 0.39072270993131714, test 0.4273077166424348\n",
      "RMSE, train 0.38853847154204346, test 0.4352801841421005\n",
      "RMSE, train 0.38786768472268945, test 0.42561024078764975\n",
      "RMSE, train 0.38873418255758435, test 0.4243353219368519\n",
      "RMSE, train 0.38691221135799014, test 0.4273101038848742\n",
      "RMSE, train 0.3859990146533351, test 0.4311770899937703\n",
      "RMSE, train 0.3869236132066198, test 0.42572750055637115\n",
      "RMSE, train 0.3863663909684089, test 0.4367489444139676\n",
      "RMSE, train 0.3853879175917753, test 0.42950915010311663\n",
      "RMSE, train 0.38659336387739746, test 0.42128517039311236\n",
      "RMSE, train 0.38478765861824665, test 0.42585811869074136\n",
      "RMSE, train 0.38345669198351856, test 0.41926809085103184\n",
      "RMSE, train 0.38503132245250954, test 0.41775753568762386\n",
      "RMSE, train 0.38504903677653673, test 0.42165376494328183\n",
      "RMSE, train 0.3834185962829263, test 0.4258052483201027\n",
      "RMSE, train 0.38145915286563264, test 0.422778063859695\n",
      "RMSE, train 0.3829623594926525, test 0.4217817655358559\n",
      "RMSE, train 0.38322402504374303, test 0.42562539321489823\n",
      "RMSE, train 0.3821010995319699, test 0.4239708091586064\n",
      "RMSE, train 0.3816421497555165, test 0.4337932505668738\n",
      "RMSE, train 0.38169485929413377, test 0.4295357708365489\n",
      "RMSE, train 0.38161235305007746, test 0.42097502450148266\n",
      "RMSE, train 0.38185750816098624, test 0.4316436262466969\n",
      "Early stopping at epoch 69 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.GRU, data_dir = 'data_synthetic', only_one = True)\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/gru/'+'output_size' + str(output) + 'input_size' + str(inputs) + '_singlevar.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b9c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.5614706338806585, test 0.4735951897117399\n",
      "RMSE, train 0.4268634483630478, test 0.3837204100864549\n",
      "RMSE, train 0.3594022280731691, test 0.3397289969387554\n",
      "RMSE, train 0.32611533893426886, test 0.31611190760327923\n",
      "RMSE, train 0.30729385521336505, test 0.3019883766049339\n",
      "RMSE, train 0.29430078059847176, test 0.29210586395234833\n",
      "RMSE, train 0.28447846776765323, test 0.28325909171854297\n",
      "RMSE, train 0.2770090084596585, test 0.2762418562366116\n",
      "RMSE, train 0.2715161224245554, test 0.2720716658739313\n",
      "RMSE, train 0.26730467736897734, test 0.2705161046356924\n",
      "RMSE, train 0.2641101499408366, test 0.26567099207351286\n",
      "RMSE, train 0.2616537304028221, test 0.26525605518010353\n",
      "RMSE, train 0.2597338008609685, test 0.2626213052820775\n",
      "RMSE, train 0.25829465310328564, test 0.26235033619788384\n",
      "RMSE, train 0.2570834506465041, test 0.2613715230216903\n",
      "RMSE, train 0.25609284867587767, test 0.2602036430109893\n",
      "RMSE, train 0.25532325570703496, test 0.2594282646933871\n",
      "RMSE, train 0.25471307400599297, test 0.2584880980993471\n",
      "RMSE, train 0.2541481703225332, test 0.2579864672114772\n",
      "RMSE, train 0.25370940711835155, test 0.2582284006620607\n",
      "RMSE, train 0.2534572084990179, test 0.2584347036336699\n",
      "RMSE, train 0.25320254407616943, test 0.25810509842009316\n",
      "RMSE, train 0.2530513155925651, test 0.25887394414073034\n",
      "RMSE, train 0.2528243261893747, test 0.2597299239808513\n",
      "RMSE, train 0.2526465195411514, test 0.2572599208403018\n",
      "RMSE, train 0.2525807988384496, test 0.25750516216841435\n",
      "RMSE, train 0.2525354901645259, test 0.25767739309418586\n",
      "RMSE, train 0.25241484846404416, test 0.258146945387125\n",
      "RMSE, train 0.25245040769986954, test 0.25926370071547644\n",
      "RMSE, train 0.2523458405239544, test 0.25706116837118903\n",
      "RMSE, train 0.2523293125152352, test 0.2571421111783674\n",
      "RMSE, train 0.25229757927034213, test 0.25782885186133847\n",
      "RMSE, train 0.2522827436919269, test 0.257471245262892\n",
      "RMSE, train 0.25228836006032146, test 0.2574636215163815\n",
      "RMSE, train 0.25226734002882784, test 0.2579952673686127\n",
      "RMSE, train 0.2522618402045942, test 0.25776438979852584\n",
      "RMSE, train 0.2522685509837663, test 0.25791504258109677\n",
      "RMSE, train 0.25224971990634804, test 0.25773578179219075\n",
      "RMSE, train 0.25225647983579297, test 0.2581491070168634\n",
      "RMSE, train 0.2522355939000256, test 0.2581245368646999\n",
      "Early stopping at epoch 40 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 1.130799406272197, test 0.8162966579937738\n",
      "RMSE, train 0.6456320130451005, test 0.4950160252407563\n",
      "RMSE, train 0.41741666013774603, test 0.35502381265656024\n",
      "RMSE, train 0.32879766830910556, test 0.30990849152084227\n",
      "RMSE, train 0.2999146441186247, test 0.296019904746497\n",
      "RMSE, train 0.28866110733042843, test 0.2885302650657567\n",
      "RMSE, train 0.28210231906127353, test 0.2828729592941024\n",
      "RMSE, train 0.2758447913385113, test 0.2750600772825154\n",
      "RMSE, train 0.2707760031316203, test 0.2706114951490371\n",
      "RMSE, train 0.26537821120639077, test 0.2653936994962456\n",
      "RMSE, train 0.2603785698773407, test 0.2622487533314169\n",
      "RMSE, train 0.25578989726510126, test 0.2559434576344884\n",
      "RMSE, train 0.2521586895954271, test 0.2525301592285968\n",
      "RMSE, train 0.24876764918930136, test 0.25138438696211035\n",
      "RMSE, train 0.2458458867089951, test 0.2490302714680837\n",
      "RMSE, train 0.24334769801572267, test 0.24534265450702225\n",
      "RMSE, train 0.24182869059595502, test 0.2438388761163743\n",
      "RMSE, train 0.24052843370056345, test 0.24284362663661152\n",
      "RMSE, train 0.2388828223955776, test 0.24209823933514682\n",
      "RMSE, train 0.23822133737778375, test 0.24066005185369618\n",
      "RMSE, train 0.23695012611838487, test 0.23972467745631193\n",
      "RMSE, train 0.2364424668131811, test 0.24155822488640952\n",
      "RMSE, train 0.23609222881948416, test 0.2399704732185553\n",
      "RMSE, train 0.2356390185835149, test 0.23931158069244102\n",
      "RMSE, train 0.2352384656728038, test 0.239578383520615\n",
      "RMSE, train 0.23501791833684996, test 0.24069755136474105\n",
      "RMSE, train 0.23524737137893917, test 0.23972020944780556\n",
      "RMSE, train 0.23473925351613928, test 0.23971554575380216\n",
      "RMSE, train 0.23458962991592372, test 0.2391183464364572\n",
      "RMSE, train 0.23451373846786708, test 0.23952399095720497\n",
      "RMSE, train 0.23483589734987692, test 0.23914777315106273\n",
      "RMSE, train 0.23452333095464628, test 0.23786194551705328\n",
      "RMSE, train 0.23451711736649636, test 0.23915463371956644\n",
      "RMSE, train 0.23426897369837954, test 0.24074481476929563\n",
      "RMSE, train 0.23438458912346044, test 0.23983407673264337\n",
      "RMSE, train 0.2342734576659164, test 0.2403983038442194\n",
      "RMSE, train 0.2342459929556499, test 0.2398331932538797\n",
      "RMSE, train 0.23470005575522238, test 0.24030571634119208\n",
      "RMSE, train 0.23461435818177487, test 0.23881683960433833\n",
      "RMSE, train 0.23441189676824853, test 0.2384649367987617\n",
      "RMSE, train 0.23421897829664864, test 0.2394842071350941\n",
      "RMSE, train 0.23447325472768984, test 0.24049374344181423\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.65576921171471, test 0.39578633480950404\n",
      "RMSE, train 0.33302337242596186, test 0.30645772331116494\n",
      "RMSE, train 0.2978537947193646, test 0.29895171268205895\n",
      "RMSE, train 0.2909866683423392, test 0.2931846714856332\n",
      "RMSE, train 0.2844196780404048, test 0.28642488480137107\n",
      "RMSE, train 0.27784103704795143, test 0.2797189616320426\n",
      "RMSE, train 0.27153789852537324, test 0.27295688493994247\n",
      "RMSE, train 0.26525460649083166, test 0.266676732191914\n",
      "RMSE, train 0.2592591570892822, test 0.2615420832707171\n",
      "RMSE, train 0.2544295308686523, test 0.2562648125907831\n",
      "RMSE, train 0.2495065022474413, test 0.2521065527148414\n",
      "RMSE, train 0.24568550024967967, test 0.24873039989094986\n",
      "RMSE, train 0.2423290772033907, test 0.24574771242444976\n",
      "RMSE, train 0.2400823525274232, test 0.24363089483558087\n",
      "RMSE, train 0.23784527244534828, test 0.24191720561500182\n",
      "RMSE, train 0.23664001369082344, test 0.24034923890180754\n",
      "RMSE, train 0.23468530934248397, test 0.23918968439102173\n",
      "RMSE, train 0.23375979953928033, test 0.23820220783614277\n",
      "RMSE, train 0.23301441365404169, test 0.2375016420295364\n",
      "RMSE, train 0.23252888918240697, test 0.23717159594882997\n",
      "RMSE, train 0.23194927460095013, test 0.2367413070118218\n",
      "RMSE, train 0.23111901362376935, test 0.2362150044033402\n",
      "RMSE, train 0.23123659191927168, test 0.23610610521414824\n",
      "RMSE, train 0.2305588400535492, test 0.23602229716223583\n",
      "RMSE, train 0.23083351153745327, test 0.23590909859590364\n",
      "RMSE, train 0.23020365203558002, test 0.23578039439100967\n",
      "RMSE, train 0.23017675318379902, test 0.23564706670871952\n",
      "RMSE, train 0.2303309097473047, test 0.23620158250917467\n",
      "RMSE, train 0.23005106363659983, test 0.23557697249609127\n",
      "RMSE, train 0.22990789747377957, test 0.2354788890663992\n",
      "RMSE, train 0.2306259474488718, test 0.23545246048454652\n",
      "RMSE, train 0.23006631453027096, test 0.2353759770069206\n",
      "RMSE, train 0.22978842887542902, test 0.23561799081794002\n",
      "RMSE, train 0.22990478977147957, test 0.2355088894827324\n",
      "RMSE, train 0.23007634253517142, test 0.2354740855333052\n",
      "RMSE, train 0.2297964606171986, test 0.23561354563163037\n",
      "RMSE, train 0.23000952180451167, test 0.2354593463242054\n",
      "RMSE, train 0.23009365371295384, test 0.2354340135659042\n",
      "RMSE, train 0.22974100021093385, test 0.23550998171170553\n",
      "RMSE, train 0.2299995700687742, test 0.2355397665186932\n",
      "RMSE, train 0.23021366075475588, test 0.23549654635421016\n",
      "RMSE, train 0.22992573025574817, test 0.23536909463112815\n",
      "RMSE, train 0.23001610548066687, test 0.2356009125186686\n",
      "RMSE, train 0.22985065615634676, test 0.23562027703513178\n",
      "RMSE, train 0.23000820773814531, test 0.23561000059309758\n",
      "RMSE, train 0.23019706813701943, test 0.2354326625272893\n",
      "RMSE, train 0.2299096225611945, test 0.2354228208985245\n",
      "RMSE, train 0.2305461208957599, test 0.235877043257157\n",
      "RMSE, train 0.22983987534097008, test 0.2353975359154375\n",
      "RMSE, train 0.22979325229234532, test 0.23552943753045902\n",
      "RMSE, train 0.22988920051977832, test 0.2356118078817401\n",
      "RMSE, train 0.22960547279955737, test 0.23586449321163327\n",
      "Early stopping at epoch 52 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.47434604452447277, test 0.40436751132502274\n",
      "RMSE, train 0.3604715491749506, test 0.3280065576819813\n",
      "RMSE, train 0.3061706768015404, test 0.29284998540784796\n",
      "RMSE, train 0.2801208734725711, test 0.27510710235904245\n",
      "RMSE, train 0.26748619401085066, test 0.2659427922438173\n",
      "RMSE, train 0.25961723571603224, test 0.25881319127830804\n",
      "RMSE, train 0.2536355732164406, test 0.25458117304187194\n",
      "RMSE, train 0.24909709027672725, test 0.2503410253454657\n",
      "RMSE, train 0.2453802264071023, test 0.24724231967154672\n",
      "RMSE, train 0.24220422881173062, test 0.243568648018089\n",
      "RMSE, train 0.23926879474470894, test 0.24202510802184835\n",
      "RMSE, train 0.2374834203136849, test 0.24014652615376547\n",
      "RMSE, train 0.23534796909742536, test 0.2392463076348398\n",
      "RMSE, train 0.23383379798729267, test 0.2388300810228376\n",
      "RMSE, train 0.23261074207918742, test 0.23803075826635547\n",
      "RMSE, train 0.232234429594725, test 0.23600568739222547\n",
      "RMSE, train 0.2315575553366563, test 0.236096730200099\n",
      "RMSE, train 0.23051340282318986, test 0.2348689366789425\n",
      "RMSE, train 0.23018308558227907, test 0.2354828128773792\n",
      "RMSE, train 0.22986706408509774, test 0.2356191490064649\n",
      "RMSE, train 0.22948438677767866, test 0.234389996119574\n",
      "RMSE, train 0.22932651542962879, test 0.2353939207307264\n",
      "RMSE, train 0.22911665928249997, test 0.23504982559996493\n",
      "RMSE, train 0.22948854523299703, test 0.23440904520890293\n",
      "RMSE, train 0.22856462371662295, test 0.23529732293065855\n",
      "RMSE, train 0.22886461159992333, test 0.23458755030935885\n",
      "RMSE, train 0.2288126884503979, test 0.23418715041057736\n",
      "RMSE, train 0.22859870850470868, test 0.2349062564910627\n",
      "RMSE, train 0.22836874139124, test 0.2347083896690724\n",
      "RMSE, train 0.22871629996914283, test 0.2349928917691988\n",
      "RMSE, train 0.2286132985552626, test 0.23469841633649433\n",
      "RMSE, train 0.22856876977801607, test 0.23487002329499113\n",
      "RMSE, train 0.22861585101037152, test 0.2339926982188926\n",
      "RMSE, train 0.22889758057910103, test 0.23421338061783828\n",
      "RMSE, train 0.22828138729908587, test 0.23409170949575947\n",
      "RMSE, train 0.22824399313736077, test 0.2340244235945683\n",
      "RMSE, train 0.2281774672410653, test 0.2352136182142239\n",
      "RMSE, train 0.22881615092546673, test 0.23531419031468093\n",
      "RMSE, train 0.2284935464758008, test 0.23512291287382445\n",
      "RMSE, train 0.22827342778515416, test 0.23437148800083235\n",
      "RMSE, train 0.22838048708040562, test 0.2343170303924411\n",
      "RMSE, train 0.22802111783858414, test 0.23470165894604197\n",
      "RMSE, train 0.22818957912893453, test 0.23496614856755033\n",
      "Early stopping at epoch 43 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 1.5677196008543814, test 1.3450366751221585\n",
      "RMSE, train 1.195145882305599, test 1.0293937561925777\n",
      "RMSE, train 0.9149873954874854, test 0.7928229627037836\n",
      "RMSE, train 0.7081944229561956, test 0.6230825146367728\n",
      "RMSE, train 0.5620256360139577, test 0.5053970579766045\n",
      "RMSE, train 0.46265195241017687, test 0.42831372266465967\n",
      "RMSE, train 0.39930108888074756, test 0.3807245539732216\n",
      "RMSE, train 0.3605047411195213, test 0.35175395171996976\n",
      "RMSE, train 0.3371139907488419, test 0.3340793926853779\n",
      "RMSE, train 0.32191582102208366, test 0.32178254610250806\n",
      "RMSE, train 0.3110055448186974, test 0.3122027159229783\n",
      "RMSE, train 0.3023550390386053, test 0.3037935523701108\n",
      "RMSE, train 0.2953409195667313, test 0.29737906096395383\n",
      "RMSE, train 0.289369388858998, test 0.2915116144605905\n",
      "RMSE, train 0.2843248161276983, test 0.28663822318896776\n",
      "RMSE, train 0.2801344191445218, test 0.2823362003180606\n",
      "RMSE, train 0.2765406718357436, test 0.2789717357267033\n",
      "RMSE, train 0.27362824561855487, test 0.27532257810850774\n",
      "RMSE, train 0.27107006380514753, test 0.2728028126245688\n",
      "RMSE, train 0.268930159554246, test 0.2706772343925208\n",
      "RMSE, train 0.2671665348743479, test 0.2688356273430438\n",
      "RMSE, train 0.2657219357938776, test 0.2671631872653961\n",
      "RMSE, train 0.26457213056123546, test 0.2660389412040553\n",
      "RMSE, train 0.2636202383155544, test 0.2651511845756168\n",
      "RMSE, train 0.26282386807724833, test 0.2640708299461475\n",
      "RMSE, train 0.2621091388075823, test 0.26351905140009796\n",
      "RMSE, train 0.2616290653034324, test 0.26288406390789126\n",
      "RMSE, train 0.2611855318199002, test 0.26235370621208315\n",
      "RMSE, train 0.26095789842187395, test 0.26206759628185555\n",
      "RMSE, train 0.26064631780008635, test 0.26178169299748316\n",
      "RMSE, train 0.26048963507937806, test 0.26159975696201165\n",
      "RMSE, train 0.26033345186301776, test 0.2612942190579146\n",
      "RMSE, train 0.260186722982795, test 0.26106202257566213\n",
      "RMSE, train 0.26010937515586136, test 0.26102665079034065\n",
      "RMSE, train 0.260061044230937, test 0.2607900810635779\n",
      "RMSE, train 0.2599631299625241, test 0.2607478893492833\n",
      "RMSE, train 0.25989856631044417, test 0.26080621926745107\n",
      "RMSE, train 0.2599390703854301, test 0.26067929499405473\n",
      "RMSE, train 0.2598259457116646, test 0.26050664447555855\n",
      "RMSE, train 0.2598346692750291, test 0.26048555182031363\n",
      "RMSE, train 0.2597584093830759, test 0.26046295217738663\n",
      "RMSE, train 0.25977641608445873, test 0.26051393754718716\n",
      "RMSE, train 0.2597446758450279, test 0.26046463317614943\n",
      "RMSE, train 0.25971095731121396, test 0.26034674417874043\n",
      "RMSE, train 0.25979156638946266, test 0.2604168141183774\n",
      "RMSE, train 0.25981534877792, test 0.26050939429397424\n",
      "RMSE, train 0.25972196737664843, test 0.26034910465813865\n",
      "RMSE, train 0.2596979500846036, test 0.26048654625731066\n",
      "RMSE, train 0.25973504913910744, test 0.2603320772490226\n",
      "RMSE, train 0.2597866914715738, test 0.2602414093480622\n",
      "RMSE, train 0.2597734950062248, test 0.26039696047621325\n",
      "RMSE, train 0.2597277321882786, test 0.26031346422089036\n",
      "RMSE, train 0.2597549354447232, test 0.26046484339335735\n",
      "RMSE, train 0.2597745728168276, test 0.26022907038611814\n",
      "RMSE, train 0.2597171938227069, test 0.26035551739133095\n",
      "RMSE, train 0.2597800985038761, test 0.26041283403053755\n",
      "RMSE, train 0.25972454712515874, test 0.26033544121694957\n",
      "RMSE, train 0.25975049608537265, test 0.26044096459041943\n",
      "RMSE, train 0.2597064809693444, test 0.26022384574344337\n",
      "RMSE, train 0.2597586389540905, test 0.26044011608628204\n",
      "RMSE, train 0.25976284022533125, test 0.2603981844649827\n",
      "RMSE, train 0.2597963963334839, test 0.26028784598447074\n",
      "RMSE, train 0.25988474099205866, test 0.2604445471497607\n",
      "RMSE, train 0.25973314076902404, test 0.2602021399854629\n",
      "RMSE, train 0.2597375961561357, test 0.2602383328124511\n",
      "RMSE, train 0.25977338461445704, test 0.26018183074953144\n",
      "RMSE, train 0.25976129048954577, test 0.26033552803776483\n",
      "RMSE, train 0.2597952364613452, test 0.2602008882879226\n",
      "RMSE, train 0.25972369769888537, test 0.26035906620754684\n",
      "RMSE, train 0.25974641349767486, test 0.26027325399158413\n",
      "RMSE, train 0.2597070031108395, test 0.26031928515631303\n",
      "RMSE, train 0.25969665240676654, test 0.26043404823492383\n",
      "RMSE, train 0.25981656998215663, test 0.26021301426178167\n",
      "RMSE, train 0.2597199256922449, test 0.260375418815731\n",
      "RMSE, train 0.25970511972123095, test 0.2601137235760689\n",
      "RMSE, train 0.2597804596617578, test 0.26033951329790855\n",
      "RMSE, train 0.25974753012339913, test 0.2603213810477375\n",
      "RMSE, train 0.25975107290451566, test 0.260279595605598\n",
      "RMSE, train 0.2597036058263433, test 0.2602604737212835\n",
      "RMSE, train 0.25969810249103653, test 0.26029375515693476\n",
      "RMSE, train 0.259735276171517, test 0.2603457378577595\n",
      "RMSE, train 0.2597440408032027, test 0.2603072815936459\n",
      "RMSE, train 0.2597772195454567, test 0.26041717581019913\n",
      "RMSE, train 0.2597526939165208, test 0.2603273516105226\n",
      "RMSE, train 0.25976066662359143, test 0.2603132398414218\n",
      "Early stopping at epoch 85 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.9715867998186222, test 0.7236090797488972\n",
      "RMSE, train 0.5987392247708376, test 0.47959139223321007\n",
      "RMSE, train 0.43234870718284085, test 0.3847339785957741\n",
      "RMSE, train 0.37101213375398934, test 0.35179480518830025\n",
      "RMSE, train 0.347479578138383, test 0.3371355880872678\n",
      "RMSE, train 0.3345049386459195, test 0.3264274677987826\n",
      "RMSE, train 0.3241393682200554, test 0.31585174293841345\n",
      "RMSE, train 0.31377992646630143, test 0.306317001454911\n",
      "RMSE, train 0.304045681680037, test 0.29717250010472235\n",
      "RMSE, train 0.29542950714730526, test 0.2887482981560594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.28718390188002885, test 0.2816263838844784\n",
      "RMSE, train 0.2802426537637376, test 0.2750718487521349\n",
      "RMSE, train 0.273799285708257, test 0.26898444999577636\n",
      "RMSE, train 0.26865157440366333, test 0.2639952228104664\n",
      "RMSE, train 0.26405191844837234, test 0.26016400691311237\n",
      "RMSE, train 0.26003094106789465, test 0.25691320147302193\n",
      "RMSE, train 0.2567884633548496, test 0.25392413101458955\n",
      "RMSE, train 0.2541918593097078, test 0.2518741847094843\n",
      "RMSE, train 0.2526562768227059, test 0.24999836668119593\n",
      "RMSE, train 0.2504983821437379, test 0.24930073466088812\n",
      "RMSE, train 0.249275857474932, test 0.24807745900194525\n",
      "RMSE, train 0.24823175612375264, test 0.24731876233876762\n",
      "RMSE, train 0.24762668757707126, test 0.24688364697967546\n",
      "RMSE, train 0.24745655267630234, test 0.2465222198831833\n",
      "RMSE, train 0.24641850552221467, test 0.246031632489067\n",
      "RMSE, train 0.24605415068751524, test 0.24629091168359174\n",
      "RMSE, train 0.24596038962568134, test 0.24611759842452358\n",
      "RMSE, train 0.24551780180128152, test 0.24588863911517597\n",
      "RMSE, train 0.24543666230006653, test 0.2455420158803463\n",
      "RMSE, train 0.24524692085779404, test 0.2454415718882771\n",
      "RMSE, train 0.24535332518545064, test 0.24537682798454316\n",
      "RMSE, train 0.24529476745500545, test 0.24517804573653107\n",
      "RMSE, train 0.24534154130715477, test 0.245340335230201\n",
      "RMSE, train 0.2454572257947577, test 0.24518200300507625\n",
      "RMSE, train 0.2447292784860065, test 0.24547730765100254\n",
      "RMSE, train 0.24503399816549515, test 0.24548453654525643\n",
      "RMSE, train 0.24465349664495997, test 0.24524775021157022\n",
      "RMSE, train 0.24486784801687583, test 0.24524140364285243\n",
      "RMSE, train 0.2452432881917589, test 0.24524578502622701\n",
      "RMSE, train 0.24503766032597743, test 0.24535898851641155\n",
      "RMSE, train 0.2449437289013843, test 0.24561195681660863\n",
      "RMSE, train 0.24464586738897257, test 0.24538694082175272\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.4906273198218647, test 0.37754134740680456\n",
      "RMSE, train 0.35782413872888147, test 0.34306213618921383\n",
      "RMSE, train 0.33143184618103216, test 0.3225635745163475\n",
      "RMSE, train 0.31306088292131234, test 0.30523075522588833\n",
      "RMSE, train 0.2983606026907632, test 0.2937915212075625\n",
      "RMSE, train 0.2860612100830265, test 0.2820534635601299\n",
      "RMSE, train 0.27690615964351395, test 0.2754040017191853\n",
      "RMSE, train 0.2690251929470397, test 0.26777587544971276\n",
      "RMSE, train 0.26318070557057727, test 0.26352605217003394\n",
      "RMSE, train 0.25904420000340683, test 0.25815841063324896\n",
      "RMSE, train 0.25490888008494783, test 0.2547253263848169\n",
      "RMSE, train 0.25181023161330773, test 0.25264527349333676\n",
      "RMSE, train 0.24923602072826398, test 0.2503376164074455\n",
      "RMSE, train 0.2473674855785432, test 0.24890387071562664\n",
      "RMSE, train 0.2458499020740617, test 0.24966363356049573\n",
      "RMSE, train 0.24459107809401806, test 0.24687245454905288\n",
      "RMSE, train 0.24337042804831774, test 0.24640986463055015\n",
      "RMSE, train 0.242797242059557, test 0.24597830591457231\n",
      "RMSE, train 0.24207916021476902, test 0.24588755850813218\n",
      "RMSE, train 0.24163766987702945, test 0.24512178104903018\n",
      "RMSE, train 0.24130413639064968, test 0.2457590440421232\n",
      "RMSE, train 0.24096783047667775, test 0.2445607427507639\n",
      "RMSE, train 0.24088698708348805, test 0.24431336032492773\n",
      "RMSE, train 0.24050605930144492, test 0.24364499847537704\n",
      "RMSE, train 0.24025351302556222, test 0.24422023997509054\n",
      "RMSE, train 0.24015648570520426, test 0.24375435723257916\n",
      "RMSE, train 0.24044901223483947, test 0.2445708116782563\n",
      "RMSE, train 0.24009808584690615, test 0.24462484874363458\n",
      "RMSE, train 0.24024982028082825, test 0.2436165902763605\n",
      "RMSE, train 0.24024180903998335, test 0.24372362564983113\n",
      "RMSE, train 0.24033469242532787, test 0.24411393781857832\n",
      "RMSE, train 0.239907327739112, test 0.24301766617489712\n",
      "RMSE, train 0.23997879426009255, test 0.2435534464727555\n",
      "RMSE, train 0.2400630710723613, test 0.24345773065994894\n",
      "RMSE, train 0.24016468661932644, test 0.2449827973863908\n",
      "RMSE, train 0.23996252766232085, test 0.2433115501355912\n",
      "RMSE, train 0.23998101161131413, test 0.24318954940619214\n",
      "RMSE, train 0.23982756399835636, test 0.24414608401379415\n",
      "RMSE, train 0.24016565074718077, test 0.2446241205824273\n",
      "RMSE, train 0.23980551863937336, test 0.24394281847136362\n",
      "RMSE, train 0.2400987765920188, test 0.2438980036947344\n",
      "RMSE, train 0.23981016978199446, test 0.24368305251534497\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.5053766368362315, test 0.3679537893545748\n",
      "RMSE, train 0.3396209518090437, test 0.3321978275222008\n",
      "RMSE, train 0.31136380822778037, test 0.3112951769973292\n",
      "RMSE, train 0.2945176096300624, test 0.29717300952685\n",
      "RMSE, train 0.2834257198210742, test 0.28811006413565743\n",
      "RMSE, train 0.2757191238674383, test 0.282240740578584\n",
      "RMSE, train 0.26973806738780587, test 0.2746547893291772\n",
      "RMSE, train 0.26386714544520695, test 0.26955634355545044\n",
      "RMSE, train 0.2591814504421719, test 0.26484516007129594\n",
      "RMSE, train 0.2559987006749967, test 0.2606943446126851\n",
      "RMSE, train 0.2515664073322105, test 0.25733425024181905\n",
      "RMSE, train 0.24861773558890032, test 0.2553788414507201\n",
      "RMSE, train 0.24618220205411934, test 0.2526604863579827\n",
      "RMSE, train 0.2442190655687036, test 0.24991523369093133\n",
      "RMSE, train 0.24290696770171372, test 0.2483864396509498\n",
      "RMSE, train 0.2416359232989092, test 0.2470344253862747\n",
      "RMSE, train 0.24041529418786756, test 0.2460287685195605\n",
      "RMSE, train 0.23953216624944892, test 0.24525184673492353\n",
      "RMSE, train 0.23860634837873407, test 0.24496511859123152\n",
      "RMSE, train 0.23881405260422994, test 0.24503715953441582\n",
      "RMSE, train 0.23812963629555878, test 0.24435050168422737\n",
      "RMSE, train 0.23744369895723455, test 0.24324748732826926\n",
      "RMSE, train 0.23730647476494748, test 0.24291500118043688\n",
      "RMSE, train 0.23720240997364586, test 0.24311551662406536\n",
      "RMSE, train 0.23672360278356339, test 0.24284111399843236\n",
      "RMSE, train 0.2377184568050438, test 0.24254818862736827\n",
      "RMSE, train 0.23753283682910037, test 0.24239694981864005\n",
      "RMSE, train 0.23651493477355007, test 0.24211210727390617\n",
      "RMSE, train 0.23645560303133684, test 0.24213228465029688\n",
      "RMSE, train 0.23678717931646007, test 0.24205215200029237\n",
      "RMSE, train 0.23651827696920316, test 0.24203816530379382\n",
      "RMSE, train 0.23647913436945026, test 0.24209198287942194\n",
      "RMSE, train 0.236268183166357, test 0.24213826460669738\n",
      "RMSE, train 0.2365488240399687, test 0.24188042085881184\n",
      "RMSE, train 0.23684377452782138, test 0.24174714660403704\n",
      "RMSE, train 0.23619342094382914, test 0.24171755982167792\n",
      "RMSE, train 0.2365631445659402, test 0.2427257306949057\n",
      "RMSE, train 0.23651254925794882, test 0.24281082528107095\n",
      "RMSE, train 0.23628079461293583, test 0.24166256941930211\n",
      "RMSE, train 0.23693670853425938, test 0.2419729759596815\n",
      "RMSE, train 0.23645416029653807, test 0.24172444159936424\n",
      "RMSE, train 0.23653213749013496, test 0.242071336191712\n",
      "RMSE, train 0.2367429849498138, test 0.2416444681208543\n",
      "RMSE, train 0.23638306743941273, test 0.24233648150858253\n",
      "RMSE, train 0.23625244092751832, test 0.24170326704930778\n",
      "RMSE, train 0.23631065253232103, test 0.24227385531471232\n",
      "RMSE, train 0.23624347970071807, test 0.24174385886601726\n",
      "RMSE, train 0.23607320700997536, test 0.24188735253281063\n",
      "RMSE, train 0.23637566482306693, test 0.24164134580077548\n",
      "RMSE, train 0.23611396556597175, test 0.24158556413168858\n",
      "RMSE, train 0.23643791404140607, test 0.24199012170235315\n",
      "RMSE, train 0.23609814659890452, test 0.2423657320364557\n",
      "RMSE, train 0.23664184366432553, test 0.24202207934976827\n",
      "RMSE, train 0.23633424347507925, test 0.24175260660022196\n",
      "RMSE, train 0.23631533324572743, test 0.2418877077524108\n",
      "RMSE, train 0.2361994100083349, test 0.24233378906442662\n",
      "RMSE, train 0.23645375288276044, test 0.24166737481801195\n",
      "RMSE, train 0.23616742384608624, test 0.24205609538940467\n",
      "RMSE, train 0.23646864145629856, test 0.24172394158262195\n",
      "RMSE, train 0.23652020588626488, test 0.24181904862023362\n",
      "Early stopping at epoch 60 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 1.2101522003077279, test 1.0260337535607613\n",
      "RMSE, train 0.9160613104824192, test 0.779409357551801\n",
      "RMSE, train 0.7027798985277326, test 0.6026886469226772\n",
      "RMSE, train 0.5501326851793065, test 0.4804862548234099\n",
      "RMSE, train 0.44655121967565914, test 0.39966946474071274\n",
      "RMSE, train 0.38043488201893066, test 0.3517212054487002\n",
      "RMSE, train 0.3422367073718674, test 0.32486167865789545\n",
      "RMSE, train 0.32058045403523877, test 0.3120038799815259\n",
      "RMSE, train 0.31064933175144116, test 0.3061549475384971\n",
      "RMSE, train 0.3058641493197315, test 0.3027492363826703\n",
      "RMSE, train 0.302541419340313, test 0.30030741226875174\n",
      "RMSE, train 0.29948081002255117, test 0.2974382507599006\n",
      "RMSE, train 0.29703436157673846, test 0.2949724985381304\n",
      "RMSE, train 0.29452776585605517, test 0.29250249380277377\n",
      "RMSE, train 0.29231915724548424, test 0.29019002969992364\n",
      "RMSE, train 0.29056059005708734, test 0.2884813639319549\n",
      "RMSE, train 0.2883993917075563, test 0.28638626875008566\n",
      "RMSE, train 0.2870556076388221, test 0.2856550955418813\n",
      "RMSE, train 0.28583946265280247, test 0.283885018805326\n",
      "RMSE, train 0.28489045864971707, test 0.283107606283689\n",
      "RMSE, train 0.2838104100636214, test 0.28230422091180996\n",
      "RMSE, train 0.28303850038854544, test 0.28162382732508545\n",
      "RMSE, train 0.2825271536342122, test 0.2811284500916125\n",
      "RMSE, train 0.2822765498922383, test 0.2805243287298639\n",
      "RMSE, train 0.28177278790592164, test 0.2800061191290112\n",
      "RMSE, train 0.2816889257254926, test 0.27966827949730017\n",
      "RMSE, train 0.28153643035137454, test 0.2799745300563715\n",
      "RMSE, train 0.2813059815998412, test 0.2792154172972097\n",
      "RMSE, train 0.2811901979764138, test 0.27917424961924553\n",
      "RMSE, train 0.28136404169615636, test 0.2793746838125132\n",
      "RMSE, train 0.28082245358935565, test 0.27899528951463054\n",
      "RMSE, train 0.2812944550590574, test 0.2790542517678212\n",
      "RMSE, train 0.2805771552765172, test 0.27879260417263385\n",
      "RMSE, train 0.280807588957558, test 0.2789076383588678\n",
      "RMSE, train 0.2806493905026558, test 0.27885914215091934\n",
      "RMSE, train 0.2808299164233868, test 0.27868741435014593\n",
      "RMSE, train 0.28067590350146626, test 0.27862143466028116\n",
      "RMSE, train 0.2803989364034381, test 0.27879665791988373\n",
      "RMSE, train 0.28020984564777, test 0.27878933298890873\n",
      "RMSE, train 0.28050752348951563, test 0.2787100495928425\n",
      "RMSE, train 0.28029373780754974, test 0.27865837577540997\n",
      "RMSE, train 0.2802047177471898, test 0.278641992769504\n",
      "RMSE, train 0.2808307388043108, test 0.27857886014853495\n",
      "RMSE, train 0.2803272885416657, test 0.2787487184849836\n",
      "RMSE, train 0.2804418074290368, test 0.27855258561291935\n",
      "RMSE, train 0.28059956456018875, test 0.2784954627691689\n",
      "RMSE, train 0.2809498003907194, test 0.27886849540775105\n",
      "RMSE, train 0.2802547637434784, test 0.27835640184960125\n",
      "RMSE, train 0.2804759965732324, test 0.278480719711821\n",
      "RMSE, train 0.28057423123150815, test 0.278828595023034\n",
      "RMSE, train 0.2803763313111195, test 0.2784383746527009\n",
      "RMSE, train 0.2803565835164598, test 0.27837172478942546\n",
      "RMSE, train 0.2804633888054239, test 0.2788252009678695\n",
      "RMSE, train 0.28042604771157925, test 0.27880406973220534\n",
      "RMSE, train 0.2803595023737712, test 0.2786007447768066\n",
      "RMSE, train 0.2802300902068122, test 0.2786760139515844\n",
      "RMSE, train 0.2805419160622703, test 0.27842489491074773\n",
      "RMSE, train 0.28032516358681947, test 0.27914624699091506\n",
      "Early stopping at epoch 58 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.7753678457752154, test 0.6066785934178726\n",
      "RMSE, train 0.5476526301947369, test 0.4753565428049668\n",
      "RMSE, train 0.45628732309979236, test 0.421415682979252\n",
      "RMSE, train 0.41425849816854843, test 0.39126249486985415\n",
      "RMSE, train 0.3857742441054869, test 0.3679503578206767\n",
      "RMSE, train 0.362176940382919, test 0.34690384378899697\n",
      "RMSE, train 0.3423946977547526, test 0.32985561179078143\n",
      "RMSE, train 0.3256963498083649, test 0.3152512447989505\n",
      "RMSE, train 0.3120897761892108, test 0.30384612238925435\n",
      "RMSE, train 0.30117326035241415, test 0.2945652969505476\n",
      "RMSE, train 0.29245959755404993, test 0.2875096974165543\n",
      "RMSE, train 0.285712558056392, test 0.2823154239550881\n",
      "RMSE, train 0.2804512027057873, test 0.27804626252340237\n",
      "RMSE, train 0.27625002574389146, test 0.2748624288517496\n",
      "RMSE, train 0.2730345566403081, test 0.2722478396218756\n",
      "RMSE, train 0.2704708146251691, test 0.27024993138468784\n",
      "RMSE, train 0.26831273182498927, test 0.2688392102718353\n",
      "RMSE, train 0.2666757973168053, test 0.26694205312625224\n",
      "RMSE, train 0.26542225538608627, test 0.26638820255580153\n",
      "RMSE, train 0.26420867420938615, test 0.26589953199676847\n",
      "RMSE, train 0.26342819306817533, test 0.264854060502156\n",
      "RMSE, train 0.26271925868185714, test 0.26415337388930116\n",
      "RMSE, train 0.2622142334304544, test 0.2637758099514505\n",
      "RMSE, train 0.2618303128267043, test 0.2630133933995081\n",
      "RMSE, train 0.26144693326798213, test 0.2632618117591609\n",
      "RMSE, train 0.26119564516339333, test 0.26346887997958973\n",
      "RMSE, train 0.26089496505614806, test 0.263402967673281\n",
      "RMSE, train 0.26074505122793706, test 0.26283810391374257\n",
      "RMSE, train 0.2606254101052659, test 0.2629207509367362\n",
      "RMSE, train 0.26060922269861664, test 0.2621855305588764\n",
      "RMSE, train 0.26054863253659755, test 0.2622454347817794\n",
      "RMSE, train 0.2604107294714122, test 0.26297225077515063\n",
      "RMSE, train 0.26035544568882374, test 0.26257615555887637\n",
      "RMSE, train 0.2603739436296647, test 0.26282816626455474\n",
      "RMSE, train 0.2602453403760167, test 0.2619900338027788\n",
      "RMSE, train 0.26029659624185786, test 0.26246089689109636\n",
      "RMSE, train 0.2602651520709323, test 0.2627330095223758\n",
      "RMSE, train 0.2602074890379693, test 0.2623953958568366\n",
      "RMSE, train 0.26031288526746627, test 0.26272490827933603\n",
      "RMSE, train 0.2602392200483385, test 0.26231516625570217\n",
      "RMSE, train 0.26026200305377856, test 0.2632659838899322\n",
      "RMSE, train 0.26021200562421937, test 0.2622940099757651\n",
      "RMSE, train 0.26014923193588885, test 0.26236995361421417\n",
      "RMSE, train 0.26021210055189276, test 0.262871255758016\n",
      "RMSE, train 0.26022228859602264, test 0.26306543719509373\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.5529970422119838, test 0.37068076828204166\n",
      "RMSE, train 0.3313152226431487, test 0.3172418296063712\n",
      "RMSE, train 0.3071094404889329, test 0.3108202858802375\n",
      "RMSE, train 0.30080887912501136, test 0.3055441464306018\n",
      "RMSE, train 0.29533821290918527, test 0.3008243498999044\n",
      "RMSE, train 0.29010899406711615, test 0.2951309512788003\n",
      "RMSE, train 0.2850671540862242, test 0.2909594883612536\n",
      "RMSE, train 0.28052855787523123, test 0.28646849711006933\n",
      "RMSE, train 0.2762520410655058, test 0.2816693349442351\n",
      "RMSE, train 0.2726379115752575, test 0.2809257389755424\n",
      "RMSE, train 0.26961711612049777, test 0.27632375225561473\n",
      "RMSE, train 0.26691622018079053, test 0.27308967955615543\n",
      "RMSE, train 0.26467874161732036, test 0.2697853143882314\n",
      "RMSE, train 0.2628824731560566, test 0.2686002575749651\n",
      "RMSE, train 0.26146856347942565, test 0.26736547073366446\n",
      "RMSE, train 0.26035266174128774, test 0.26523637293128793\n",
      "RMSE, train 0.2593775921137878, test 0.2651705357733123\n",
      "RMSE, train 0.2586063749152716, test 0.26604677941821037\n",
      "RMSE, train 0.25816151404527804, test 0.2631804876781385\n",
      "RMSE, train 0.25772469161671374, test 0.26300215399866805\n",
      "RMSE, train 0.2573157913247833, test 0.26321686120755083\n",
      "RMSE, train 0.25698209326764393, test 0.2644869418592628\n",
      "RMSE, train 0.2567914328433473, test 0.26283504314925693\n",
      "RMSE, train 0.2566108018193277, test 0.26213989755429257\n",
      "RMSE, train 0.25647592736667046, test 0.2622181409542714\n",
      "RMSE, train 0.25636762911829714, test 0.26169886378520124\n",
      "RMSE, train 0.2562675539053342, test 0.2621012395675029\n",
      "RMSE, train 0.25619706549919774, test 0.2618685677784299\n",
      "RMSE, train 0.25611748188867695, test 0.26159739207237137\n",
      "RMSE, train 0.25612795952657413, test 0.26123269435462604\n",
      "RMSE, train 0.2560763549176567, test 0.2622888525691601\n",
      "RMSE, train 0.25611255570177005, test 0.26226491132460605\n",
      "RMSE, train 0.2560465754982869, test 0.26158617402708856\n",
      "RMSE, train 0.2560605169712428, test 0.26134119449405496\n",
      "RMSE, train 0.2559736283170268, test 0.2635525608554893\n",
      "RMSE, train 0.25606096348821317, test 0.26334141263174354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.25590803671310836, test 0.26168077541600676\n",
      "RMSE, train 0.25601166779083523, test 0.26245743501077007\n",
      "RMSE, train 0.25591636763158937, test 0.26262479289135804\n",
      "RMSE, train 0.25590029275337145, test 0.26296276988786293\n",
      "Early stopping at epoch 40 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9227324176692602, test 0.47004417252416414\n",
      "RMSE, train 0.38358340450007505, test 0.34464729980876047\n",
      "RMSE, train 0.3333864406202779, test 0.33205297542735934\n",
      "RMSE, train 0.32127818124688634, test 0.3226338449555139\n",
      "RMSE, train 0.31264296121368507, test 0.3161973327708741\n",
      "RMSE, train 0.30540663835526716, test 0.30873851974805194\n",
      "RMSE, train 0.29922854437521007, test 0.30340410862118006\n",
      "RMSE, train 0.293268620779719, test 0.29815215757116675\n",
      "RMSE, train 0.28774327417892037, test 0.29304076731204987\n",
      "RMSE, train 0.28255499109174265, test 0.28790273191407323\n",
      "RMSE, train 0.27797538388257076, test 0.28246670061101514\n",
      "RMSE, train 0.2736938367738868, test 0.27917086076922715\n",
      "RMSE, train 0.2699199880125246, test 0.2749559529280911\n",
      "RMSE, train 0.2667735954652531, test 0.27199949184432626\n",
      "RMSE, train 0.2639950385524167, test 0.26906804492076236\n",
      "RMSE, train 0.2619057032232634, test 0.26716712784642976\n",
      "RMSE, train 0.25984567420726473, test 0.2653386197052896\n",
      "RMSE, train 0.25843221003735306, test 0.26387533351468545\n",
      "RMSE, train 0.2571552430815769, test 0.26299046888016164\n",
      "RMSE, train 0.25597146345358907, test 0.2625783523544669\n",
      "RMSE, train 0.2551709884645963, test 0.26110543434818584\n",
      "RMSE, train 0.254536453051248, test 0.2612396107676129\n",
      "RMSE, train 0.2539245336871557, test 0.2598672304302454\n",
      "RMSE, train 0.25342574062747786, test 0.2593796656777461\n",
      "RMSE, train 0.2530819307636432, test 0.25857807726909715\n",
      "RMSE, train 0.2529115460323866, test 0.2593198268053432\n",
      "RMSE, train 0.2525904862341857, test 0.25839047056312364\n",
      "RMSE, train 0.2524332409592891, test 0.25820608988093835\n",
      "RMSE, train 0.25228714081223563, test 0.2589014033631732\n",
      "RMSE, train 0.2521832786462825, test 0.25832998791399103\n",
      "RMSE, train 0.2520180869320727, test 0.25845393848915893\n",
      "RMSE, train 0.2519861257098841, test 0.2575836624018848\n",
      "RMSE, train 0.2519029742953452, test 0.2576565927204986\n",
      "RMSE, train 0.25191481590195736, test 0.2587818444396059\n",
      "RMSE, train 0.2517760128460147, test 0.2583442614413798\n",
      "RMSE, train 0.2516776733476706, test 0.2573295008235921\n",
      "RMSE, train 0.2520221364167001, test 0.2578326648411651\n",
      "RMSE, train 0.25168472127706715, test 0.2576105630335708\n",
      "RMSE, train 0.2517676492682611, test 0.2576353296947976\n",
      "RMSE, train 0.25172778213340224, test 0.25727214803919196\n",
      "RMSE, train 0.25167841675004576, test 0.2572949539559583\n",
      "RMSE, train 0.25183773910005885, test 0.25763595771665376\n",
      "RMSE, train 0.2516456104702119, test 0.2576242243715872\n",
      "RMSE, train 0.2517199381583869, test 0.25745579476157826\n",
      "RMSE, train 0.25164848494559827, test 0.2581782336346805\n",
      "RMSE, train 0.2517740876046997, test 0.2575298435986042\n",
      "RMSE, train 0.2516282627340218, test 0.2585278859672447\n",
      "RMSE, train 0.25165049210567064, test 0.2573498566634953\n",
      "RMSE, train 0.2516772671405113, test 0.25758967564130825\n",
      "RMSE, train 0.25169408108775665, test 0.25732195819728076\n",
      "Early stopping at epoch 50 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 1.5859858834535727, test 1.4138271531888418\n",
      "RMSE, train 1.3115405951969503, test 1.1711347166981017\n",
      "RMSE, train 1.0920230103474038, test 0.9801494827760118\n",
      "RMSE, train 0.9190096636678139, test 0.8284791795802968\n",
      "RMSE, train 0.7876455361157461, test 0.7145442300076995\n",
      "RMSE, train 0.6874536686862995, test 0.6322649336819138\n",
      "RMSE, train 0.612033242331351, test 0.5697295112269265\n",
      "RMSE, train 0.5553957440754427, test 0.5250317834849868\n",
      "RMSE, train 0.5115368461037513, test 0.4894492054092033\n",
      "RMSE, train 0.47814252790802186, test 0.4606049031551395\n",
      "RMSE, train 0.44873375999122406, test 0.4368533045053482\n",
      "RMSE, train 0.4248950312437575, test 0.4174158652978284\n",
      "RMSE, train 0.40499774540301764, test 0.39920010497527464\n",
      "RMSE, train 0.3879671754530572, test 0.3849679742540632\n",
      "RMSE, train 0.37433337600402583, test 0.37219016240643604\n",
      "RMSE, train 0.362632694035314, test 0.36213455256074667\n",
      "RMSE, train 0.35259653140906416, test 0.35478589025193025\n",
      "RMSE, train 0.3450932454049977, test 0.3493384637736848\n",
      "RMSE, train 0.339796361125892, test 0.344439876531916\n",
      "RMSE, train 0.3342105416106243, test 0.3418227592483163\n",
      "RMSE, train 0.33118728640811895, test 0.33892079229865757\n",
      "RMSE, train 0.3281798109834231, test 0.3372263748730932\n",
      "RMSE, train 0.3259370695466829, test 0.33592918927648235\n",
      "RMSE, train 0.324934229449509, test 0.33216298491294893\n",
      "RMSE, train 0.32269909140331293, test 0.33177113639456884\n",
      "RMSE, train 0.32157308915082145, test 0.33022153723452774\n",
      "RMSE, train 0.3211447242363346, test 0.33001710953457014\n",
      "RMSE, train 0.3199847409408337, test 0.32890725415199995\n",
      "RMSE, train 0.3195555441909366, test 0.3281291731234108\n",
      "RMSE, train 0.31895436979586783, test 0.3285090106406382\n",
      "RMSE, train 0.31838346352244773, test 0.3278685810842684\n",
      "RMSE, train 0.31852780676939907, test 0.3271805014727371\n",
      "RMSE, train 0.3180062667119737, test 0.3268305801653436\n",
      "RMSE, train 0.31794657582551045, test 0.32616819481232334\n",
      "RMSE, train 0.31813837967666925, test 0.32532018090465237\n",
      "RMSE, train 0.317958529218869, test 0.326048111010875\n",
      "RMSE, train 0.3180117765867632, test 0.32598172194723574\n",
      "RMSE, train 0.31738976704074406, test 0.3266483855300716\n",
      "RMSE, train 0.31737242080677047, test 0.32752787401633604\n",
      "RMSE, train 0.3170585379101872, test 0.32545364195747034\n",
      "RMSE, train 0.31808585045384424, test 0.325700162909925\n",
      "RMSE, train 0.3173601051918302, test 0.32521173783711027\n",
      "RMSE, train 0.3175437263738616, test 0.32546620230589596\n",
      "RMSE, train 0.3173227213761386, test 0.3255070353459035\n",
      "RMSE, train 0.31692941811479514, test 0.3247078154236078\n",
      "RMSE, train 0.3172482183296436, test 0.32566558183836086\n",
      "RMSE, train 0.31699144038369714, test 0.32591759892446653\n",
      "RMSE, train 0.31748724805114054, test 0.3255053447293384\n",
      "RMSE, train 0.3173239126898884, test 0.32583938871643375\n",
      "RMSE, train 0.31708202868180596, test 0.32484519574791193\n",
      "RMSE, train 0.31693153071961894, test 0.32537403356816086\n",
      "RMSE, train 0.3168241366224611, test 0.3248814567923546\n",
      "RMSE, train 0.3171858546650747, test 0.32530380479459253\n",
      "RMSE, train 0.3173319973327495, test 0.3246887179889849\n",
      "RMSE, train 0.31699524365349274, test 0.32554984292281525\n",
      "RMSE, train 0.3167999109866053, test 0.32613937703094315\n",
      "RMSE, train 0.3171115801355158, test 0.3255794982292822\n",
      "RMSE, train 0.31772554070082104, test 0.32530409816120354\n",
      "RMSE, train 0.31730144521249926, test 0.3265643452427217\n",
      "RMSE, train 0.31702395056197846, test 0.32541121875068973\n",
      "RMSE, train 0.3173856991373636, test 0.32626434109572855\n",
      "RMSE, train 0.3171074988730333, test 0.325290199169623\n",
      "RMSE, train 0.3172980247629494, test 0.3256475580856204\n",
      "RMSE, train 0.31743322105059696, test 0.32494866235979963\n",
      "Early stopping at epoch 64 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.715180261854099, test 0.5558473363928839\n",
      "RMSE, train 0.48980716468908325, test 0.4218821245322534\n",
      "RMSE, train 0.398206380049744, test 0.3777666860217348\n",
      "RMSE, train 0.36582570917269575, test 0.3660679708380218\n",
      "RMSE, train 0.353292843686091, test 0.35836135951477455\n",
      "RMSE, train 0.3457409135429314, test 0.35371628157589413\n",
      "RMSE, train 0.33933671670777915, test 0.3489048155622745\n",
      "RMSE, train 0.33355086771228387, test 0.3435694617689203\n",
      "RMSE, train 0.3283249987581653, test 0.3400404483353326\n",
      "RMSE, train 0.32365061852229016, test 0.3359778515242655\n",
      "RMSE, train 0.31918710934607974, test 0.33153377992844363\n",
      "RMSE, train 0.3154475345472584, test 0.3266433373503729\n",
      "RMSE, train 0.31234540933985344, test 0.3245993132164719\n",
      "RMSE, train 0.30956920767578844, test 0.3213896311204368\n",
      "RMSE, train 0.3070948212637228, test 0.3191528049630856\n",
      "RMSE, train 0.3052016591544643, test 0.3180855839350902\n",
      "RMSE, train 0.30375918468685964, test 0.31609108312687745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.302220733109611, test 0.3155854668365706\n",
      "RMSE, train 0.3012527322622158, test 0.3139331831571159\n",
      "RMSE, train 0.3003568645616818, test 0.3138546161695358\n",
      "RMSE, train 0.299727684078997, test 0.31413918603724295\n",
      "RMSE, train 0.29921515419611483, test 0.3118146757740493\n",
      "RMSE, train 0.29885170745742695, test 0.31196794816113393\n",
      "RMSE, train 0.2984634336802457, test 0.3113023072754571\n",
      "RMSE, train 0.2982276001519152, test 0.31059188060804244\n",
      "RMSE, train 0.2979209142081406, test 0.3108388498562192\n",
      "RMSE, train 0.29782493938712795, test 0.3119289876397597\n",
      "RMSE, train 0.29775197551723553, test 0.3117802015958576\n",
      "RMSE, train 0.2974978624905706, test 0.3103654048311601\n",
      "RMSE, train 0.297438927262086, test 0.31039839108055883\n",
      "RMSE, train 0.29744070805108064, test 0.3106726773014856\n",
      "RMSE, train 0.297354072917069, test 0.30949520299194055\n",
      "RMSE, train 0.29726536047431923, test 0.31087956543362466\n",
      "RMSE, train 0.29728575872733454, test 0.3108223967185808\n",
      "RMSE, train 0.29725676347321994, test 0.31100927826461444\n",
      "RMSE, train 0.29720773594662747, test 0.31126639602381156\n",
      "RMSE, train 0.29718968856895983, test 0.310850658001156\n",
      "RMSE, train 0.297263681771643, test 0.31216154008283525\n",
      "RMSE, train 0.29726912218225376, test 0.3133858803215377\n",
      "RMSE, train 0.2971102683867574, test 0.31050604335758664\n",
      "RMSE, train 0.2972358098345487, test 0.3132475918039269\n",
      "RMSE, train 0.29714939633025184, test 0.31043400895704915\n",
      "Early stopping at epoch 42 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.7089045658672224, test 0.5334133343789184\n",
      "RMSE, train 0.486479641352017, test 0.46419641520213156\n",
      "RMSE, train 0.438575600997286, test 0.43652438423008594\n",
      "RMSE, train 0.4145922505798929, test 0.4205403974623356\n",
      "RMSE, train 0.39503672336739204, test 0.40314639135471825\n",
      "RMSE, train 0.3784472780598597, test 0.3887591337405362\n",
      "RMSE, train 0.3644945162421451, test 0.377681943542749\n",
      "RMSE, train 0.3525990076770126, test 0.3696393000269399\n",
      "RMSE, train 0.3426623327077992, test 0.35894342229782955\n",
      "RMSE, train 0.3342259765520798, test 0.34979177751008744\n",
      "RMSE, train 0.32702912754797314, test 0.3476597584277681\n",
      "RMSE, train 0.3209724093913466, test 0.34228178743019844\n",
      "RMSE, train 0.31587544780870513, test 0.3344692843920976\n",
      "RMSE, train 0.3117045483014363, test 0.33020448540020914\n",
      "RMSE, train 0.3081665090738736, test 0.32888753712177277\n",
      "RMSE, train 0.30523573750554805, test 0.32268771341124786\n",
      "RMSE, train 0.30289861375815513, test 0.3201287744693386\n",
      "RMSE, train 0.301019575986613, test 0.3203345211674866\n",
      "RMSE, train 0.2993767277432734, test 0.31897023652942436\n",
      "RMSE, train 0.2981806466280706, test 0.31419666779670613\n",
      "RMSE, train 0.29709347979897843, test 0.31527152136691566\n",
      "RMSE, train 0.296280465436095, test 0.3122319162470623\n",
      "RMSE, train 0.29556557548513324, test 0.3130876566599874\n",
      "RMSE, train 0.29516796792487915, test 0.3125932341785107\n",
      "RMSE, train 0.2946257056433911, test 0.31309036273979446\n",
      "RMSE, train 0.29428777974674086, test 0.31517751601714533\n",
      "RMSE, train 0.2939441459797624, test 0.3131266658745923\n",
      "RMSE, train 0.29383291201466905, test 0.3098261218735026\n",
      "RMSE, train 0.29369279908595913, test 0.31059682282429296\n",
      "RMSE, train 0.2934315656787426, test 0.31447852265487597\n",
      "RMSE, train 0.2932717780496332, test 0.3099177042836124\n",
      "RMSE, train 0.2932160868001947, test 0.31170757953981754\n",
      "RMSE, train 0.29328793064290726, test 0.3100515062947875\n",
      "RMSE, train 0.2931058698305042, test 0.3094552751739048\n",
      "RMSE, train 0.29303383706867553, test 0.3093167755354955\n",
      "RMSE, train 0.2931433618068695, test 0.3163618964766993\n",
      "RMSE, train 0.29314735928227387, test 0.31164393682503005\n",
      "RMSE, train 0.29302579847622373, test 0.31232872995936756\n",
      "RMSE, train 0.29291897215780904, test 0.31187433814539495\n",
      "RMSE, train 0.29300663445029856, test 0.3103107961925488\n",
      "RMSE, train 0.2929281984896105, test 0.3091189741943646\n",
      "RMSE, train 0.2930240203535755, test 0.30905416658491763\n",
      "RMSE, train 0.29288986351809987, test 0.31061220089498076\n",
      "RMSE, train 0.29298010854285006, test 0.308542328552135\n",
      "RMSE, train 0.29289620081206114, test 0.30891625778478327\n",
      "RMSE, train 0.2929438883151125, test 0.3088241861681047\n",
      "RMSE, train 0.29289252756964285, test 0.31068410832905075\n",
      "RMSE, train 0.2929326228602765, test 0.31249701195550195\n",
      "RMSE, train 0.29295675534392196, test 0.3109887032543571\n",
      "RMSE, train 0.29297884806742863, test 0.31209152531855316\n",
      "RMSE, train 0.29291638438180617, test 0.3105518180623795\n",
      "RMSE, train 0.2928545521727084, test 0.31149369767568647\n",
      "RMSE, train 0.2929399088732987, test 0.31033442075391415\n",
      "RMSE, train 0.29301393334698506, test 0.3085278099023023\n",
      "RMSE, train 0.2930292506080625, test 0.3088144806837573\n",
      "RMSE, train 0.2929282616337235, test 0.3166967291855118\n",
      "RMSE, train 0.2930014522794873, test 0.31195386578735795\n",
      "RMSE, train 0.2929524954169493, test 0.312669275599776\n",
      "RMSE, train 0.29297702230353817, test 0.3084856132859165\n",
      "RMSE, train 0.29289940978243345, test 0.31125499481715047\n",
      "RMSE, train 0.2930426291785161, test 0.30807639785038615\n",
      "RMSE, train 0.2929640891928571, test 0.3102296300015403\n",
      "RMSE, train 0.2929567455042003, test 0.31037644868336833\n",
      "RMSE, train 0.29293767003577, test 0.3096703950641225\n",
      "RMSE, train 0.2929264256761646, test 0.30937390854057756\n",
      "RMSE, train 0.2929103043717896, test 0.3129129852484731\n",
      "RMSE, train 0.29309025640442365, test 0.3110392190588331\n",
      "RMSE, train 0.2928421131717904, test 0.31641550347642994\n",
      "RMSE, train 0.292948519373025, test 0.31118517448601213\n",
      "RMSE, train 0.2928633304432282, test 0.3077034974850497\n",
      "RMSE, train 0.2929042236538794, test 0.3089909706879588\n",
      "RMSE, train 0.2928849550366685, test 0.31286027029301355\n",
      "RMSE, train 0.2928272961614534, test 0.3119628585658027\n",
      "RMSE, train 0.29300055861685453, test 0.3148672599526285\n",
      "RMSE, train 0.29288882670167504, test 0.31063413641695836\n",
      "RMSE, train 0.29289091996087596, test 0.3102963951606195\n",
      "RMSE, train 0.2929435221571254, test 0.3091902679320678\n",
      "RMSE, train 0.2929841975842972, test 0.31113977122654035\n",
      "RMSE, train 0.2929098985894559, test 0.31305752709073925\n",
      "RMSE, train 0.2930431007772613, test 0.3101927047794305\n",
      "Early stopping at epoch 80 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.7553748314110738, test 0.6467768102884293\n",
      "RMSE, train 0.6006127430422287, test 0.5394712977939182\n",
      "RMSE, train 0.5018240325454111, test 0.46192089087433286\n",
      "RMSE, train 0.4336140362239591, test 0.40787663012743\n",
      "RMSE, train 0.3884413176469726, test 0.37366625534163583\n",
      "RMSE, train 0.35936231993520357, test 0.3514987493554751\n",
      "RMSE, train 0.34055205946662676, test 0.33725691354937026\n",
      "RMSE, train 0.3279593398548522, test 0.3276276441084014\n",
      "RMSE, train 0.319386842959332, test 0.32035473618242477\n",
      "RMSE, train 0.3131584941216235, test 0.31522338622146184\n",
      "RMSE, train 0.307992841877706, test 0.31160944054524103\n",
      "RMSE, train 0.3039909364439728, test 0.31036704497204887\n",
      "RMSE, train 0.30057124803570723, test 0.3060086339712143\n",
      "RMSE, train 0.29759468977663395, test 0.30362826138734816\n",
      "RMSE, train 0.2950737578367609, test 0.3009749091333813\n",
      "RMSE, train 0.2929575642083854, test 0.2999757225314776\n",
      "RMSE, train 0.2913420170224259, test 0.2999491607149442\n",
      "RMSE, train 0.2897082483872892, test 0.29877869470251933\n",
      "RMSE, train 0.28833904633464197, test 0.2968236949708727\n",
      "RMSE, train 0.2872937684753192, test 0.29725768433676825\n",
      "RMSE, train 0.2864848695434329, test 0.2959183265765508\n",
      "RMSE, train 0.2858911137576052, test 0.29629446930355496\n",
      "RMSE, train 0.28520167339844205, test 0.29609311670064925\n",
      "RMSE, train 0.28466364520418674, test 0.2967913231915898\n",
      "RMSE, train 0.28423863942571725, test 0.2983128526144557\n",
      "RMSE, train 0.284033965409766, test 0.29588592449824014\n",
      "RMSE, train 0.2835660356516144, test 0.29522958348194756\n",
      "RMSE, train 0.2834379714976424, test 0.29541580544577706\n",
      "RMSE, train 0.28326097154874363, test 0.29597043328815037\n",
      "RMSE, train 0.2830728874855607, test 0.2966221364008056\n",
      "RMSE, train 0.2828723691464113, test 0.2970218633611997\n",
      "RMSE, train 0.28280960417018747, test 0.29557445728116566\n",
      "RMSE, train 0.2827345296700367, test 0.29628085030449763\n",
      "RMSE, train 0.28266866671830176, test 0.2968144029378891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2825829658828013, test 0.29503176245424484\n",
      "RMSE, train 0.28259010757558106, test 0.29655589676565597\n",
      "RMSE, train 0.28258466383196273, test 0.2957611789306005\n",
      "RMSE, train 0.2824273264874024, test 0.29659577475653753\n",
      "RMSE, train 0.28240948132266896, test 0.29618440253867045\n",
      "RMSE, train 0.2823671348935189, test 0.2964678434862031\n",
      "RMSE, train 0.2824811639811472, test 0.29700881474547913\n",
      "RMSE, train 0.2823489287069866, test 0.29652443445391125\n",
      "RMSE, train 0.2824382553243573, test 0.2975229195422596\n",
      "RMSE, train 0.2823793210109289, test 0.2969665578669972\n",
      "RMSE, train 0.28229423726826025, test 0.29682933787504834\n",
      "Early stopping at epoch 45 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 1.1858947310587595, test 1.0627520692468895\n",
      "RMSE, train 1.005286288946357, test 0.9048201664529666\n",
      "RMSE, train 0.8686138320085763, test 0.7863190785200909\n",
      "RMSE, train 0.7633267995926454, test 0.6969618652806138\n",
      "RMSE, train 0.6819250016020096, test 0.6310345491375586\n",
      "RMSE, train 0.6226122102410986, test 0.583304307677529\n",
      "RMSE, train 0.5767275587926576, test 0.5492638566277244\n",
      "RMSE, train 0.5448813231475196, test 0.5257391884471431\n",
      "RMSE, train 0.519076951303517, test 0.5092114607493082\n",
      "RMSE, train 0.5013379511448457, test 0.49742775688869784\n",
      "RMSE, train 0.48774448179236835, test 0.48854731459810274\n",
      "RMSE, train 0.475496646390276, test 0.48160259290175006\n",
      "RMSE, train 0.466323829440441, test 0.47585240021498515\n",
      "RMSE, train 0.45888880791465925, test 0.4711095922523075\n",
      "RMSE, train 0.45275532299411325, test 0.46732374438733765\n",
      "RMSE, train 0.4481986571276392, test 0.46414013523044007\n",
      "RMSE, train 0.442690297487604, test 0.46136456968808415\n",
      "RMSE, train 0.43894084351715656, test 0.459396400234916\n",
      "RMSE, train 0.4362035583167321, test 0.45780743553180886\n",
      "RMSE, train 0.43359765971493897, test 0.45654780650981747\n",
      "RMSE, train 0.4314628201912551, test 0.45524830815165934\n",
      "RMSE, train 0.42999967674025696, test 0.4541331293305965\n",
      "RMSE, train 0.42833678063670116, test 0.4533538177157893\n",
      "RMSE, train 0.4265759230242965, test 0.45270686875088045\n",
      "RMSE, train 0.426555304881413, test 0.45226956061040513\n",
      "RMSE, train 0.4248689947545091, test 0.4519092190747309\n",
      "RMSE, train 0.4242540879543953, test 0.4513843839216714\n",
      "RMSE, train 0.42446654116903365, test 0.4508899486426151\n",
      "RMSE, train 0.42328114742026063, test 0.45087293979495463\n",
      "RMSE, train 0.4231916580777296, test 0.4507847827191305\n",
      "RMSE, train 0.4236294917926229, test 0.45051653848754036\n",
      "RMSE, train 0.4223127973910357, test 0.4503849233039702\n",
      "RMSE, train 0.42199253802777503, test 0.4502325529100919\n",
      "RMSE, train 0.4217671718093177, test 0.45003751973913175\n",
      "RMSE, train 0.4218607522674761, test 0.45006473573169326\n",
      "RMSE, train 0.42126363818249085, test 0.450181577241782\n",
      "RMSE, train 0.42184187100248405, test 0.4499176534438374\n",
      "RMSE, train 0.42131063360311, test 0.44996336268054116\n",
      "RMSE, train 0.42086676459003486, test 0.4501969659268254\n",
      "RMSE, train 0.42160353487161667, test 0.44995372599423533\n",
      "RMSE, train 0.42089466032888606, test 0.4499587574691484\n",
      "RMSE, train 0.4209382761005667, test 0.4501316774674136\n",
      "RMSE, train 0.4218739302132124, test 0.4500077318663549\n",
      "RMSE, train 0.4211134330931969, test 0.44993962753902783\n",
      "RMSE, train 0.4215263747644308, test 0.4499749207135403\n",
      "RMSE, train 0.4207925557871611, test 0.4501264989376068\n",
      "RMSE, train 0.420719618027834, test 0.44996782309479183\n",
      "Early stopping at epoch 47 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7556640224324332, test 0.680578521763285\n",
      "RMSE, train 0.6736465905501385, test 0.6329038413241506\n",
      "RMSE, train 0.6291487780258511, test 0.6013913756857315\n",
      "RMSE, train 0.5953368051636099, test 0.5733241755515337\n",
      "RMSE, train 0.565616587082846, test 0.54941452263544\n",
      "RMSE, train 0.5396311495716524, test 0.5277234232053161\n",
      "RMSE, train 0.5168048713845436, test 0.5098749666164318\n",
      "RMSE, train 0.4968761665878272, test 0.4938357256663342\n",
      "RMSE, train 0.47950981542317556, test 0.4814068867514531\n",
      "RMSE, train 0.46486936174709387, test 0.46964348045488197\n",
      "RMSE, train 0.45244786402944365, test 0.46111245763798553\n",
      "RMSE, train 0.44215581697797535, test 0.4543043238421281\n",
      "RMSE, train 0.4334171062918625, test 0.44945780948425335\n",
      "RMSE, train 0.42649526122694065, test 0.445169974428912\n",
      "RMSE, train 0.4210188733131597, test 0.4419481122555832\n",
      "RMSE, train 0.4164642071859403, test 0.44102241455887753\n",
      "RMSE, train 0.41318786795241663, test 0.4391468426523109\n",
      "RMSE, train 0.4105092037582036, test 0.4391910115567346\n",
      "RMSE, train 0.4085512785899519, test 0.4383075109993418\n",
      "RMSE, train 0.4072892924375606, test 0.43785640473167103\n",
      "RMSE, train 0.4061272871313673, test 0.4376906535277764\n",
      "RMSE, train 0.4053778987415511, test 0.4385212594643235\n",
      "RMSE, train 0.4046833522693075, test 0.437992827501148\n",
      "RMSE, train 0.4042754854367237, test 0.43894666417812306\n",
      "RMSE, train 0.40415674624870523, test 0.43857770940909785\n",
      "RMSE, train 0.4039530785321587, test 0.4386884883667032\n",
      "RMSE, train 0.4035550440576943, test 0.43808051276331145\n",
      "RMSE, train 0.40345262984434765, test 0.4385678151932855\n",
      "RMSE, train 0.40320023311057474, test 0.43814345356076956\n",
      "RMSE, train 0.40313255542305987, test 0.43889090170462924\n",
      "RMSE, train 0.40308955548839137, test 0.43928738419587415\n",
      "Early stopping at epoch 31 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.7089349148729741, test 0.659953107105361\n",
      "RMSE, train 0.6460008107105677, test 0.6234535968965954\n",
      "RMSE, train 0.6068802972366868, test 0.5928966525528166\n",
      "RMSE, train 0.573428305814851, test 0.565230463941892\n",
      "RMSE, train 0.5448473568634203, test 0.541899327105946\n",
      "RMSE, train 0.5200304242398218, test 0.5254528461231126\n",
      "RMSE, train 0.49926279131774953, test 0.5040918240944544\n",
      "RMSE, train 0.48168236772326445, test 0.4912347957491875\n",
      "RMSE, train 0.4667823194573832, test 0.4826374178131421\n",
      "RMSE, train 0.4543645836995297, test 0.47060185273488364\n",
      "RMSE, train 0.44405401319345694, test 0.46423236893283\n",
      "RMSE, train 0.4355581333293426, test 0.4606383724345101\n",
      "RMSE, train 0.4285021351193482, test 0.4552018695407444\n",
      "RMSE, train 0.4229451808727013, test 0.4510163325402472\n",
      "RMSE, train 0.4181545651505257, test 0.4481282613343663\n",
      "RMSE, train 0.4145475843283687, test 0.44539145247803796\n",
      "RMSE, train 0.4116666979706191, test 0.4449854494796859\n",
      "RMSE, train 0.4095204496640722, test 0.444764506816864\n",
      "RMSE, train 0.40789582574303257, test 0.44584038025803036\n",
      "RMSE, train 0.4064333462972204, test 0.44487779868973626\n",
      "RMSE, train 0.40526767657452195, test 0.44232380439837776\n",
      "RMSE, train 0.4044502473905723, test 0.4428506698873308\n",
      "RMSE, train 0.40378482386750997, test 0.44620941595898733\n",
      "RMSE, train 0.4033080291635585, test 0.4436237378252877\n",
      "RMSE, train 0.4029390253628682, test 0.4438093650672171\n",
      "RMSE, train 0.4025401659410276, test 0.44370195849074257\n",
      "RMSE, train 0.40235936284225904, test 0.4419530121816529\n",
      "RMSE, train 0.40193632313344035, test 0.44302232679393555\n",
      "RMSE, train 0.4018642946555608, test 0.4431304974688424\n",
      "RMSE, train 0.40166886331578794, test 0.44430858774317633\n",
      "RMSE, train 0.4015880839201318, test 0.4431240752339363\n",
      "RMSE, train 0.4014006192793422, test 0.4428192272782326\n",
      "RMSE, train 0.40137936809474245, test 0.44253420482079187\n",
      "RMSE, train 0.4012511662958125, test 0.4411273699667719\n",
      "RMSE, train 0.40135601178976404, test 0.4419165442387263\n",
      "RMSE, train 0.4011188842697606, test 0.4434659252564112\n",
      "RMSE, train 0.4011519678198102, test 0.4445462074544695\n",
      "RMSE, train 0.4011530482142441, test 0.4421596462527911\n",
      "RMSE, train 0.40105856693979863, test 0.4436617765161726\n",
      "RMSE, train 0.4010225280195555, test 0.44252077440420784\n",
      "RMSE, train 0.4010875414645254, test 0.4451587175329526\n",
      "RMSE, train 0.40107501043142335, test 0.4448215264413092\n",
      "RMSE, train 0.40111269904275465, test 0.4425701936086019\n",
      "RMSE, train 0.40112355720964726, test 0.4419347910417451\n",
      "Early stopping at epoch 44 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 1.0382541169258663, test 0.9273230644563834\n",
      "RMSE, train 0.90993566035853, test 0.8270568221043317\n",
      "RMSE, train 0.8081769288700318, test 0.7435419651178213\n",
      "RMSE, train 0.7254955967267355, test 0.6727882727789574\n",
      "RMSE, train 0.6578765814178087, test 0.6326459714999566\n",
      "RMSE, train 0.6040610576344427, test 0.5794142446456811\n",
      "RMSE, train 0.5615683428223631, test 0.5549844255050024\n",
      "RMSE, train 0.5278110291077712, test 0.531552432057185\n",
      "RMSE, train 0.500898465514183, test 0.51572130047358\n",
      "RMSE, train 0.4802989738288327, test 0.48122196453504074\n",
      "RMSE, train 0.46396971231680423, test 0.4677071067958306\n",
      "RMSE, train 0.45123597450345476, test 0.4569223486842253\n",
      "RMSE, train 0.44043551492171124, test 0.4616224213670462\n",
      "RMSE, train 0.43227824118464164, test 0.4535851726929347\n",
      "RMSE, train 0.4254752428175133, test 0.4435566822305704\n",
      "RMSE, train 0.419657638975393, test 0.4345650762701646\n",
      "RMSE, train 0.41495106998262377, test 0.4450227858928534\n",
      "RMSE, train 0.4108131696409154, test 0.430750473569601\n",
      "RMSE, train 0.4076702430890728, test 0.4327569829347806\n",
      "RMSE, train 0.4044789443042048, test 0.4250540400926883\n",
      "RMSE, train 0.40166642946246256, test 0.4228571117975009\n",
      "RMSE, train 0.3994494457482549, test 0.43193247742377794\n",
      "RMSE, train 0.397382593322023, test 0.4221689114585901\n",
      "RMSE, train 0.39555372163142744, test 0.42091212865824884\n",
      "RMSE, train 0.39412838619817453, test 0.4213177420389958\n",
      "RMSE, train 0.39256447576845177, test 0.4200703610594456\n",
      "RMSE, train 0.39152013150702386, test 0.4238514584990648\n",
      "RMSE, train 0.3904656855580963, test 0.4180573721249134\n",
      "RMSE, train 0.38921243722936444, test 0.4197878011335165\n",
      "RMSE, train 0.38868042515631407, test 0.41607017182291317\n",
      "RMSE, train 0.3879579555394122, test 0.41886369253580386\n",
      "RMSE, train 0.3872361738826627, test 0.4237880022862019\n",
      "RMSE, train 0.3868638504517041, test 0.41554491432049334\n",
      "RMSE, train 0.3864296350245164, test 0.419806220019475\n",
      "RMSE, train 0.3859921047620684, test 0.4261915060954216\n",
      "RMSE, train 0.38575446039345407, test 0.4237357313052202\n",
      "RMSE, train 0.3852367802665241, test 0.4314413607502595\n",
      "RMSE, train 0.3850478737432266, test 0.43476104736328125\n",
      "RMSE, train 0.38479726480732085, test 0.4198979318906099\n",
      "RMSE, train 0.3847092626343635, test 0.4157848560657257\n",
      "RMSE, train 0.3845294001874894, test 0.4148167497836627\n",
      "RMSE, train 0.3842513760395139, test 0.41520401276648045\n",
      "RMSE, train 0.3841609293333838, test 0.41781208855219376\n",
      "RMSE, train 0.38418377569159984, test 0.4245968611958699\n",
      "RMSE, train 0.3842099414807614, test 0.4177039838754214\n",
      "RMSE, train 0.3841859951290386, test 0.41668094436709696\n",
      "RMSE, train 0.3838569133359695, test 0.4204798336976614\n",
      "RMSE, train 0.3840246501370011, test 0.4195037776461014\n",
      "RMSE, train 0.38371494797717004, test 0.42344088298388016\n",
      "RMSE, train 0.38358515436032853, test 0.4200805102785428\n",
      "RMSE, train 0.3836826917445548, test 0.4180485216470865\n",
      "Early stopping at epoch 51 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_model(config, 1000, model_fnc = ml_models.Baseline, data_dir = 'data_synthetic', only_one = True)\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/baseline/'+'output_size' + str(output) + 'input_size' + str(inputs) + '_singlevar.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960e763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
