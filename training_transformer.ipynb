{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8559c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml_models\n",
    "import data_pipeline2 as dp \n",
    "import numpy as np\n",
    "from training_models import train_transformer\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ad117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'input_size' : 30,\n",
    "    'lr' : 1e-4,\n",
    "    'batch_size' : 32,\n",
    "    'hidden_size' : 8,\n",
    "    'output_size' : 3,\n",
    "    'layer_amt' : 3\n",
    "    }\n",
    "\n",
    "output_sizes = [1,5,10,20,40]\n",
    "input_sizes = [5,10,20,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0825c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.7976528884982874, test 1.1920749497029088\n",
      "RMSE, train 0.3139755380130097, test 1.1753682090390114\n",
      "RMSE, train 0.2062058546414724, test 1.1341165184013304\n",
      "RMSE, train 0.15294457846891737, test 1.0787519738078117\n",
      "RMSE, train 0.11751392460152095, test 1.0498504850172228\n",
      "RMSE, train 0.09434049429276244, test 1.0285613188339817\n",
      "RMSE, train 0.07864377798564114, test 1.0046975490066312\n",
      "RMSE, train 0.06505317863798424, test 1.0066914394978554\n",
      "RMSE, train 0.0553938643712359, test 1.0026563144018572\n",
      "RMSE, train 0.048570724763712395, test 0.9960838258266449\n",
      "RMSE, train 0.04225946801968596, test 0.989909109569365\n",
      "RMSE, train 0.03699724131959524, test 0.9930147571909812\n",
      "RMSE, train 0.03302093671465462, test 0.987160314956019\n",
      "RMSE, train 0.029184597492836445, test 0.9891310884587227\n",
      "RMSE, train 0.025937194854992886, test 0.9928803477556475\n",
      "RMSE, train 0.023121674626093845, test 0.9863461621346012\n",
      "RMSE, train 0.02105355635745517, test 0.9855858510540377\n",
      "RMSE, train 0.0188472108720349, test 0.988017841933235\n",
      "RMSE, train 0.016921544059183405, test 0.9779857945057654\n",
      "RMSE, train 0.015327584176975866, test 0.9821023743960166\n",
      "RMSE, train 0.014105898763877689, test 0.978858633868156\n",
      "RMSE, train 0.01278645815484211, test 0.9810356372787107\n",
      "RMSE, train 0.01183966557603889, test 0.983045210280726\n",
      "RMSE, train 0.010815049169618238, test 0.9817405516101468\n",
      "RMSE, train 0.009854444380382098, test 0.9787689423368823\n",
      "RMSE, train 0.00940114624426505, test 0.9811305134527145\n",
      "RMSE, train 0.00840144875834847, test 0.9923881085649613\n",
      "RMSE, train 0.007621138367209245, test 0.9802892434020196\n",
      "RMSE, train 0.007043292536584315, test 0.9863425704740709\n",
      "Early stopping at epoch 29 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.9177452030512485, test 1.4380353590673651\n",
      "RMSE, train 0.302349523071818, test 1.3057256158718393\n",
      "RMSE, train 0.22037728883416546, test 1.16588402336294\n",
      "RMSE, train 0.17396560662731467, test 1.124088364938074\n",
      "RMSE, train 0.1418102811418685, test 1.0824790162242148\n",
      "RMSE, train 0.11559293464369137, test 1.0620862664270008\n",
      "RMSE, train 0.10142743523017718, test 1.04374729749585\n",
      "RMSE, train 0.08542937907929483, test 1.0352594970671598\n",
      "RMSE, train 0.07440380571100876, test 1.0235340297222137\n",
      "RMSE, train 0.06542363562640029, test 1.0197593446605462\n",
      "RMSE, train 0.05876729247887969, test 1.0130300642537677\n",
      "RMSE, train 0.051691301958823974, test 1.000490805334296\n",
      "RMSE, train 0.04712631712528134, test 1.0160181684927507\n",
      "RMSE, train 0.04263153403190526, test 1.006245669747187\n",
      "RMSE, train 0.038170272145073424, test 1.0080676398986628\n",
      "RMSE, train 0.036379723230882094, test 1.0017009490777637\n",
      "RMSE, train 0.032567680694600226, test 1.0010960693201743\n",
      "RMSE, train 0.0310805901613554, test 1.0044153248968204\n",
      "RMSE, train 0.027491088245848293, test 1.0025174004479873\n",
      "RMSE, train 0.025710347551580987, test 0.9981233391387403\n",
      "RMSE, train 0.024081517387980873, test 0.9944829837349821\n",
      "RMSE, train 0.022723377325010265, test 0.9968267496952341\n",
      "RMSE, train 0.020581321634337124, test 0.9938959272439815\n",
      "RMSE, train 0.019220400123709912, test 0.9913294081352959\n",
      "RMSE, train 0.018871626956199827, test 0.9968500851599638\n",
      "RMSE, train 0.017199841771003328, test 0.9827454922613034\n",
      "RMSE, train 0.016231666361490784, test 0.9961785693799169\n",
      "RMSE, train 0.014992719945056658, test 0.9891373559463122\n",
      "RMSE, train 0.013865656973530165, test 0.9822055071838631\n",
      "RMSE, train 0.013778720055763357, test 0.9877716371835756\n",
      "RMSE, train 0.013240856340019267, test 0.9864712305798018\n",
      "RMSE, train 0.012717391018329664, test 0.9911296717391527\n",
      "RMSE, train 0.011963403153116343, test 0.9887654761637538\n",
      "RMSE, train 0.011516833801844312, test 0.986833237912044\n",
      "RMSE, train 0.010760072906226341, test 0.9822200682045015\n",
      "RMSE, train 0.010456507342588534, test 0.9860178448937156\n",
      "RMSE, train 0.01002774510753194, test 0.9832057524318537\n",
      "RMSE, train 0.009287350952930689, test 0.9795216595338396\n",
      "RMSE, train 0.009338196631905582, test 0.988693328435756\n",
      "RMSE, train 0.008541201421828858, test 0.9887146471945707\n",
      "RMSE, train 0.008531883930191698, test 0.9872899533303316\n",
      "RMSE, train 0.00784096849595879, test 0.9831595539061491\n",
      "RMSE, train 0.007493387404848117, test 0.9817999164181307\n",
      "RMSE, train 0.007552049145845297, test 0.990703360600905\n",
      "RMSE, train 0.007094906099133103, test 0.9768030574499083\n",
      "RMSE, train 0.0068573827851989766, test 0.9870232117077535\n",
      "RMSE, train 0.006627015340583105, test 0.9754826818123337\n",
      "RMSE, train 0.0064036925177199215, test 0.9754800661043688\n",
      "RMSE, train 0.006276059994259133, test 0.9856612972976747\n",
      "RMSE, train 0.006062162666994445, test 0.983656864520932\n",
      "RMSE, train 0.005814309793275589, test 0.9872746462664328\n",
      "RMSE, train 0.0054241948523502115, test 0.9789191257855123\n",
      "RMSE, train 0.0053969156371734975, test 0.9775651737678149\n",
      "RMSE, train 0.005406424176251433, test 0.9767984866110746\n",
      "RMSE, train 0.005137855629860857, test 0.9846854160639865\n",
      "RMSE, train 0.005091387730210582, test 0.982517274943265\n",
      "RMSE, train 0.004923418127490501, test 0.9864603295799129\n",
      "RMSE, train 0.004507166628541071, test 0.9824383180003521\n",
      "Early stopping at epoch 58 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.988699645312356, test 1.3102362166371262\n",
      "RMSE, train 0.3592594124710382, test 1.322446810048923\n",
      "RMSE, train 0.22622847318776382, test 1.1789684828959013\n",
      "RMSE, train 0.17906462404328877, test 1.1243203904545098\n",
      "RMSE, train 0.14773174537333852, test 1.0609480011881443\n",
      "RMSE, train 0.1282181982387866, test 1.036610470790612\n",
      "RMSE, train 0.11215425950727229, test 1.0393152631688536\n",
      "RMSE, train 0.09944004946743756, test 1.0241805505857133\n",
      "RMSE, train 0.09249266155207081, test 1.0079724025308041\n",
      "RMSE, train 0.08068297169546583, test 1.0195692228643518\n",
      "RMSE, train 0.07477161884784445, test 1.0094039168274194\n",
      "RMSE, train 0.06995078311688992, test 1.012228465132546\n",
      "RMSE, train 0.06559887927954894, test 1.0060496853108991\n",
      "RMSE, train 0.06150046352352669, test 1.0032211631013637\n",
      "RMSE, train 0.05738354165321474, test 1.0080685819450177\n",
      "RMSE, train 0.05265575040902283, test 1.0003990920489294\n",
      "RMSE, train 0.050059971723284545, test 1.0044836699962616\n",
      "RMSE, train 0.04716825701081867, test 1.006491952820828\n",
      "RMSE, train 0.043819427196341534, test 1.0040620918336667\n",
      "RMSE, train 0.04122705950038329, test 1.0089603923914725\n",
      "RMSE, train 0.03936925451797463, test 1.006859510614161\n",
      "RMSE, train 0.03606344253094847, test 1.0168653904345997\n",
      "RMSE, train 0.033977370482803915, test 1.0024869729552353\n",
      "RMSE, train 0.03204043835862232, test 1.0134894641345007\n",
      "RMSE, train 0.02961210433894129, test 1.0105274309191787\n",
      "RMSE, train 0.028559920689794047, test 0.9993358395601574\n",
      "RMSE, train 0.026698173522186685, test 1.0162515713457476\n",
      "RMSE, train 0.025865530164272926, test 1.0036420579019345\n",
      "RMSE, train 0.02448574819369738, test 1.0071175563753696\n",
      "RMSE, train 0.023062645525200917, test 1.0052574998454045\n",
      "RMSE, train 0.021187925012285776, test 0.9992015730393561\n",
      "RMSE, train 0.02066816246287941, test 0.9965429039377915\n",
      "RMSE, train 0.019178242360088808, test 1.0010976712954671\n",
      "RMSE, train 0.01780545844464128, test 1.0008591711521149\n",
      "RMSE, train 0.01708595623383358, test 0.9951414295978713\n",
      "RMSE, train 0.01636571287195375, test 1.0061884166901571\n",
      "RMSE, train 0.015209495345118649, test 1.007596310816313\n",
      "RMSE, train 0.01491322410580859, test 1.0002575127179163\n",
      "RMSE, train 0.014064361620297247, test 0.9981246716097781\n",
      "RMSE, train 0.013585296842748168, test 1.0000515687361098\n",
      "RMSE, train 0.012973419068925289, test 0.9951730804485187\n",
      "RMSE, train 0.011998854366057654, test 0.9910232077042261\n",
      "RMSE, train 0.011941765919069586, test 0.9979719425502577\n",
      "RMSE, train 0.01136634467558852, test 0.9890768763266111\n",
      "RMSE, train 0.010965876678413929, test 1.0003782638855148\n",
      "RMSE, train 0.01018298178392925, test 0.9940797945386485\n",
      "RMSE, train 0.00977942060732813, test 0.996817666187621\n",
      "RMSE, train 0.00955742131273296, test 1.0009965585512028\n",
      "RMSE, train 0.009076897661561079, test 0.9926409716146034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.008966654409537278, test 0.998641371204142\n",
      "RMSE, train 0.00870874911389832, test 0.9947863451221532\n",
      "RMSE, train 0.008690302051218556, test 0.9913282457150911\n",
      "RMSE, train 0.008168350114846535, test 0.9890665542661098\n",
      "RMSE, train 0.008031511252352805, test 0.9939960340658823\n",
      "RMSE, train 0.007852239653404588, test 0.9987888893014506\n",
      "RMSE, train 0.007348828580675286, test 0.989896087270034\n",
      "RMSE, train 0.007075704616317744, test 0.9948125031956455\n",
      "RMSE, train 0.006910587030240515, test 0.9939496807361904\n",
      "RMSE, train 0.006799697824098519, test 0.9939658186937633\n",
      "RMSE, train 0.006553168220421684, test 0.9848440922143167\n",
      "RMSE, train 0.006270095532231811, test 0.9911161352667892\n",
      "RMSE, train 0.005943772530725309, test 0.9908674913540221\n",
      "RMSE, train 0.0058910457011776916, test 0.9873569683547605\n",
      "RMSE, train 0.005697044145280142, test 0.9926725712261701\n",
      "RMSE, train 0.005474326764988, test 0.9902085384778809\n",
      "RMSE, train 0.005211525667421043, test 0.9926831635989641\n",
      "RMSE, train 0.005163464678336244, test 0.9877713139642749\n",
      "RMSE, train 0.005237168048881789, test 0.9982688766822481\n",
      "RMSE, train 0.004676531458438348, test 0.9941532483749222\n",
      "RMSE, train 0.004603145205215224, test 0.9875204150091138\n",
      "Early stopping at epoch 70 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 1, 'layer_amt': 3}\n",
      "RMSE, train 0.5821655915787795, test 1.198067650491116\n",
      "RMSE, train 0.28014788362319826, test 1.1410530893241657\n",
      "RMSE, train 0.19103357403901425, test 1.121829739972657\n",
      "RMSE, train 0.13621166754771816, test 1.06791024406751\n",
      "RMSE, train 0.10674931618400577, test 1.0302863962510054\n",
      "RMSE, train 0.08510697419201702, test 1.0425464195363663\n",
      "RMSE, train 0.0706517666284893, test 1.0429789821306865\n",
      "RMSE, train 0.05990908327367966, test 1.0075879307354199\n",
      "RMSE, train 0.05237726942327114, test 0.9970550420237523\n",
      "RMSE, train 0.046656807324446756, test 1.015319218822554\n",
      "RMSE, train 0.0411787690630356, test 1.0136351906785779\n",
      "RMSE, train 0.03620102069382878, test 1.0066702547026616\n",
      "RMSE, train 0.033936834013920836, test 0.9934485981277391\n",
      "RMSE, train 0.030578318829948267, test 0.9984054670614355\n",
      "RMSE, train 0.028351389809660524, test 0.999240860635159\n",
      "RMSE, train 0.026902930736586204, test 1.0060587203970142\n",
      "RMSE, train 0.02324765681807032, test 1.0055346068213968\n",
      "RMSE, train 0.021983956498025, test 1.012553659139895\n",
      "RMSE, train 0.020025086822543905, test 1.0014390063052083\n",
      "RMSE, train 0.019186184832688448, test 0.9989890836033166\n",
      "RMSE, train 0.017790276323820783, test 1.0049175614235448\n",
      "RMSE, train 0.016856643456858993, test 0.9954847710974076\n",
      "RMSE, train 0.016140858169316107, test 1.000080998621735\n",
      "Early stopping at epoch 23 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.8833343938834244, test 1.1029714794198344\n",
      "RMSE, train 0.4840669761742315, test 1.1174607577402729\n",
      "RMSE, train 0.3688651847562963, test 1.076060100035234\n",
      "RMSE, train 0.3060492287059465, test 1.057794892590893\n",
      "RMSE, train 0.259871807490145, test 1.0053127989296085\n",
      "RMSE, train 0.22570517067346843, test 0.9879140011535203\n",
      "RMSE, train 0.20356993088799138, test 0.979544044033555\n",
      "RMSE, train 0.1877721426257443, test 0.9787698944738089\n",
      "RMSE, train 0.1776493224615772, test 0.9783118879499514\n",
      "RMSE, train 0.16692632520871778, test 0.9705047538457823\n",
      "RMSE, train 0.15836056356408423, test 0.9670577591115778\n",
      "RMSE, train 0.1523943425967328, test 0.9664022060465222\n",
      "RMSE, train 0.14577812189236283, test 0.9707431404058599\n",
      "RMSE, train 0.1405785976638717, test 0.9615415181995424\n",
      "RMSE, train 0.13541540212088055, test 0.961167243886585\n",
      "RMSE, train 0.1306286861429051, test 0.967640673818667\n",
      "RMSE, train 0.1262573041021824, test 0.9650490934198553\n",
      "RMSE, train 0.12263303891485257, test 0.9631825611611043\n",
      "RMSE, train 0.11722286030529969, test 0.9743765395534926\n",
      "RMSE, train 0.11203583798581554, test 0.9646283048243562\n",
      "RMSE, train 0.10692212161337657, test 0.9695485643118866\n",
      "RMSE, train 0.10073066716112437, test 0.97732858766209\n",
      "RMSE, train 0.0944979559149473, test 0.9812697812545398\n",
      "RMSE, train 0.08784409137743135, test 0.9807837359176195\n",
      "RMSE, train 0.08342455817957319, test 0.9815995136568368\n",
      "Early stopping at epoch 25 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.966428233325974, test 1.0617334807323198\n",
      "RMSE, train 0.5636381373609886, test 1.1538695561683785\n",
      "RMSE, train 0.42465791540328135, test 1.1266818314285603\n",
      "RMSE, train 0.3564632830540996, test 1.0673538012019659\n",
      "RMSE, train 0.3065779884307345, test 1.0238325136192774\n",
      "RMSE, train 0.2738121715335807, test 0.9947667142092171\n",
      "RMSE, train 0.2507821637367414, test 0.9967070787639941\n",
      "RMSE, train 0.23327178849784796, test 0.9972725641929497\n",
      "RMSE, train 0.21838196323922843, test 0.9963285326957703\n",
      "RMSE, train 0.2043106859811574, test 0.9989422049562809\n",
      "RMSE, train 0.19286469859648342, test 0.9984906189522501\n",
      "RMSE, train 0.18276381986754492, test 0.9988142928834689\n",
      "RMSE, train 0.17560181478885087, test 0.99765637466463\n",
      "RMSE, train 0.16799268389721056, test 0.99694694502879\n",
      "RMSE, train 0.1620100181826875, test 1.0041423788515187\n",
      "RMSE, train 0.15460172934411479, test 1.0026206449937012\n",
      "Early stopping at epoch 16 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.845218626372435, test 1.1283343413046427\n",
      "RMSE, train 0.48551402619201894, test 1.1149623739932264\n",
      "RMSE, train 0.3793067043253539, test 1.127147368554558\n",
      "RMSE, train 0.319957264628026, test 1.086302218160459\n",
      "RMSE, train 0.27891359054574777, test 1.0509737229772977\n",
      "RMSE, train 0.2469998814311682, test 1.030429720878601\n",
      "RMSE, train 0.2251692439605987, test 1.0290061884692736\n",
      "RMSE, train 0.20846330470249283, test 1.0199044522430216\n",
      "RMSE, train 0.1948394458213403, test 1.019183347267764\n",
      "RMSE, train 0.18410548217156353, test 1.025538008660078\n",
      "RMSE, train 0.17744631368934718, test 1.021561452852828\n",
      "RMSE, train 0.16992810944781064, test 1.0018524155020714\n",
      "RMSE, train 0.16429363559598756, test 1.0055984487490994\n",
      "RMSE, train 0.1590661876439269, test 1.0115224436989851\n",
      "RMSE, train 0.15486953279291624, test 1.0100651415331023\n",
      "RMSE, train 0.15007559755464006, test 1.0006364429635661\n",
      "RMSE, train 0.14594257353502682, test 1.0003354070442063\n",
      "RMSE, train 0.14247256223607427, test 1.0074840965015548\n",
      "RMSE, train 0.13950735152027446, test 1.0039472351116794\n",
      "RMSE, train 0.13612378537979522, test 1.004163993788617\n",
      "RMSE, train 0.13260887339224223, test 1.0087704669151987\n",
      "RMSE, train 0.12718407358479136, test 1.0058263960693563\n",
      "RMSE, train 0.12346580058076542, test 1.0061293435948235\n",
      "RMSE, train 0.11882657429491512, test 1.0128583466368062\n",
      "RMSE, train 0.11495076223785841, test 1.0142856000789575\n",
      "RMSE, train 0.1095404823621114, test 0.9996434130838939\n",
      "RMSE, train 0.1055505338707261, test 1.0154934844800405\n",
      "RMSE, train 0.09921038061510244, test 1.013823931238481\n",
      "RMSE, train 0.09696368178381119, test 1.0085941585046905\n",
      "RMSE, train 0.09223737297397033, test 1.0063216090202332\n",
      "RMSE, train 0.08720345584947559, test 1.016761771270207\n",
      "RMSE, train 0.08310881895794328, test 1.0053535609373025\n",
      "RMSE, train 0.07943863804758504, test 1.0176754295825958\n",
      "RMSE, train 0.07566598199778653, test 1.0087428486772947\n",
      "RMSE, train 0.07176852523306616, test 1.0071795220885957\n",
      "RMSE, train 0.0681259204229758, test 1.0036881874714578\n",
      "Early stopping at epoch 36 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 5, 'layer_amt': 3}\n",
      "RMSE, train 0.8288226708369033, test 1.1015174611650331\n",
      "RMSE, train 0.49746228998622566, test 1.0873639740125098\n",
      "RMSE, train 0.4078964640211068, test 1.0438884869970457\n",
      "RMSE, train 0.3527890052874106, test 1.0268899623793786\n",
      "RMSE, train 0.31195323056288626, test 0.9897762019224842\n",
      "RMSE, train 0.2816854885490133, test 0.9835968360756383\n",
      "RMSE, train 0.25929465441802896, test 0.9865562434148307\n",
      "RMSE, train 0.24179075151900498, test 0.9814962172749067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.2290238769756844, test 0.9939312784358708\n",
      "RMSE, train 0.21864282778830865, test 0.981284053638728\n",
      "RMSE, train 0.210854121408719, test 0.9923535085687734\n",
      "RMSE, train 0.2024411920886168, test 1.0002706177306897\n",
      "RMSE, train 0.19443694125032074, test 0.9841191985390403\n",
      "RMSE, train 0.18801639081504934, test 0.9958422870346995\n",
      "RMSE, train 0.1803840291492805, test 0.9833045577762103\n",
      "RMSE, train 0.1755794376717803, test 0.9817288162732365\n",
      "RMSE, train 0.16962865494136997, test 0.9785077698302992\n",
      "RMSE, train 0.16370327592187522, test 0.9953223448811155\n",
      "RMSE, train 0.15942340346012254, test 0.9860908666042366\n",
      "RMSE, train 0.15415022055866665, test 1.0027337598078179\n",
      "RMSE, train 0.14834609804424506, test 0.995368748602241\n",
      "RMSE, train 0.14286615717746226, test 0.9974339020372641\n",
      "RMSE, train 0.13782396963581187, test 0.9899219437078997\n",
      "RMSE, train 0.13215743005275726, test 1.001420010821988\n",
      "RMSE, train 0.12615234991376148, test 0.99490955261269\n",
      "RMSE, train 0.12098650189804273, test 0.9889983691350378\n",
      "RMSE, train 0.11582027339264933, test 0.9935661921597491\n",
      "Early stopping at epoch 27 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.854235343265632, test 1.0674897351507413\n",
      "RMSE, train 0.5039482728755178, test 1.0386506854477575\n",
      "RMSE, train 0.3809643855764846, test 0.9947297133631625\n",
      "RMSE, train 0.32270865948978533, test 0.972082662885472\n",
      "RMSE, train 0.2881948393731078, test 0.9674314391815056\n",
      "RMSE, train 0.26674391797258834, test 0.9473804619352696\n",
      "RMSE, train 0.2522063118921331, test 0.9453926025810888\n",
      "RMSE, train 0.24284412560999885, test 0.9482446818028466\n",
      "RMSE, train 0.23508000007468807, test 0.9394859934257249\n",
      "RMSE, train 0.22892131727219614, test 0.9342462774050437\n",
      "RMSE, train 0.22276394423251308, test 0.9323930598921695\n",
      "RMSE, train 0.21790810883784098, test 0.9302753093889204\n",
      "RMSE, train 0.21450403705239296, test 0.9324662776316627\n",
      "RMSE, train 0.20952302987171598, test 0.9314476963827165\n",
      "RMSE, train 0.2048657169211502, test 0.9282625115523904\n",
      "RMSE, train 0.1998819679883886, test 0.9284302844839581\n",
      "RMSE, train 0.19524015735619324, test 0.924132955781484\n",
      "RMSE, train 0.1916426067386777, test 0.931181559623298\n",
      "RMSE, train 0.18728746806294466, test 0.9329624271998971\n",
      "RMSE, train 0.18423559667527184, test 0.9275741279125214\n",
      "RMSE, train 0.180869762316223, test 0.9368756489228394\n",
      "RMSE, train 0.17823361965619827, test 0.9295577472549373\n",
      "RMSE, train 0.17467391940434118, test 0.9357563378447193\n",
      "RMSE, train 0.17271738019117638, test 0.9349425531039803\n",
      "RMSE, train 0.17021240438681004, test 0.9379828491453397\n",
      "RMSE, train 0.167210220797988, test 0.9352947099734161\n",
      "RMSE, train 0.16505724925948076, test 0.935422471519244\n",
      "Early stopping at epoch 27 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.8123963148730575, test 1.0370780639026476\n",
      "RMSE, train 0.49405805130673064, test 1.0387326722559722\n",
      "RMSE, train 0.3995675816657437, test 1.0032717471537382\n",
      "RMSE, train 0.3421154617314126, test 0.9893282024756722\n",
      "RMSE, train 0.3040166192879849, test 0.9629169018372246\n",
      "RMSE, train 0.2763919602850187, test 0.9599239727725153\n",
      "RMSE, train 0.258437590614246, test 0.9667693018913269\n",
      "RMSE, train 0.2451196883008232, test 0.9577851544255795\n",
      "RMSE, train 0.23665165939148824, test 0.9564665229424186\n",
      "RMSE, train 0.22844897764250477, test 0.9451560476551886\n",
      "RMSE, train 0.22247917671745243, test 0.9383725819380387\n",
      "RMSE, train 0.21706852440241794, test 0.9517584323883057\n",
      "RMSE, train 0.2120033648110246, test 0.9509054505306741\n",
      "RMSE, train 0.20554472483900196, test 0.9470979939336363\n",
      "RMSE, train 0.20059059044611174, test 0.94310266505117\n",
      "RMSE, train 0.19493079777103067, test 0.945791172462961\n",
      "RMSE, train 0.18964001011190393, test 0.954120931936347\n",
      "RMSE, train 0.18462933726498024, test 0.9469041098719058\n",
      "RMSE, train 0.17919879360816535, test 0.9374324897061224\n",
      "RMSE, train 0.17438162948675218, test 0.9437651328418566\n",
      "RMSE, train 0.1695878335814567, test 0.9461804120436959\n",
      "RMSE, train 0.1648550843167457, test 0.9436792954154637\n",
      "RMSE, train 0.1621704423788247, test 0.9367275631946066\n",
      "RMSE, train 0.15894746631700268, test 0.9349614542463551\n",
      "RMSE, train 0.1566610221143994, test 0.933880977526955\n",
      "RMSE, train 0.1544108350312381, test 0.9296576432559801\n",
      "RMSE, train 0.15231452981947333, test 0.9355133963667828\n",
      "RMSE, train 0.1506554574691819, test 0.935556860073753\n",
      "RMSE, train 0.14922975766177896, test 0.933135940199313\n",
      "RMSE, train 0.14769654499560658, test 0.9316422376943672\n",
      "RMSE, train 0.14642728986950185, test 0.9297317385673523\n",
      "RMSE, train 0.14517833159607688, test 0.9336777412373086\n",
      "RMSE, train 0.1436327723212809, test 0.9302041914152063\n",
      "RMSE, train 0.14247986539850316, test 0.9259869523670362\n",
      "RMSE, train 0.14127050009566, test 0.9271664774936178\n",
      "RMSE, train 0.13999431097836504, test 0.9323632543501646\n",
      "RMSE, train 0.13902924943818154, test 0.9283529271250186\n",
      "RMSE, train 0.13733057500577023, test 0.9291208225747813\n",
      "RMSE, train 0.13643481205919492, test 0.9304156401883001\n",
      "RMSE, train 0.13495154750005456, test 0.9310462847999904\n",
      "RMSE, train 0.1336187745608595, test 0.9314894147541212\n",
      "RMSE, train 0.13195410671380928, test 0.9314775694971499\n",
      "RMSE, train 0.13111425822327852, test 0.9287856397421463\n",
      "RMSE, train 0.12928278185822656, test 0.936098199305327\n",
      "Early stopping at epoch 44 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 0.9764974242903192, test 0.9322341352427771\n",
      "RMSE, train 0.7624190968248342, test 0.9577604740037831\n",
      "RMSE, train 0.5311337409399015, test 0.9677717034969855\n",
      "RMSE, train 0.38857604269222296, test 0.9467443512120378\n",
      "RMSE, train 0.31913052890199184, test 0.9289082458259863\n",
      "RMSE, train 0.2812456664683573, test 0.930907035092695\n",
      "RMSE, train 0.2561342377432793, test 0.9271981880205487\n",
      "RMSE, train 0.23999064258663108, test 0.9240783354557982\n",
      "RMSE, train 0.22788880174069126, test 0.9217399249383069\n",
      "RMSE, train 0.2211348207943108, test 0.9235760110233902\n",
      "RMSE, train 0.21444328299685977, test 0.9242754518438917\n",
      "RMSE, train 0.21028422627748394, test 0.914603418713316\n",
      "RMSE, train 0.2060186835548803, test 0.9204680963393745\n",
      "RMSE, train 0.2031110123869015, test 0.9193246632540991\n",
      "RMSE, train 0.199844319857824, test 0.924687028478045\n",
      "RMSE, train 0.19708046357193335, test 0.9184732163717987\n",
      "RMSE, train 0.19480070070835506, test 0.918140847201741\n",
      "RMSE, train 0.19200445738341243, test 0.9212431803755804\n",
      "RMSE, train 0.1906019344658595, test 0.917135999837053\n",
      "RMSE, train 0.18771402925386557, test 0.9220321637774826\n",
      "RMSE, train 0.18582627508004151, test 0.9196718012521027\n",
      "RMSE, train 0.18402970091109852, test 0.9197656370084221\n",
      "Early stopping at epoch 22 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 10, 'layer_amt': 3}\n",
      "RMSE, train 1.0136897928184934, test 1.0189729078362386\n",
      "RMSE, train 0.7094419171111752, test 1.034205973148346\n",
      "RMSE, train 0.514896690168164, test 1.0248057320713997\n",
      "RMSE, train 0.41134227797238515, test 1.0041489855696757\n",
      "RMSE, train 0.34515629008863913, test 0.9810243118554354\n",
      "RMSE, train 0.3001785890923606, test 0.9658943396061659\n",
      "RMSE, train 0.27303865491741836, test 0.9446238335222006\n",
      "RMSE, train 0.2535414340896438, test 0.9459815615167221\n",
      "RMSE, train 0.24310500419350586, test 0.9314472079277039\n",
      "RMSE, train 0.23298926794468755, test 0.9288573345790306\n",
      "RMSE, train 0.22629864009642842, test 0.9211338522533575\n",
      "RMSE, train 0.22032734443141958, test 0.9250067646304766\n",
      "RMSE, train 0.21572952574551707, test 0.914717131604751\n",
      "RMSE, train 0.2104590240903575, test 0.9191853068768978\n",
      "RMSE, train 0.2067899549699793, test 0.9197560989608368\n",
      "RMSE, train 0.20255114777822686, test 0.9260452880213658\n",
      "RMSE, train 0.19829527548316753, test 0.9157804728796085\n",
      "RMSE, train 0.19435711205005646, test 0.9180238855381807\n",
      "RMSE, train 0.1908045184958463, test 0.9282075259834528\n",
      "RMSE, train 0.18745346604423088, test 0.9275792526702086\n",
      "RMSE, train 0.1827937707380213, test 0.9253092141201099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.18021400863624581, test 0.9278685934841633\n",
      "RMSE, train 0.17625262321095275, test 0.9239024333655834\n",
      "Early stopping at epoch 23 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.8754931487678702, test 1.0617494327681405\n",
      "RMSE, train 0.5536849198777691, test 1.0804424046405725\n",
      "RMSE, train 0.4363831969907341, test 1.0146307817527227\n",
      "RMSE, train 0.3643687130449125, test 0.9952056466468743\n",
      "RMSE, train 0.3088742000799553, test 0.9451119309025151\n",
      "RMSE, train 0.2775395369088208, test 0.9219917037657329\n",
      "RMSE, train 0.25763496896150584, test 0.9087635294667312\n",
      "RMSE, train 0.24645872141411101, test 0.9012324426855359\n",
      "RMSE, train 0.23812566067788077, test 0.9003530772668975\n",
      "RMSE, train 0.23178994233571887, test 0.8964212720415422\n",
      "RMSE, train 0.22746934912173578, test 0.8985331532146249\n",
      "RMSE, train 0.22423010908700283, test 0.8978472442499229\n",
      "RMSE, train 0.22076731056689178, test 0.9024376145430973\n",
      "RMSE, train 0.21760212933575665, test 0.9023852912443024\n",
      "RMSE, train 0.2155487890596743, test 0.8889914319983551\n",
      "RMSE, train 0.21306201955202098, test 0.898266328232629\n",
      "RMSE, train 0.21079210777947585, test 0.895647683846099\n",
      "RMSE, train 0.20883623758951822, test 0.8895413971373013\n",
      "RMSE, train 0.20709245416593447, test 0.8865338143493448\n",
      "RMSE, train 0.20504014236215412, test 0.8862329955611911\n",
      "RMSE, train 0.2037444567563487, test 0.885454281100205\n",
      "RMSE, train 0.20208517492856334, test 0.8915745594671795\n",
      "RMSE, train 0.20062632388019355, test 0.8765456096402237\n",
      "RMSE, train 0.19932529388689527, test 0.8817584381571838\n",
      "RMSE, train 0.1982794505318785, test 0.8726794437638351\n",
      "RMSE, train 0.1967779645018588, test 0.8791360988148621\n",
      "RMSE, train 0.19549020592423566, test 0.8726823340569224\n",
      "RMSE, train 0.1938866244746709, test 0.8733360868479524\n",
      "RMSE, train 0.19244793628815213, test 0.8735454045236111\n",
      "RMSE, train 0.1913220538942383, test 0.8621044020567622\n",
      "RMSE, train 0.19045864207941982, test 0.872535956225225\n",
      "RMSE, train 0.18876570959885916, test 0.8708847377981458\n",
      "RMSE, train 0.1878383382992547, test 0.8678651191294193\n",
      "RMSE, train 0.1865957606916594, test 0.8703699862318379\n",
      "RMSE, train 0.18619479878535716, test 0.8679120146802494\n",
      "RMSE, train 0.1850446344136153, test 0.8665693545980113\n",
      "RMSE, train 0.1845136836398401, test 0.8694499236132417\n",
      "RMSE, train 0.18361870217297332, test 0.8689617131437574\n",
      "RMSE, train 0.1826191105614041, test 0.8643744470817702\n",
      "RMSE, train 0.18223483980611, test 0.8704060816339084\n",
      "Early stopping at epoch 40 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9738247934478281, test 1.0054687797476392\n",
      "RMSE, train 0.5666112392606222, test 1.0169422484319144\n",
      "RMSE, train 0.4479141838080145, test 0.9572034839096419\n",
      "RMSE, train 0.3726165821533567, test 0.9155909249541956\n",
      "RMSE, train 0.3214039813910899, test 0.8900132849128968\n",
      "RMSE, train 0.2891855098206901, test 0.8823225416174723\n",
      "RMSE, train 0.2695145043690643, test 0.8686794819088157\n",
      "RMSE, train 0.25425625552377357, test 0.8614898613833506\n",
      "RMSE, train 0.24583042015409257, test 0.8705402716584162\n",
      "RMSE, train 0.2386146411967919, test 0.8579637337168422\n",
      "RMSE, train 0.23260756090884785, test 0.8590516962042642\n",
      "RMSE, train 0.22865793920819535, test 0.8621936954489542\n",
      "RMSE, train 0.22451493491506364, test 0.8587408388426544\n",
      "RMSE, train 0.22168375498243512, test 0.8530226420918736\n",
      "RMSE, train 0.2186632975935936, test 0.849644790548797\n",
      "RMSE, train 0.21656903136738748, test 0.8510860300392186\n",
      "RMSE, train 0.21418541325715626, test 0.8536761031238311\n",
      "RMSE, train 0.2120471518870961, test 0.8508000833178879\n",
      "RMSE, train 0.20990786521023164, test 0.8510509204427037\n",
      "RMSE, train 0.2078785901312871, test 0.8570185681001856\n",
      "RMSE, train 0.2060264891239025, test 0.8570220169671084\n",
      "RMSE, train 0.2040180904715585, test 0.8546928664959899\n",
      "RMSE, train 0.20233781051074443, test 0.861922818586367\n",
      "RMSE, train 0.2005304377442518, test 0.8565617400571841\n",
      "RMSE, train 0.19891007635491845, test 0.8538132309913635\n",
      "Early stopping at epoch 25 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.873780967220841, test 1.0180658350870446\n",
      "RMSE, train 0.5821490321759657, test 1.0049285929179885\n",
      "RMSE, train 0.44530382801971075, test 0.9675627547560386\n",
      "RMSE, train 0.3704487585823213, test 0.9204216205958023\n",
      "RMSE, train 0.3176560658881896, test 0.8946797245914496\n",
      "RMSE, train 0.2852422803852734, test 0.8695205797269506\n",
      "RMSE, train 0.264557401386406, test 0.8692903038367484\n",
      "RMSE, train 0.25224579559227633, test 0.867369640799402\n",
      "RMSE, train 0.2436981961095701, test 0.8632849859959871\n",
      "RMSE, train 0.2379646714679419, test 0.851770376985513\n",
      "RMSE, train 0.23270049747831748, test 0.8538070488901972\n",
      "RMSE, train 0.2287840892045345, test 0.8606938146850438\n",
      "RMSE, train 0.22523924566787665, test 0.8463601857713126\n",
      "RMSE, train 0.22228188738403865, test 0.8483437733742797\n",
      "RMSE, train 0.21947978543130917, test 0.8506180482003295\n",
      "RMSE, train 0.21770871750957327, test 0.8530287279666049\n",
      "RMSE, train 0.21507595553817205, test 0.8427959342026016\n",
      "RMSE, train 0.21334573821189, test 0.8480375189225651\n",
      "RMSE, train 0.2114865788017486, test 0.8555625978025417\n",
      "RMSE, train 0.20906140034102488, test 0.8447585777171607\n",
      "RMSE, train 0.20720158255440038, test 0.8441052193780547\n",
      "RMSE, train 0.205890862222522, test 0.8591293466901316\n",
      "RMSE, train 0.20352905018878945, test 0.8413574354162494\n",
      "RMSE, train 0.20155762511166145, test 0.8388915386014771\n",
      "RMSE, train 0.1994400640989426, test 0.8463257973633923\n",
      "RMSE, train 0.19728229833753544, test 0.8443925293903907\n",
      "RMSE, train 0.19561317354228322, test 0.8486702184653977\n",
      "RMSE, train 0.19383960682677542, test 0.8424536250169995\n",
      "RMSE, train 0.19220131621508021, test 0.8545898708324988\n",
      "RMSE, train 0.19076100752784067, test 0.8573877018632241\n",
      "RMSE, train 0.18909940753583387, test 0.8448852225414758\n",
      "RMSE, train 0.18781057279778207, test 0.8474654838876817\n",
      "RMSE, train 0.18670485074899543, test 0.8469209184924376\n",
      "RMSE, train 0.18540161759581533, test 0.8496042380055178\n",
      "Early stopping at epoch 34 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 20, 'layer_amt': 3}\n",
      "RMSE, train 0.9273254498638555, test 0.9323266439967686\n",
      "RMSE, train 0.6696552821407421, test 0.9170587354236179\n",
      "RMSE, train 0.49458972639793336, test 0.9050533215204875\n",
      "RMSE, train 0.394398801570954, test 0.8917926748593649\n",
      "RMSE, train 0.3372168161798359, test 0.895381959941652\n",
      "RMSE, train 0.3010751191737517, test 0.8981831146611108\n",
      "RMSE, train 0.27718231941490484, test 0.8809283441967435\n",
      "RMSE, train 0.261864395797092, test 0.8563119828701019\n",
      "RMSE, train 0.2511972722338859, test 0.8668739802307552\n",
      "RMSE, train 0.2421338025209396, test 0.8722420076529185\n",
      "RMSE, train 0.23745967230867504, test 0.8548647979895274\n",
      "RMSE, train 0.2310288613938257, test 0.8555913269519806\n",
      "RMSE, train 0.22833068363589418, test 0.858955932325787\n",
      "RMSE, train 0.22512396828665565, test 0.8492022891839345\n",
      "RMSE, train 0.2223113156312881, test 0.8530519372887082\n",
      "RMSE, train 0.2199650118052156, test 0.8563092483414544\n",
      "RMSE, train 0.21814275522919677, test 0.8606855875915951\n",
      "RMSE, train 0.21629767075703152, test 0.8712036795086331\n",
      "RMSE, train 0.21442535210330532, test 0.8648924516306983\n",
      "RMSE, train 0.2130072353824451, test 0.8552182800239987\n",
      "RMSE, train 0.21128993081757322, test 0.8633153756459554\n",
      "RMSE, train 0.2098864048237428, test 0.861891719367769\n",
      "RMSE, train 0.20792145693719868, test 0.8571974178155263\n",
      "RMSE, train 0.2069538447734802, test 0.862414104408688\n",
      "Early stopping at epoch 24 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 5, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.8748830237715052, test 0.9471759826245935\n",
      "RMSE, train 0.5680610800576384, test 0.9016949191237941\n",
      "RMSE, train 0.43816667999206954, test 0.8505553880123177\n",
      "RMSE, train 0.36293301226748814, test 0.8149238614120868\n",
      "RMSE, train 0.3146612633994273, test 0.8010083906578295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE, train 0.28503999416431763, test 0.7892598034155489\n",
      "RMSE, train 0.266408652650115, test 0.7903187720462529\n",
      "RMSE, train 0.2559458500452904, test 0.7899261616697215\n",
      "RMSE, train 0.24833308346114125, test 0.7883093230652086\n",
      "RMSE, train 0.24273689539333426, test 0.786221141164953\n",
      "RMSE, train 0.23821342588928335, test 0.7788246382366527\n",
      "RMSE, train 0.23544830510114984, test 0.7766461185734681\n",
      "RMSE, train 0.23270564211172695, test 0.7805062129039957\n",
      "RMSE, train 0.23009432557159648, test 0.7758789158830739\n",
      "RMSE, train 0.22767215493547305, test 0.7750960272369962\n",
      "RMSE, train 0.2260126349104063, test 0.7684644117499843\n",
      "RMSE, train 0.22401234970261824, test 0.7731742937155445\n",
      "RMSE, train 0.22220288858291282, test 0.7715880076090494\n",
      "RMSE, train 0.22057737668743926, test 0.7623851931456364\n",
      "RMSE, train 0.21876181716732407, test 0.7675315334339334\n",
      "RMSE, train 0.2173797916666511, test 0.7696102761258983\n",
      "RMSE, train 0.2155696421060119, test 0.7685879818116775\n",
      "RMSE, train 0.2146560780722238, test 0.7706641247778228\n",
      "RMSE, train 0.21342430586191144, test 0.7714639092334593\n",
      "RMSE, train 0.21224040295792093, test 0.7704566988078031\n",
      "RMSE, train 0.21119092488638638, test 0.7688708347503586\n",
      "RMSE, train 0.21002661606210368, test 0.7691882806594925\n",
      "RMSE, train 0.20910012780308432, test 0.7720397969689032\n",
      "RMSE, train 0.2086090731154444, test 0.7693338315896313\n",
      "Early stopping at epoch 29 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 10, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.8471086643862001, test 0.9630687770744165\n",
      "RMSE, train 0.6245446627338728, test 0.9027698673307896\n",
      "RMSE, train 0.4976384440305257, test 0.8821072336286306\n",
      "RMSE, train 0.4076977883926546, test 0.866102920845151\n",
      "RMSE, train 0.34625327203309897, test 0.828449917336305\n",
      "RMSE, train 0.3049152838912877, test 0.7994646473477284\n",
      "RMSE, train 0.2777042180450276, test 0.7934871496011814\n",
      "RMSE, train 0.26028701350694955, test 0.7785113584250212\n",
      "RMSE, train 0.24919395856182985, test 0.7727872182925543\n",
      "RMSE, train 0.24139350987594538, test 0.768577316775918\n",
      "RMSE, train 0.23644993740199793, test 0.7653255052864552\n",
      "RMSE, train 0.23286950734980177, test 0.7663278517623743\n",
      "RMSE, train 0.22982450307469177, test 0.7636620625853539\n",
      "RMSE, train 0.22726680372248997, test 0.7603103471919894\n",
      "RMSE, train 0.22563435829649067, test 0.7621203095962604\n",
      "RMSE, train 0.22393826421613644, test 0.7599565759301186\n",
      "RMSE, train 0.22258264763337193, test 0.7640207583705584\n",
      "RMSE, train 0.22152930027758233, test 0.761287190951407\n",
      "RMSE, train 0.22003943032839082, test 0.7630998380482197\n",
      "RMSE, train 0.21853687125022966, test 0.766555207160612\n",
      "RMSE, train 0.21809529878123843, test 0.7650308993955454\n",
      "RMSE, train 0.21682825229234165, test 0.7680770885199308\n",
      "RMSE, train 0.21584604477340524, test 0.7747140585755309\n",
      "RMSE, train 0.21452665705271443, test 0.767643059293429\n",
      "RMSE, train 0.21346753421756956, test 0.773197490721941\n",
      "RMSE, train 0.2125459515085124, test 0.7746901027858257\n",
      "Early stopping at epoch 26 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 20, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.8450344069948736, test 0.8416745060020023\n",
      "RMSE, train 0.6290655524904194, test 0.8377289639578925\n",
      "RMSE, train 0.47624426718670726, test 0.8238206406434377\n",
      "RMSE, train 0.3845539268939643, test 0.8058651957246993\n",
      "RMSE, train 0.3292571080502153, test 0.786994825469123\n",
      "RMSE, train 0.2961291185607807, test 0.7762891279326545\n",
      "RMSE, train 0.27728906884347654, test 0.777859651380115\n",
      "RMSE, train 0.2644725129450107, test 0.7739521721998851\n",
      "RMSE, train 0.25583888493940193, test 0.773630991909239\n",
      "RMSE, train 0.2505894483662037, test 0.7790323853492737\n",
      "RMSE, train 0.24507828647235655, test 0.7670593314700657\n",
      "RMSE, train 0.24079116419801172, test 0.7705609778563182\n",
      "RMSE, train 0.2381590763031633, test 0.7750525799062516\n",
      "RMSE, train 0.23592280903755816, test 0.7677868194050259\n",
      "RMSE, train 0.23305751029853872, test 0.7578588830100166\n",
      "RMSE, train 0.23125495691344422, test 0.7609667903847165\n",
      "RMSE, train 0.2293274885399965, test 0.7635020110342238\n",
      "RMSE, train 0.22796758049421234, test 0.7680940495596992\n",
      "RMSE, train 0.22614238328850172, test 0.7684089163939158\n",
      "RMSE, train 0.22501935494556582, test 0.7614550451437633\n",
      "RMSE, train 0.22395169558229472, test 0.7589875850412581\n",
      "RMSE, train 0.2229075112111485, test 0.7612158748838637\n",
      "RMSE, train 0.2221554167106788, test 0.7610711336135865\n",
      "RMSE, train 0.2205664189356678, test 0.755215330587493\n",
      "RMSE, train 0.2200546317666046, test 0.7570673750506507\n",
      "RMSE, train 0.21896216518313416, test 0.752846380074819\n",
      "RMSE, train 0.21828451053794182, test 0.7572633028030396\n",
      "RMSE, train 0.21707993456616878, test 0.757027413447698\n",
      "RMSE, train 0.2161256802290919, test 0.7549606654379103\n",
      "RMSE, train 0.21561259123674942, test 0.7566948433717092\n",
      "RMSE, train 0.2146216853047317, test 0.7532908194594913\n",
      "RMSE, train 0.2138220903606749, test 0.7543526457415687\n",
      "RMSE, train 0.21302831634838948, test 0.753741470972697\n",
      "RMSE, train 0.2125746637904098, test 0.7577980968687269\n",
      "RMSE, train 0.2114256725237376, test 0.7532983740170797\n",
      "RMSE, train 0.2108806996653986, test 0.7541058235698276\n",
      "Early stopping at epoch 36 (no improvement for 10 epochs).\n",
      "Finished Training\n",
      "{'input_size': 40, 'lr': 0.0001, 'batch_size': 32, 'hidden_size': 8, 'output_size': 40, 'layer_amt': 3}\n",
      "RMSE, train 0.8874280656980948, test 0.9014602685586001\n",
      "RMSE, train 0.6935890079287353, test 0.8618497382371854\n",
      "RMSE, train 0.5606391719568555, test 0.8364339570204417\n",
      "RMSE, train 0.4597002623422866, test 0.8181113233933082\n",
      "RMSE, train 0.3870200950222966, test 0.8028082224803094\n",
      "RMSE, train 0.33738668518274373, test 0.7834130708987896\n",
      "RMSE, train 0.302120140547693, test 0.7597911915717981\n",
      "RMSE, train 0.27828603035935734, test 0.7729225105200058\n",
      "RMSE, train 0.2614923871101991, test 0.7587565726194626\n",
      "RMSE, train 0.25085804404870743, test 0.7563683016177936\n",
      "RMSE, train 0.24328423098797367, test 0.7557133054121946\n",
      "RMSE, train 0.23784056886148602, test 0.7641447492134876\n",
      "RMSE, train 0.23474154437999487, test 0.7601802219183017\n",
      "RMSE, train 0.23113965496095912, test 0.7586034268904955\n",
      "RMSE, train 0.2286185041487774, test 0.7636126505258756\n",
      "RMSE, train 0.22687346239884695, test 0.769961247077355\n",
      "RMSE, train 0.2249316211987136, test 0.7660946815441816\n",
      "RMSE, train 0.22360691734563523, test 0.7693363825480143\n",
      "RMSE, train 0.22172151863389297, test 0.7675985479966189\n",
      "RMSE, train 0.22041894077697646, test 0.767573193861888\n",
      "RMSE, train 0.2196309101822963, test 0.7643824364894476\n",
      "Early stopping at epoch 21 (no improvement for 10 epochs).\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_transformer(config, 1000,data_dir = 'data_synthetic')\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/transformer/'+'output_size' + str(output) + 'input_size' + str(inputs) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2575f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in output_sizes:\n",
    "\n",
    "    config['output_size'] = output\n",
    "\n",
    "    for inputs in input_sizes:\n",
    "\n",
    "        config['input_size'] = inputs    \n",
    "\n",
    "        print(config)\n",
    "\n",
    "        mod = train_transformer(config, 1000,data_dir = 'data_synthetic', only_one = True)\n",
    "\n",
    "        torch.save(obj = mod.state_dict(), f = 'models/transformer/'+'output_size' + str(output) + 'input_size' + str(inputs) + '_singlevar.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0306f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "    \n",
    "    \n",
    "class TransAm(nn.Module):\n",
    "    def __init__(self, feature_size=250, num_layers=3, dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(feature_size,1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self,src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d483e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
